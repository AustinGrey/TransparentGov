{
    "Committee": "GFC",
    "Date": "2017-10-30",
    "Title": "GFC General Faculties Council - 2017-10-30",
    "Location": "Council Chamber, 2-100 University Hall (UNH)",
    "Time": "2:00 PM - 4:00 PM",
    "Attendees": [
        "David Turpin, Chair",
        "Chris Andersen",
        "Allen Berger",
        "Lisa Collins",
        "Lesley Cormack",
        "Greta Cummings",
        "Kathleen DeLong",
        "Wendy Rodgers",
        "(Delegate)",
        "Walter Dixon",
        "Joseph Doucet",
        "Heather McCaw",
        "Philip Stack",
        "(Delegate)",
        "Pierre-Yves Mocquais",
        "Kerry Mummery",
        "Jonathan Schaeffer",
        "Andrew Sharman",
        "Jacqui Tam",
        "Jennifer Tupper",
        "Kue Young",
        "Heather Zwicker",
        "Jason Acker",
        "Susan Andrew",
        "Jeff Birchall",
        "Cary Brown",
        "Peter Carver",
        "Ryan Dunch",
        "Duncan Elliott",
        "Nadir Erbilgin",
        "Bill Foster",
        "Kim Frail",
        "Eva Lemaire",
        "Pierre Lemelin",
        "Lisa McDermott",
        "Rob McMahon",
        "Lynn McMullen",
        "Al Meldrum",
        "Roger Moore",
        "Carolyn Sale",
        "Georg Schmolzer",
        "Jorge Sousa",
        "Lisa Stein",
        "Eleni Stroulia",
        "John Seubert",
        "Brent Swallow",
        "Amy Tse",
        "Benjamin Tucker",
        "Dilini Vethanayagam",
        "Akiko Watanabe",
        "Ian Winship",
        "Firouz Khodayari",
        "Shane Scott",
        "Ilya Ushakov",
        "Members:",
        "Solomon Amoateng",
        "Alizeh Ansari",
        "Ruben Araya",
        "Marina Banister",
        "Darcy Bemister",
        "Robert Bilak",
        "Katherine Binhammer",
        "Michelle Borowitz",
        "Heather Bruce",
        "Meijun Chen",
        "Darren Choi",
        "André Costopoulos",
        "Jonah Dunch",
        "Shannon Erichsen",
        "Shawn Flynn",
        "Kyle Foster",
        "Connor Palindat",
        "Maryam Kebbe",
        "Maryse Ndilu Kiese",
        "Marina Kirillovich",
        "Gohar Jamal",
        "Amy Li",
        "Monica Lillo",
        "Steven Lin",
        "Wei Liu",
        "Habba Mahal",
        "Kyle Monda",
        "Sean Oliver",
        "Michael Sandare",
        "Babak Soltannia",
        "Andrews Tawiah",
        "James Thibaudeau",
        "Amanda Wakaruk",
        "Brayden Whitlock",
        "Janet Williamson",
        "Ziyu Yang",
        "Brandon Yip",
        "Katherine Aitchison",
        "Daniel Atchison",
        "Daniel Bilyk",
        "Stanford Blade",
        "Abigail Bridarolli",
        "Sylvia Brown",
        "Katy Campbell",
        "Li-Kwong Cheah",
        "Brandon Christensen",
        "David Cooper",
        "Neal Davies",
        "Pamela Mayne",
        "Correia",
        "Benjamin Denga",
        "Genna DiPinto",
        "Fraser Forbes",
        "Tarek El-Bialy",
        "Dean Eurich",
        "Adam Gaudry",
        "Murray Gingras",
        "Robert Haennel",
        "Daanish Hamid",
        "Lesley Harrington",
        "Irehobhude Iyioha",
        "Gaganpreet Jhajj",
        "Mahmoud Kenawi",
        "Dennis Kunimoto",
        "Alex Kwan",
        "Leijun Li",
        "Mark Loewen",
        "Godfrey Man",
        "Vivian Mushahwar",
        "Aleks Nakevski",
        "Katelynn Nguyen",
        "Anthony Nguyen",
        "Alice Nakamura",
        "Smit Patel",
        "Paul Paton",
        "Carla Peck",
        "Leonard Ratzlaff",
        "Marc Secanell",
        "Carrie Smith-Prei",
        "Kim Solez",
        "Sarah Stahlke",
        "Bruce Sutherland",
        "Eddie Wang",
        "Matthew Barnett",
        "Delane Howie",
        "LJ Valencia",
        "Jonathan White",
        "Erin Wright",
        "Bonnie Watt",
        "Meg Brolley, GFC",
        "Secretary",
        "Marion Haggarty-",
        "France, University",
        "Secretary",
        "Andrea Patrick, scribe"
    ],
    "Items": [
        {
            "Item No.": "5",
            "Agenda Title": "Peter Lougheed Leadership College (PLLC) - Next Steps ",
            "Motion": "N/A",
            "Action Requested": "N/A",
            "Date": "2017-10-30",
            "Committee": "GFC",
            "Proposed By": "President, Provost and Vice-President (Academic) ",
            "Presenter": " David Turpin, President ",
            "Description": "Presenter(s): David Turpin, President and Chair, GFC Purpose of the Proposal: To give GFC the opportunity to reflect on the recent review of PLLC commissioned from Dr Peter Mackinnon, and the response to that review prepared by PLLC Vice-Principal Dr Martin Ferguson- Pell, and to engage in discussion about opportunities for the future evolution of PLLC and for leadership initiatives more broadly at the University of Alberta. Discussion: The Chair reported that there were good discussions earlier this month at both the GFC Academic Planning Committee and the GFC Executive Committee on possible next steps for the PLLC. He noted that the current Principal of the PLLC, the Right Honourable Kim Campbell, will be stepping down next year which gives the university an opportunity to inform the future direction and potential of the PLLC before the next Principal is selected. The Chair provided a summary of the Mackinnon Report and PLLC response which were made public earlier this year. The Report included comments surrounding a strong student experience yet identified sustainability issues. Hi indicated that the deans have engaged in preliminary discussions about the direction of the PLLC, and the Chair invited members to provide suggestions and comments. During the ensuing discussion, members noted that the PLLC could provide: university-wide activities and support to existing leadership programs at the university; professional development activities to graduate students; an avenue towards community engagement; and that this is an opportunity to collaborate and reduce duplication across the institution. Members identified several concerns with the existing PLLC including lack of flexibility in the certificate program and a lack of direction to formally incorporate bilingual leadership training. A member suggested broadening admission to all undergraduate students to eliminate current admission restrictions for students in certain Faculties. A member expressed concerns that the PLLC was non-compliant with the Graduate Students’ Association (GSA) Collective Agreement in regards to teaching hours. The Chair stated that a working group would be established to plan next steps and noted that the working group would include students.",
            "Participation": [
                "President, Students’ Union (September 12, 2017) ",
                "President, Graduate Students’ Association (October 10, 2017) ",
                "Deans Council (September 20, 2017) ",
                "Academic Planning Committee (October 11, 2017) ",
                "General Faculties Council (October 30, 2017) ",
                "PLLC Academic Oversight Committee (October 26, 2017) ",
                "Deans of Arts, Science, ALES, Augustana, Business ",
                "Vice-Provost (Programs) ",
                "Deputy Provost ",
                "Acting Associate Vice-President (Human Resource Services) "
            ],
            "Approval Route": [
                "N/A"
            ],
            "Final Approver": "N/A"
        },
        {
            "Item No.": "6",
            "Agenda Title": "GFC Executive Committee update on the ad hoc committee recommendations ",
            "Motion": "N/A",
            "Action Requested": "Information",
            "Date": "2017-10-30",
            "Committee": "GFC",
            "Proposed By": "GFC Executive Committee ",
            "Presenter": "Eleni Stroulia, Chair GFC Executive ad hoc Transition Committee ",
            "Description": "Purpose of the Proposal: To receive the status report on the implementation of recommendations from the Report of the ad hoc Committee on Academic Governance including Delegated Authority. Discussion: Dr Stroulia reported to members on the status of the 48 recommendations contained within the Report of the ad hoc Committee on Academic Governance including Delegated Authority. She reported that eight recommendations are complete, and that these related to the ‘Principles’ documents approved by GFC in April 2017. Six recommendations in relation to early consultation, GFC meeting frequency, Board relations, and orientation, have all been implemented. She noted that 25 recommendations are in progress. A member questioned why graduate students are not represented on all GFC standing committees and enquired about how standing committee composition was determined. It was clarified that the ad hoc Committee had outlined key principles within the Principles for General Faculties Council Membership Composition document approved by GFC in April 2017, and that additionally, all GFC standing committees had been tasked with reviewing membership to ensure that it remains appropriate. The Chair confirmed that amendments to GFC standing committee terms of reference would require final approval by GFC.",
            "Participation": [
                "GFC Executive Committee ",
                "General Faculties Council ",
                "GFC Executive ad hoc transition committee ",
                "GFC Executive Committee ",
                "GFC Executive ad hoc transition committee ",
                "General Faculties Council "
            ],
            "Approval Route": [
                "N/A"
            ],
            "Final Approver": " N/A"
        },
        {
            "Item No.": "7",
            "Agenda Title": "Faculty of Graduate Studies and Research: Proposed revisions to existing Supervision and Examinations policy ",
            "Motion": "THAT General Faculties Council approve the proposed revisions to existing Supervision and Examinations policy, as recommended by the GFC Executive Committee and the GFC Academic Standards Committee, as submitted by the Faculty of Graduate Studies and Research and as set forth in Attachment 1, to take effect July 1, 2018. ",
            "Action Requested": "Approval",
            "Date": "2017-10-30",
            "Committee": "GFC",
            "Proposed By": "Heather Zwicker, Dean, Faculty of Graduate Studies and Research ",
            "Presenter": "Heather Zwicker, Dean, Faculty of Graduate Studies and Research Deborah Burshtyn, Vice-Dean, Faculty of Graduate Studies and Research ",
            "Description": "Purpose of the Proposal: The revisions are intended to clarify the policies, elaborate on procedures, and improve policies. The impact will be to have greater clarity for students, faculty and staff in the administration and conduct and outcomes of examinations in thesis-based programs. Discussion: Dr Burshtyn reported that the proposal contains two changes in relation to who can chair candidacy and doctoral examinations, and conflict resolutions between students and supervisors. She summarized the process used to develop this proposal.",
            "Participation": [
                "Dean and Associate Deans, FGSR ",
                "FGSR Program Services staff ",
                "Graduate Program Administrators Council (GPAC) ",
                "Faculty Graduate Councils (or equivalents) ",
                "FGSR Council ",
                "Graduate Students Association (GSA)—represented on the PRC (below), also conducted wider consultation with graduate students ",
                "FGSR Policy Review Committee (PRC) ",
                "Brent Epperson, Graduate Ombudsperson (as a member of PRC) ",
                "Graduate Students Association (GSA)—(represented on PRC and FGSR Council) ",
                "Vice Dean, FGSR "
            ],
            "Approval Route": [
                "FGSR Council, May 17, 2017, approved",
                "ASC-Subcommittee on Standards - June 1, 2017 (for discussion)",
                "GFC Academic Standards Committee - June 15, 2017",
                "GFC Executive Committee - September 11, 2017",
                "General Faculties Council - September 25, 2017"
            ],
            "Final Approver": " General Faculties Council"
        },
        {
            "Item No.": "8",
            "Agenda Title": "Report of the GFC Committee on Learning Environment on Teaching and Learning and Teaching Evaluation and the Use of the Universal Student Ratings of Instruction (USRI) as an Evaluation Tool ",
            "Motion": "THAT General Faculties Council Receive the CLE Report on Teaching and Learning and Teaching Evaluation and the Use of the Universal Student Ratings of Instruction (USRI) as an Evaluation Tool as set forth in Attachment 2, and Endorse the Recommendations of the Committee as set forth in Attachment 1, and as recommended by the GFC Executive Committee. ",
            "Action Requested": "Endorse, Receive",
            "Date": "2017-10-30",
            "Committee": "GFC",
            "Proposed By": "Sarah Forgie, Chair, Committee  on the Learning Environment ",
            "Presenter": "Sarah Forgie, Chair, Committee  on the Learning Environment and Principal Investigator Norma Nocente, Co-Investigator L Francisco Vargas M, Research Coordinator Rebecca Best-Bertwistle, Research Assistant ",
            "Description": "Purpose of the Proposal: The GFC Committee on the Learning Environment (CLE) was requested by GFC to report on research into the use of student rating mechanisms of instruction in university courses. This report fulfills this request. Discussion: The Chair reported that full discussion on this proposal was deferred at the last meeting due to limited time. He added that GFC Policy Manual Section 111 notes that teaching evaluation will be multifaceted and that multifaceted evaluation will include the use of USRIs. He also noted that USRIs are just one of many tools used to assess teaching performance and that tools such as this continue to be questioned at all universities. Further, the Chair pointed out the complexities inherent in the evaluation of teaching, noting the many legislative pieces surrounding it including the Post-Secondary Learning Act’s delegation to GFC to make recommendations to the Board with respect to promotions and tenure, as well as contents of the AASUA Collective Agreement. Dr Forgie noted that CLE had engaged the Centre for Teaching and Learning (CTL) in preparing the report, and that the team had interviewed chairs, conducted a literature review, and referenced previous reports on the use of USRIs at the university as part of their initiative. Dr Forgie indicated that CLE is looking for direction from GFC, as outlined in the recommendations, to continue investigating ways evaluation can be improved towards the betterment of teaching and learning at the university. In speaking against the motion, a member expressed concern that the issue of bias had not been adequately addressed within the report, and that until the issue was resolved, personnel decisions could not be made using the tool. GFC CLE should instead be directed to report back to GFC on new evaluation mechanisms and that this could be discussed at a late winter/spring meeting of GFC. A member, speaking in favour of the motion, noted that the academy had been reviewing the issue for years with no resolution and that resolution was needed. A member also added support for the motion and stated that the USRI is the only way students can provide feedback, although multifaceted methods should be reviewed as well. A member expressed support for the usage of USRIs in improving teaching. A member noted that informed, scholarly discussions are important on contentious issues and that the report’s recommendations provide the right direction for constructive resolution.",
            "Participation": [
                "Provost and Vice-President (Academic) ",
                "Vice-Provost Council ",
                "Deans’ Council ",
                "Chairs’ Council ",
                "GFC Executive Committee ",
                "General Faculties Council ",
                "GFC Committee on the Learning Environment ",
                "GFC Executive Committee ",
                "GFC Committee on the Learning Environment ",
                "Sarah Forgie, Vice-Provost (Learning Initiatives) and Principal Investigator ",
                "Norma Nocente, Co-Investigator ",
                "L Francisco Vargas M, Research Coordinator ",
                "Rebecca Best-Bertwistle, Research Assistant ",
                "GFC Executive Committee ",
                "General Faculties Council "
            ],
            "Approval Route": [
                "GFC Committee on the Learning Environment – April 2017",
                "GFC Executive Committee – September 11, 2017",
                "General Faculties Council – September 25, 2017, October 30, 2017"
            ],
            "Final Approver": " General Faculties Council"
        },
        {
            "Item No.": "9",
            "Agenda Title": "Proposed Revisions to Standing Committee Terms of Reference GFC Campus Law Review Committee (CLRC) including a name change to GFC Student Conduct Policy Committee (SCPC) ",
            "Motion": "THAT General Faculties Council approve the proposed changes to the GFC Campus Law Review Terms of Reference including a name change to GFC Student Conduct Policy Committee (SCPC) as set forth in Attachment 1, to take effect upon approval. ",
            "Action Requested": "Approval",
            "Date": "2017-10-30",
            "Committee": "GFC",
            "Proposed By": "Steven Penney, Chair, GFC Campus Law Review Committee ",
            "Presenter": "Steven Penney, Chair, GFC Campus Law Review Committee ",
            "Description": "Purpose of the Proposal: To approve the revised terms of reference for the GFC Campus Law Review Committee, including a name change to the GFC Student Conduct Policy Committee. Discussion: Professor Penney provided members with a summary of the proposed amendments to the committee name and terms of reference. He reported that although the ad hoc Committee did not identify any major issues with the committee, several items were being amended to reflect the GFC-approved Principles for Standing Committee Composition, the removal of outdated items from the terms of reference, and the recommendation that the chair possess legal training. Professor Penney indicated that CLRC had engaged in several discussions about changing the committee name to better reflect its mandate and that this name change forms part of the proposed changes. A member sought clarification about membership composition.",
            "Participation": [
                "Campus Law Review Committee ",
                "General Faculties Council ",
                "Board of Governors has been provided with brief highlights of the work of the ad hoc Committee on Academic Governance including Delegated Authority ",
                "Report of the ad hoc Committee on Academic Governance ",
                "Campus Law Review Committee ",
                "General Faculties Council ",
                "GFC Executive Committee ",
                "ad hoc Committee on Academic Governance Including Delegated Authority ",
                "Campus Law Review Committee ",
                "General Faculties Council ",
                "GFC Executive Committee "
            ],
            "Approval Route": [
                "GFC Campus Law Review Committee - September 28, 2017",
                "GFC Executive Committee - October 16, 2017",
                "General Faculties Council - October 30, 2017"
            ],
            "Final Approver": " General Faculties Council"
        },
        {
            "Item No.": "10",
            "Agenda Title": "Proposed Revisions to Standing Committee Terms of Reference - GFC Facilities Development Committee (FDC) ",
            "Motion": "THAT General Faculties Council approve the proposed changes to the GFC Facilities Development Committee Terms of Reference as set forth in Attachment 1, to take effect upon approval. ",
            "Action Requested": "Approval",
            "Date": "2017-10-30",
            "Committee": "GFC",
            "Proposed By": "Wendy Rodgers, Chair ",
            "Presenter": " Wendy Rodgers, Chair ",
            "Description": "Purpose of the Proposal: To approve the revised terms of reference for the GFC Facilities Development Committee (FDC). Discussion: Dr Rodgers reported that the proposed changes to the committee terms of reference were intended to bring FDC into alignment with the GFC Principles for Standing Committee Composition and that as the ad hoc Committee had not identified any other major issues within FDC’s terms of reference, mandate or delegated authority from GFC, the other changes were minor. These changes included reference to the Long Range Development Plan (LRDP) and in the inclusion of an extended ‘Definitions’ section to the terms of reference. During the discussion, members enquired about the lack of certain membership categories within the composition, including an elected graduate student member and members from Campus Saint-Jean and Augustana Faculty.",
            "Participation": [
                "Facilities Development Committee ",
                "General Faculties Council ",
                "Board of Governors has been provided with brief highlights of the work of the ad hoc Committee on Academic Governance including Delegated Authority ",
                "Report of the ad hoc Committee on Academic Governance ",
                "Facilities Development Committee ",
                "General Faculties Council ",
                "GFC Executive Committee ",
                "ad hoc Committee on Academic Governance Including Delegated Authority ",
                "Facilities Development Committee ",
                "General Faculties Council ",
                "GFC Executive Committee "
            ],
            "Approval Route": [
                "GFC Facilities Development Committee (September 28, 2017)",
                "GFC Executive Committee (October 16, 2017)",
                "General Faculties Council (October 30, 2017)"
            ],
            "Final Approver": " General Faculties Council"
        },
        {
            "Item No.": "11",
            "Agenda Title": "Proposed Changes to the Admission of Aboriginal Students Calendar Section and updates to Faculty Sections",
            "Motion": "THAT General Faculties Council approve the proposed changes to the calendar sections related to the admission of First Nations, Métis and Inuit students as set forth in Attachments 1 and 2, and as recommended by the GFC Academic Planning Committee and the GFC Academic Standards Committee, to take effect in 2018/19.",
            "Action Requested": "Approval",
            "Date": "2017-10-30",
            "Committee": "GFC",
            "Proposed By": "Lisa Collins, Vice-Provost and University Registrar",
            "Presenter": "Lisa Collins, Vice-Provost and University Registrar Chris Andersen, Dean, Faculty of Native Studies",
            "Description": "Purpose of the Proposal: In order to achieve consistency across Faculties, relevant Calendar sections are being updated to indicate that proof of Aboriginal identity will be required. Discussion: Ms Collins provided a summary of the proposed changes which include a requirement to prove Aboriginal identity in cases where places are reserved for Aboriginal students, eligibility requirements for Métis identity, the removal of the statutory declaration as proof of identity, and an updated appeals mechanism. She reported that there was extensive consultation surrounding the proposed changes. Dean Andersen commented on the shift from Aboriginal ancestry to Aboriginal identity and the importance of a connection to the community.",
            "Participation": [
                "October 27, 2014 - FNMI Definitions Working Group (Subcommittee of the Council on Aboriginal Initiatives) – Collaboration on changes",
                "November 17, 2014 - Vice-Provosts’ Council - Advice",
                "December 1, 2014 – Vice Provosts’ Council - Advice",
                "December 11, 2014 -Council on Aboriginal Initiatives – Reporting/Consultation",
                "February 2, 2015 – Aboriginal Students’ Association – Consultation",
                "February 9 , 2015 – Native Studies Students’ Association - Consultation",
                "February 10, 2015 - University Legal Counsel - Advice",
                "February 13, 2015 – Council on Aboriginal Initiatives - Reporting/Consultation",
                "March 9, 2015 – Safe Disclosure and Human Rights - Advice",
                "April 1, 2015 – Faculty of Medicine and Dentistry Indigenous Health Initiatives - Consultation",
                "May 5, 2015 - Students’ Union - Consultation",
                "May 5, 2015 - Graduate Students Association – Consultation",
                "November 16, 2015 - Consultation with Catherine Bell, Faculty of Law",
                "November 10,2015 Consultation with Faculty of Rehabilitation Medicine",
                "November 17, 2015 – Law Faculty Councils – Approval",
                "November 17, 2015 – Medicine and Dentistry Faculty Councils – Approval",
                "November 23, 2015 – Vice-Provosts’ Council - Advice",
                "November 25, 2015 – FGSR Council - Approval of Occupational Therapy Section",
                "November 26, 2015 - President’s Executive Committee – Operational – Consultation",
                "November 26, 2015 - General Council - Consultation",
                "December 2, 2015 - Deans’ Council -Consultation",
                "December 15, 2015 - FNS Executive Meeting - Consultation",
                "December 17, 2015 – Council on Aboriginal Initiatives - Consultation",
                "November, 2016 Approval by Faculty of Native Studies Faculty Council",
                "May 9, 2017 Approval by Nursing Faculty Council",
                "June 1, 2017 Academic Standards Committee Subcommittee on Standards – Consultation",
                "June 15, 2017 – GFC Academic Standards Committee (ASC)",
                "September 13, 2017 – GFC Academic Planning Committee (APC)"
            ],
            "Approval Route": [
                "Academic Standards Committee - June 15, 2017",
                "Academic Planning Committee – June 14, 2017",
                "GFC Executive Committee (for information) – October 16, 2017",
                "General Faculties Council – October 30, 2017"
            ],
            "Final Approver": "General Faculties Council"
        },
        {
            "Item No.": "13",
            "Agenda Title": "General Faculties Council Standing Committee Report GFC Executive Committee",
            "Motion": "N/A",
            "Action Requested": "N/A",
            "Date": "2017-10-30",
            "Committee": "GFC",
            "Proposed By": "N/A",
            "Presenter": "N/A",
            "Description": "N/A",
            "Participation": [
                "N/A"
            ],
            "Approval Route": [
                "N/A"
            ],
            "Final Approver": "N/A"
        },
        {
            "Item No.": "14",
            "Agenda Title": "General Faculties Council Standing Committee Report GFC Academic Planning Committee",
            "Motion": "N/A",
            "Action Requested": "N/A",
            "Date": "2017-10-30",
            "Committee": "GFC",
            "Proposed By": "N/A",
            "Presenter": "N/A",
            "Description": "N/A",
            "Participation": [
                "N/A"
            ],
            "Approval Route": [
                "N/A"
            ],
            "Final Approver": "N/A"
        },
        {
            "Item No.": "15",
            "Agenda Title": "General Faculties Council Standing Committee Report GFC Academic Standards Committee",
            "Motion": "N/A",
            "Action Requested": "N/A",
            "Date": "2017-10-30",
            "Committee": "GFC",
            "Proposed By": "N/A",
            "Presenter": "N/A",
            "Description": "N/A",
            "Participation": [
                "N/A"
            ],
            "Approval Route": [
                "N/A"
            ],
            "Final Approver": "N/A"
        },
        {
            "Item No.": "16",
            "Agenda Title": "Report of the GFC Nominating Committee (Current list of vacancies)",
            "Motion": "N/A",
            "Action Requested": "N/A",
            "Date": "2017-10-30",
            "Committee": "GFC",
            "Proposed By": "N/A",
            "Presenter": "N/A",
            "Description": "N/A",
            "Participation": [
                "N/A"
            ],
            "Approval Route": [
                "N/A"
            ],
            "Final Approver": "N/A"
        },
        {
            "Item No.": "18A",
            "Agenda Title": "2018-2019 Academic Schedule ",
            "Motion": "N/A",
            "Action Requested": "Information",
            "Date": "2017-10-30",
            "Committee": "GFC",
            "Proposed By": "Lisa Collins, Vice-Provost and University Registrar ",
            "Presenter": "Lisa Collins, Vice-Provost and University Registrar; and Anna Vocioni, Assistant Registrar (Examinations and Timetabling), Office of the Registrar ",
            "Description": "Materials before members are contained in the official meeting file. - 2018-2019 Academic Schedule - Waiver of Advertising Requirements Report to GFC - Report of Undergraduate Student Financial Support",
            "Participation": [
                "Distribution list including President, Provost and Vice-President; GFC ",
                "Executive members; Deans, Associate and Assistant Deans, Students Union, GSA and Office of the Registrar "
            ],
            "Approval Route": [
                "GFC Executive Committee - October 16, 2017",
                "General Faculties Council – October 30, 2017 (for information)"
            ],
            "Final Approver": " GFC Executive Committee"
        },
        {
            "Item No.": "18B",
            "Agenda Title": "Waiver of Advertising Requirements: Report to General Faculties Council ",
            "Motion": "N/A",
            "Action Requested": "N/A",
            "Date": "2017-10-30",
            "Committee": "GFC",
            "Proposed By": "Steven Dew, Provost and Vice-President (Academic) ",
            "Presenter": "Steven Dew, Provost and Vice-President (Academic) ",
            "Description": "Materials before members are contained in the official meeting file. - 2018-2019 Academic Schedule - Waiver of Advertising Requirements Report to GFC - Report of Undergraduate Student Financial Support",
            "Participation": [
                "AASUA ",
                "Steven Dew, Provost and Vice-President (Academic) "
            ],
            "Approval Route": [
                "N/A"
            ],
            "Final Approver": "N/A"
        },
        {
            "Item No.": "18C",
            "Agenda Title": "Annual Report on Undergraduate Student Financial Support ",
            "Motion": "N/A",
            "Action Requested": "N/A",
            "Date": "2017-10-30",
            "Committee": "GFC",
            "Proposed By": "Lisa Collins, Vice Provost and University Registrar ",
            "Presenter": "Lisa Collins, Vice Provost and University Registrar Melissa Padfield, Deputy Registrar ",
            "Description": "Materials before members are contained in the official meeting file. - 2018-2019 Academic Schedule - Waiver of Advertising Requirements Report to GFC - Report of Undergraduate Student Financial Support",
            "Participation": [
                "Dr Wendy Rodgers, Deputy Provost:  August 17, 2017 ",
                "Dr Tammy Hopper, Vice Provost Programs: August 17, 2017 ",
                "Kelly Spencer, Office of Advancement:  August 17, 2017 ",
                "Edith Finczak, Office of the Provost and Vice-President (Academic): August 17, 2017 ",
                "Kate Peters, Policy Initiatives Manager: August 17, 2017 ",
                "André Costopoulos, Dean of Students: August 17, 2017 ",
                "Alexis Ksiazkiewicz, Government & Stakeholder Relations: August 17, 2017 ",
                "Heather Zwicker, Dean Faculty of Graduate Studies and Research:  August 17, 2017 ",
                "Britta Baron, Vice Provost and AVP International: August 17, 2017 ",
                "Marina Banister, Students’ Union President: August 17, 2017 ",
                "Babak Soltannia, Graduate Students’ Association President: August 17, 2017 ",
                "GFC Executive (for information): Oct 16, 2017 ",
                "GFC (for information): Oct 30, 2017 ",
                "BLDC: Dec 1, 2017 ",
                "VPC: Sept 18, 2017 ",
                "PEC-O: Sept 21, 2017 ",
                "Deans’ Council: Oct 4, 2017 ",
                "GFC UASC: Oct 10, 2017 ",
                "GFC APC: Oct 11, 2017 ",
                "ACEM and ACUS: Oct 27, 2017 ",
                "Lisa Collins, Vice Provost and University Registrar ",
                "Melissa Padfield, Deputy Registrar ",
                "Fiona Halbert, Assistant Registrar Student Financial Support ",
                "Douglas Akhimienmhonan, Assistant Registrar Enrolment Management ",
                "Kim Uniat, Associate Director RO Communications "
            ],
            "Approval Route": [
                "N/A"
            ],
            "Final Approver": "N/A"
        }
    ],
    "url": "/static/GFC/2017-10-30/Past-Meeting-Material.pdf",
    "content": "This agenda and its corresponding attachments are transitory records. University Governance is the official copy holder for files of the Board of \nGovernors, GFC, and their standing committees. Members are instructed to destroy this material following the meeting. \nGENERAL FACULTIES COUNCIL \nOPEN SESSION AGENDA \nMonday, October 30, 2017 \nCouncil Chamber, 2-100 University Hall  \n2:00 PM - 4:00 PM \nOPENING SESSION                               \n1. Approval of the Agenda David Turpin \n2. Approval of the Minutes of September 25, 2017 David Turpin \n3. Report from the President (no documents) David Turpin \n4. New Members of GFC  \nMotion: To Appoint New Members \nMotion: To Receive New Members \nDavid Turpin \nDISCUSSION ITEMS  \n5. Peter Lougheed Leadership College (PLLC) - Next Steps David Turpin \n6. Executive Committee update on ad hoc recommendations Eleni Stroulia \nACTION ITEMS  \n7. Faculty of Graduate Studies and Research: Proposed Revisions to existing \nSupervision and Examinations policy \nMotion: To Approve \nHeather Zwicker  \nDeborah Burshtyn \n8. Report of the GFC Committee on the Learning Environment (CLE) on \nTeaching and Learning and Teaching Evaluation and the Use of Universal \nStudent Ratings of Instruction (USRI) as an Evaluation Tool \nMotion: To Receive the report, and endorse the recommendations \nSarah Forgie  \nNorma Nocente  \nFrancisco Vargas \n9. Proposed Revisions to Standing Committee Terms of Reference GFC Campus \nLaw Review Committee (CLRC) including a name change to GFC Student \nConduct Policy Committee (SCPC) \nMotion: To Approve \nSteven Penney \n10. Proposed Revisions to Standing Committee Terms of Reference - GFC \nFacilities Development Committee (FDC) \nMotion: To Approve \nWendy Rodgers \n11. Changes to the Admission of Aboriginal Students Calendar Section and \nupdates to Faculty sections \nMotion: To Approve \nChris Andersen \nLisa Collins \nGFC General Faculties Council 10/30/2017 \nPage 2 \nDISCUSSION ITEMS  \n12. Question Period \n12.1 Question from GFC member Kyle Monda regarding safety and security in \nthe Fine Arts Building \nDavid Turpin \nINFORMATION REPORTS  \n[If a GFC member has a question about a report, or feels that the report should be \ndiscussed by GFC, the GFC member should notify the Secretary to GFC, in writing, two \nbusiness days or more before GFC meets so that the Committee Chair (or relevant \nexpert) can be invited to attend.] \n13. Report of the GFC Executive Committee (October 16, 2017)  \n14. Report of the GFC Academic Planning Committee (October 11, 2017)  \n15. Report of the GFC Academic Standards Committee (September 21, October \n18, 2017) \n16. GFC Nominations and Elections  \n- Current GFC committee vacancies \n17. Information Forwarded to GFC Members Between Meetings (no items to date)  \n18. Information Reports  \n - 2018-2019 Academic Schedule  \n - Waiver of Advertising Requirements Report to GFC  \n - Report of Undergraduate Student Financial Support  \nCLOSING SESSION  \n19. Next meeting date: November 27, 2017  \nPresenter(s):                               \nDavid Turpin Chair, General Faculties Council \nEleni Stroulia Member of GFC Executive Committee, Chair of transition committee \nHeather Zwicker Vice-Provost and Dean, Faculty of Graduate Studies and Research \nDeborah Burshtyn Vice-Dean, Faculty of Graduate Studies and Research \nSarah Forgie Chair, GFC Committee on the Learning Environment \nNorma Nocente Associate Director, Centre for Teaching and Learning \nFrancisco Vargas Research Coordinator, Centre for Teaching and Learning \nSteven Penney Chair, GFC Campus Law Review Committee \nWendy Rodgers Chair, GFC Facilities Development Committee \nChris Andersen Dean, Faculty of Native Studies \nLisa Collins Vice-Provost and University Registrar \nhttp://www.governance.ualberta.ca/GeneralFacultiesCouncil/NominatingCommittee/Committee-Membership-Replenishment/CURRENT%20VACANCIES.aspx\nGFC General Faculties Council 10/30/2017 \nPage 3 \nDocumentation was before members unless otherwise noted. \nMeeting REGRETS to: Andrea Patrick, 780-492-1937, apatrick@ualberta.ca \nPrepared by: Meg Brolley, GFC Secretary and Manager of GFC Services \nUniversity Governance www.governance.ualberta.ca \nhttp://www.uofaweb.ualberta.ca/governance/\nITEM 4 - New Members of GFC \nGENERAL FACULTIES COUNCIL \nOPEN SESSION \nMeeting of October 30, 2017 \nMOTION I: TO APPOINT  [This motion may be proposed only by statutory member s of GFC]: \nThe following undergraduate student representatives, to serve on GFC for terms commencing immediately \nand ending April 30, 2018: \nAleks Nakevski Alberta School of Business \nBrandon Yip Alberta School of Business \nAlizeh Ansari Faculty of Education \nGohar Jamal Faculty of Education \nAmy Li Faculty of Education \nDaniel Atchison Faculty of Engineering \nDaniel Bilyk Faculty of Engineering \nGaganpreet Jhajj Faculty of Science \nMarina Kirillovich Faculty of Science \nMOTION II: TO RECEIVE [This motion may be proposed by any member of GFC]: \nThe following statutory faculty member/s who has been elected/re-elected by their Faculty, to serve on \nGFC for a term of office commencing immediately and ending June 30, 2020: \nJohn Seubert Faculty of Pharmacy and Pharmaceutical Sciences \nItem No. 5 \nGENERAL FACULTIES COUNCIL \nFor the Meeting of October 30, 2017 \nOUTLINE OF ISSUE \nAdvice, Discussion, Information Item \nAgenda Title: Peter Lougheed Leadership College (PLLC) - Next Steps \nItem \nProposed by President, Provost and Vice-President (Academic) \nPresenter David Turpin, President \nDetails \nResponsibility President,  Provost and Vice-President (Academic) \nThe Purpose of the item is \n(please be specific) \nThe purpose of this proposal is to give GFC the opportunity to reflect on \nthe recent review of PLLC commissioned from Dr Peter Mackinnon, and \nthe response to that review prepared by PLLC Vice-Principal Dr Martin \nFerguson-Pell, and to engage in discussion about opportunities for the \nfuture evolution of PLLC and for leadership initiatives more broadly at the \nUniversity of Alberta. \nTimeline/Implementation Date Consultation in Fall 2017 \nSupplementary Notes and \ncontext \nThe Report to the University of Alberta President and Provost on the \nPeter Lougheed Leadership College by Peter MacKinnon (attached) \nhighlights a commitment and esprit de corps by the faculty, staff, and \nstudents within the college; a positive certificate program; and issues \naround long-term sustainability. This report positions the university to \nhave an open discussion on the future evolution of PLLC. \nEngagement and Routing (Include meeting dates) \nParticipation: \n(parties who have seen the \nproposal and in what capacity) \n<For further information see \nthe link posted on \nthe Governance Toolkit section \nStudent Participation Protocol> \nThose who have been informed: \n• President, Students’ Union (September 12, 2017)\n• President, Graduate Students’ Association (October 10, 2017)\nThose who have been consulted: \n• Deans Council (September 20, 2017)\n• Academic Planning Committee (October 11, 2017)\n• General Faculties Council (October 30, 2017)\n• PLLC Academic Oversight Committee (October 26, 2017)\nThose who are actively participating: \n• Deans of Arts, Science, ALES, Augustana, Business\n• Vice-Provost (Programs)\n• Deputy Provost\n• Acting Associate Vice-President (Human Resource Services)\nAlignment/Compliance \nAlignment with Guiding \nDocuments \nInstitutional Strategic Plan - For the Public Good \nExperience diverse and rewarding learning opportunities that inspire us, \nnurture our talents, expand our knowledge and skills, and enable our \nsuccess. \n8. Objective: Create and facilitate co-curricular and extracurricular\nlearning experiences for undergraduate and graduate students that \nenable their self-discovery and give them the skills to use their talents, \ncreativity, and curiosity to contribute as future citizens and leaders. \nhttp://www.governance.ualberta.ca/GovernanceToolkit/Toolkit.aspx\nhttp://www.governance.ualberta.ca/GovernanceToolkit/Toolkit.aspx\nItem No. 5 \nGENERAL FACULTIES COUNCIL \nFor the Meeting of October 30, 2017 \niv.   Strategy: Expand access to leadership development programs for \nundergraduate and graduate students, such as the Peter Lougheed \nLeadership College \nSustain our people, our work, and the environment by attracting and \nstewarding the resources we need to deliver excellence to the benefit of \nall. \n21. Objective: Encourage continuous improvement in administrative, \ngovernance, planning, and stewardship systems, procedures, and \npolicies that enable students, faculty, staff, and the institution as a whole \nto achieve shared strategic goals. \n i.      Strategy: Encourage transparency and improve communication \nacross the university through clear consultation and decision-making \nprocesses, substantive and timely communication of information, and \naccess to shared, reliable institutional data. \nCompliance with Legislation, \nPolicy and/or Procedure \nRelevant to the Proposal \n(please quote legislation and \ninclude identifying section \nnumbers) \nGeneral Faculties Council Terms of Reference \n3. Mandate of the Committee \n• high level strategic and stewardship policy issues or matters of \nsignificant risk to the University; \n•  those things which a Standing Committee considers to be of major \nstrategic significance to or long-term impact on the University; \nPowers of GFC under the PSLA \n• make recommendations to the board with respect to affiliation with \nother institutions, academic planning, campus planning, a building \nprogram, the budget, the regulation of residences and dining halls, \nprocedures in respect of appointments, promotions, salaries, tenure and \ndismissals, and any other matters considered by the general faculties \ncouncil to be of interest to the university; (GFC 24 NOV 1980) (GFC 20 \nNOV 1995). (PSLA Section 26(1)(o))  \nAttachments: \n1. Report to the University of Alberta President and Provost on the Peter Lougheed Leadership College by \nPeter MacKinnon \n2. Synthesis of Recommendations and Comments in Peter MacKinnon’s Report on The Peter Lougheed \nLeadership College (PLLC) by Martin Ferguson-Pell \nPrepared by: Kathleen Brough, Senior Administrative Officer, Office of the Provost and Vice-President \n(Academic) \nReport to the University of Alberta President and Provost \non the Peter Lougheed Leadership College \nby Peter MacKinnon \nFebruary 2017 \n1 \nOn November 2, 3 and 4, 2016 I was on site at the University of Alberta for interviews and \ndiscussions in support of my review of the Peter Lougheed Leadership College under terms of \nreference that required me to assess (1) The strengths, weaknesses, challenges and \nopportunities of PLLC; (2) the merits of the academic and co-curricular programming offered by \nPLLC and the audience for this programming; and (3) PLLC's sustainability in three key areas: \nleadership, governance and finances. I participated in 25 meetings involving 67 participants, \nand received telephone and email submissions from others. \nI am grateful to all who met with me, or otherwise expressed their views. I must add my \ngratitude to Bobbi Schiestel of the president's office. She compiled background documents and \ninformation, coordinated an intensive interview schedule, and provided excellent support that \nmade the most of my time on campus. I thank her warmly. \nThe terms of reference shall be addressed in order. \nThe strengths, weaknesses, challenges and opportunities of PLLC \nStrengths\nThe interviews and supporting documents point to three strengths: a compelling vision with \nexisting and potentially further alignment with the University of Alberta Strategic Plan for 2016-\n2021; considerable progress in implementing the vision, and a commitment and esprit de corps \nwithin the college that is palpable. \nThe original vision is that of John and the late Bunny Ferguson who, on the death of Peter \nLougheed, sought to commemorate his legacy at their university. It rests on recognition that \nleadership is fundamentally important; that it can be learned, and that there is a discrete field of \nstudy and experience to support that learning. The Fergusons developed and carried their vision \nto public and private sector leadership in the university, province and beyond, and secured early \nand considerable financial support for its implementation. It finds contemporary expression in \nthe college's vision to serve as \"a thriving centre of excellence for leadership skills development \nwhere students are immersed in and benefit from leading-edge learning experiences.\" \nThe 2016-2021 University of Alberta Strategic Plan, For the Public Good, makes explicit \nreference to the objective of accessing \"leadership development programs for undergraduate \nand graduate students, such as the Peter Lougheed Leadership College.\" In addition, there are \ncountless references to leadership in the plan. These imply that there is an opportunity for the \nuniversity to reflect on the role that the systematic and interdisciplinary study of leadership may \nplay in the next stage of the university's evolution. As the university builds its portfolio of \nAttachment 1\n2 \nsignature areas, perhaps leadership will be included among them. In its objective to attract \noutstanding students in Alberta, across Canada, and beyond, a unique and distinguished \ncapacity in leadership education and development might assist the university in recruiting the \nexceptional students it seeks to attract. Existing university capacity in French language \ninstruction and scholarship (Campus Saint-Jean) suggests potential opportunities to recruit \nstudents from French speaking regions in Canada and abroad. \nThere has been considerable progress in translating the PLLC vision into reality. \nComplementary first year courses are in place, as are second year courses devoted to \nworkshops and capstone projects. Co-curricular leadership projects and an ambitious instruction \ndevelopment model are evolving. And Peter Lougheed Hall, anticipated to be a residence and \nimportant college meeting and social centre will be open to students in September 2017. \nThe third strength is the evident commitment and esprit de corps within the college. The \nleadership is passionate about the program and potential; teaching fellows shared their passion; \nthe mentorship program is developing as planned; and, it must be emphasized, students are \nenthusiastic about the quality of their experience. Within a short time, and despite inevitable \ngrowing pains, the Peter Lougheed Leadership College has inspired enthusiastic commitment \namong its members that is notable in an organization so young. \nWeaknesses and Challenges \nFirst and most important, the college has both a short term and long term sustainability problem. \nFinancial commitments on a scale contemplated at its inception have not been confirmed. It was \nhoped that $105 million, one-third from the provincial government matched by the federal \ngovernment, with the remaining third from philanthropy, would be raised to support the initiative \nat each of the U of A and Banff Centre. This would have resulted in a pool of $210 million which \n- if endowed - could have supported the initiative in perpetuity. The reality is that only the \nprovincial commitment has been realized. A matching federal grant and philanthropic support at \nthe level anticipated are not in sight. This means that the provincial grant is not part of a larger \ninvestment fund to support the College in perpetuity. Instead it is being spent to pay for \noperations and for the capital costs of the building. \nWhat does this mean? First, provincial grant monies are being spent at a rate that could see \nthem exhausted before the expiry of the current ten year commitment. Second, upon the expiry \nof the provincial grant, continuing operations are in jeopardy unless new sources of revenue are \nconfirmed from within the university's operating budget or from external sources. Quite simply, \nas seen from 2016, the college is not sustainable. \nAnother challenge is the building that is expected to be its home: Peter Lougheed Hall. The \nuniversity will take delivery of the completed building early in 2017 and will welcome residence \nstudents the following September. The dream here is of a residential college of which there are \nmany examples worldwide. A notable Canadian example is Massey College at the University of \nToronto. \n3 \nNorthrop Frye once observed that most of what we learn, we learn from one another. Peter \nLougheed Hall is intended to be more than a place to live while studying down the street or \nacross campus. It is was intended to be an interdisciplinary, intellectual community of the \ncollege's students living in proximity to one another with opportunities for informal dialogue and \nprogramming to enhance their study. This intention may not be realized. Without substantial \ninducements, it is unlikely that the hall's 143 spaces - or even half that number - will be \noccupied by PLLC students. A premium will be added to normal residence fees to reflect the \nquality of the space and the anticipated enhanced experience. The students are in their third \nand fourth years, a time at which many students prefer to live off campus. And the Edmonton \nhousing market has softened, for the foreseeable future at least, making off campus costs more \nfavourable in comparison to those of living in residence. \nA third weakness or challenge is what might be called a lack of equity in the college on the part \nof the wider University of Alberta community. The college was inspired by interests outside the \nuniversity's normal academic channels. It was not integrated from its inception within these \nchannels, and it has had an unsettled relationship with other parts of the university. There has \nbeen some softening of attitudes, in part attributable to the approval of the college's certificate \nprogram by General Faculties Council, and in part because there have been recent \ncollaborative efforts. But there remains a residual skepticism about the role of the college in the \nuniversity. \nOpportunities \nLeadership can be taught, and there are innumerable conferences, workshops, books and \nprograms to that end. But in Canada there is only one university college committed to \nleadership skills development: PLLC. It is now an established fact, though it rests on a \nprecarious foundation, and the question before the university is clear: after present \ncommitments are met, will the college succumb to its sustainability issues, or is distinction in the \nstudy of leadership a goal to which the university aspires? Struggling along with an uncertain \nfuture is not an option at an institution of the stature and repute of the University of Alberta. \nIn the short term there are measures that might be taken to stabilize the college. First, a \nbalanced budget in 2017-18 and subsequent years should be finalized. Second, the college \ncould explore the potential for a more equitable sharing of expenditures on this partnership \ninitiative between U of A and The Banff Centre. (the 3.5 million annual grant is being drawn \ndown at PLLC with deficits, while The Banff Centre is accumulating annual surpluses). Third, \nthe $10,000 awards to students are no longer affordable. Phasing out of the $2500 awards in \neach of years 1 and 2 is underway. The $5,000 committed to the stretch experience awards \ncould instead be a credit against fees at Peter Lougheed Hall; this would be an inducement to \nPLLC students to live there. Fourth, PLLC should explore revenue generating opportunities from \nlending its expertise in leadership programs to other organizations. \n4 \nThese are possibilities only and, whatever their merits, they will not in themselves assure the \nsustainability of PLLC beyond the ten year agreement with the provincial government. That will \nrequire additional resources from government and philanthropy or a university commitment to \noperating budget support. \nMerits of PLLC Academic and Co-curricular Programming \nA second year of operation is too soon to assess these but some observations can be made. I \nheard no criticism of the academic programming; on the contrary, those in the university who \nhad an opinion on the subject viewed it positively, and PLLC staff and students are enthusiastic \nabout its quality. Some concern was expressed about its demanding nature for students already \ntaking a full course load but this could be alleviated if PLLC courses were approved as electives \nfor credit in all faculties. \nBanister Research Associates has been commissioned to undertake a review of the co-\ncurricular programs, and some results from their questionnaires are expected by year end. In \nthe interim I would suggest that the stretch program appears to be unfocused. Clearer criteria \nare needed to identify what is (and what is not) a stretch program as distinct from paid summer \nemployment. It has been suggested above that the $5 thousand award for all students in the \nprogram be used instead as a credit toward fees in Peter Lougheed Hall. An alternative might \nbe to commit some of these funds to needs based bursaries. \nI heard that the mentorship program is developing as planned. Forty mentors have been \nrecruited and demands on them are highly variable. They are available to those who seek them \nout but are not assigned to students, and this might be reconsidered. The Banister review \nshould provide more information on this subject. \nThe most challenging concerns were those expressed about the relationship between this \nprogram and other leadership initiatives at the University of Alberta. The external origins and \nearly implementation of the PLLC initiative meant that there has been no wider university \nconsideration of its nature and availability. GFC approval of the certificate was a positive step \nbut it was after the fact and not a substitute for systematic attention to program structure and \navailability, and to the relationship between PLLC and other U of A leadership commitments. \nThe sustainability issue is germane here. PLLC's long term sustainability requires that it be \nembedded within the university. It may be time to commission a university wide council of deans \nor associate deans and students to work with college leadership to this end. \n5 \nPLLC's Sustainability in Leadership, Governance and Finances \nThe third of these, finances, has been addressed above and I repeat for emphasis: PLLC has \nshort and long term financial sustainability issues that must be addressed now. \nThe college has dedicated and creative leadership but on account of its origins, and its \ndesignation as an administrative rather than an academic unit, appointment and succession \nprocesses did not receive the attention usually devoted to them in the university context. \nPLLC's governance arrangements, including the present Academic Oversight Committee, are \nad hoc and fall short of what will be necessary to embed PLLC within the university and assure \nits sustainability. The administration of PLLC should report to the provost's office rather than to \nthe university president, with the resources of that office committed to early consideration of \nappointment and reappointment processes, and to the role of PLLC in the wider university. \n1 \n Synthesis of Recommendations and Comments in Peter MacKinnon’s Report on \nThe Peter Lougheed Leadership College (PLLC) \nMay 2017 \nMartin Ferguson-Pell, Vice-Principal, PLLC \nThe PLLC is grateful for Peter MacKinnon’s support for the College’s vision, and appreciates his \nthoughtful input. This synthesis document is a response to the strengths, weaknesses, challenges and \nopportunities laid out in the MacKinnon Report. \nSTRENGTHS, WEAKNESSES, CHALLENGES AND OPPORTUNITIES OF PLLC \nStrengths \nStrategic Plan Alignment: There are explicit references to PLLC and also many references to \n“leadership” in the U of A Strategic Plan. PLLC is ready and poised to contribute to For the Public \nGood as the plan unfolds. \nLeadership as a possible signature area: There are interesting opportunities here. Leadership \nencompasses a broad set of soft skills that employers have identified as needed and sometimes \nlacking in the typical accomplished graduate. It is important to recognize that the need for these \nsoft skills in graduating students has been studied and illuminated by academic studies and is \nsupported by evidence. \nRecruitment of exceptional students:  We have seen progress in this area with the recruitment of a \nLoran scholar for the 2017-19 cohort and PLLC’s contribution in preparing a student from the \nFaculty of Science to be elected a Rhodes Scholar. Other excellent results include PLLC scholars \nbeing admitted to prestigious, very competitive professional programs such as in medicine, law and \nrehabilitation medicine. PLLC scholars who applied for QE2 scholarships in 2016 had a very high \nsuccess rate and their skills at interview were particularly commended. \nWeaknesses and Challenges \nFinancial sustainability: Throughout the development of PLLC we have been careful to plan for \nfinancial sustainability and enable growth to reach an intake of about 125 students per year, with \nsufficient funds to complete the 10-year GOA grant period (2024-25). We have included in our \nplanning projected inflation costs that were not accounted for in the original fixed-cost funding \nmodel.  \nNeed for new sources of revenue: New revenue sources will need to be identified from 2025 \nonwards, and we recommend consideration be given to opportunities to raise revenue in the \ninterest of PLLC’s long-term sustainability. \nManaging a full course load: It is true that if more programs could accept PLLC courses as elective \nthis would reduce the workload of PLLC students. We tend to hear this concern in the first semester \nof the first year. Discussions with second year students indicate that the skills they learn provide \nAttachment 2\n2 \nnumerous systemic benefits that lead to less pressure in the winter term of year one and the second \nyear. \nPLLC, through the teaching fellows and forum structure, work closely with any students needing \nsupport. Lead Instructors, teaching fellow and the Director of Instruction hold regular office hours \nand refer students to support services if necessary. This early intervention approach is beneficial \nnot only to the student’s academic performance in PLLC, but also to academic performance in their \nprimary degree subjects. \nStretch Experience: We agree that the first year stretch program needs further development. \nChanges have already been put in place for the 2016-18 cohort; and we will continue to closely \nmonitor the program.  \nWe would like to emphasize that one of the signature features of the PLLC stretch experience is the \nopportunity to tailor the experience to each student’s personal strategy, gaps in experiences and \npersonal passions while requiring all stretch experiences to include 200+ hours of voluntary work \nfor the social benefit of the community in which the stretch experience is conducted. The \nunderlying pedagogy is to create a personal strategic challenge that some students are ill-equipped \nto handle without the support provided by the PLLC team during the planning stages.  The students \nlearn and mature through this process, an important skill for life. The mentors also play an active \nrole in connecting scholars to opportunities and supporting them through the stretch experience. \nThe process of creating the stretch experience by the scholar is as important as the experience \nitself. Opportunities to assume the responsibility of designing a learning experience, to reflect on \npersonal priorities and ambitions, and to be creative in meeting the specifications of the program \nare a rare experience for the typical, highly regulated North American undergraduate. The stretch \nexperience is therefore an important opportunity for scholars to examine their values and personal \nnarrative. \nWith regard to the stretch experience student funding, we respectfully disagree that the $5,000 \naward should be reallocated to create residence bursaries. To reallocate these funds would create \naccess issues and inequities for students who do not have the means to lose 200 hours of otherwise \npaid work during the summer. The $5,000 is closely benchmarked to funding provided for \nundergraduate research experiences by U of A, NSERC, AIHS, CIHR. \nRelationship with other U of A leadership initiatives: When PLLC was first being developed, the \nLougheed Academic Consultative Committee (LACC) was formed to ensure that broad university-\nwide perspectives were included in the planning process. LACC included faculty members, \nundergraduate student representative, graduate student representatives and deans of interested \nfaculties and units (Arts, Science, Engineering, Augustana, Dean of Students, UAI, PER). A \nsubcommittee was subsequently formed to undertake a horizon scan of leadership programs at U of \nA so that there was awareness of other programs by the PLLC leadership.  \nClose links were formed with Alberta Students Leadership Summit (PLLC has participated in the \nSummit and provided significant funding to support it from January 2015). The Emerging Leaders \nprogram, and SU initiative has similarly been supported by PLLC as sponsors, participants and \nfacilitators. PLLC has also worked closely with the U of A Ambassadors program and more recently \nwith Gold College. PLLC participated fully in the SU and Provost sponsored Interdisciplinary \nLearning conference on February 4, 2017. PLLC has also funded 10 students each year from the \nAlberta School of Business Certificate in Leadership to attend the residential Banff Retreat PLLC \nholds for its scholars. The Lougheed Lectures held every two weeks during term time are open to all \n3 \non campus and beyond. We are in discussions with Campus St. Jean to consider how a version of the \nFoundations of Leadership course could be provided in French. We have worked closely with \nFaculty of Extension to share experiences with their leadership programming. Without doubt there \nare other further opportunities to extend PLLC’s collaborative activities, but these are naturally \nlimited by resources and the capacity of the lean PLLC administrative team.  \nCouncil of Deans: PLLC feels that that an advisory group of deans with a focus on strategic \ndevelopment of PLLC rather than operational oversight process would be beneficial to the further \ndevelopment of the College. Academic guidance can always be offered in this context. \nPeter Lougheed Hall: At this point, given feedback from current students in PLLC, it is unlikely that \nthe original goal of two cohorts of PLLC scholars living throughout their PLLC experience in \nresidence will be realized in the short to medium term. However, the public spaces of PLH will be of \ngreat value in providing PLLC with a physical focal point and a gathering place for PLLC scholars. \nPLH will accommodate many of PLLC’s activities such as talks and special events. In most cases \nthese opportunities will be extended to other residents in PLH creating a lively setting for \nleadership-related activities. \nThe role of the college in the university: We do not understand the skepticism surrounding PLLC and \nits role in the university, and need more guidance. Like many prestigious programs at U of A, PLLC \nis selective. The criteria for selection are widely available for review and were the result of 9 focus \ngroups with students facilitated by SU in December 2014. We seek students who have the passion, \npotential and commitment for an intensive academic and co-curricular experience.  \nWe agree with Dr. MacKinnon’s statement that “Leadership can be taught …” The concern raised by \ncolleagues with Dr. MacKinnon about this point appears to misunderstand the learning goals of \nPLLC. PLLC is not intended to generate leaders, but to provide opportunities for undergraduate \nstudents to learn leadership skills and practice them through experiential learning opportunities \nthat will serve them in many ways in their careers so that they can live consequential lives, with \nwhatever focus or role in society they may choose. All activities undertaken by PLLC, academic and \nco-curricular, are respectful of academic values. The content seeks specifically to develop \nunderstanding and insights for developing leadership skills. PLLC seeks to create an atmosphere of \nfreedom to discuss issues within the trust of a forum structure.  By creating an environment that is \nconducive to free and open discussion we create an environment that is more open to creative \nlearning and deeper understanding. \nOpportunities \nOptions for the Future: We agree the long-term financial sustainability of PLLC is a concern. PLLC’s \ncurrent budget approach will allow it to deliver content on the scale and quality originally intended \nuntil 2024-25, at which point the University, the Government of Alberta and the community at large \nwill need to make a decision for the long term. There will be 10 years of longitudinal data collected \nto demonstrate the value proposition of continuing PLLC by that time. We will have the opportunity \nto make a decision based on solid evidence.  \nMore equitable sharing of expenditures with Banff Centre: The Banff Centre, at least for the short \nterm, has agreed to cover the cost of the Banff Retreat. However, beyond this and several other \nareas of significant collaboration, we believe it is unlikely that The Banff Centre would cover costs \nthat are explicitly related to the academic costs of PLLC or the costs of Peter Lougheed Hall. \n4 \nStudent Awards: We introduced the $2,500 per year award in response to concerns raised by SU \nand LACC about equitable access to PLLC for students who rely on working (especially in the \nevenings) to cover their tuition and living costs.  This is not an extraordinarily large award and is \nadministered by the Office of the Registrar. We resisted means testing this award. However, with \nPLLC scaling up it is clear that this element of the funding to students is no longer affordable and we \npropose and have budgeted for it to be replaced by a bursary fund to be administered by the Office \nof the Registrar. At present about 10% of PLLC scholars are already receiving a bursary from UofA. \nWe do not share the view that the summer stretch experience funding should be withdrawn and \nthis cost remains in the balanced budget. It is important to recognize that the stretch experience \nrequires a minimum of 200 hours of voluntary work for the social good of the community and that \nno other bursaries are available to cover off this activity outside the normal academic term. \nRevenue Generating activities: Extensive analysis has been undertaken to consider the benefits, \nfeasibility and business case for a residential summer school. This could both generate net revenue \nfor PLLC programming and also increase utilization of PLH. We request that the university give \nserious consideration to conducting a summer school pilot in 2018. \nLending expertise to other organizations: There is potential but with caution. At present there is \ninsufficient capacity in PLLC to take on contract work. There may be other groups on campus \n(Faculty of Extension, School of Business) that might want to take the lead on such initiatives and \nPLLC could certainly provide expertise in exchange for a revenue share in support of them. \nItem No. 6 \nGENERAL FACULTIES COUNCIL \nFor the Meeting of October 30, 2017 \n OUTLINE OF ISSUE \nInformation Item  \nAgenda Title: GFC Executive Committee update on the ad hoc committee recommendations \nItem   \nAction Requested Information   \nProposed by GFC Executive Committee \nPresenter Eleni Stroulia, Chair GFC Executive ad hoc Transition Committee \nDetails \nResponsibility General Faculties Council \nThe Purpose of the Proposal is \n(please be specific) \nTo receive the status report on the implementation of recommendations \nfrom the Report of the ad hoc Committee on Academic Governance \nincluding Delegated Authority. \nThe Impact of the Proposal is Provides a progress report of the implementation phase and \nrecommends next steps towards implementation of recommendations. \nReplaces/Revises (eg, policies, \nresolutions) \nN/A \nTimeline/Implementation Date Ongoing \nEstimated Cost and funding \nsource \nN/A \nNext Steps (ie.: \nCommunications Plan, \nImplementation plans) \nSupplementary Notes and \ncontext \nUpdate on Implementation of Recommendations: \nProposals for revised terms of reference for 2 of GFC’s 9 standing \ncommittees are on the agenda for the October 30, 2017 meeting of GFC. \nIn addition, 48 recommendations were made in the Report of the ad hoc \nCommittee on Academic Governance including Delegated Authority. The \nstatus of these recommendations, as of October 23, 2017, is detailed in \nAttachment 1, and is summarized as follows: \n• 8 are complete – these are related to principle documents approved \nby GFC in April 2017 \n• 6 are implemented – these include early consultation, GFC meeting \nfrequency, Board relations, and orientation \n• 25 are in-progress – the majority of which are committees working on \nterms of reference \n• 7 have no action taken to date – of these, 3 relate to Nominating \nCommittee and COSA \n• 2 remain as status quo until other recommendations are \nimplemented \nItem No. 6 \nGENERAL FACULTIES COUNCIL \nFor the Meeting of October 30, 2017 \n Engagement and Routing (Include meeting dates) \nParticipation: \n(parties who have seen the \nproposal and in what capacity) \n<For further information see \nthe link posted on the \nGovernance Toolkit section \nStudent Participation Protocol> \nThose who have been informed: \n• GFC Executive Committee \n• General Faculties Council \nThose who have been consulted: \n• GFC Executive ad hoc transition committee \n• GFC Executive Committee \nThose who are actively participating: \n• GFC Executive ad hoc transition committee \n• General Faculties Council \nApproval Route (Governance) \n(including meeting dates) \nN/A \nFinal Approver N/A \nAlignment/Compliance \nAlignment with Guiding \nDocuments \nFor the Public Good \nObjective 21: Encourage continuous improvement in administrative, \ngovernance, planning, and stewardship systems, procedures, and \npolicies that enable students, faculty, staff, and the institution as a whole \nto achieve shared strategic goals. \nCompliance with Legislation, \nPolicy and/or Procedure \nRelevant to the Proposal \n(please quote legislation and \ninclude identifying section \nnumbers) \nMay 15, 2017 GFC Executive Committee established a GFC Executive \nad hoc Transition Committee “To advise and guide the implementation of \nthe recommendations of the ad hoc Committee on Academic \nGovernance including Delegated Authority” \nTerms of Reference: \n1. Monitor the progress of the implementation groups \n2. Provide advice and guidance to implementation groups \n3. Report to GFC and the GFC Executive Committee on the status of \nthe recommendations \nAttachments: \n1.  Attachment 1: Progress of Implementation of Recommendations of ad hoc Committee on Academic \nGovernance including Delegated Authority \nPrepared by: University Governance \nhttp://www.governance.ualberta.ca/GovernanceToolkit/Toolkit.aspx\nhttp://www.governance.ualberta.ca/GovernanceToolkit/Toolkit.aspx\nStatus of ad hoc Recommendations - October 23, 2017\nPage 1\nStatus Notes Recommendation\n1 Complete Orientation and Education - responsibilities of members\nGFC  core document - Roles and Responsibilities of Members approved \nby GFC April 21, 2017\nGeneral GFC and GFC Committee Orientation - That the responsibilities of \nmembers be clearly outline in a core GFC document\n2 Complete Delegated Authority and Early Consultation\nGFC core document - GFC Principles of Delegation approved by GFC \nApril 21, 2017\nThat substantive and strategic issues of broad relevance to the university \ncommunity  be brought to GFC for early consultation regardless of whether \nauthority for those issues has been delegated to another body or individual\n3 Complete Delegated Authority GFC core document - GFC Principles of Delegation approved by GFC April 21, 2017\nDelegated Authority - That the GFC Executive Committee be responsible for \nensuring that all delegations of authority are reviewed at a minimum once every \nthree years\n4 Complete Committee Composition - Vice Chair\nGFC core document - GFC Principles of Committee Composition \napproved by GFC April 21, 2017\nThat each committee should elect an academic staff member who, whenever \npossible, is a member of GFC, as Vice-Chair\n5 Complete Committee Composition - membership\nGFC core document - GFC Principles of Committee Composition \napproved by GFC April 21, 2017\nCommittee Composition - That elected positions on GFC standing committees \nbe filled, as much as possible, by members of GFC\n6 Complete Committee Composition - Voting status\nGFC core document - GFC Principles of Committee Composition \napproved by GFC April 21, 2017\nThat ex-officio members on standing committees vote in accordance with their \nvoting status on GFC\n7 Complete Delegated Authority GFC core document - GFC Principles of Delegation approved by GFC April 21, 2017\nThat when individuals, standing committees, and other bodies are uncertain as to \nwhether an item falls within the intended delegation or whether the significance of \nan issue and the division of opinion on the issue suggest that it is an issue that \nshould be considered by the full GFC, that individual, committee, or body should \nerr on the side of caution and refer the matter to full GFC\n8 Complete Implementation of Recommendations\nTransition Committee terms approved by Executive May 15, 2017; first \nmeeting of transition committee September 20, 2017\nThat the GFC Executive Committee establish a Transition Committee with \nrepresentatives from GFC Executive and the Ad Hoc Committee on Academic \nGovernance Including Delegated Authority to advise and guide the \nimplementations of the recommendations of the recommendations to be \ncompleted on or before April 2019\n9 Implemented General Faculties Council - early consultation 2016-17 - Items for Early Consultation introduced to GFC agenda\nThat opportunities be created to allow agenda items that are in the development \nstage to come before GFC for early consultation and discussion, and that this \nshall include items that will be considered for approval by standing committees as \nwell as items that will eventually be decided upon by GFC.\n10 Implemented General Faculties Council - meeting frequency 2017-18 scheduled includes 8 GFC meetings That GFC schedule eight meetings per year between September and June\n11 Implemented General Faculties Council - Board Relations Joint meeting date set for January 25, 2018\nGFC/Board Relations - That an annual joint meeting between the Board and \nGFC be established\n12 Implemented General Faculties Council - Board relations Board Chair has been invited to attend GFC on November 27, 2017\nGFC/Board Relations - That the Chair of the Board of Governors be invited \nannually to speak at a GFC meeting\n13 Implemented Orientation and Education - orientation sessions September 2017 and ongoing\nOrientation and Education - General GFC and GFC Committee Orientation - \nThat a variety of orientation sessions be offered including a general orientation to \ngovernance (Governance 101), followed by orientations more specific to GFC \nand GFC standing committees, and follow up sessions through the year\n14 Implemented Orientation and Education - Chair/Vice-Chair orientation September 2017 and ongoing\nOrientation and Education - Committee Chair and Vice-Chair Orientation - \nThat orientation for Chairs and Vice-Chairs include a focus on delegated authority \nand reporting to GFC, including the responsibility of GFC Committees to refer \nmatters to full GFC if they are uncertain whether the item falls within their \ndelegated authority or the significance of the issue and division of opinion on the \nissues suggest it should be discussed and debated by GFC itself\nStatus of ad hoc Recommendations - October 23, 2017\nPage 2\nStatus Notes Recommendation\n15 in-progress Terms of Reference - all committees All delegations and sub-delegations included in ToR\nThat delegations of authority to GFC standing committees and any sub-\ndelegations be clearly articulated in the terms of reference of each affected \nstanding committee\n16 in-progress\nTerms of Reference - \nCampus Law Review \nCommittee\nCurrently in place; included in draft ToR Task-Oriented Committees - That a strong preference be given to appointing a member with legal training as the Chair of the Campus Law Review Committee\n17 in-progress\nTerms of Reference - \nAcademic Planning \nCommittee\nAPC review of ToR That GFC’s Academic Planning Committee be replaced by an Academic and Research Planning Committee (APRC)\n18 in-progress\nTerms of Reference - \nAcademic Planning \nCommittee\nAPC review of ToR\nThat the new Academic and Research Planning Committee assume the \nacademic planning responsibilities of APC, as well as responsibility for research \nand research policy, including Academic Centres and Institutes, research ethics, \ncopyright and intellectual property, postdoctoral fellow, field research policy, and \nfunded and endowed chairs\n19 in-progress\nTerms of Reference - \nAcademic Planning \nCommittee and Academic \nStandards Committee\nASC recommend to APC on change to role / mandate\nProgram Approval and Regulations - Suspension and Termination of \nPrograms - That the delegated authority to approve the suspension of a program \nmove from the Academic Standards Committee to the Academic Planning \nCommittee\n20 in-progress\nTerms of Reference - \nAcademic Planning \nCommittee and Academic \nStandards Committee\nASC recommend to APC on change to role / mandate\nProgram Approval and Regulations - Suspension and Termination of \nPrograms - That the Academic Standards Committee recommend to the \nAcademic Planning Committee on program terminations and suspensions and vet \nthe Calendar language for such proposals\n21 in-progress\nTerms of Reference - \nAcademic Planning \nCommittee and Academic \nStandards Committee\nASC recommend to APC on change to role / mandate; also inform BLDC \nof change\nProgram Approval and Regulations - Certificate Programs - That the \nAcademic Standards Committee be given the delegated authority to approve \nestablishment, termination, and changes to certificates for all Faculties; those \nrequiring additional funding and/or space would be recommended to the \nAcademic Planning Committee for approval\n22 in-progress\nTerms of Reference - \nAcademic Planning \nCommittee and Academic \nStandards Committee\nASC recommend to APC on change to role / mandate\nProgram Approval and Regulations - Proposals from the Centre collegial de \nl'Alberta (CCA) - That the Academic Standards Committee be given delegated \nauthority to approve the establishment, termination, and changes to college level \ndiploma and certificate programs from the Centre collegial de l’Alberta; those \nrequiring additional funding and/or space would be recommended to the \nAcademic Planning Committee for approval\n23 in-progress\nTerms of Reference - \nAcademic Standing \nCommittee\nASC review of ToR - expand membership\nThat the ex-officio members on ASC remain unchanged; and that the \nmembership be expanded to include two additional elected GFC members and \nthe Associate Dean of Students as  a non-voting member\n24 in-progress\nTerms of Reference - \nAcademic Standing \nCommittee\nASC review of ToR - expand role/mandate\nProgram Approval and Regulations - New Programs - That the role of the \nAcademic Standards Committee be expanded to allow the committee to comment \non all academic portions of program proposals including program structure of new \nprograms and changes to programs\n25 in-progress\nTerms of Reference - \nAcademic Standing \nCommittee\nASC review of ToR - expand role/mandate\nProgram Approval and Regulations - New Programs - That the Academic \nStandards Committee review and approve courses associated with new program, \nsubject to challenge through normal course circulation process\n26 in-progress\nTerms of Reference - \nAcademic Standing \nCommittee\nASC review of ToR - expand role/mandate\nProgram Approval and Regulations - Program Changes - That the Academic \nStandards Committee recommend to the Academic Planning Committee on \nprogram changes\n27 in-progress Course and Minor Program Changes\nA working group of the ASC Subcommittee on Standards has been \nformed; first meeting was August 31, 2017\nThat, over the next year, the ASC Subcommittee on Standards be charged with \nreviewing and revising the policy on course and minor program changes\nStatus of ad hoc Recommendations - October 23, 2017\nPage 3\nStatus Notes Recommendation\n28 in-progress\nTerms of Reference - \nAcademic Standing \nCommittee and Executive \nCommittee AND Course and \nMinor Program Changes\nASC review of ToR - course designators and re-numbering of courses - \nwill provide a recommendation to Exec; this is also included in the course \nand minor program change policy\nThat the delegated authority to ratify new course designators and to approve re-\nnumbering of courses move from the Executive Committee to the Academic \nStandards Committee\n29 in-progress General Faculties Council - Board Relations Joint meeting date set for January 25, 2018\nGFC/Board Relations - That the Chair of GFC Executive Committee consult \nannually with GFC Executive and the Board on the focus and goals of the annual \njoint meeting of the Board and GFC\n30 in-progress\nTerms of Reference - \nCommittee on the Learning \nEnvironment\nCLE review of ToR - mandate; additional mandate pieces may include \nitems currently in ASC mandate\nThat the responsibility to “recommend to GFC on broad policy directions for \nexcellence in teaching and learning in a manner that ensures accountability of all \nFaculties in this matter” be moved to the Committee on the Learning Environment \nform the Academic Planning Committee\n31 in-progress\nTerms of Reference - \nCommittee on the Learning \nEnvironment\nCLE review of ToR - membership\nThat committee composition be changed as follows:  remove Vice-President \n(Research) and one Associate Dean, add a Librarian (A1.4) to boost linkage \nbetween GFC and Learning Service, add a sessional staff member (A2.1), elect \nrather than appoint a Dean\n32 in-progress\nTerms of Reference - \nUndergraduate Awards and \nScholarship Committee\nextensive orientation occuring to frame discussions on UASC role and \nmandate \nThat the Undergraduate Awards and Scholarship Committee work with relevant \nstakeholders to propose revisions to the committee’s terms of reference to \nprovide a more strategic and comprehensive mandate and role\n33 in-progress Terms of Reference - CLRC, UTAC, UASC\nTask-Oriented Committees - That no major changes be made to the Campus \nLaw Review Committee, the University Teaching Awards Committee, or the \nUndergraduate Awards and Scholarship Committee at this time\n34 in-progress\nOrientation and Education - \nnew staff and senior admin \norientations\ndiscussion has occurred with organizers Ongoing Governance Education - That governance sessions be included with new staff and senior administration orientations\n35 in-progress Free-standing Nominating Committee\nFree-Standing Nominating Committee - That a free-standing Nominating \nCommittee be established\n36 in-progress Free-standing Nominating Committee status quo\nFree-Standing Nominating Committee - That the Replenishment Committee \nremain in place in the interim and be disbanded when no longer needed\n37 in-progress Council on Student Affairs medium/long\nOngoing Work - COSA - That the GFC Executive Committee establish a \nworking group to revise the COSA terms of reference in accordance with the \nprinciple of GFC and its standing committees and reflect a role and mandate that \ngives student issues a well-define venue for discussion and clear pathway for \ncomments to reach GFC\n38 in-progress Council on Student Affairs COSA scheduled added to governance calendar Ongoing Work - COSA - That COSA be brought under the governance umbrella and be supported by University Governance\n39 in-progress Council on Student Affairs status quo That the current COSA remain in place in the interim and be disbanded when no longer needed\n40 no action taken Delegated Authority - records Medium/long term time frame\nDelegated Authority - That a comprehensive record of all delegations and sub-\ndelegations of GFC authority be compiled and curated by the GFC Secretary\n41 no action taken Orientation and Education - handbook short/medium time frame\nOrientation and Education - General GFC and GFC Committee Orientation - \nThat a comprehensive GFC and committee member guidebook be made widely \navailable to members wanting a single reference for all the information they \nrequire to be effective in their roles\nStatus of ad hoc Recommendations - October 23, 2017\nPage 4\nStatus Notes Recommendation\n42 no action taken Orientation and Education - phase 2 medium/ongoing time frame\nOrientation and Education - Ongoing Governance Education - That \nmeasures be taken to increase the profile and relevance of GFC, through the \npromotion of education sessions further to Governance 101 that are aimed at the \nwider university community\n43 no action taken Faculty of Graduate Studies & Research\nOngoing Work - FGSR - That further works and consultation occur with FGSR \nand Governance to develop a proposal for approval pathways that recognizes the \nunique nature of the Faculty\n44 no action taken Faculty Councils\nOngoing Work - Faculty Councils - That the link between GFC and Faculty \nCouncils be more clearly defined and delegated authority be identified and \ncurated\n45 no action taken\nDelegated Authority - \ndelegations to other \nbodies/individuals\nwill include Administration, UAPPOL policies and procedures, HR job \ndescriptions\nOngoing Work - Other Delegations - That the Governance staff continue to \nwork to identify and curate the list of GFC delegated authorities to other bodies \nand officers, and report the results of these efforts to GFC Executive Committee \nfor consideration in the context of ongoing evaluations and reforms to academic \ngovernance\n46 no action taken General Faculties Council - composition\nFuture Work to Be Done - That the composition of General Faculties Council be \nreviewed on or before April 2019 with the intention of decreasing its sized, \nkeeping in mind the parameters of the PSLA\n47 status quo Replenishment Committee status quo\nTask-Oriented Committees - That no changes be made to the Replenishment \nCommittee and that it be disbanded once the Nominating Committee is \nestablished and appropriate processes are in place to do its tasks\n48 status quo Current Delegations - transitioning status quo\nThat the current delegated authorities and committee terms of reference remain \nin place until such time as the new terms of reference are approved by GFC\nItem No. 7 \nGENERAL FACULTIES COUNCIL \nFor the Meeting of October 30, 2017 \nOUTLINE OF ISSUE \nAction Item \nAgenda Title: Faculty of Graduate Studies and Research: Proposed revisions to existing Supervision \nand Examinations policy \nMotion:  THAT General Faculties Council approve the proposed revisions to existing Supervision and \nExaminations policy, as recommended by the GFC Executive Committee and the GFC Academic Standards \nCommittee, as submitted by the Faculty of Graduate Studies and Research and as set forth in Attachment 1, \nto take effect July 1, 2018. \nItem \nAction Requested Approval Recommendation \nProposed by Heather Zwicker, Dean, Faculty of Graduate Studies and Research \nPresenter Heather Zwicker, Dean, Faculty of Graduate Studies and Research \nDeborah Burshtyn, Vice-Dean, Faculty of Graduate Studies and \nResearch \nDetails \nResponsibility Provost and Vice-President (Academic) \nThe Purpose of the Proposal is \n(please be specific) \nThe revisions are intended to clarify the policies, elaborate on \nprocedures, and improve policies.  The impact will be to have greater \nclarity for students, faculty and staff in the administration and conduct \nand outcomes of examinations in thesis-based programs. \nThe Impact of the Proposal is The conduct of graduate examinations holds extremely high stakes for \nindividual students and presents significant reputational risk for the \nfaculty, program and institution. A major revision the Supervision and \nStructure of Examining Committees in the Graduate Program Manual \nwas approved by FGSR Council in May 2012. Subsequently in May 2013 \nthe authority for approval of supervisors, supervisory committees, \nexternal examiners and examining committees was delegated to the \ndisciplinary Faculty or department. The changes to the Calendar \ngoverning examinations encompassing both sets of changes was \napproved by FGSR Council October 2013 and first appeared in the \n2014-2015 Calendar.  A number of areas came to light that cause \nproblems due to apparent contradictions, gaps and/or confusing \nlanguage.  The FSGR Policy Review Committee undertook a \ncomprehensive review of the Supervision and Examination regulations.  \nThe resulting proposal addresses the organization and clarity of the \npolicy as well as changes to policy. The significant policy changes \ninclude: \n• The chair of doctoral examinations cannot be an examiner to\nremove issues of bias.\n• One supervisor of a supervisory team must meet the employment\ncriteria of a UofA examiner.\n• Size limits for examination committees are set to prevent\nextraordinarily long examinations in light of current flexibility in\nsupervisory committee composition and the need to fulfill\nexaminer composition balance.\n• A revamped section on “Conduct of Thesis and Candidacy\nExams” was added back to provide consistency across the\nacademy.\n• Guidance was added to the outcome of “Conditional Pass” for\nItem No. 7 \nGENERAL FACULTIES COUNCIL \nFor the Meeting of October 30, 2017 \ndoctoral candidacy examinations to lessen the rates of students \nnot meeting the conditions. \nReplaces/Revises (eg, policies, \nresolutions) \nRevises Supervision and Examinations policy as found in the FGSR \nsection of the Calendar. \nTimeline/Implementation Date Effective July 1, 2018. The changes will be published in the 2018-2019 \nCalendar. \nEstimated Cost and funding \nsource \nn/a \nNext Steps (ie.: \nCommunications Plan, \nImplementation plans) \nUpon final approval, an email will be sent to all members of FGSR \nCouncil that includes all Associate Deans Graduate and Graduate \nCoordinators of graduate programs, as well as the Graduate Program \nadministrators. There will be internal communication to front end FGSR \nstaff. \nSupplementary Notes and \ncontext \nThe GFC Academic Standards Committee discussed the parameters of \nwho can chair candidacy and doctoral examinations. Members \ndiscussed the role of the chair and how the proposed changes would \npreserve neutrality; the importance of having chairs with experience \nsupervising graduate students; and having chairs from outside of the \ndepartment to accommodate small departments. The committee also \nprovided comments on the requirement of a student to withdraw if no \nsupervisor was available. \nEngagement and Routing (Include meeting dates) \nParticipation: \n(parties who have seen the \nproposal and in what capacity) \n<For further information see \nthe link posted on the \nGovernance Toolkit section \nStudent Participation Protocol> \nThose who have been informed: \n•  \nThose who have been consulted: \n• Dean and Associate Deans, FGSR \n• FGSR Program Services staff \n• Graduate Program Administrators Council (GPAC) \n• Faculty Graduate Councils (or equivalents) \n• FGSR Council \n• Graduate Students Association (GSA)—represented on the PRC \n(below), also conducted wider consultation with graduate \nstudents \nThose who are actively participating: \n• FGSR Policy Review Committee (PRC) \n• Brent Epperson, Graduate Ombudsperson (as a member of PRC) \n• Graduate Students Association (GSA)—(represented on PRC \nand FGSR Council) \n• Vice Dean, FGSR \nApproval Route (Governance) \n(including meeting dates) \nFGSR Council, May 17, 2017, approved \nASC-Subcommittee on Standards - June 1, 2017 (for discussion) \nGFC Academic Standards Committee - June 15, 2017 \nGFC Executive Committee - September 11, 2017 \nGeneral Faculties Council - September 25, 2017 \nFinal Approver General Faculties Council \nhttp://www.governance.ualberta.ca/GovernanceToolkit/Toolkit.aspx\nhttp://www.governance.ualberta.ca/GovernanceToolkit/Toolkit.aspx\nItem No. 7 \nGENERAL FACULTIES COUNCIL \nFor the Meeting of October 30, 2017 \nAlignment/Compliance \nAlignment with Guiding \nDocuments \nFor the Public Good \nSustain:  \nGOAL: Sustain our people, our work, and the environment by attracting \nand stewarding the resources we need to deliver excellence to the \nbenefit of all. \n21. OBJECTIVE \nEncourage continuous improvement in administrative, governance, \nplanning, and stewardship systems, procedures, and policies that enable \nstudents, faculty, staff, and the institution as a whole to achieve shared \nstrategic goals. \ni. Strategy: Encourage transparency and improve communication across \nthe university through clear consultation and decision-making processes, \nsubstantive and timely communication of information, and access to \nshared, reliable institutional data. \nii. Strategy: Ensure that individual and institutional annual review \nprocesses align with and support key institutional strategic goals. \niii. Strategy: Consolidate unit review and strategic planning processes, \nand where possible, align with accreditation processes, to ensure \nefficient assessment practices. \niv. Strategy: Facilitate easy access to and use of university services and \nsystems, reduce duplication and complexity, and encourage cross-\ninstitutional administrative and operational collaboration. \nCompliance with Legislation, \nPolicy and/or Procedure \nRelevant to the Proposal \n(please quote legislation and \ninclude identifying section \nnumbers) \n1. Post-Secondary Learning Act (PSLA):  \n“26(1) Subject to the authority of the board of Governors, a general \nfaculties council is responsible for the academic affairs of the university \n[…] \n(3) A general faculties council may delegate any of its powers, duties \nand functions under this Act” \n2. GFC Academic Standard Committee – terms of reference \n“B. Admission and Transfer, Academic Standing, Marking and Grading, \nTerm Work, Examinations, International Baccalaureate (IB), Advanced \nPlacement (AP)   \ni. All proposals from the Faculties or the Administration related to \nadmission and transfer, to the academic standing of students, to \ninstitutional marking and grading policies and/or procedures and to term \nwork policies and procedures are submitted to the Provost and Vice-\nPresident (Academic) (or delegate) who chairs the GFC Academic \nStandards Committee. ASC will consult as necessary with the Faculties \nand with other individuals and offices in its consideration of these \nproposals. “ \n3. UAPPOL Academic Standing Policy: “All current academic \nstanding regulations, including academic standing categories, \nUniversity graduating standards and requirements for all individual \nprograms will be those prescribed by Faculty Councils and GFC as set \nforth in the University Calendar.” \n4. UAPPOL Academic Standing Regulations Procedures: “All \nproposed new academic standing regulations and changes to existing \nacademic standing regulations will be submitted by the Faculties or the \nAdministration to the Provost and Vice-President (Academic). Faculties \nItem No. 7 \nGENERAL FACULTIES COUNCIL \nFor the Meeting of October 30, 2017 \nwill also submit to the Provost and Vice President (Academic) any \nproposed changes to the use and/or computation of averages relating to \nacademic standing, including promotion and graduation. If the Provost \nand Vice-President (Academic) determines the proposal to be in good \norder, the proposal will be introduced to the appropriate University \ngovernance process(es). In considering these proposals, governance \nbodies will consult as necessary with the Faculties and with other \nindividuals and offices. Normally, changes become effective once they \nare approved by GFC or its delegate and are published in the University \nCalendar.” \n5. GFC Executive Committee – terms of reference \n“7. Examinations \n“consider and make decisions on the reports of faculty councils as to the \nappointment of examiners and the conduct and results of examinations \nin the faculties” \n“8. Agendas of General Faculties Council \nGFC has delegated to the Executive Committee the authority to decide \nwhich items are placed on a GFC agenda, and the order in which those \nagenda items appear on each GFC agenda. \n[…] \nThe role of the Executive Committee shall be to examine and debate the \nsubstance of reports or recommendations and to decide if an item is \nready to be forwarded to the full governing body” \nAttachments (each to be numbered 1 - <>) \n1. Proposal for revision to existing Supervision and Examinations policy; changes to be reflected in the 2018-\n2019 Calendar (pages 1-25) \nPrepared by: Janice Hurlburt, Graduate Governance and Policy Coordinator \nPage 1 of 25 \nSeptember 18, 2017 \n2018-2019 University of Alberta Proposed Calendar Graduate Program Changes: Proposal from the \nFaculty of Graduate Studies and Research regarding policy and process for Supervision and \nExaminations. \nCurrent Proposed \nFaculty of Graduate Studies and \nResearch \n[…] \nSupervision and Examinations \nThe minimum requirements for all graduate programs are \nset by the Council of the Faculty of Graduate Studies and \nResearch of the University of Alberta. In this Calendar the \nminimum requirements acceptable are outlined under the \nrespective headings. Students should note that the \nindividual graduate program may impose additional \nrequirements. \nSupervision and Supervisory \nCommittees \nDepartmental Regulations \nDepartments are responsible for preparing a set of \nregulations and guidelines for supervisors and students. \nGuidelines should deal with the selection and functioning \nof supervisors and should outline the joint \nresponsibilities of faculty members and graduate \nstudents. Avenues of appeal open to students who feel \nthey are receiving unsatisfactory supervision should also \nbe specified. \nAppointment of the Supervisor(s) \nEvery student in a thesis-based program is required to \nhave a supervisor. The department that admits a student \nto a thesis-based graduate program is responsible for \nproviding supervision within a subject area in which it \nhas competent supervisors, and in which the student has \nexpressed an interest. \nNormally there is only one supervisor. Departments may \nconsider the appointment of more than one supervisor for \na student. \nImplicit in the admission process is the following: on the \napplicant's part, that there has been an indication of at \nFaculty of Graduate Studies and \nResearch \n[…] \nSupervision and Examinations \nThe minimum requirements for all graduate programs are \nset by the Council of the Faculty of Graduate Studies and \nResearch of the University of Alberta. In this Calendar the \nminimum requirements acceptable are outlined under the \nrespective headings. Students should note that the \nindividual graduate program may impose additional \nrequirements. \nSupervision and Supervisory \nCommittees \nDepartmental Regulations and Responsibilities \nDepartments are responsible for preparing a set of \nregulations and guidelines for supervisors and students. \nGuidelines should deal with the selection and functioning \nof supervisors and should outline the joint \nresponsibilities of faculty members and graduate \nstudents. Options for students to pursue who believe they \nare receiving unsatisfactory supervision should also be \nspecified. \nAppointment of the Supervisor(s) \nEvery student in a thesis-based program is required to \nhave a supervisor. The department that admits a student \nto a thesis-based graduate program is responsible for \nproviding supervision within a subject area in which it \nhas competent supervisors, and in which the student has \nexpressed an interest. \nNormally there is only one supervisor. Departments may \nconsider the appointment of more than one supervisor for \na student. \nImplicit in the admission process is the following: on the \napplicant's part, that there has been an indication of at \nAttachment 1\nPage 2 of 25 \nleast a general area of interest and, preferably, provision \nof some form of proposal, particularly if the program is at \nthe doctoral level; on the department's part, that the \napplication has been reviewed, the area of interest \nexamined, academic expectations and potential \nperformance considered, and that the department accepts \nits obligation to provide appropriate supervision for the \napplicant in the specified subject area. \nIt is expected that every effort will be made to arrive at a \nmutually agreeable arrangement for supervision between \nthe student and the department. Students are normally \ninvolved in the process for selecting their supervisor(s) \nalthough this process varies from program to program. \nWhen the department is making arrangements for the \nappointment of supervisors, supervisory committees, and \nexamining committees, or for the scheduling of meetings \nand examinations, the student shall be consulted and kept \ninformed, but the student shall not be asked to conduct \nsuch organizational activities. \nThe authority for the appointment of supervisors, and \nfinal examining committees rests with the Dean of the \ndepartment's Faculty, while the authority for the \nappointment of supervisory committees and doctoral \ncandidacy examining committees rests with the \ndepartment. Such appointment decisions are final and \nnonappealable. \nArticle 7.02.1 of the Faculty Agreement lists the \n\"supervision of graduate students\" as a form of \n\"participation in teaching programs\". It is expected that a \ndepartment will monitor and review the performance of \nsupervisors. \nSupervisors on Leave \nIt is the responsibility of supervisors to make adequate \nprovision for supervision of their graduate students \nduring their leave. Therefore, if a supervisor is to be \nabsent from the University for a period exceeding two \nmonths, it is the supervisor's responsibility to nominate \nan adequate interim substitute and to inform the student \nand the department. \nSupervisors planning to take a sabbatical should follow \nthe requirements found in Appendix E of the Faculty \nAgreement with respect to adequate advance \narrangements for graduate students while a supervisor is \non sabbatical. \nEligibility for Appointment as Supervisor \nleast a general area of interest and, preferably, provision \nof some form of proposal, particularly if the program is at \nthe doctoral level; on the department's part, that the \napplication has been reviewed, the area of interest \nexamined, academic expectations and potential \nperformance considered, and that the department accepts \nits obligation to provide appropriate supervision for the \napplicant in the specified subject area. \nIt is expected that every effort will be made to arrive at a \nmutually agreeable arrangement for supervision between \nthe student and the department. Students are normally \ninvolved in the process for selecting their supervisor(s) \nalthough this process varies from program to program. \n[moved to Committee and Exam Sections] \nThe authority for the appointment of supervisors rests \nwith the Dean of the department's Faculty. Such \nappointment decisions are final and non-appealable. \n[the other statements have been moved to appropriate \nsections under Size and Composition of Examining \nCommittees] \nArticle 7.02.1 of the Faculty Agreement lists the \n\"supervision of graduate students\" as a form of \n\"participation in teaching programs\". It is expected that a \ndepartment will monitor and review the performance of \nsupervisors. \nSupervisors on Leave \nIt is the responsibility of supervisors to make adequate \nprovision for supervision of their graduate students \nduring their leave. Therefore, if a supervisor is to be \nabsent from the University for a period exceeding two \nmonths, it is the supervisor's responsibility to nominate \nan adequate interim substitute or indicate the means by \nwhich supervision will be maintained. It is the \nsupervisor’s responsibility to inform the student and the \ndepartment in writing at the time the leave is approved. \nSupervisors planning to take a sabbatical should follow \nthe requirements found in Appendix E of the Faculty \nAgreement with respect to adequate advance \narrangements for graduate students while a supervisor is \non sabbatical. \nEligibility for Appointment as Supervisor \nPage 3 of 25 \nEach of the following criteria must be met by at least one \nof the supervisor(s): \n1. be a tenured, tenure-track, or retired faculty \nmember, or a Faculty Service Officer, of the \nUniversity of Alberta (current or retired \ncategories A1.1, A1.3, or current category C1.1, as \ndefined in the University's Recruitment Policy \n(Appendix A) Definition and Categories of \nAcademic Staff and Colleagues); \n2. be active in the general subject area of the \nstudent's research;. \n3. demonstrate continuing scholarly or creative \nactivity of an original nature; \nand \n4. either hold a degree equivalent to or higher than \nthat for which the student is a candidate, or have \na demonstrated record of successfully \nsupervising students for the degree. \nIf one of conditions (1)-(4) is not satisfied by any of the \nproposed supervisors, then a departmental justification \n(with the proposed supervisors' CV) is put forward to the \nDean of the department's Faculty for approval. \nFor supervisors from outside the University of Alberta, \nworking with a supervisor at the University of \nAlberta, there should be an indication of the means by \nwhich meaningful interaction can be maintained. \nTime Line for the Appointment of \nSupervisors and Introductory Meetings \nIdeally, the supervisor for a thesis-based student, both \nmaster's and doctoral, should be appointed as soon as the \nstudent arrives to begin their program of studies. If this is \nnot possible, an interim academic advisor may be \nappointed by the department. Supervisor(s) must be \nappointed within the first 12 months of the student's \nprogram following the procedures approved by the Dean \nof the department's Faculty.  \nEvery department must develop a list of topics that will \nbe covered during the introductory meetings between a \nsupervisor and a graduate student. These meetings \nshould be held during the term in which a supervisor is \nfirst appointed. Topics likely to be listed include program \nrequirements, academic integrity requirements, the role \nof the supervisor, the preferred means of communication, \nthe availability or non-availability of funding, and \nscholarly practices and outputs.  \nEach of the following criteria must be met by at least one \nof the supervisor(s): \n1. be a tenured, tenure-track, or retired faculty \nmember, or a Faculty Service Officer, of the \nUniversity of Alberta (current or retired \ncategories A1.1, A1.3, or current category C1.1, as \ndefined in the University's Recruitment Policy \n(Appendix A) Definition and Categories of \nAcademic Staff and Colleagues); \n2. be active in the general subject area of the \nstudent's research; \n3. demonstrate continuing scholarly or creative \nactivity of an original nature; \nand \n4. either hold a degree equivalent to or higher than \nthat for which the student is a candidate, or have \na demonstrated record of successfully \nsupervising students for the degree. \nIf one of conditions (2)-(4) is not satisfied by any of the \nproposed supervisors, then a departmental justification \n(with the proposed supervisors' CV) is put forward to the \nDean of the department's Faculty for approval. \nFor supervisors from outside the University of Alberta, \nworking with a supervisor at the University of Alberta, the \nmeans by which meaningful interaction can be \nmaintained should be specified in writing to the student \nand the department. \nTime Line for the Appointment of Supervisors  \nIdeally, the supervisor for a thesis-based student, both \nmaster's and doctoral, should be appointed as soon as the \nstudent arrives to begin their program of studies. If this is \nnot possible, an interim academic advisor should be \nappointed by the department. Supervisor(s) must be \nappointed within the first 12 months of the student's \nprogram following the procedures approved by the Dean \nof the department's Faculty and submitted to FGSR.  \nIntroductory Meetings  \nEvery department must develop a list of topics that will \nbe covered during the introductory meetings between a \nsupervisor and a graduate student. These meetings \nshould be held during the term in which a supervisor is \nfirst appointed. Topics likely to be listed include program \nrequirements, academic integrity requirements, the role \nof the supervisor, the composition of the supervisory \ncommittee, the preferred means of communication, the \navailability of funding, and scholarly practices and \noutputs.  \nPage 4 of 25 \n[Moved from just before The Roles and Structure of \nExamining Committees ] \nResolving Conflicts in Supervisor-Student \nRelationships   \nThe relationship between students and supervisors is \nnormally close and long-lasting. At times, conflicts may \narise between a student and the supervisor. In such cases, \nthe first step must be to try to resolve the \nmisunderstanding or conflict informally. This is more \nlikely to be successful if attended to as early as possible. \nThe supervisor and student should discuss the problem \ntogether. The supervisor should document the \ndiscussions and keep a record of any agreements made. \nThis document should be shared with the student. In the \nevent of a conflict that cannot be resolved, the graduate \ncoordinator should be consulted as early as possible by \nthe parties involved. \nIt is the responsibility of the graduate coordinator to \narrange for consultation and mediation. The graduate \ncoordinator or the parties involved may request advice \nand/or mediation assistance from their Faculty, the FGSR, \nand/or other appropriate services, such as the Student \nOmbudservice. The student and supervisors shall not be \nrequired to participate in informal resolution. \nIf informal resolution is unsuccessful or \ninappropriate, and the graduate coordinator determines \nthat the supervisor-student relationship is beyond repair, \nthe department will attempt in good faith to work with \nthe student to find alternative supervision within the \ndepartment, and inform the FGSR of these efforts in \nwriting. \nWhere the supervisor has been providing funding to the \nstudent, the funding should continue for a period of at \nleast 30 days from the date on which the graduate \ncoordinator determines that the supervisor-student \nrelationship is beyond repair. \nIf the best arrangements of the department and the FGSR \nfail to meet the expectations of the student, the student \nmay choose to withdraw without prejudice. If the student \nrefuses to accept the supervision provided, or if no \nsupervision can be secured, then the student is not \nfulfilling the academic requirement of having a supervisor \nand may, on academic grounds, be required to withdraw. \nResolving Conflicts in Supervisor-Student \nRelationships   \nThe relationship between students and supervisors is \nnormally close and long-lasting. At times, conflicts may \narise between a student and the supervisor. In such cases, \nthe first step should be to try to resolve the \nmisunderstanding or conflict informally. This is more \nlikely to be successful if attended to as early as possible. \nThe supervisor and student should discuss the problem \ntogether. The supervisor should document the \ndiscussions and keep a record of any agreements made. \nThis document should be shared with the student. In the \nevent of a conflict that cannot be resolved, the graduate \ncoordinator should be consulted as early as possible by \nthe parties involved. \nIt is the responsibility of the graduate coordinator to \narrange for consultation and mediation. The graduate \ncoordinator or the parties involved may request advice \nand/or mediation assistance from their Faculty, the FGSR, \nand/or other appropriate services such as the Student \nOmbudservice. The student and supervisors shall not be \nrequired to participate in informal resolution. \nIf informal resolution is unsuccessful or inappropriate \nand the graduate coordinator determines that the \nsupervisor-student relationship is beyond repair, the \ndepartment will attempt in good faith to work with the \nstudent to find alternative supervision within the \ndepartment and  inform the FGSR of these efforts in \nwriting. \nWhere the supervisor has been providing funding to the \nstudent, the funding should continue for a period of at \nleast 30 days from the date on which the graduate \ncoordinator determines that the supervisor-student \nrelationship is beyond repair. \nIf the best arrangements of the department and the FGSR \nfail to meet the expectations of the student, the student \nmay choose to withdraw without prejudice. If the student \nrefuses to accept the supervision provided, or if no \nsupervision can be secured, then the student is not \nfulfilling the academic requirement of having a supervisor \nand may, on academic grounds, be required to withdraw. \nPage 5 of 25 \nSupervisory Committees \nThesis-based master's students \nEvery thesis-based master's student must have a \nsupervisor. It is not a University requirement for master's \nstudents to have a supervisory committee; however, some \ngraduate programs may require them. As ex-officio \nmembers of the master's final examining \ncommittee, departments should ensure that the members \nof the supervisory committee meet the eligibility criteria \nas examiners. \nDoctoral students \nEvery doctoral student's program shall be under the \ndirection of a supervisory committee approved by the \ndepartment. A doctoral supervisory committee must have \nat least three members, and must include all the \nsupervisors. As ex-officio members of the candidacy and \nthe doctoral final examining committees, all members of \nthe supervisory committee must meet the eligibility \ncriteria for examiners. \n[moved from below] \n The supervisory committee is chaired by one of the \nsupervisors. \nCompliance with the University of Alberta's Conflict \nPolicy - Conflict of Interest and Commitment, and \nInstitutional Conflict - is mandatory. \nThe committee will arrange for the necessary \nexaminations and for adjudication of the thesis. The \ncommittee shall have a formal regular meeting with the \nstudent at least once a year. \nThe department should ensure that the members of a \nsupervisory committee are sufficiently competent and \nexperienced to serve at the required level. In forming a \nSupervisory Committees \nThesis-based master's students \nIt is not a University requirement for master's students to \nhave a supervisory committee; however, some graduate \nprograms require them. If required by the program, the \nsupervisory committee members are ex-officio members \nof the master's final examining committee. Attention \nshould be paid to the qualifications of the committee \nmembers as examiners to ensure the composition and \nsize of the examination committee will be appropriate.   \nDoctoral students \nEvery doctoral student's program shall be under the \ndirection of a supervisory committee approved by the \ndepartment.  \nA doctoral supervisory committee must have at least \nthree members, and must include all the supervisors.   \nThe department should ensure that the members of a \nsupervisory committee are sufficiently competent and \nexperienced to serve at the required level. In forming a \nsupervisory committee, the department should consider \nthe rank and experience of the prospective members, \ntheir publications and other demonstrations of \ncompetence in the subject area or field of specialization, \nand the prospective members' experience in graduate \nsupervision.  \nAttention should be paid to the qualifications of the \ncommittee members as examiners to ensure the \ncomposition of the examination committee will be \nappropriate as they are ex-officio members of doctoral \nexamining committees.   \nThe supervisory committee is chaired by one of the \nsupervisors. \nCompliance with the University of Alberta's Conflict \nPolicy - Conflict of Interest and Commitment, and \nInstitutional Conflict - is mandatory. \nThe supervisor is responsible for ensuring committee \nmeetings are held and making arrangements. The \ncommittee shall have a formal regular meeting with the \nstudent at least once a year.  The department should \nmaintain a record of meetings that have occurred and \nwhen students who are not on an approved leave fail to \nrespond to requests to schedule a committee meeting. \n[Moved above] \nhttps://policiesonline.ualberta.ca/PoliciesProcedures/Policies/Conflict-Policy--Conflict-of-Interest-and-Commitment-and-Institutional-Conflict.pdf\nhttps://policiesonline.ualberta.ca/PoliciesProcedures/Policies/Conflict-Policy--Conflict-of-Interest-and-Commitment-and-Institutional-Conflict.pdf\nhttps://policiesonline.ualberta.ca/PoliciesProcedures/Policies/Conflict-Policy--Conflict-of-Interest-and-Commitment-and-Institutional-Conflict.pdf\nhttps://policiesonline.ualberta.ca/PoliciesProcedures/Policies/Conflict-Policy--Conflict-of-Interest-and-Commitment-and-Institutional-Conflict.pdf\nPage 6 of 25 \nsupervisory committee, the department should consider \nthe rank and experience of the prospective members, \ntheir publications and other demonstrations of \ncompetence in the subject area or field of specialization, \nand the prospective members' experience in graduate \nsupervision. \nFor doctoral students, the department shall appoint the \nsupervisory committee well in advance of the candidacy \nexamination. \nResolving Conflicts in Supervisor-Student \nRelationships  \nThe relationship between students and supervisors is \nnormally close and long-lasting. At times, conflicts may \narise between a student and the supervisor. In such cases, \nthe first step must be to try to resolve the conflict or \nmisunderstanding informally. This is more likely to be \nsuccessful if attended to as early as possible. The \nsupervisor and student should discuss the problem \ntogether. The supervisor should document the \ndiscussions and keep a record of any agreements made. In \nthe event of a conflict the graduate coordinator should be \nnotified as early as possible. \nIt is the responsibility of the graduate coordinator to \narrange for consultation and mediation. The graduate \ncoordinator or the parties involved may request advice \nand/or mediation assistance from their Faculty, the FGSR, \nand/or other appropriate services, such as the Student \nOmbudservice. The student and supervisors shall not be \nrequired to participate in informal resolution against \ntheir wishes if either party's behaviour towards the other \nwarrants a complaint under the Code of Student \nBehaviour, the Discrimination and Harassment Policy, or \nother University policy. \nIf informal resolution is unsuccessful or inappropriate, \nand the graduate coordinator determines that the \nsupervisor-student relationship is beyond repair, the \ndepartment will attempt in good faith to work with the \nstudent to find alternative supervision within the \ndepartment, and will keep the FGSR apprised of these \nefforts. \nWhere the supervisor has been providing funding to the \nstudent, the funding should continue for a period of at \nleast 30 days from the date on which the graduate \ncoordinator determines that the supervisor-student \nrelationship is beyond repair. \nIf the best arrangements of the department and the FGSR \nfail to meet the expectations of the student, the student \nmay choose to withdraw without prejudice. If the student \nrefuses to accept the supervision provided, or if no \nFor doctoral students, the department shall appoint the \nsupervisory committee well in advance of the candidacy \nexamination. \n[Moved above to just before Supervisory \nCommittees] \nPage 7 of 25 \nsupervision can be secured, then the student is not \nfulfilling the academic requirement of having a supervisor \nand may, on academic grounds, be required to withdraw. \nThe Structure of Examining Committees  \nFormal examining committees are required for thesis-\nbased master’s final examination, doctoral candidacy \nexaminations, and doctoral final examinations. Members \nof these examining committees perform two functions: 1) \nthey bring disciplinary knowledge and expertise to the \nassessment of the thesis, and 2) they ensure that the \nUniversity’s expectations are met regarding the conduct \nof the examination, adherence to all relevant policies, and \nthe suitability of the thesis for the degree.  \nThe Chair  \nEvery examining committee must have a chair who is not \na supervisor but is a member of the student’s home \ndepartment. The chair should have sufficient experience \nof graduate examinations to be able to allow the \nexamination to be conducted in a fair manner, and is \nresponsible for moderating the discussion and directing \nquestions. It is the chair’s responsibility to ensure that \ndepartmental and FGSR regulations relating to the final \nexamination are followed. If the chair is not an examiner, \nthen the chair does not vote.  \nThe FGSR encourages, and for doctoral examinations \nstrongly recommends, that committee chairs not be \nexaminers.  \nExaminers  \nExaminers are full voting members of the examining \ncommittee. With the exception of the Dean, FGSR, the \nDean of the department’s Faculty, or a Pro Dean (Dean’s \nrepresentative), who may participate fully in the \nexamination, persons other than the examiners may \nattend only with the prior approval of the Dean, FGSR, the \nDean of the department’s Faculty, or the chair of the \nexamining committee. With the possible exception of the \nPro Deans, all examiners must be either active in the \ngeneral subject area of the student’s research, or bring \nrelevant expertise to the assessment of the thesis.  \nThe Role and Structure of Examining \nCommittees  \nFormal examining committees are required for thesis-\nbased master’s final examination, doctoral candidacy \nexaminations, and doctoral final examinations. Members \nof these examining committees perform two functions: 1) \nthey bring knowledge and expertise to the assessment of \nthe thesis, and 2) they ensure that the University’s \nexpectations are met regarding the conduct of the \nexamination, adherence to all relevant policies, and the \nsuitability of the thesis for the degree.  \nThe Chair  \nEvery examining committee must have a chair who is not \nthe supervisor and is a faculty member with experience \nsupervising graduate students. The chair should have \nsufficient experience of graduate examinations to be able \nto allow the examination to be conducted in a fair \nmanner. The chair is responsible for moderating the \ndiscussion and directing questions. It is the chair’s \nresponsibility to ensure that departmental and FGSR \nregulations relating to the final examination are followed. \nIf the chair is not an examiner, then the chair does not \nvote.  \nThe committee chair is not an examiner for doctoral \nexaminations.  See Size and Composition of Examining \nCommittees for the requirements for each examination.  \nThe chair should not have real or apparent conflict of \ninterest with the student or any of the examiners.  \nExaminers  \nExaminers are full voting members of the examining \ncommittee. All examiners must be either active in the \ngeneral subject area of the student’s research or bring \nrelevant expertise to the assessment of the thesis.  \n[Deleted sentences already found under Attendance at \nExaminations, below] \nCategories of Examiners and Eligibility \nThere are four types of examiners: ex-officio examiner, \narm’s length examiner, University of Alberta examiner \nand External examiner. \nPage 8 of 25 \nArm’s Length Examiners  \nAn arm’s length examiner must not be (or have been) a \nmember of the supervisory committee, or have been \nconnected with the thesis research in a significant way.  \nThe examiner should not have been associated with the \nstudent, outside of usual contact in courses or other non-\nthesis activities within the University, nor be related to \nthe student or supervisor(s).  \nExcept in special circumstances (fully justified in writing \nto the Dean of the department’s Faculty), an arm’s length \nexaminer should not be a close collaborator of the \nsupervisor(s) within the last six years.  \nArm’s length examiners who have served on a student’s \ncandidacy examination committee do not lose their arm’s \nlength status as a result, and are eligible to serve as arm’s \nlength examiners on the student’s doctoral final \nexamination if the other conditions of being arm’s length \nremain unchanged.  \nIn the case of a doctoral final examination, the required \nExternal (i.e., the arm’s length examiner from outside the \nUniversity of Alberta) is, by definition, an arm’s length \nexaminer. \nEvery examining committee requires a minimum number \nof arm’s length examiners: At least one for a master’s final \nexamination, at least two for a candidacy examination, \nand at least two for a doctoral final examination. \nCompliance with the University of Alberta’s Conflict Policy \n- Conflict of Interest and Commitment, and Institutional \nConflict is mandatory.  \nEx-Officio Examiners  \nThe supervisor(s), and, for doctoral students, the other \nmembers of the student’s supervisory committee, are ex-\nofficio members of the examining committee.  \nEx-officio Examiners \nThe supervisor(s) and, for doctoral students, the other \nmembers of the student’s supervisory committee are ex-\nofficio members of the examining committee. \nBy definition, no individual can be both an ex-officio and \nan arm’s length examiner on the same examining \ncommittee. \nArm’s Length Examiners  \nAn arm’s length examiner is knowledgeable in the field \nand comes fresh to the examination. They must not be (or \nhave been) a member of the supervisory committee, or \nhave been connected with the thesis research in a \nsignificant way. The examiner should not have been \nassociated with the student, outside of usual contact in \ncourses or other non-thesis activities within the \nUniversity, nor be related to the student or supervisor(s).  \nThe arm’s length examiners should not be a former \nsupervisor or student of the supervisor(s). \nExcept in special circumstances (fully justified in writing \nto the Dean of the department’s Faculty), an arm’s length \nexaminer should not be an active collaborator of the \nsupervisor(s) (see Conflict of Interest Guidelines, below ) \nArm’s length examiners who have served on a student’s \ncandidacy examination committee do not lose their arm’s \nlength status as a result, and are eligible to serve as arm’s \nlength examiners on the student’s doctoral final \nexamination if the other conditions of being arm’s length \nremain unchanged.  \nExternal Examiner \nAn external examiner from outside the University of \nAlberta is required for doctoral thesis examinations. In \naddition to being an arm’s length examiner this examiner \nmust fulfill additional criteria as described under “Final \nDoctoral Examination … Inviting the External Examiner or \nReader” in the Calendar. \n[Moved above] \nPage 9 of 25 \n[Moved from below] \n[Restored from earlier Calendar wording and revised] \nMinimum Membership Requirements for \nExamining Committees  \nAt least half of the examiners on every examining \ncommittee must have a degree which is equivalent to, or \nhigher than, the degree being examined.  \nAt least half of the examiners on every examining \ncommittee must be tenured, tenure-track, or retired \nUniversity of Alberta faculty members, or Faculty Service \nOfficers, (current or retired categories A1.1, A1.3, or \ncurrent category C1.1, as defined in the University of \nAlberta’s Recruitment Policy (Appendix A) Definition and \nCategories of Academic Staff and Colleagues).  \nMinimum Size of an Examining Committee  \nBy definition, no individual can be both an arm’s length \nexaminer and an ex-officio examiner on the same \nexamining committee.  \nThe minimum size of a master’s final examining \ncommittee is three. This minimum size condition is \nautomatically met except when the student has one \nsupervisor, no supervisory committee, and there is only \none arm’s length examiner on the examining committee. \nIn this case, the examining committee requires at least \none more examiner.  \nUniversity of Alberta Examiners \nThe University of Alberta examiner is a tenured, tenure-\ntrack, or retired University of Alberta faculty member, or \nFaculty Service Officer, (current or retired categories \nA1.1, A1.3, or current category C1.1, as defined in the \nUniversity of Alberta’s Recruitment Policy (Appendix A) \nDefinition and Categories of Academic Staff and \nColleagues). \nConflict of Interest Guidelines  for \nSupervisory and Examination Committees \nThe key relationships are: the supervisor to the student; \nthe supervisor to the other committee members; and the \nstudent to the committee members. There must be no \nconflict of interest in these relationships, as defined by \nthe University of Alberta policy.  Any personal or \nprofessional relationships that alter or affect this \nacademic relationship may constitute a conflict of \ninterest.  \nIt is a best practice to request examiners and the chair \ndeclare any potential conflicts of interest prior to \napproval of the examination committee. Where potential \nconflicts-of-interest emerge, the matter may be referred \nto an Associate Dean at FGSR for advice on how to best \nmanage unavoidable conflicts of interest. \nSize and Composition of Examining Committees \nFor all examination committees, Aat least half of the \nexaminers must have a degree equivalent to or higher \nthan the degree being examined.  \nFor all examination committees, at least half of the \nexaminers must fulfill the criteria as a University of \nAlberta examiner as tenured, tenure-track, or retired \nUniversity of Alberta faculty members, or Faculty Service \nOfficers (see above under Categories of Examiners and \nEligibility).  \n[Moved above under Categories of Examiners and \nEligibility] \nMaster’s Thesis Examination Committee \n• The minimum size of a master’s final examining \ncommittee is three examiners. The maximum size \nis five examiners. \n• The ex officio members of the committee are the \nsupervisor(s) and the supervisory committee \nhttps://policiesonline.ualberta.ca/PoliciesProcedures/Policies/Conflict-Policy--Conflict-of-Interest-and-Commitment-and-Institutional-Conflict.pdf\nPage 10 of 25 \n[Moved here from The Appointment of the Supervisor(s)] \nFor doctoral candidacy and doctoral final \nexaminations, the minimum size of the \nexamining committee is five.  \n[Moved here from The Appointment of the Supervisor(s)] \nmembers if there is a committee. \n• There must be one arm’s length examiner. \n• At least half of the examiners must hold a \nmaster’s degree or higher (see above). \n• At least half of the examiners must fulfill the \ncriteria of University of Alberta examiner (see \nabove) \n• The chair is not the supervisor. The chair is a \nfaculty member in the student’s home \ndepartment or with experience chairing master’s \nexaminations. The FGSR recommends that \ncommittee chairs not be examiners except in \nextenuating circumstances where any conflict of \ninterest in this role be managed transparently for \nthe student. \nThe authority for the appointment of final examining \ncommittees rests with the Dean of the department’s \nFaculty [unless delegated to the department]. \nDoctoral Candidacy Examination Committee \n• The minimum size of a doctoral candidacy \ncommittee is five examiners. The maximum size \nis seven examiners. \n• The ex officio members of the committee are the \nsupervisor(s) and the supervisory committee \nmembers. \n• There must be two arm’s length examiners. \n• At least half or more of the examiners must hold a \ndoctoral degree or higher (see above). \n• At least half of the examiners must fulfill the \ncriteria of University of Alberta examiner (see \nabove) \n• The chair is not an examiner. The chair is a \nfaculty member in the student’s home \ndepartment or with experience chairing doctoral \nexaminations  \nThe authority for the appointment of doctoral candidacy \nexamining committees rests with the department.  \nDoctoral Thesis Examination Committee \n• The minimum size of a doctoral final examining \ncommittee is five examiners. The maximum size \nis seven examiners. \n• The ex officio members of the committee are the \nsupervisor(s) and the supervisory committee \nmembers. \n• There must be two arm’s length examiners, one \nof whom must be a reader or examiner external \nto the University  \n• At least half of the examiners must hold a \ndoctoral degree or higher (see above). \n• At least half of the examiners must fulfill the \ncriteria of University of Alberta examiner (see \nPage 11 of 25 \n[Moved here from The Appointment of the Supervisor(s)] \nConduct of Examinations  \nCommon Examination Protocols  \nAttendance at Examinations: In the absence of \nunforeseen circumstances, it is essential that all \nexaminers attend the entire examination. Attendance \nmeans participation in the examination either in person \nor via Teleconferencing (see below). The only exception \nallowed is the External Reader for a doctoral final \nexamination, who participates by providing a detailed \nreport and a list of questions.  \nIf the department has warning that any member of the \nexamining committee cannot attend the examination, the \ndepartment should contact the Dean of the FGSR for \nadvice. The situation will be dealt with on a case-by-case \nbasis, but it may be necessary that the examination be \npostponed and rescheduled, or the examiner be replaced.  \nExcept for the Dean, FGSR, the Dean of the department’s \nFaculty, or a Pro Dean (the representative of the Dean, \nFGSR), who may participate fully in the examination, \npersons other than the examiners may attend only with \nthe approval of the Dean, FGSR, the Dean of the \ndepartment’s Faculty, or the chair of the committee.  \nAttendance and Responsibilities of a Pro Dean at \nExaminations: A Pro Dean is a full voting member when \nattending an examination. The Pro Dean’s presence is in \naddition to the regular membership. Attendance of the \nPro Dean may be at the request of a committee member, \nstudent, chair, graduate coordinator, the Dean of the \ndepartment’s Faculty, or the Dean, FGSR.  \nThe Pro Dean’s role is to ensure the proper conduct of the \nexamination and will intercede actively to correct \nprocedural problems. The Pro Dean has the power to \nadjourn an examination. If problems are encountered, the \nPro Dean is asked to submit a brief report to the Dean, \nFGSR.  \nTeleconferencing Guidelines for Examinations: The \nterm ‘teleconferencing’ is used here generically to include \nall forms of distance conference facilitation including \ntelephone, video and electronic communication. \nDepartments may wish to use teleconferencing for one or \nmore of the examiners (including the External). It is \nabove) \n• The chair is not an examiner. The chair is a \nfaculty member in the student’s home \ndepartment or with experience chairing doctoral \nexaminations.  \nThe authority for the appointment of final examining \ncommittees rests with the Dean of the department’s \nFaculty [unless delegated to the department]. \nConduct of Examinations  \nCommon Examination Protocols  \nAttendance at Examinations: In the absence of \nunforeseen circumstances, it is essential that all \nexaminers attend the entire examination. Attendance \nmeans participation in the examination either in person \nor via Teleconferencing (see below). The only exception \nallowed is the External Reader for a doctoral final \nexamination, who participates by providing a detailed \nreport and a list of questions.  \nIf the department has warning that any member of the \nexamining committee cannot attend the examination, the \ndepartment should contact the Dean of the FGSR for \nadvice. The situation will be dealt with on a case-by-case \nbasis, but it may be necessary that the examination be \npostponed, or the examiner replaced.  \nThe Dean, FGSR, the Dean of the department’s Faculty, or \na Pro Dean (the representative of the Dean, FGSR) may \nparticipate fully in the examination. Persons other than \nthe examiners may attend only with the approval of the \nDean, FGSR, the Dean of the department’s Faculty, or the \nchair of the committee.  \nResponsibilities of a Pro Dean at Examinations: A Pro \nDean is a full voting member when attending an \nexamination. The Pro Dean’s presence is in addition to the \nregular membership. Attendance of the Pro Dean may be \nat the request of a committee member, student, chair, \ngraduate coordinator, the Dean of the department’s \nFaculty, or the Dean, FGSR.  \nThe Pro Dean’s role is to ensure the proper conduct of the \nexamination and will intercede actively to correct \nprocedural problems. The Pro Dean has the power to \nadjourn an examination. If problems are encountered, the \nPro Dean is asked to submit a brief report to the Dean, \nFGSR.  \nTeleconferencing Guidelines for Examinations: The \nterm ‘teleconferencing’ is used here generically to include \nall forms of distance conference facilitation including \ntelephone, video and synchronous electronic \ncommunication. Departments may wish to use \nPage 12 of 25 \nrecommended that no more than two participants use \nteleconferencing. Teleconferencing may be used for \nmaster’s or doctoral examinations. Examiners \nparticipating in examinations by this means are \nconsidered to be in attendance.  \nStudents must attend their candidacy examinations in \nperson. In exceptional circumstances, for the final \nexaminations, students may participate by \nteleconferencing. It is recommended that if the student is \nthe remote participant, no remote committee members be \nused.  \nUse of teleconferencing must be submitted for approval to \nthe Dean of the department’s Faculty at the time the \nexamination committee is approved, following the \nFaculty’s established procedures.  \nTimelines and Approval of the Examining Committee: \nIt is the responsibility of the department to nominate the \nmembers of the examining committee following the \nprocedures established by the Dean of the department’s \nFaculty using the Forms available on the FGSR website \nThe notice of final approval must be received by the FGSR \nat least two weeks in advance of the examination to be \ncoded into the system.  \nScheduling of Examinations: It is the responsibility of \nthe supervisor(s) to ensure that:  \n1. proper arrangements are made for the student’s \nexamination,  \n2. the exam is scheduled and held in accordance \nwith FGSR and departmental regulations,  \n3. committee members are informed of meetings \nand details of examinations  \n4. the student does not make these arrangements,  \n5. the student provides copies of the thesis \n(master’s and doctoral final examination) to \nthe examiners at least three weeks before the \nexamination. Note that the External for a doctoral \nfinal examination must receive a copy of the \nthesis at least four weeks before the examination.  \nIn the absence of the supervisor, the department’s \ngraduate coordinator or designate shall be responsible for \nthese arrangements.  \nChanging an Examining Committee Member: Changes \nto the membership of the Examining Committee \nmust occur following the procedures established by the \nDean of the department’s Faculty.  \nteleconferencing for one or more of the examiners \n(including the External). No more than two \nparticipants may attend by teleconference. \nTeleconferencing may be used for master’s or doctoral \nexaminations. Examiners participating in examinations by \nthis means are considered to be in attendance.  \n Students must attend their candidacy examinations in \nperson. In exceptional circumstances, for the final \nexaminations, students may participate by \nteleconferencing. It is recommended that if the student is \nthe remote participant, no remote committee members be \nused.  \nUse of teleconferencing must be submitted for approval to \nthe Dean of the department’s Faculty at the time the \nexamination committee is approved, following the \nFaculty’s established procedures.  \nTimelines and Approval of the Examining Committee: \nIt is the responsibility of the department to nominate the \nmembers of the examining committee following the \nprocedures established by the Dean of the department’s \nFaculty using the Forms available on the FGSR website \nThe notice of final approval must be received by the FGSR \nat least two weeks in advance of the examination to be \ncoded into the system.  \nScheduling of Examinations: It is the responsibility of \nthe supervisor(s) to ensure that:  \n1. proper arrangements are made for the student’s \nexamination,  \n2. the exam is scheduled and held in accordance \nwith FGSR and departmental regulations,  \n3. committee members are informed of meetings \nand details of examinations  \n4. the student does not make these arrangements,  \n5. the student provides a copy of the thesis \n(master’s and doctoral final examination) to \nthe individual delegated by the program to \ndistribute the thesis to the examiners (ex. chair of \nthe examination, program administrator, \nsupervisor). The supervisor is responsible for \nensuring that all examiners receive the thesis in a \ntimely way. All examiners for a doctoral final \nexamination must receive a copy of the thesis at \nleast four weeks before the examination.  \nIn the absence of the supervisor, the department’s \ngraduate coordinator or designate shall be responsible for \nthese arrangements.  \nChanging an Examining Committee Member: Changes \nto the membership of the Examining Committee must \nfollow the procedures established by the Dean of the \ndepartment’s Faculty.  \nPage 13 of 25 \nLanguage of Examinations: The language used to \nconduct examinations shall be English, except where \nalready approved by the FGSR Council. However, the \nexamining committee may petition the Dean of the FGSR, \nand on receiving written approval, may conduct the \nexamination in a language other than English.  \nTime Limit for Submission of Theses to FGSR: \nFollowing completion of the final examination at which \nthe thesis is passed or passed subject to revisions, the \nstudent shall make the appropriate revisions where \nnecessary and submit the approved thesis to the FGSR \nwithin six months of the date of the final examination. \nDepartments may impose earlier deadlines for submitting \nrevisions.  \nIf the thesis is not submitted to the FGSR within the six-\nmonth time limit, the student will be considered to have \nwithdrawn from the program. After this time, the student \nmust apply and be readmitted to the FGSR and register \nagain before the thesis can be accepted. If the final \nexamination is adjourned, the six-month time limit will \ntake effect from the date of completion of the examination \nwhere the thesis was passed with or without revisions.  \nIn order to convocate, all thesis-based students must \nsubmit their thesis to the FGSR and have it approved \nbefore they can be cleared for convocation. The thesis \ncannot be approved without a valid student registration \nat the time of approval.  \nLanguage of Examinations: The language used to \nconduct examinations shall be English, except where \nalready approved by the FGSR Council. However, the \nexamining committee may petition the Dean of the FGSR, \nand on receiving written approval, may conduct the \nexamination in a language other than English.  \nTime Limit for Submission of Theses to FGSR: \nFollowing completion of the final examination at which \nthe thesis is passed or passed subject to revisions, the \nstudent shall make any necessary revisions and submit \nthe approved thesis to the FGSR within six months of the \ndate of the final examination. Departments may impose \nearlier deadlines for submitting revisions.  \nIf the thesis is not submitted to the FGSR within the six-\nmonth time limit, the student will be considered to have \nwithdrawn from the program. After this time, the student \nmust apply and be readmitted to the FGSR and register \nagain before the thesis can be accepted. If the final \nexamination is adjourned, the six-month time limit will \ntake effect from the date of completion of the examination \nwhere the thesis was passed with or without revisions.  \nIn order to convocate, all thesis-based students must \nsubmit their thesis to the FGSR and have it approved \nbefore they can be cleared for convocation. The thesis \ncannot be approved without a valid student registration \nat the time of approval.  \nConduct of Thesis and Candidacy Examinations \nThe following apply to all examinations.  Matters specific \nto each type of examination are detailed in the sections \nthat follow.  Programs may have additional regulations in \ntheir program guidelines. \n• The student may be required to give a presentation \nprior to the examination.  The presentation may be \npublic or only for the examining committee (and \nothers approved to attend the examination—see \nAttendance at Doctoral Examinations, above). \n• If a public seminar is held before the examination, \ntypically the examiners do not ask questions until the \nexamination itself begins. \n• At the start of the examination the chair should \nreview the procedures as detailed by the program’s \nguidelines for the examination including the order of \nexaminers, number of rounds of questions, the length \nof time allotted to each examiner and whether \ninterjections by other examiners are \npermitted.  Departmental examination procedures \nshould have flexibility to adjust accordingly when \nthere are large supervisory committees so as not to \nextend the questioning portion of the examination \nbeyond a reasonable duration (2 hours for master’s \nand 3 hours for doctoral examinations).  \nPage 14 of 25 \nThesis Based Master’s Program Examination  \nDecision of the Master’s Final Examining Committee: \nThe decision of the examining committee will be based \nboth on the content of the thesis and on the student’s \nability to defend it. The final examination may result in \none of the following outcomes:  \n• The student may be asked to leave the room while the \norder of examiners is determined, and the student’s \nacademic record is reviewed by the supervisor for the \ncommittee.  Typically the order of examiners is the \nExternal if applicable, the arm’s length examiners, the \nsupervisory committee members, and then the \nsupervisor.  The Examiners may seek clarification at \nthis time regarding exam procedures. \n• If academic misconduct is suspected, an Associate \nDean, FGSR should be consulted prior to the exam. \n• For thesis examinations the questioning should focus \non establishing the quality of the thesis (or thesis \nsubstitute) and the student’s breadth and depth of \nunderstanding at a level appropriate to the degree \nqualification.  Expectations for a Candidacy \nexamination are detailed in the program’s guidelines. \n• When the questions have concluded, the chair should \nask the student if they have any final comments they \nwould like to add. \nDeliberation: \n• The student is required to leave the room and will be \nasked to take their personal belongings including \nelectronic devices with them. \n• The deliberations are confidential proceedings. The \ncommittee will agree on the report to be provided to \nthe student with the outcome of the examination. \n• The examiners are asked to give their opinions on the \nquality of the thesis and the defense, or performance \nin the candidacy examination, in the same order as \nquestioning occurred. All examiners must provide \ntheir opinion before a final decision is made. \n• The options of the outcomes from the vote are \ndetailed for each type of examination. \n• If the outcome of the first vote does not result in a \ndecision (eg. two of five examiners vote to fail), the \nchair will allow for further discussion and attempt to \nreach a decision.  Only in cases where a decision \ncannot be reached in a reasonable time will the \nstudent be informed and matter referred to the Dean \nFGSR, who will determine the appropriate course of \naction. \n• The chair of the Examination Committee may sign the \nthesis examination form on behalf of an examiner \nwho is participating from a remote location.  \nThesis Based Master’s Program Examination  \nEach department offering a thesis-based Master’s degree \nis required to establish detailed examination procedures \nfor final examinations. These procedures must be made \navailable publicly.  \nDecision of the Master’s Final Examining Committee: \nThe decision of the examining committee will be based \nboth on the content of the thesis and on the student’s \nability to defend it. The final examination may result in \nPage 15 of 25 \n• Adjourned  \n• Pass  \n• Pass subject to revisions  \n• Fail  \nThere is no provision for a final examination to be “passed \nsubject to major revisions”.  \nIf the Examining Committee fails to reach a decision, the \ndepartment will refer the matter to the Dean, FGSR, who \nwill determine an appropriate course of action. \nAdjourned: An adjourned examination is one that has \nbeen abandoned officially. A majority of examiners must \nagree to an outcome of Adjourned. The final examination \nshould be adjourned in the following situations:  \n• The revisions to the thesis are sufficiently substantial \nthat it will require further research or experimentation or \nmajor reworking of sections, or if the committee is so \ndissatisfied with the general presentation of the thesis \nthat it will require a reconvening of the examining \ncommittee. In such circumstances the committee cannot \npass the student, and must adjourn the examination.  \n• The committee is dissatisfied with the student’s oral \npresentation and defence of the thesis, even if the thesis \nitself is acceptable with or without minor revisions.  \n• Compelling, extraordinary circumstances such as a \nsudden medical emergency taking place during the \nexamination.  \n• Discovery of possible offences under the Code of Student \nBehaviour after the examination has started.  \nIf the examination is adjourned, the committee should:  \n• Specify in writing to the student, with as much precision \nas possible, the nature of the deficiencies and, in the case \nof revisions to the thesis, the extent of the revisions \nrequired. Where the oral defence is unsatisfactory, it may \nbe necessary to arrange some discussion periods with the \nstudent prior to reconvening the examination.  \n• Decide upon a date to reconvene. If the date of the \nreconvened examination depends upon the completion of \na research task or a series of discussions, it should be \nmade clear which committee members will decide on the \nappropriate date to reconvene. This new examination \nmust be held within six months of the initial examination. \n• Make it clear to the student what will be required by \nway of approval before the examination is reconvened \n(e.g., approval of the committee chair or supervisor, \napproval of the entire committee, or of select members of \nthe committee).  \n• Specify the supervision and assistance the student may \nexpect from the committee members in meeting the \nnecessary revisions.  \n• Advise the Dean, FGSR, in writing of the adjournment \nand the conditions.  \n• When the date is set for the adjourned final examination, \nthe department will notify the FGSR. Normally a Pro Dean \none of the following outcomes:  \n• Adjourned  \n• Pass  \n• Pass subject to revisions  \n• Fail  \nThere is no provision for a final examination to be “passed \nsubject to major revisions”.  \nIf the Examining Committee fails to reach a decision, the \ndepartment will refer the matter to the Dean, FGSR, who \nwill determine an appropriate course of action. \nAdjourned: An adjourned examination is one that has \nbeen abandoned officially. A majority of examiners must \nagree to an outcome of Adjourned. The final examination \nshould be adjourned in the following situations:  \n• The revisions to the thesis are sufficiently substantial \nthat it will require further research or experimentation or \nmajor reworking of sections, or if the committee is so \ndissatisfied with the general presentation of the thesis \nthat it will require a reconvening of the examining \ncommittee. In such circumstances the committee cannot \npass the student, and must adjourn the examination.  \n• The committee is dissatisfied with the student’s oral \npresentation and defence of the thesis, even if the thesis \nitself is acceptable with or without minor revisions.  \n• Compelling, extraordinary circumstances such as a \nsudden medical emergency taking place during the \nexamination.  \n• Discovery of possible offences under the Code of Student \nBehaviour after the examination has started.  \nIf the examination is adjourned, the committee should:  \n• Specify in writing to the student, with as much precision \nas possible, the nature of the deficiencies and, in the case \nof revisions to the thesis, the extent of the revisions \nrequired. Where the oral defence is unsatisfactory, it may \nbe necessary to arrange some discussion periods with the \nstudent prior to reconvening the examination.  \n• Decide upon a date to reconvene. If the date of the \nreconvened examination depends upon the completion of \na research task or a series of discussions, it should be \nmade clear which committee members will decide on the \nappropriate date to reconvene. This new examination \nmust be held within six months of the initial examination. \n• Make it clear to the student what will be required by \nway of approval before the examination is reconvened \n(e.g., approval of the committee chair or supervisor, \napproval of the entire committee, or of select members of \nthe committee).  \n• Specify the supervision and assistance the student may \nexpect from the committee members in meeting the \nnecessary revisions.  \n• Advise the Dean, FGSR, in writing of the adjournment \nand the conditions.  \n• When the date is set for the adjourned final examination, \nPage 16 of 25 \nattends the examination.  \nPass: All or all but one of the examiners must agree to an \noutcome of Pass. If the student passes the examination, \nthe department should submit a completed Thesis \nApproval/Program Completion form to the FGSR. If one of \nthe examiners fails the student, that examiner does not \nhave to sign this form.  \nPass subject to revisions: All or all but one of the \nexaminers must agree to an outcome of Pass subject to \nrevisions. The student has satisfactorily defended the \nthesis but the revisions to the thesis are sufficiently minor \nthat it will not require a reconvening of the examining \ncommittee.  \nIf the examining committee agrees to a “Pass subject to \nrevisions” for the student, the chair of the examining \ncommittee must provide in writing, within five working \ndays of the examination, to the Dean, FGSR, the graduate \ncoordinator and the student:  \n• the reasons for this outcome,  \n• the details of the required revisions,  \n• the approval mechanism for meeting the requirement \nfor revisions (e.g., approval of the examining committee \nchair or supervisor, or approval of the entire examining \ncommittee, or select members of the committee), and  \n• the supervision and assistance the student can expect to \nreceive from committee members.  \nThe student must make the revisions within six months of \nthe date of the final examination. Once the required \nrevisions have been made and approved, the department \nshall submit a completed Thesis Approval/Program \nCompletion form to the FGSR indicating “pass subject to \nrevisions”. If one of the examiners fails the student that \nexaminer does not have to sign the form. If the required \nrevisions have not been made and approved by the end of \nthe six months deadline, the outcome of the examination \nis a Fail.  \nFail: All or all but one of the examiners must agree to an \noutcome of Fail. If the examination result is a Fail, no \nmember of the examining committee signs the Thesis \nApproval/Completion form.  \nWhen the outcome is a Fail, the committee chair will \nprovide the reasons for this decision to the department. \nThe department will then provide this report, together \nwith its recommendation for the student’s program, to the \nDean, FGSR, and to the student. \nAn Associate Dean, FGSR will normally arrange to meet \nwith the student, the graduate coordinator, and others if \nneeded, before acting upon any departmental \nthe department will notify the FGSR. Normally a Pro Dean \nattends the examination. The Pro Dean should be included \non all correspondence for the rescheduling of the \nexamination. \nPass: Pass is the decision given when the only revisions \nrequired are typographical or minor editorial changes. All \nor all but one of the examiners must agree to an outcome \nof Pass. If the student passes the examination, the \ndepartment should submit a completed Thesis \nApproval/Program Completion form to the FGSR. If one of \nthe examiners fails the student, that examiner does not \nhave to sign this form.  \nPass subject to revisions: All or all but one of the \nexaminers must agree to an outcome of Pass subject to \nrevisions. The student has satisfactorily defended the \nthesis but the revisions to the thesis it will not require a \nreconvening of the examining committee.  \nIf the examining committee agrees to a “Pass subject to \nrevisions” for the student, the chair of the examining \ncommittee must provide in writing, within five working \ndays of the examination, to the student, the graduate \ncoordinator, and FGSR:  \n• the reasons for this outcome,  \n• the details of the required revisions,  \n• the approval mechanism for meeting the requirement \nfor revisions (e.g., approval of the examining committee \nchair or supervisor, or approval of the entire examining \ncommittee, or select members of the committee), and  \n• the supervision and assistance the student can expect to \nreceive from committee members.  \nThe student must make the revisions within six months of \nthe date of the final examination. Once the required \nrevisions have been made and approved, the department \nshall submit a completed Thesis Approval/Program \nCompletion form to the FGSR indicating the committee \ndecision was “pass subject to revisions”. If one of the \nexaminers fails the student that examiner does not have \nto sign the form. If the required revisions have not been \nmade and approved by the end of the six months deadline, \nthe student will be required to withdraw.  \nFail: All or all but one of the examiners must agree to an \noutcome of Fail. If the examination result is a Fail, no \nmember of the examining committee signs the Thesis \nApproval/Completion form.  \nWhen the outcome is a Fail, the committee chair will \nprovide the reasons for this decision to the department. \nThe department will then provide this report, together \nwith its recommendation for the student’s program, to the \nDean, FGSR, and to the student. \nAn Associate Dean, FGSR will normally arrange to meet \nwith the student, the graduate coordinator, and others if \nPage 17 of 25 \nrecommendation that affects the student’s academic \nstanding.  \nDoctoral Candidacy Examination  \nEstablishing Candidacy Examination Procedures: Each \ndepartment offering a doctoral degree is responsible for \nestablishing detailed examination policies and procedures \nfor the candidacy examination. These documents should \nbe publicly available.  \nThe candidacy examination is an oral examination; some \ndepartments may also require that students take \ncomprehensive written examinations prior to the \ncandidacy examination, but such examinations do not \nform part of the candidacy examination itself.  \nFor candidacy examinations, students must demonstrate \nto the satisfaction of the examining committee that they \npossess:  \n1. an adequate knowledge of the discipline and of the \nsubject matter relevant to the thesis;  \n2. the ability to pursue and complete original research at \nan advanced level; and  \n3. the ability to meet any other requirements found in the \ndepartment’s published policy on candidacy \nexaminations.  \nThe candidacy examination must be held within three \nyears of the commencement of the program in accordance \nwith The Degree of PhD of the University Calendar. The \ncandidacy examination must be passed no less than six \nmonths prior to taking the final examination.  \nDecision of the Candidacy Committee: The candidacy \nexamination may result in one of the following outcomes: \n• Adjourned  \n• Pass  \n• Conditional pass  \n• Fail and repeat the candidacy  \n• Fail with a recommendation to terminate the doctoral \nprogram or for a change of category to a master’s \nprogram. If the Examining Committee fails to reach a \ndecision, the department will refer the matter to the Dean, \nFGSR, who will determine an appropriate course of action. \nAdjourned: A majority of examiners must agree to an \noutcome of Adjourned. The candidacy examination should \nbe adjourned in the event of compelling, extraordinary \ncircumstances such as a sudden medical emergency \ntaking place during the examination or possible offences \nunder the Code of Student Behaviour after the \nneeded, before acting upon any departmental \nrecommendation that affects the student’s academic \nstanding.  \nDoctoral Candidacy Examination  \nEstablishing Candidacy Examination Procedures: Each \ndepartment offering a doctoral degree is responsible for \nestablishing detailed examination policies and procedures \nfor the candidacy examination. These documents should \nbe publicly available.  \nThe candidacy examination is an oral examination; some \ndepartments may also require that students take \ncomprehensive written examinations prior to the \ncandidacy examination, but such examinations do not \nform part of the candidacy examination itself.  \nFor candidacy examinations, students must demonstrate \nto the satisfaction of the examining committee that they \npossess:  \n1. an adequate knowledge of the discipline and of the \nsubject matter relevant to the thesis;  \n2. the ability to pursue and complete original research at \nan advanced level; and  \n3. the ability to meet any other requirements found in the \ndepartment’s published policy on candidacy \nexaminations.  \nThe candidacy examination must be held within three \nyears of the commencement of the program in accordance \nwith The Degree of PhD of the University Calendar. The \ncandidacy examination must be passed no less than six \nmonths prior to taking the final examination.  \nDecision of the Candidacy Committee: The candidacy \nexamination may result in one of the following outcomes: \n• Adjourned  \n• Pass  \n• Conditional pass  \n• Fail and repeat the candidacy  \n• Fail with a recommendation to terminate the doctoral \nprogram or for a change of category to a master’s \nprogram. If the Examining Committee fails to reach a \ndecision, the department will refer the matter to the Dean, \nFGSR, who will determine an appropriate course of action. \nWhen the decision is Conditional Pass or Fail, chairs may \nrefer to the decision process flowchart found on the FGSR \nwebsite. \nAdjourned: A majority of examiners must agree to an \noutcome of Adjourned. The candidacy examination should \nbe adjourned in the event of compelling, extraordinary \ncircumstances such as a sudden medical emergency \ntaking place during the examination or possible offences \nPage 18 of 25 \nexamination has started.  \nPass: All or all but one of the examiners must agree to an \noutcome of Pass. If the student passes the candidacy \nexamination, the department should complete the Report \nof Completion of Candidacy Examination form and submit \nit to the FGSR.  \nConditional Pass:  \nA majority of examiners must agree to an outcome of \nConditional Pass. If the candidacy examining committee \nagrees to a conditional pass for the student, the chair of \nthe examining committee will provide in writing within \nfive working days to the Dean, FGSR, the graduate \ncoordinator and the student:  \n• the reasons for this recommendation,  \n• the details of the conditions,  \n• the timeframe for the student to meet the conditions,  \n• the approval mechanism for meeting the conditions \n(e.g., approval of the committee chair or supervisor, or \napproval of the entire committee, or select members of \nthe committee), and  \n• the supervision and assistance the student can be \nexpected to receive from committee members  \nConditions are subject to final approval by the Dean, \nFGSR. At the deadline specified for meeting the \nconditions, two outcomes are possible:  \n• All the conditions have been met. In this case, the \ndepartment will complete the Report of Completion of \nCandidacy Examination form and submit it to the FGSR; or \n• Some of the conditions have not been met. In this case, \nthe outcome of the candidacy examination is a Fail, and \nthe options below are available to the examining \ncommittee. Note that the options are different after a \nfailed second candidacy examination.  \nFail: If the candidacy examining committee agrees that \nthe student has failed, the committee chair will provide \nthe reasons for this recommendation to the department. \nThe graduate coordinator will then provide this report, \ntogether with the department’s recommendation for the \nstudent’s program, to the Dean, FGSR, and to the student.  \nFor failed candidacy examinations, an Associate Dean, \nunder the Code of Student Behaviour after the \nexamination has started.  \nPass: All or all but one of the examiners must agree to an \noutcome of Pass. If the student passes the candidacy \nexamination, the department should complete the Report \nof Completion of Candidacy Examination form and submit \nit to the FGSR.  \nConditional Pass:  \nA Conditional Pass is appropriate when the student has \nsatisfied the committee in all but a very discrete area of \ndeficiency that can addressed through a reasonable \nrequirement (e.g., coursework, literature review, \nupgrading of writing skills).  Reworking of the entire \ncandidacy proposal is not an acceptable condition and the \nexaminers should consider the options available for a \nstudent that has failed the examination. \nA majority of examiners must agree to an outcome of \nConditional Pass. If the candidacy examining committee \nagrees to a conditional pass for the student, the chair of \nthe examining committee will provide in writing within \nfive working days to the Dean, FGSR, the graduate \ncoordinator and the student:  \n• the reasons for this recommendation,  \n• the details of the conditions,  \n• the timeframe for the student to meet the \nconditions, but which should be no less than six weeks \nand no more than six months. \n• the approval mechanism for meeting the conditions \n(e.g., approval of the committee chair or supervisor, or \napproval of the entire committee, or select members of \nthe committee), \n• the supervision and assistance the student can expect \nto receive from committee members \nConditions are subject to final approval by the Dean, \nFGSR. At the deadline specified for meeting the \nconditions, two outcomes are possible:  \n• All the conditions have been met. In this case, the \ndepartment will complete the Report of Completion of \nCandidacy Examination form and submit it to the FGSR; or \n• If the conditions are not met by the deadline, the \noutcome of the examination is a fail and the committee \nmust be reconvened to make the recommendation as \ndescribed in the following section.   \nFail: All or all but one of the examiners must agree to an \noutcome of Fail. \nPage 19 of 25 \nFGSR, normally arranges to meet with the student and \nothers as required before acting upon any department \nrecommendation.  \nThe options available to the examining committee when \nthe outcome of a student’s candidacy exam is “Fail” are  \n• Repeat the Candidacy:  \nA majority of examiners must agree to an outcome of Fail \nand Repeat the Candidacy. If the student’s first candidacy \nexam performance was inadequate but the student’s \nperformance and work completed to date indicate that \nthe student has the potential to perform at the doctoral \nlevel, the examining committee should consider the \npossibility of recommending that the student be given an \nopportunity to repeat the candidacy exam. Normally, the \ncomposition of the examining committee does not change \nfor the repeat candidacy exam.  \nIf the recommendation of a repeat candidacy is \nformulated by the examining committee and approved by \nthe FGSR, the student and graduate coordinator are to be \nnotified in writing of the student’s exam deficiencies by \nthe chair of the examining committee. The second \ncandidacy exam is to be scheduled no later than six \nmonths from the date of the first candidacy. In the event \nthat the student fails the second candidacy, the examining \ncommittee shall recommend one of the following two \noptions to the department:  \n• Change of Category to a Master’s Program: All or all but \none of the examiners must agree to an outcome of Fail and \nChange of Category to a Master’s Program. This outcome \nshould be considered if the student’s candidacy \nexamination performance was inadequate and the \nstudent’s performance and work completed to date \nindicates that the student has the potential to complete a \nmaster’s, but not a doctoral, program; or  \n• Termination of the Doctoral Program: All or all but one \nof the examiners must agree to an outcome of Fail and \nTerminate the Doctoral Program. If the student’s \nperformance was inadequate, and the work completed \nduring the program is considered inadequate, then the \nexamining committee should recommend termination of \nthe student’s program.  \n[moved from above] \nThe options available to the examining committee when \nthe outcome of a student’s candidacy exam is “Fail” are  \n• Repeat the Candidacy:  Repeating the Candidacy is not \nan option after a second failed examination. A majority of \nexaminers must agree to an outcome of Fail and Repeat \nthe Candidacy. If the student’s first candidacy exam \nperformance was inadequate but the student’s \nperformance and work completed to date indicate that \nthe student has the potential to perform at the doctoral \nlevel, the examining committee should consider the \npossibility of recommending that the student be given an \nopportunity to repeat the candidacy exam. Normally, the \ncomposition of the examining committee does not change \nfor the repeat candidacy exam.  \nIf the recommendation of a repeat candidacy is \nformulated by the examining committee and approved by \nthe FGSR, the student and graduate coordinator are to be \nnotified in writing of the student’s exam deficiencies by \nthe chair of the examining committee. The second \ncandidacy exam is to be scheduled no later than six \nmonths from the date of the first candidacy. In the event \nthat the student fails the second candidacy, the examining \ncommittee shall recommend one of the following two \noptions to the department:  \n• Change of Category to a Master’s Program: All or all but \none of the examiners must agree to an outcome of Fail and \nChange of Category to a Master’s Program. This outcome \nshould be considered if the student’s candidacy \nexamination performance was inadequate and the \nstudent’s performance and work completed to date \nindicate that the student has the potential to complete a \nmaster’s, but not a doctoral, program; or  \n• Termination of the Doctoral Program: All or all but one \nof the examiners must agree to an outcome of Fail and \nTerminate the Doctoral Program. If the student’s \nperformance was inadequate, and the work completed \nduring the program is considered inadequate, then the \nexamining committee should recommend termination of \nthe student’s program.  \nIf the candidacy examining committee agrees that the \nstudent has failed, the committee chair will provide the \nreasons and the recommendation for the student’s \nprogram to the department. The graduate coordinator \nwill then provide this report, together with the \ndepartment’s recommendation for the student’s program, \nto the Dean, FGSR, and to the student.  \nFor failed candidacy examinations, an Associate Dean, \nFGSR, normally arranges to meet with the student (and \nothers as required) before acting upon any department \nrecommendation.  \nPage 20 of 25 \nFinal Doctoral Examination  \nEach department offering a doctoral degree is required to \nestablish detailed examination procedures for final \nexaminations. These procedures must be made available \npublicly.  \nPreliminary Acceptance of the Thesis: Before the thesis \nis forwarded to the External, the supervisory committee \nmembers must declare in writing to the supervisor(s) \neither that the thesis is of adequate substance and quality \nto warrant that the student proceed to the final \nexamination or that the thesis is unsatisfactory and the \nstudent should not be allowed to proceed to the final \nexamination.  \nThe purpose of this process is to ensure the thesis is \nvetted by the supervisor(s) and all supervisory committee \nmembers and to verify that it is of sufficient substance \nand quality to proceed to the final examination.  \nThis process is critical to protect and uphold the \nreputation of the department and the University of \nAlberta for excellence in graduate programs. It is also \ncritical to ensure that Externals and other additional \nmembers of the examining committee are not asked to \ninvest time reading a thesis that is substandard. \nDepartments may choose to prepare a “Preliminary \nAcceptance of Thesis” signature sheet for their own \nrecords.  \nAttendance at Doctoral Examinations: Faculty \nmembers of the student’s home department as well as \nmembers of FGSR Council (or their alternates) have the \nright to attend doctoral examinations but should notify \nthe chair of the examining committee. Other persons may \nattend the examination only with special permission of \nthe Dean of the department’s Faculty, the Dean, FGSR, or \nthe chair of the examining committee.  \nExcept for a Dean or a Pro Dean who may participate fully \nin the examination, persons who are not members of the \nexamining committee:  \n• may participate in the questioning only by permission of \nthe chair of the committee, but  \n• are not permitted to participate in the discussion of the \nstudent’s performance and must withdraw before such \ndiscussion commences  \nInviting the External Examiner or Reader: Every Final \nDoctoral Examining Committee must have an External i.e., \nan arm’s length examiner from outside the University of \nAlberta. The term External Examiner refers to an \nExternal that attends the examination; whereas the term \nExternal Reader refers to an External who provides a \nwritten evaluation of the thesis and questions to be asked \nduring the examination. External Readers are deemed to \nbe in attendance at the examination.  \nFinal Doctoral Examination  \nEach department offering a doctoral degree is required to \nestablish detailed examination procedures for final \nexaminations. These procedures must be made available \npublicly.  \nPreliminary Acceptance of the Thesis: Before the thesis \nis forwarded to the External, the supervisory committee \nmembers must declare in writing to the supervisor(s) \neither that the thesis is of adequate substance and quality \nto warrant that the student proceed to the final \nexamination or that the thesis is unsatisfactory and the \nstudent should not be allowed to proceed to the final \nexamination.  \nThe purpose of this process is to ensure the thesis is \nvetted by the supervisor(s) and all supervisory committee \nmembers and to verify that it is of sufficient substance \nand quality to proceed to the final examination.  \nThis process is critical to protect and uphold the \nreputation of the department and the University of \nAlberta for excellence in graduate programs. It is also \ncritical to ensure that Externals and other additional \nmembers of the examining committee are not asked to \ninvest time reading a thesis that is substandard. \nDepartments may choose to prepare a “Preliminary \nAcceptance of Thesis” signature sheet for their own \nrecords.  \nAttendance at Doctoral Examinations: Faculty \nmembers of the student’s home department as well as \nmembers of FGSR Council (or their alternates) have the \nright to attend doctoral examinations but should notify \nthe chair of the examining committee. Other persons may \nattend the examination only with special permission of \nthe Dean of the department’s Faculty, the Dean, FGSR, or \nthe chair of the examining committee.  \nExcept for a Dean or a Pro Dean who may participate fully \nin the examination, persons who are not members of the \nexamining committee:  \n• may participate in the questioning only by permission of \nthe chair of the committee, but  \n• are not permitted to participate in the discussion of the \nstudent’s performance and must withdraw before such \ndiscussion commences  \nInviting the External Examiner or Reader: Every Final \nDoctoral Examining Committee must have an External i.e., \nan arm’s length examiner from outside the University of \nAlberta. The term External Examiner refers to an \nExternal who attends the examination, whereas the term \nExternal Reader refers to an External who provides a \nwritten evaluation of the thesis and questions to be asked \nduring the examination. External Readers are deemed to \nPage 21 of 25 \nIt is the responsibility of the department to recommend \nan External Examiner or Reader and to submit the name \nto the Dean of the department’s Faculty for approval. \nNormally, this should be done at least two months in \nadvance of the examination date. The submission must \nfollow the procedures established by the Dean of the \ndepartment’s Faculty.  \nThe External:  \n• Must be a recognized authority in the specific field of \nresearch of the student’s thesis.  \n• Will be experienced in evaluating doctoral area work; \nand  \n• Must be in a position to review the thesis objectively and \nto provide a critical analysis of the work and the \npresentation.  \nIt is essential that the External not have an association \nwith the student, the supervisor, or the \ndepartment, within the last six years as this could hinder \nobjective analysis. For example, a proposed External who \nhas within the last six years been associated with the \nstudent as a research collaborator or coauthor would not \nbe eligible. Also, a proposed External must not have had \nan association within the last six years with the doctoral \nstudent’s supervisor (as a former student, supervisor, or \nclose collaborator, for instance).  \nUnder normal circumstances the same person will not be \nused as an External at the University of Alberta if that \nExternal has served in the same capacity in the same \ndepartment at this University within the preceding two \nyears; this does not preclude an External serving in \nanother department.  \nOnce the External has been approved an official letter of \ninvitation is issued to the External by the department.  \nApproval of the Doctoral Final Examining Committee: \nThe department will recommend the names of all \nmembers of the final examining committee and forward \nthem to the Dean of the department’s Faculty, if decanal \napproval is required, following the procedures \nestablished by their Faculty.  \nExternal Readers: Do not attend the examination. \nInstead, the External Reader is asked in the letter of \ninvitation to prepare a written report consisting of:  \n• an evaluation of the scope, structure, methodology, and \nfindings of the thesis,  \n• a list of minor errors (if any), and  \n• either a list of clear, direct, contextualized questions to \nbe posed to the candidate during the examination, or a \nbrief written commentary of the thesis which can be read \nto the candidate for response during the examination.  \nThe External Reader must include a statement that the \nthesis falls into one of the following two categories:  \n• Acceptable with minor or no revisions: In this case, \nbe in attendance at the examination.  \nIt is the responsibility of the department to recommend \nan External Examiner or Reader and to submit the name \nto the Dean of the department’s Faculty for approval. \nNormally, this should be done at least two months in \nadvance of the examination date. The submission must \nfollow the procedures established by the Dean of the \ndepartment’s Faculty.  \nThe External:  \n• Will be a recognized authority in the specific field of \nresearch of the student’s thesis; \n• Will be experienced in evaluating doctoral area work; \nand  \n• Must be in a position to review the thesis objectively and \nto provide a critical analysis of the work and the \npresentation.  \nIt is essential that the External not have an association \nwith the student, the supervisor, or the department \nwithin the last six years as this could hinder objective \nanalysis. For example, a proposed External who has \nwithin the last six years been associated with the student \nas a research collaborator or coauthor would not be \neligible. Also, a proposed External must not have had an \nassociation within the last six years with the doctoral \nstudent’s supervisor (as a former student, supervisor, or \nclose collaborator, for instance).  \nUnder normal circumstances the same person will not be \nused as an External at the University of Alberta if that \nExternal has served in the same capacity in the same \ndepartment at this University within the preceding two \nyears; this does not preclude an External serving in \nanother department.  \nOnce the External has been approved an official letter of \ninvitation is issued to the External by the department.  \nApproval of the Doctoral Final Examining Committee: \nThe department will recommend the names of all \nmembers of the final examining committee and forward \nthem to the Dean of the department’s Faculty, if decanal \napproval is required, following the procedures \nestablished by their Faculty.  \nExternal Readers: Do not attend the examination. \nInstead, the External Reader is asked in the letter of \ninvitation to prepare a written report consisting of:  \n• an evaluation of the scope, structure, methodology, and \nfindings of the thesis,  \n• a list of minor errors (if any), and  \n• either a list of clear, direct, contextualized questions to \nbe posed to the candidate during the examination, or a \nbrief written commentary of the thesis which can be read \nto the candidate for response during the examination.  \nThe External Reader must include a statement that the \nthesis falls into one of the following two categories:  \nPage 22 of 25 \nthe External Reader submits the report to the Graduate \nCoordinator at least one week before the examination. If \nthe External Reader considers the thesis to be of a calibre \nworthy of consideration for an award, the External \nReader comments on this in the written evaluation; or  \n• Unacceptable without major revisions: In this case, \nthe External Reader contacts the Dean of the FGSR \nimmediately by email as the examination may need to be \npostponed.  \nThe questions or commentary will be made available to \nthe student for the first time during the examination and \nthe committee will evaluate the student’s answers as part \nof the examination.  \nExternal Examiners: Attend the examination in person. \nIn the letter of invitation, the External Examiner is \nrequested to prepare and send to the Graduate \nCoordinator, at least one week in advance of the \nexamination, an evaluation of the thesis placing it \ntemporarily in one of the following categories:  \n• the thesis is acceptable with minor or no revisions,  \n• the External Examiner wishes to reserve judgment until \nafter the examination, or  \n• the thesis is unacceptable without major revisions.  \nIn the first two cases, the External Examiner is asked to \nprovide a brief written commentary (approximately two \nto three pages) on the structure, methodology, quality, \nsignificance and findings of the thesis for the reference of \nboth the student and supervisor. The commentary should \nnot be given to the student prior to the examination. \nIf the thesis is judged by the External Examiner to fall into \nthe “Unacceptable” category, then the External Examiner \nis asked to contact the Dean of the FGSR immediately, \nsince the final examination may have to be postponed.  \nThe Examination: The examining committee should \nconduct a final examination, based largely on the thesis. \nThe graduate coordinator should ensure that the chair of \nthe examining committee, the student, and all examiners \nhave a final copy of the thesis at the examination.  \nThe student should make a brief presentation about the \nthesis.  \nThe most time should be allotted to the arm’s length \nexaminers, including the External Examiner, while the \nleast time is allocated to the supervisor(s).  \nNo final decision should be made without each examiner \nhaving given an opinion.  \nDecision of the Doctoral Final Examining Committee: The \ndecision of the examining committee will be based both \non the content of the thesis and on the student’s ability to \ndefend it. The final examination may result in one of the \nfollowing outcomes:  \n• Adjourned  \n• Pass  \n• Acceptable with minor or no revisions: In this case, \nthe External Reader submits the report to the Graduate \nCoordinator at least one week before the examination. If \nthe External Reader considers the thesis to be of a calibre \nworthy of consideration for an award, the External \nReader comments on this in the written evaluation; or  \n• Unacceptable without major revisions: In this case, \nthe External Reader contacts the Dean of the FGSR \nimmediately by email as the examination may need to be \npostponed.  \nThe questions or commentary will be made available to \nthe student for the first time during the examination and \nthe committee will evaluate the student’s answers as part \nof the examination.  \nExternal Examiners: Attend the examination in person. \nIn the letter of invitation, the External Examiner is \nrequested to prepare and send to the Graduate \nCoordinator, at least one week in advance of the \nexamination, an evaluation of the thesis placing it \ntemporarily in one of the following categories:  \n• the thesis is acceptable with minor or no revisions,  \n• the External Examiner wishes to reserve judgment until \nafter the examination, or  \n• the thesis is unacceptable without major revisions.  \nIn the first two cases, the External Examiner is asked to \nprovide a brief written commentary (approximately two \nto three pages) on the structure, methodology, quality, \nsignificance and findings of the thesis for the reference of \nboth the student and supervisor. The commentary should \nnot be given to the student prior to the examination. \nIf the thesis is judged by the External Examiner to fall into \nthe “Unacceptable” category, then the External Examiner \nis asked to contact the Dean of the FGSR immediately, \nsince the final examination may need to be postponed.  \nThe Examination: The examining committee should \nconduct a final examination, based largely on the thesis. \nThe graduate coordinator should ensure that the chair of \nthe examining committee, the student, and all examiners \nhave a final copy of the thesis at the examination.  \nThe student should make a brief presentation about the \nthesis.  \nThe most time should be allotted to the arm’s length \nexaminers, including the External Examiner, while the \nleast time is allocated to the supervisor(s).  \nNo final decision should be made without each examiner \nhaving given an opinion.  \nDecision of the Doctoral Final Examining Committee: The \ndecision of the examining committee will be based both \non the content of the thesis and on the student’s ability to \ndefend it. The final examination may result in one of the \nfollowing outcomes:  \n• Adjourned  \nPage 23 of 25 \n• Pass subject to revisions  \n• Fail  \nThere is no provision for a final examination to be “passed \nsubject to major revisions”.  \nIf the Examining Committee fails to reach a decision, the \ndepartment will refer the matter to the Dean, FGSR, who \nwill determine an appropriate course of action.  \nAdjourned: An adjourned examination is one that has \nbeen abandoned officially. A majority of examiners must \nagree to an outcome of Adjourned. The final examination \nshould be adjourned in the following situations:  \n• The revisions to the thesis are sufficiently substantial \nthat it will require further research or experimentation or \nmajor reworking of sections, or if the committee is so \ndissatisfied with the general presentation of the thesis \nthat it will require a reconvening of the examining \ncommittee. In such circumstances the committee cannot \npass the student, and must adjourn the examination.  \n• The committee is dissatisfied with the student’s oral \npresentation and defence of the thesis, even if the thesis \nitself is acceptable with or without minor revisions.  \n• Compelling, extraordinary circumstances such as a \nsudden medical emergency taking place during the \nexamination.  \n• Discovery of possible offences under the Code of Student \nBehaviour after the examination has started.  \nIf the examination is adjourned, the committee should:  \n• Specify in writing to the student, with as much precision \nas possible, the nature of the deficiencies and, in the case \nof revisions to the thesis, the extent of the revisions \nrequired. Where the oral defence is unsatisfactory, it may \nbe necessary to arrange some discussion periods with the \nstudent prior to reconvening the examination.  \n• Decide upon a date to reconvene. If the date of the \nreconvened examination depends upon the completion of \na research task or a series of discussions, it should be \nmade clear which committee members will decide on the \nappropriate date to reconvene. The final date set for \nreconvening shall be no later than six months from the \ndate of the examination. This new examination must be \nheld within six months of the initial examination.  \n• Make it clear to the student what will be required by \nway of approval before the examination is reconvened \n(e.g., approval of the committee chair or supervisor, \napproval of the entire committee, or of select members of \nthe committee).  \n• Specify the supervision and assistance the student may \nexpect from the committee members in meeting the \nnecessary revisions.  \n• Advise the Dean of the department’s Faculty following \nthe procedures established for this purpose.  \n• Advise the FGSR in writing of the adjournment and the \nconditions.  \n• Pass  \n• Pass subject to revisions  \n• Fail  \nThere is no provision for a final examination to be “passed \nsubject to major revisions”.  \nIf the Examining Committee fails to reach a decision, the \ndepartment will refer the matter to the Dean, FGSR, who \nwill determine an appropriate course of action.  \nAdjourned: An adjourned examination is one that has \nbeen abandoned officially. A majority of examiners must \nagree to an outcome of Adjourned. The final examination \nshould be adjourned in the following situations:  \n• The revisions to the thesis are sufficiently substantial \nthat it will require further research or experimentation or \nmajor reworking of sections, or if the committee is so \ndissatisfied with the general presentation of the thesis \nthat it will require a reconvening of the examining \ncommittee. In such circumstances the committee cannot \npass the student, and must adjourn the examination.  \n• The committee is dissatisfied with the student’s oral \npresentation and defence of the thesis, even if the thesis \nitself is acceptable with or without minor revisions.  \n• Compelling, extraordinary circumstances such as a \nsudden medical emergency taking place during the \nexamination.  \n• Discovery of possible offences under the Code of Student \nBehaviour after the examination has started.  \nIf the examination is adjourned, the committee should:  \n• Specify in writing to the student, with as much precision \nas possible, the nature of the deficiencies and, in the case \nof revisions to the thesis, the extent of the revisions \nrequired. Where the oral defence is unsatisfactory, it may \nbe necessary to arrange some discussion periods with the \nstudent prior to reconvening the examination.  \n• Decide upon a date to reconvene. If the date of the \nreconvened examination depends upon the completion of \na research task or a series of discussions, it should be \nmade clear which committee members will decide on the \nappropriate date to reconvene. The final date set for \nreconvening shall be no later than six months from the \ndate of the examination. This new examination must be \nheld within six months of the initial examination.  \n• Make it clear to the student what will be required by \nway of approval before the examination is reconvened \n(e.g., approval of the committee chair or supervisor, \napproval of the entire committee, or of select members of \nthe committee).  \n• Specify the supervision and assistance the student may \nexpect from the committee members in meeting the \nnecessary revisions.  \n• Advise the Dean of the department’s Faculty following \nthe procedures established for this purpose.  \n• Advise the FGSR in writing of the adjournment and the \nPage 24 of 25 \n• When the date is set for the adjourned final examination, \nthe department will notify the Dean of the department’s \nFaculty and the FGSR. Normally a Pro Dean attends the \nexamination.  \nPass:  \nAll or all but one of the examiners must agree to an \noutcome of Pass. If the student passes the examination, \nthe department should submit a completed Thesis \nApproval/Program Completion form to the FGSR. If one of \nthe examiners fails the student, that examiner does not \nhave to sign this form.  \nPass Subject to Revisions: All or all but one of the \nexaminers must agree to an outcome of Pass Subject to \nRevisions. The student has satisfactorily defended the \nthesis but the revisions to the thesis are sufficiently minor \nthat it will not require a reconvening of the examining \ncommittee. If the examining committee agrees to a “Pass \nsubject to revisions” for the student, the chair of the \nexamining committee must provide in writing, within five \nworking days of the examination, to the Dean, FGSR, the \ngraduate coordinator and the student. \n• the reasons for this outcome,  \n• the details of the required revisions,  \n• the approval mechanism for meeting the requirement \nfor revisions (e.g., approval of the examining committee \nchair or supervisor, or approval of the entire examining \ncommittee, or select members of the committee), and  \n• the supervision and assistance the student can expect to \nreceive from committee members.  \nThe student must make the revisions within six months of \nthe date of the final examination. Once the required \nrevisions have been made and approved, the department \nshall submit a completed Thesis Approval/Program \nCompletion form to the FGSR indicating “pass subject to \nrevisions”. If one of the examiners fails the student that \nexaminer does not have to sign the form. If the required \nrevisions have not been made and approved by the end of \nthe six months deadline, the outcome of the examination \nis a Fail.  \nFail: All or all but one of the examiners must agree to an \noutcome of Fail. If the examination result is a Fail, no \nmember of the examining committee signs the Thesis \nApproval/Completion form.  \nWhen the outcome is a Fail, the committee chair will \nprovide the reasons for this decision to the graduate \ncoordinator. The department will then provide this \nreport, together with its recommendation for the \nconditions.  \n• When the date is set for the adjourned final examination, \nthe department will notify the Dean of the department’s \nFaculty and the FGSR. Normally a Pro Dean attends the \nexamination.  \nPass: Pass is the decision given when the only revisions \nrequired are typographical or minor editorial changes. All \nor all but one of the examiners must agree to an outcome \nof Pass. If the student passes the examination, the \ndepartment should submit a completed Thesis \nApproval/Program Completion form to the FGSR. If one of \nthe examiners fails the student, that examiner does not \nhave to sign this form.  \nPass Subject to Revisions: All or all but one of the \nexaminers must agree to an outcome of Pass Subject to \nRevisions. The student has satisfactorily defended the \nthesis but the revisions to the thesis it will not require a \nreconvening of the examining committee. If the examining \ncommittee agrees to a “Pass subject to revisions” for the \nstudent, the chair of the examining committee must \nprovide in writing, within five working days of the \nexamination, to the student, the graduate coordinator, \nand FGSR:  \n• the reasons for this outcome,  \n• the details of the required revisions,  \n• the approval mechanism for meeting the requirement \nfor revisions (e.g., approval of the examining committee \nchair or supervisor, or approval of the entire examining \ncommittee, or select members of the committee), and  \n• the supervision and assistance the student can expect to \nreceive from committee members.  \n• A date for the revisions to be resubmitted, as \nnegotiated with the student, but which should be no \nless than six weeks and no more than six months. \nThe student must make the revisions within six months of \nthe date of the final examination. Once the required \nrevisions have been made and approved, the department \nshall submit a completed Thesis Approval/Program \nCompletion form to the FGSR indicating the committee \ndecision was “pass subject to revisions”. If one of the \nexaminers fails the student that examiner does not have \nto sign the form. If the required revisions have not been \nmade and approved by the end of the six months deadline, \nthe student will be required to withdraw.  \nFail: All or all but one of the examiners must agree to an \noutcome of Fail. If the examination result is a Fail, no \nmember of the examining committee signs the Thesis \nApproval/Completion form.  \nWhen the outcome is a Fail, the committee chair will \nprovide the reasons for this decision to the graduate \ncoordinator. The department will then provide this \nPage 25 of 25 \nstudent’s program, to the Dean of the department’s \nFaculty, the FGSR, and to the student.  \nAn Associate Dean, FGSR will normally arrange to meet \nwith the student and with the graduate coordinator \nbefore acting upon any department recommendation that \naffects the student’s academic standing. \nreport, together with its recommendation for the \nstudent’s program, to the Dean of the department’s \nFaculty, the FGSR, and to the student.  \nAn Associate Dean, FGSR will normally arrange to meet \nwith the student and with the graduate coordinator \nbefore acting upon any department recommendation that \naffects the student’s academic standing.  \nJustification:  \nThe conduct of graduate examinations holds extremely high stakes for individual students and presents \nsignificant reputational risk for the faculty, program and institution. A major revision the Supervision and \nStructure of Examining Committees in the Graduate Program Manual was approved by FGSR Council in May \n2012. Subsequently in May 2013 the authority for approval of supervisors, supervisory committees, \nexternal examiners and examining committees was delegated to the disciplinary department/Faculty of the \nprogram and the change to the Calendar governing examinations was approved by FGSR Council October \n2013 appearing in the 2014-2015 Calendar.  A number of areas have come to light that have caused \nproblems due to apparent contradictions, gaps and/or confusing language.  The revisions are not intended \nto significantly alter the policies governing examinations but to clarify the policies, elaborate on procedures, \nand update graduate level examination procedures given changes to practices and technologies. \nApproved: FGSR Council, May 17, 2017 \nItem No. 8 \nGENERAL FACULTIES COUNCIL \nFor the Meeting of October 30, 2017 \nOUTLINE OF ISSUE \nAction Item \nAgenda Title: Report of the GFC Committee on Learning Environment on Teaching and Learning and \nTeaching Evaluation and the Use of the Universal Student Ratings of Instruction (USRI) as an \nEvaluation Tool \nMotion: THAT General Faculties Council Receive the CLE Report on Teaching and Learning and Teaching \nEvaluation and the Use of the Universal Student Ratings of Instruction (USRI) as an Evaluation Tool as set \nforth in Attachment 2, and Endorse the Recommendations of the Committee as set forth in Attachment 1, \nand as recommended by the GFC Executive Committee. \nItem   \nAction Requested Endorse   Receive    \nProposed by Sarah Forgie, Chair, Committee  on the Learning Environment \nPresenter Sarah Forgie, Chair, Committee  on the Learning Environment and \nPrincipal Investigator \nNorma Nocente, Co-Investigator \nL Francisco Vargas M, Research Coordinator \nRebecca Best-Bertwistle, Research Assistant \nDetails \nResponsibility Provost and Vice-President (Academic) \nThe Purpose of the Proposal is \n(please be specific) \nThe GFC Committee on the Learning Environment (CLE) was requested \nby GFC to report on research into the use of student rating mechanisms \nof instruction in university courses. This report fulfills this request. \nThe Impact of the Proposal is  \nReplaces/Revises (eg, policies, \nresolutions) \nN/A \nTimeline/Implementation Date N/A \nEstimated Cost and funding \nsource \nNext Steps (ie.: \nCommunications Plan, \nImplementation plans) \nFinal report will be forwarded to General Faculties Council for \ndiscussion. \nRecommendations arising from the report will inform the work of the \nCommittee on the Learning Environment over the next year. \nSupplementary Notes and \ncontext \nOn May 30, 2016, General Faculties Council passed the following \nmotion: \nTHAT the General Faculties Council, on the recommendation of the GFC \nExecutive Committee, request that the GFC Committee on the Learning \nEnvironment report by 30 April 2017, on research into the use of student \nrating mechanisms of instruction in university courses. This will be \ninformed by a critical review of the University of Alberta’s existing \nUniversal Student Ratings of Instruction (USRIs) and their use for \nassessment and evaluation of teaching as well as a broad review of \npossible methods of multifaceted assessment and evaluation of \nteaching. The ultimate objective will be to satisfy the Institutional \nStrategic Plan: For the Public Good strategy to: Provide robust supports, \ntools, and training to develop and assess teaching quality, using \nItem No. 8 \nGENERAL FACULTIES COUNCIL \nFor the Meeting of October 30, 2017 \nqualitative and quantitative criteria that are fair, equitable, non-\ndiscriminatory and meaningful across disciplines. \nEngagement and Routing (Include meeting dates) \nParticipation: \n(parties who have seen the \nproposal and in what capacity) \n<For further information see \nthe link posted on \nthe Governance Toolkit section \nStudent Participation Protocol> \nThose who have been informed: \n• Provost and Vice-President (Academic) \n• Vice-Provost Council \n• Deans’ Council \n• Chairs’ Council \n• GFC Executive Committee \n• General Faculties Council \nThose who have been consulted: \n• GFC Committee on the Learning Environment \n• GFC Executive Committee \nThose who are actively participating: \n• GFC Committee on the Learning Environment \n• Sarah Forgie, Vice-Provost (Learning Initiatives) and Principal \nInvestigator \n• Norma Nocente, Co-Investigator \n• L Francisco Vargas M, Research Coordinator \n• Rebecca Best-Bertwistle, Research Assistant \n• GFC Executive Committee \n• General Faculties Council \nApproval Route (Governance) \n(including meeting dates) \nGFC Committee on the Learning Environment – April 2017 \nGFC Executive Committee – September 11, 2017 \nGeneral Faculties Council – September 25, 2017, October 30, 2017 \nFinal Approver General Faculties Council  \nAlignment/Compliance \nAlignment with Guiding \nDocuments \nFor the Public Good \nGOAL: EXCEL as individuals, and together, sustain a culture that \nfosters and champions distinction and distinctiveness in teaching, \nlearning, research, and service. \nOBJECTIVE 14: Inspire, model, and support excellence in teaching and \nlearning.  \nStrategy iii: Provide robust supports, tools, and training to develop and \nassess teaching quality, using qualitative and quantitative criteria that \nare fair, equitable, and meaningful across disciplines. \nCompliance with Legislation, \nPolicy and/or Procedure \nRelevant to the Proposal \n(please quote legislation and \ninclude identifying section \nnumbers) \n1. Post-Secondary Learning Act (PSLA): The PSLA gives GFC \nresponsibility, subject to the authority of the Board of Governors, over \nacademic affairs (Section 26(1)).  \n2. General Faculties Council Terms of Reference (3. Mandate of the \nCommittee) \n“The issues which remain with GFC or which would be referred by a \nStanding Committee of GFC would generally be in the nature of the \nfollowing: \nhttp://www.governance.ualberta.ca/GovernanceToolkit/Toolkit.aspx\nhttp://www.governance.ualberta.ca/GovernanceToolkit/Toolkit.aspx\nItem No. 8 \nGENERAL FACULTIES COUNCIL \nFor the Meeting of October 30, 2017 \n• High level strategic and stewardship policy issues or matters of \nsignificant risk to the University”  \n3. GFC Executive Committee Terms of Reference (3. Mandate of the \nCommittee) \n“5. Agendas of General Faculty Council \nGFC has delegated to the Executive Committee the authority to decide \nwhich items are placed on a GFC Agenda, and the order in which those \nagenda items appear on each GFC agenda.  \nWhen ordering items, the GFC Executive Committee will be mindful of \nany matters that are of particular concern to students during March and \nApril so that the student leaders who bring those items forward are able \nto address these items at GFC before their terms end. (EXEC 06 NOV \n2006)  \n[…]  \nWith respect to recommendations from other bodies and other GFC \ncommittees, however, the role of the Executive Committee shall be to \nexamine and debate the substance of reports or recommendations and \nto decide if an item is ready to be forwarded to the full governing body.  \nThe Executive Committee may decide to refer a proposal back to the \noriginating body, to refer the proposal to another body or individual for \nstudy or review, or to take other action in order to ready a proposal for \nconsideration by General Faculties Council. When the GFC Executive \nCommittee forwards a proposal to GFC, it shall make a recommendation \nthat GFC endorse; endorse with suggested amendments; not endorse; \nor forward the proposal with no comment.” \n4. GFC Committee on the Learning Environment (CLE) Terms of \nReference (3.Mandate of the Committee):  \n“The Committee on the Learning Environment is a standing committee \nof the General Faculties Council that promotes an optimal learning \nenvironment in alignment with guiding documents of the University of \nAlberta.  \nThe Committee on the Learning Environment is responsible for making \nrecommendations concerning policy matters and action matters with \nrespect to the following:  \n[…] \nb) To review and, as necessary, recommend to the GFC Academic \nPlanning Committee and GFC Executive Committee as relates to the \ndevelopment and implementation of policies on teaching, learning, \nteaching evaluation, and recognition for teaching that promote the \nUniversity Academic Plan. \nc) To develop policies that promote ongoing assessment of teaching and \nlearning through all Faculties and units. \nd) To nurture the development of innovative and creative teaching \npractices. \ne) To encourage the sharing and discussion of evidence about effective \nteaching and learning. \nf) To encourage the sharing and discussion of evidence about effective \nteaching, learning, and the services. \ng) To promote projects with relevant internal and external bodies that \nItem No. 8 \nGENERAL FACULTIES COUNCIL \nFor the Meeting of October 30, 2017 \noffer unique teaching and learning opportunities that would benefit the \nuniversity community. \nh) To consider any matter deemed by the GFC Committee on the \nLearning Environment to be within the purview of its general \nresponsibility. \n5. GFC policy 111 Teaching and Learning and Teaching Evaluation \n“111.2 Teaching Evaluation  \n1. Evaluation of teaching at the University of Alberta serves two \npurposes: \na. Summative – Evaluation provides a review and overview of an \ninstructor’s teaching that is an essential element in promotion and tenure \ndecisions. In its summative form, teaching evaluation forms a basis for \nrewarding excellence, as well as the basis for withholding reward. \nb. Formative – Evaluation provides helpful feedback to teachers by \nidentifying teaching strengths and weaknesses and, in so doing, giving \nguidance for the improvement or refinement of teaching skills. \n2. Evaluation of teaching must be multifaceted. Multifaceted evaluation \nshall include the Universal Student Ratings of Instruction set out in \nSection 111.3 and other methods of assessing teaching designed within \nindividual Faculties to respond to the particular conditions of that \nFaculty. Such assessments shall include one or more of the following: \ninput from administrators, peers, self, undergraduate and graduate \nstudents, and alumni. \n3. Recognizing that the evaluation of teaching at the University shall be \nmultifaceted, Faculty Evaluation Committee (FEC) decisions concerning \ntenure, promotion or unsatisfactory teaching performance must be \nbased on more than one indicator of the adequacy of teaching. \n4. Assessment of teaching involving input from administrators, peers, \nself, alumni, or undergraduate and graduate students in addition to the \nUniversal Student Ratings of Instruction should occur annually prior to \ntenure. For continuing faculty (ie, Categories A1.1, A1.5 and A1.6), such \nassessment will occur at least triennially.  \n5. The University shall continue to support University Teaching Services \nin its education programming which is focused on the development and \nimprovement of teaching and learning and its efforts to enhance \nresearch in university teaching. \n111.3 Universal Student Ratings of Instruction \nIn recognition of the University's commitment to teaching, the General \nFaculties Council endorses a system of Universal Student Ratings of \nInstruction. This system, however, is only one part of the multi-faceted \napproach described in Section 111.2. \nThe Universal Student Ratings of Instruction are administered \nelectronically via a system known as the eUSRI system.   \nThe Universal Student Ratings of Instruction are designed to provide a \nminimal university-wide base of information on student ratings to the \nItem No. 8 \nGENERAL FACULTIES COUNCIL \nFor the Meeting of October 30, 2017 \nparties listed in this Section. With this purpose in mind, the General \nFaculties Council adopts the following policies: \nA. All Faculties will ensure that evaluation of all instructors and courses \nwill take place each time a course is offered. The term ‘instructors’ is \nmeant to include tenured professors, tenure-track professors, sessional \ninstructors, clinical instructors, field supervisors and graduate teaching \nassistants with responsibilities for courses. \n[…] \nD. The anonymity of student responses to the Universal Student Ratings \nof Instruction is of fundamental importance in maintaining student \nconfidentiality and encouraging the free expression of views. Under \nnormal circumstances, the anonymity of students will be protected. \nUniversal Student Ratings of Instruction offer an avenue of feedback, \nincluding feedback critical of instructors. \n[…] \nG. The numerical summaries for the ten Universal Student Ratings of \nInstruction questions will be reported to the instructor, the Chair, Director \nor Dean and students. \n[…] \nI. All results given out to students, Chairs, Directors and Deans will have \nthe following cautionary preface: \nStudent questionnaires form an important part of evaluating teaching \neffectiveness but cannot be taken alone as a complete assessment of \nan instructor or course. Factors other than an instructor’s teaching ability \nmay influence ratings. These factors include class size, class level, \nFaculty, time in class, required versus optional course, grade \nexpectations, student GPA, gender, race, ethnicity, age of both students \nand instructors. \n[…] \nJ. Nothing in this section will prevent instructors from seeking other \nmeans of feedback from students during the term.” \nThe full GFC Policy 111 Teaching and Learning and Teaching \nEvaluation is available \nat: http://www.gfcpolicymanual.ualberta.ca/111TeachingandLearningand\nTeach.aspx \n5. University of Alberta Faculty Agreement July 2006 (incorporating \nJune 2007 and July 2008 amendments) \n“13.06 The standards for evaluation of teaching performance shall be \nbroadly based, including course content, course design and \nperformance in the classroom. Such evaluation may take into account \ninformation such as statistical summaries of responses to student \nquestionnaires, comprehensive reviews of student commentary; reviews \nby peers, reviews by administrative officials and reviews of teaching \ndossiers and other materials provided by the staff member.” \nAttachments (each to be numbered 1 - <>) \n1. Attachment 1 – Recommendations from GFC Committee on Learning Environment (2 pages) \n2. Attachment 2 -  Summary Report of the Evaluation of Teaching at the University of Alberta (96 pages) \nPrepared by: Sarah Forgie, Chair of CLE with the assistance of University Governance \nhttp://www.gfcpolicymanual.ualberta.ca/111TeachingandLearningandTeach.aspx\nhttp://www.gfcpolicymanual.ualberta.ca/111TeachingandLearningandTeach.aspx\nGFC COMMITTEE ON THE LEARNING ENVIRONMENT \n Recommendations from the GFC Committee on the Learning Environment on Teaching Evaluation and \nthe Use of the Universal Student ratings of Instruction (USRI) as an Evaluation Tool \nWith General Faculties Council approval, the Committee on the Learning Environment would like to continue \nour work examining teacher assessment and evaluation.  We believe that “Robust supports, tools, and training \nto assess teaching quality, using qualitative and quantitative criteria that are fair, equitable, and meaningful \nacross disciplines” is an attainable goal towards fulfilling Objective 13 in For the Public Good:  “To inspire, \nmodel, and support excellence in teaching and learning.”    \nWe plan to use the following recommendations in our work plan:  \n1) Re-examine the overall goals of teaching assessment and evaluation at the U of A ensuring that these \ngoals:  \na. Provide the instructor with feedback to improve their teaching (formative assessment) \nb. Provide administrators with evidence of effective teaching for merit, promotion and tenure decisions \n(summative evaluation). \n2) Consult with the Faculties and the literature in order to define qualities and measures of effective teaching \nand ensure that there is a clear link between these qualities and measures. \n3) Examine GFC Policy 111. “Teaching and Learning and Teaching Evaluation” and transition this policy to \nUAPPOL.  In the process, we will: \na. Examine how decisions regarding promotion and tenure can be based on multiple indicators of effective \nteaching, including course based evaluations and more broadly on other teaching related duties.   \nb. Support consistent interpretation of multiple indicators of effective teaching across the University. \nc. Separate instructor feedback for improvement of teaching (formative assessment) and administrative \nevidence of effective teaching for merit, promotion and tenure decisions (summative evaluation) in both \npolicy and practice. \nd. Develop guidelines for the timing, depth and frequency of summative evaluations. \n4) Create a suite of assessment and evaluation tools and supports (for both faculty and administrators) with \ndefinitions, examples and specific strategies.  In developing these resources we will: \na. Investigate methods for instructors to use feedback to improve their teaching and recommend \nopportunities for teaching development, support and training.   \nb. Investigate methods and tools to support administrators in using a variety of assessment and \nevaluation strategies and recommend opportunities for training. \n5) Ensure student input is included in teaching evaluation. In our re-examination of the current methods in \nwhich student ratings are collected, we will consider:  \na. Using student input for both feedback to improve teaching and for feedback in promotion and tenure \ndecisions (formative assessment and summative evaluation), but separating these two purposes in \nboth policy and practice. \nb. Examining when student evaluations should not be used by FEC for merit, promotion or tenure \ndecisions. \nc. Shifting the emphasis of some of the student rating questions from teacher to student, looking at \nparticipation and learning in addition to instruction. \nd. Increasing the flexibility of the student rating instrument to apply to multiple teaching contexts (including \nvarious class sizes and levels) and unique needs within Faculties. \ne. Creating options within the student rating tool that allow the instructor to contextualize their course.  \nf. Examining qualitative student comments and methods to optimize their use in teaching evaluation.  \ng. Continued investigations into bias and student ratings. \nh. Standardizing methods to optimize response rates and quality of comments with the electronic student \nratings.  \nGFC COMMITTEE ON THE LEARNING ENVIRONMENT \n i. Providing all students (including those with accommodation requirements or those who have withdrawn \nfrom a course) with a fair opportunity to provide feedback. \nSummary Report of the Evaluation of Teaching at the \nUniversity of Alberta \nPrepared by: \nSarah Forgie, Vice-Provost (Learning Initiatives) and CLE Chair \nNorma Nocente, Associate Director, CTL \nL. Francisco Vargas M., Senior Research Coordinator, CTL  \nAnita Parker, Research Assistant, CTL \nCarol Brown, Educational Developer, CTL \nRebecca Best-Bertwistle, Research Assistant, CTL \nApril 2017 \nTable of Contents \n1. Introduction 1 \n2. Method 2 \n2.1. Student Ratings of Instruction 2 \n2.2. Evaluation of Teaching at University of Alberta 3 \n2.3. Multifaceted Evaluation 3 \n3. Findings 3 \n3.1. Student Ratings of Instruction 3 \nInformation from University of Alberta reports and documents 3 \nReview of the literature 4 \nInformation from other universities 6 \n3.2. Evaluation of Teaching at University of Alberta 6 \nInformation from interviews with department chairs 6 \n3.3. Multifaceted Evaluation 7 \nApproaches to multifaceted evaluation 8 \n4. Conclusion 9 \n5. References 10 \n6. Appendices 12 \n1 \n1. Introduction \nThe University of Alberta is committed to excellence in teaching. Its institutional strategic             \nplan, ​For the Public Good, pledges to “inspire, model, and support excellence in teaching and               \nlearning” (University of Alberta, 2016, p. 21). Evaluation of teaching plays an important role in               \nupholding this commitment by shaping the quality of instruction being offered to students.             \nUniversal Student Ratings of Instruction (USRI) questionnaires can provide ​formative          \nevaluation​, revealing areas of strength or shortcomings related to aspects of teaching, such as              \nplanning, organization, communication, and assessment. \nTeaching evaluations also affect the careers of instructors at the University of Alberta,             \nsince USRI results are used as ​summative evaluation for faculty annual review, as well as               \ntenure and promotion. This dual purpose of USRIs (summative and formative) is often             \ncontentious, ​because of their perceived weight with Faculty Evaluation Committees (FEC).           \nConsequently, in May 2016 the Committee on the Learning Environment (CLE) was tasked by              \nthe General Faculties Council (GFC) to report on research into tools for evaluation of teaching               \nby students in university courses. This was to include a critical review of the USRI, as well as an                   \noverview of possible multifaceted evaluation methods, ultimately intending to satisfy the           \nUniversity’s institutional strategic plan to “provide robust supports, tools, and training to develop             \nand assess teaching quality, using qualitative and quantitative criteria that are fair, equitable,             \nand meaningful across disciplines” (University of Alberta, 2016, p. 21). \nCLE approached their investigation with three questions:  \n1. What does the research have to say about student ratings of instruction?  \n2. How are the USRIs and other tools used in the evaluation of teaching at the               \nUniversity of Alberta?  \n3. What are some approaches for multifaceted evaluation of teaching?  \nThe purpose of this report is to address these questions and provide CLE and GFC with                \ninformation to guide future decisions on the USRI instrument and multifaceted evaluation of             \nteaching at the University of Alberta. \n2. Method \nData for this report were obtained from multiple sources. We reviewed 81 articles             \nrelating to the three questions above, beginning with literature referenced in the ​2009 CLE              \nreport Evaluation of Teaching at the U of A (Kanuka et al. 2009), which led us to more recent                   \narticles (see ​Appendix A​). We researched evaluation processes by other universities, reviewed            \nUniversity of Alberta reports and documents, and conducted interviews with University of Alberta             \ndepartment chairs (see a full report of interviews with department chairs in ​Appendix B​).  \n2.1. Student Ratings of Instruction \nInvestigation of question 1, what research has to say about student ratings of instruction,              \nincluded a review of reports and documents, which provided background information about the             \nhistory and current status of teaching evaluation at University of Alberta. These included: \n● Report from the sub-committee on evaluation of alternate-delivery courses (Erkut &           \nKreber, 2002); \n2 \nhttps://docs.google.com/document/d/1sYc7CRUexl1NlOl7JGizsYzc97Zfy439A9xbQlx8kKw/edit\nhttps://drive.google.com/open?id=0B5B3IdGb_-gwbTJmUjFvaGhTbkk\n● Evaluation of teaching at the U of A ​(Kanuka, Marentette, Braga, Campbell, Harvey,             \nHolte, Nychka, Precht, Read, Skappak, & Varnhagen, 2009); \n● AASUA position statement on URSIs ​(Association of Academic Staff University of           \nAlberta [AASUA], 2012); \n● Report of the GFC Committee on the Learning Environment subcommittee on the status             \nof the USRIs ​(​Andrews, Chelen, Connor, Kostiuk, Kwong See, & Milner, 2013​); \n● Report of the Renaissance Committee (Cheeseman, MacLaren, Carey, Glanfield, Liu,          \nMcFarlane, Cahill, Garneau, Supernant, & Szeman, 2013); and \n● GFC policy manual.​ (General Faculties Council, n.d.). \nFor this report, Test Scoring & Questionnaire Services (TSQS) at University of Alberta             \nconducted descriptive analyses that generated gender-specific USRI scores using data from the            \nacademic years 2011/12 to 2015/16. TSQS also participated in an unstructured interview about             \nthe validity, reliability, and use of USRIs at the University of Alberta. \n2.2. Evaluation of Teaching at University of Alberta \nInvestigation of question 2, how USRIs and other tools are used at University of Alberta,               \nincluded short, semi-structured interviews with department chairs (or their equivalents in           \nnon-departmental faculties). These interviews were 35-40 minutes, audio recorded, and used an            \ninterview protocol pre-approved by CLE with questions about their experiences evaluating           \nteaching (see ​Appendix C​). Interview participants were also given two sample USRI case             \nstudies representing real teaching scores and were asked to interpret the scores within the              \ncontext of their department (see ​Appendix D​). They were asked to reflect on both score sets as                 \nif both instructors were teaching different sections of the same course. All potential interview              \nparticipants were emailed directly with information about the study, including a research letter of              \ninvitation, and were encouraged to contact any member of the research team if they had               \nquestions or concerns. Data was collected from January to March 2017.  \n2.3. Multifaceted Evaluation \nInformation sources for question 3, approaches to multifaceted evaluation, included: \n● University of Alberta reports and documents (listed above);  \n● Multifaceted summative evaluation of teaching​, a symposium held in May 2015 at Centre             \nof Teaching and Learning (CTL), University of Alberta; \n● University of Alberta peer review of teaching​ (Gibson, n.d.); and \n● Interviews with department chairs.  \n3. Findings \n3.1. Student Ratings of Instruction \nInformation from University of Alberta reports and documents \nThe 2009 CLE report ​outlined a number of recommendations related to the USRI             \ninstrument and to teaching evaluation more generally, as well as GFC policy (Kanuka et al.,               \n2009). ​This report reviewed literature from up to 2008 and selected 35 articles providing insights               \n3 \nhttps://docs.google.com/document/d/1qNWd1zwfL7qAyGkSK9Duawk2CZa9QxlY8HMrrnOb1kE/edit\nhttps://docs.google.com/document/d/1eflt4J3IB-5685QR_z2TNCFXhwTlT1jMu2Ce5UHx5Wg/edit\non the following themes: validity; bias; whether students can effectively measure quality            \nteaching; the need for effective tools; correlations between grades and ratings; the impact of              \nevaluation on quality teaching; and the evaluation of faculty for tenure and promotion.  \nIn 2012, the 2009 CLE report was revisited, and the resulting 2013 CLE report, ​Report of                \nthe GFC Committee on the Learning Environment subcommittee on the status of the USRIs​, ​put               \nforward four recommendations, including that the purpose of USRIs needs to be clearly             \nidentified, and that GFC policy needs updating. It was also suggested that a “working group be                \nstruck to determine how to promote consistent interpretation and implementation of policy”            \n(Andrews et al., 2013). \nIn 2013, the Renaissance Committee, ratified by the AASUA and the Governors of the              \nUniversity of Alberta, addressed aspects of the       \nterms and conditions of work performed at the        \nUniversity of Alberta. Their report detailed a       \nnumber of concerns and made specific      \nrecommendations related to the evaluation of      \nteaching, including USRIs (​Cheeseman et al.,      \n2013)​. The committee recommended that the      \nUniversity of Alberta ​design a set of questions        \non the USRI that evaluate the effectiveness of        \nteaching​. There is no evidence to indicate that any of the recommendations from the 2009 CLE,                \n2013 CLE, or 2013 Renaissance Committee reports were pursued. See ​Appendix E for a table               \nsummarizing the positions and recommendations related to USRIs in University of Alberta            \npolicy, documents, and reports. \nReview of the literature \nIn our review of articles referenced in the 2009 CLE report, as well as articles published                \nthereafter, we organized literature relating to student ratings of instruction into two categories ​–              \nbiases and validity (see ​Appendix A​). \nBiases. ​We divided the biases category into sub-categories of gender, instructor           \ncharacteristics, the correlation between grades and ratings, nonresponse, and non-instructional          \nfactors. \n● Gender. ​The literature in this category is extensive and conflicted. Numerous articles in             \nthis subcategory report gender differences or no differences in student evaluations of            \nteaching. For example, Boring, Ottoboni, and Stark (2016) concluded that student           \nratings are “biased against female instructors by an amount that is large and statistically              \nsignificant.” On the other hand, Wright and Jenkins-Guarieri (2012) conducted a           \nmeta-analysis of 193 studies and concluded that student evaluations appear to be free             \nfrom gender bias. The University of Alberta TSQS conducted descriptive analyses and            \nthe results showed there is no apparent difference between scores for males (​N ​=              \n18576, ​Mdn ​= 4.53) and females (​N ​= 13679, ​Mdn = 4.57) for statement 211 ​(“overall the                 \ninstructor was excellent”)​. \n● Instructor characteristics. ​Article findings in this sub-category, seven articles total, were           \nthat: instructor personality positively correlates with student evaluations (Clayson, 2013;          \n4 \nhttps://docs.google.com/document/d/11hFvMpGYeT9BWjW7iWcdFrFE0W11oALycSs2MprsaRY/edit\nhttps://docs.google.com/document/d/1sYc7CRUexl1NlOl7JGizsYzc97Zfy439A9xbQlx8kKw/edit\nKim & MacCann, 2016); instructor physical attractiveness positively correlates with          \nstudent evaluations on   \nRateMyProfessor.com (Felton, Mitchell,   \n& Stinson, 2004); instructor age     \nnegatively correlates with student    \nevaluations on RateMyProfessor.com   \n(Stonebraker & Stone, 2015) and     \ninstructor age impacts negatively on perceptions of teachers and anticipated rapport in            \nthe classroom based on photographs (Wilson, Beyer, & Monteiro, 2014); instructor           \nposition (limited term lecturer versus full time faculty) does affect student evaluations            \n(Cho & Otani, 2014); and instructor rank (i.e. achievement of tenure) does not affect              \nstudent evaluations (Cheng, 2015). \n● Correlation between grades and ratings. Most literature, seven articles in this           \nsub-category, reported that students receiving higher grades tended to provide more           \nfavourable evaluations of teaching. Cho, Baek, and Cho (2015) found this to be true in               \ntheir research study and suggested that it might be a psychological “gift” from the              \nstudent to the instructor. However, two articles suggested otherwise, such as an analysis             \nof 50,000 courses by Centra (2003) that debunked the correlation between expected            \ngrades and student evaluations. \n● Nonresponse. ​Nonresponse bias occurs when students choose not to participate in an            \nevaluation of teaching, and the missing data may cause skewed results. Three articles in              \nthis sub-category reported that nonresponse bias does influence student evaluations of           \nteaching. For example, Macfadyen, Dawson, Prest, and Gasevic (2016) uncovered that           \n“respondent pools do not fully represent the distribution of students in courses.” No             \narticles suggested otherwise. \n● Non-instructional. Non-instructional bias occurs when circumstances beyond the control         \nof an instructor ​– ​such as class type,        \ntime, size, and semester ​– ​influence      \nstudent evaluation of teaching. The four      \narticles in this sub-category varied in      \ntheir investigations and conclusions. For     \nexample, Nargundkar and Shrikhande    \n(2014) studied numerous factors and     \nconcluded that the combined impact was      \nstatistically significant; Reardon, Leierer, and Lee (2014) determined that class schedule           \ndoes not affect ratings. \nIt should be noted that GFC Policy 111.3 (I) also recognizes student bias may impact the                \nevaluation of an instructor.  \nValidity. ​Validity refers to the extent that an instrument or procedure measures what it              \nintends to measure, and the extendibility of the results to other situations. Literature within this               \ncategory equally supports opposing viewpoints as to whether or not student evaluations of             \nteaching are valid measures of teaching quality; whether or not students have the knowledge,              \nskills, or motivation to measure teaching quality. For example, Grammatikopoulos, Linardakis,           \n5 \nGregoriadis, and Oikonomidis (2015) found an instrument used in the Greek higher education             \nsystem to be valid, whereas Lama, Arias, Mendoza, and Manahan (2015) stated that students              \nat an Australian university completed surveys without diligence. A meta-analysis by Uttl, White,             \nand Gonzalez (2016) re-analyzed meta-analytic data from Cohen (1981) and concluded that            \nstudent evaluations of teaching did not indicate teaching quality. Marsh and Roche (1997) found              \nthat student evaluations correlated with those of peers and trained evaluators, whereas            \nUijtdehaage and O’Neal (2015) reported that students mindlessly evaluated a fictitious           \ninstructor, even when a photograph was provided. During this project, our research team was              \nnot able to find information on the validity of the USRI instrument at the University of Alberta .  1\nRelated to validity is the impact of student evaluations on teaching quality. In our review               \nof the literature, five articles were divided as to whether or not results from student evaluations                \nhad a positive impact on teaching quality. For example, Makondo and Ndebele (2014) reported              \nthat lecturers perceive student feedback as valuable for building their teaching skills, yet ​Stein,              \nSpiller, Harris, Deaker, and Kennedy (2013) argued that evaluation data ​is not being used              \neffectively for professional development. In a 2011 survey of 564 academic staff at the              \nUniversity of Alberta, 69.2% of respondents agreed that ​qualitative comments on USRIs helped             \nimprove the quality of their teaching; 49.5% stated that the USRI’s ​quantitative scores were not               \nhelpful in this regard (AASUA, 2012).  \nInformation from other universities \nThe general consensus that student input should be sought related to their experience             \nwith course instruction and the learning environment is evident in the practices of institutions              \nother than the University of Alberta​. ​For example, in 2015 Stanford University introduced a new               \nend-of-term course evaluation instrument that included nine required items and additional           \ncustomizable, open- or closed-ended questions (​Stanford University VPTL, n.d.​). \nSome institutions use multiple instruments to seek insight on students’ perceptions of            \nteaching and learning, as well as the broader context of the student experience. ​For example,               \nboth University of Oxford and University of Sydney have recently adopted “The Student             \nBarometer”, which includes the learning experience, living experience, support services, and           \nother areas (​I-graduate, n.d.​). This measure is administered once per year and aims to “track               \nand compare the decision-making, expectations, perceptions and intentions of students from           \napplication to graduation” (University of Sydney, 2016a, para. 2). The University of Oxford also              \nemploys department-specific evaluation mechanisms, as well as the “National Student Survey”           \nfor undergraduate students in the last year of their program (​Ipsos MORI, n.d.​; University of               \nOxford, 2015, p. 7). \nUniversity of Sydney uses a “Student Experience Survey” for undergraduate students in            \ntheir first and final year of their program, as well as a mandatory online “Unit of Study Survey                  \n(USS)” with eight required items (six quantitative, two open response) and up to four              \nfaculty-specific quantitative items and one faculty-specific open response item (​University of           \nSydney, 2016b​). Each faculty can also have up to four USS versions to allow customization of                \n1 ​TSQS measures the reliability of the USRI by comparing medians to the previous academic \nyears. \n6 \nhttps://vptl.stanford.edu/teaching-learning/teaching-practices/evaluation-feedback/stanfords-new-course-evaluations/standard\nhttps://www.i-graduate.org/services/student-barometer/\nhttp://sydney.edu.au/education-portfolio/ei/ses/\nhttp://sydney.edu.au/education-portfolio/ei/ses/\nhttp://www.thestudentsurvey.com/\nthe survey for different contexts (University of Sydney, 2016c). ​Taken together, the examples             \nprovided here highlight that other institutions value student feedback on the teaching and             \nlearning environment and are making efforts to update and improve the instruments they utilize              \nto obtain this feedback. \nIn summary ​for question 1, what research has to say about student ratings of instruction,               \nwe conclude that the topic of survey tools is prevalent the literature, often around the concerns                \nof biases or validity. It is evident that universities globally value student feedback and are               \nworking to implement high-quality instruments. University of Alberta reports and documents           \nhave historically addressed the USRI, making recommendations for the instrument and           \nUniversity policy; however, there is no indication suggestions made in these reports have had              \nany traction. \n3.2. Evaluation of Teaching at University of Alberta \nInformation from interviews with department chairs \nInterview participants from all faculties other than Faculty of Medicine and Dentistry            \n(FOMD) reported using USRIs scores and comments to evaluate teaching; only a portion of              \nFOMD participants reported using this tool. Department chairs revealed that, although they try             \nto consider all the USRI statements, they focus primarily on USRI statement 221 (“overall the               \ninstructor was excellent”), and statement 25 (“overall the quality of the course content was              \nexcellent”) as indicators of effective teaching. \nMost participants stated that they     \napproach the interpretation of USRI results      \nwith a contextual attitude, indicating that      \nUSRIs should be understood in light of       \ninstructor characteristics and   \nnon-instructional elements. \nParticipants identified several issues    \nwith using USRIs exclusively to evaluate      \nteaching, which aligned with our review of the        \nliterature, such as biases with gender,      \ninstructor characteristics, and   \nnon-instructional factors. Most department    \nchairs voiced their need for additional      \nsupports to better evaluate teaching. Although      \nsome recommended possible alternatives to     \nsupplement USRI scores, they still expressed      \nhope that the institution would provide      \nsolutions for their concerns. \nParticipants also raised the issue of using       \nUSRIs for purposes of tenure and promotion.       \nThe 2009 CLE report mentioned this concern,       \nand our review of the literature included seven        \n7 \narticles concerning the use of student surveys for summative purposes, and misinterpretation of             \ntheir results leading to incorrect conclusions.  \nIn summary for question 2, ‘how USRIs and other tools are used at University of Alberta’,                \nwe conclude that ​participants from all faculties other than FOMD consistently use USRIs scores              \nand comments to evaluate teaching. Department chairs focus on one or two statements as a               \nbarometer of effective teaching, and although most approach interpretation of results with a             \ncontextual attitude, they also recognize issues with the USRI that are consistent with our review               \nof the literature, specifically perceived issues of bias, validity, and concerns about potential             \nmisinterpretations of student survey results for the summative purposes of tenure and            \npromotion. \n3.3. Multifaceted Evaluation \nAccording to Lyde, Grieshaber, & Byrns (2016), a ​comprehensive system of teaching            \nevaluation is necessary due to the limitations of student surveys and the complex nature of               \nteaching performance. In our review of articles referenced in the 2009 CLE report, as well as                \nmore recently, ten articles recognized the need for instruments that are of high psychometric              \nquality, and also that evaluations should include multiple sources of information, such as             \nsurveys, peer evaluations, self-evaluations, focus groups, and more.  \nReference to multifaceted evaluation is found in University of Alberta documents and            \nreports discussed earlier. The 2009 CLE report commented that an imprecise definition of             \nteaching excellence in section 111.1 of the GFC policy exacerbates the lack of guidance              \nprovided to individual faculties for multifaceted evaluation (Kanuka et al., 2009, pp. 21-22). The              \n2013 CLE report recommended the creation of a resource to guide faculties with “possibilities              \nand/or examples” of multifaceted evaluation (Andrews et al., 2013).  \nIn May 2015, the Centre for Teaching and Learning (CTL) hosted a symposium entitled              \nMultifaceted Summative Evaluation of Teaching​, wherein some recommendations for best          \npractice were brought forward. Key points included: \n● University of Alberta policy needs to include a clear definition of teaching excellence,             \nincluding a specific set of criteria of effective teaching that can be used for purposes of                \nevaluation; these criteria should be shared with faculty, instructors and students. \n● Both formative and summative evaluation of teaching should be multifaceted, collecting           \nmultiple sources of evidence at multiple times annually.  \n● A multifaceted teaching evaluation plan should be developed to supplement University           \npolicy, including definitions, examples, evaluation procedures, and specific strategies for          \ntraining and support. \nApproaches to multifaceted evaluation \nThe 2013 Renaissance Committee report highlighted the importance of rigorous,          \nmultifaceted evaluation, which was described as information “collected through a variety of            \nmethods and assessed at multiple points in time” (Cheeseman et al., 2013, p. 7, 69). “The array                 \ncan include student ratings of courses, a teaching dossier, peer observations, external reviews             \nof content, reflection of the teacher (self-assessment), administrator reviews of content and            \ncourse observation, review of published work on teaching Scholarship, and evidence supporting            \n8 \nhttps://www.ualberta.ca/centre-for-teaching-and-learning/events/symposium-series/past-symposia/multifaceted-summative-evaluation-teaching\nthe reputation of the teacher in the field(s) of instruction, within and without the University”               \n(Cheeseman et al., p. 70). See ​Appendix F for a table summarizing the positions and               \nrecommendations related to multifaceted evaluation in University of Alberta policy, documents,           \nand reports. \nPeer review of teaching. Gibson (n.d.), author of ​University of Alberta Peer Review of              \nTeaching (an online article provided as a resource for the 2015 CTL symposium), defined peer               \nreview of teaching as “informed collegial assessment of faculty teaching for either fostering             \nimprovement or making personnel decisions” and stated that both formative and summative            \nmethods were required for comprehensive teaching evaluation (para 5). Gibson explained that            \nwhile quantitative student questionnaires provide information about day-to-day classroom         \ninteraction, peer review can broaden this to aspects, such as “course content, academic rigor              \nand appropriateness of objectives and topics;… subject matter expertise; instructional materials           \nand methods; and, assessment and grading” (para 3). Gibson outlined six phases of summative              \npeer review and provided eighteen appendices of practical resources, such as sample            \nobservation tools and reports. \nTeaching dossiers (portfolios). ​A teaching dossier serves “to facilitate the presentation of            \na faculty member’s teaching achievements and major strengths for self-assessment and           \ninterpretation by others\" (Day, Robberecht & Roed, 1996, p. 1). They are a cumulative record of                \none’s teaching activities and often include: “(a) a statement regarding the faculty member’s             \nteaching philosophy, goals, and strategies; (b) a description of teaching (planning, preparing,            \nand teaching courses; assessing student learning; and giving feedback); (c) an evaluation of             \nteaching accomplishments; and (d) suggestions regarding possible changes for future teaching”           \n(Day et al.,1996, p. 1). Teaching dossiers require instructors to gather multiple sources of              \nevidence and define the value of their scholarship in teaching (Cheeseman et al., 2013).              \nRelated to summative evaluation of teaching, the 2013 Renaissance Committee report           \nrecommended that “​a teaching dossier, following CTL standards, should be part of all tenure              \nand promotion packages” (Cheeseman et al., 2013, p. 70). A document from the ​University of               \nSydney​ provides a comprehensive list of data sources instructors may include in a dossier.  \nInterviews with department chairs​. Participants indicated having already implemented         \nsome approaches for multi-faceted evaluation of teaching. In-class peer observation was the            \nmost commonly used additional source of information, followed by annual instructor pedagogical            \nself-reflections. Some departments chairs    \nhave also implemented yearly faculty     \naudits, in which a small portion of their        \nprofessoriate teaching is evaluated in a      \nmore comprehensive way, and using a      \nvariety of supplementary sources of     \ninformation. Participants indicated,   \nhowever, that they mostly obtain these      \nextra resources on a voluntary basis (only       \nwhen professors agree to provide them),      \nand even when they do obtain these resources, not all of them bring this information to FEC.                 \n9 \nhttps://docs.google.com/document/d/1X6E4VtHWARCopnvqFoGIPb9FSZZpH3HugEBSSrXGFRM/edit\nhttps://www.ualberta.ca/centre-for-teaching-and-learning/events/symposium-series/past-symposia/multifaceted-summative-evaluation-teaching/peer-review-of-teaching\nhttp://sydney.edu.au/education-portfolio/ei/programs/teaching_insights/pdf/insight7_evidence.pdf\nhttp://sydney.edu.au/education-portfolio/ei/programs/teaching_insights/pdf/insight7_evidence.pdf\nhttps://www.ualberta.ca/centre-for-teaching-and-learning/events/symposium-series/past-symposia/multifaceted-summative-evaluation-teaching/peer-review-of-teaching\nThey voiced their need for additional institutional supports to better evaluate teaching with a              \nmulti-faceted approach, and they hope the institution will provide a solution. \nIn summary for question 3, approaches to multifaceted evaluation, we conclude that:            \nthere are numerous potential evaluative methods in addition to student surveys; multifaceted            \nevaluation is encouraged by several University reports and documents and literature in general,             \nas well as mandated by University policy; yet this has not yet translated into its consistent or                 \nformal implementation across faculties en masse. \n4. Conclusion \nThe purpose of this report is to support CLE with their investigation into student ratings               \nof instruction, the use of USRIs and other evaluation tools at the University of Alberta, and                \napproaches for multifaceted evaluation of teaching.  \nQuestion 1, w​hat does the research have to say about student ratings of instruction?  \nResearch around student ratings of instruction primarily point to concerns about biases            \nand validity of survey tools and results. The perspective that student feedback is valuable to               \nhelp ensure high-quality teaching environments, yet that survey tools are imperfect and limited             \nfor a comprehensive evaluation of teaching, is shared by universities globally.  \nQuestion 2, how are the USRIs and other tools used in the evaluation of teaching at the                 \nUniversity of Alberta? \nSemi-structured interviews with department chairs revealed that USRIs are the primary           \nsource of teaching evaluation information for all faculties except FOMD. Specifically, most            \ndepartment chairs indicated that they start with only one or two statements but they do their best                 \nto contextualize the numerical results. Some department chairs expressed concerns around           \nbiases, validity, and the potential for misinterpretation of USRI results for summative purposes             \nof promotion and tenure decisions. \nQuestion 3, what are some approaches for multifaceted evaluation of teaching?  \nMultifaceted evaluation is supported by the literature and is also mandated by GFC             \npolicy. However, impeding its University-wide adoption and consistency is a lack of support and              \ntime for those responsible for conducting such robust, comprehensive evaluations of teaching.            \nMoving forward, systematic and purposeful evaluation of teaching can only materialize if there             \nare realistic and tangible expectations, and supports (documents, workshops, etc.). \n5. References \nThese are the references used in the preparation of this report, not including our review of the \nliterature. For the latter, see ​Appendix G​. \nAndrews, N., Chelen, D., Connor, B., Kostiuk, L., Kwong See, S., & Milner, R. (2013, June 5). \nReport of the GFC Committee on the Learning Environment subcommittee on the status \nof the USRIs. ​Retrieved from \n10 \nhttps://docs.google.com/document/d/1WJosw7X5j6mZ5dGFBQY4BCow4HILSK0q7zku0Bm36wI/edit\nhttp://www.governance.ualberta.ca/en/GeneralFacultiesCouncil/CommitteeontheLearnin\ngEnvironm/~/media/Governance/Documents/GO05/LEA/13-14/Reports/Item-5-USRI-Su\nbcommittee-Final-Report-June-2013-FINAL.pdf \nAssociation of Academic Staff University of Alberta (AASUA). (2012). ​AASUA position statement \non URSIs.​ Retrieved from \nhttp://www.aasua.ca/wp-content/uploads/2014/03/AASUA_Position_Statement_on_USR\nIs.pdf \nCentre for Teaching and Learning. (2015). ​Multifaceted summative evaluation of teaching \nsymposium​. Retrieved from \nhttps://www.ualberta.ca/centre-for-teaching-and-learning/events/symposium-series/past-\nsymposia/multifaceted-summative-evaluation-teaching \nCheeseman, C., MacLaren, I., Carey, J., Glanfield, F., Liu, L., McFarlane, L., Cahill, J. C., \nGarneau, T., Supernant, K., & Szeman, I. (2013, December 9). ​Report of the \nRenaissance Committee.​ Retrieved from ​http://www.renaissance.ualberta.ca/ \nDay, R., Robberecht, P., & Roed, B. (1996).​ ​Teaching dossier: A guide.​ Retrieved from:  \nhttps://d1pbog36rugm0t.cloudfront.net/-/media/ualberta/centre-for-teaching-and-learning/\ninstructional-resources/teaching-dossier/teachingdossierguide-1.pdf \nErkut, E. & Kreber, C. (2002). ​Report from the sub-committee on evaluation of  \nalternate-delivery courses: Continuing discussion. ​General Faculties Council Teaching \nand Learning Committee. Retrieved from \nhttps://docs.google.com/document/d/1KpLMK5kN4r6Mp_BSEoYiZ1xOrbdI9shhScBDAc\n2NPdI/edit \nGeneral Faculties Council. (n.d.).​GFC policy manual.​ Retrieved from \nhttp://www.gfcpolicymanual.ualberta.ca/ \nGibson, S. (n.d.). ​University of Alberta peer review of teaching​. Retrieved from \nhttps://www.ualberta.ca/centre-for-teaching-and-learning/events/symposium-series/past-\nsymposia/multifaceted-summative-evaluation-teaching/peer-review-of-teaching \nI-graduate. (n.d.). ​The student barometer. ​Retrieved from \nhttps://www.i-graduate.org/services/student-barometer/ \nIpsos MORI. (n.d.). ​National student survey. ​Retrieved from ​http://www.thestudentsurvey.com/ \nKanuka, H., Marentette, P., Braga, J., Campbell, K., Harvey, S., Holte, R., Nychka, J., Precht, \nD., Read, D., Skappak, C., & Varnhagen, C. (2009, January 9). ​Evaluation of teaching at \nthe U of A: Report of the sub-committee of the Committee on the Learning Environment \n(CLE).​ Retrieved from \nhttps://www.ualberta.ca/-/media/ualberta/centre-for-teaching-and-learning/symposium/ev\naluating-teaching-2009/symposiumevaluating-teaching-at-the-u-of-a-taskforce-report.pdf \nLyde, A. R., Grieshaber, D. C., Byrns, G. (2016). Faculty teaching performance: Perceptions of \na multi-source method for evaluation (MME). ​Journal of the Scholarship of Teaching and \nLearning, 16​(3), 82-94. doi: 10.14434/josotl.v16i3.18145 \nStanford University Vice Provost for Teaching and Learning (VPTL). (n.d.). ​Standard Course  \nEvaluation Questions​. Retrieved from: \nhttps://vptl.stanford.edu/teaching-learning/teaching-practices/evaluation-feedback/stanfo\nrds-new-course-evaluations/standard \n11 \nhttps://www.ualberta.ca/-/media/ualberta/centre-for-teaching-and-learning/symposium/evaluating-teaching-2009/symposiumevaluating-teaching-at-the-u-of-a-taskforce-report.pdf\nhttp://www.aasua.ca/wp-content/uploads/2014/03/AASUA_Position_Statement_on_USRIs.pdf\nhttp://www.governance.ualberta.ca/en/GeneralFacultiesCouncil/CommitteeontheLearningEnvironm/~/media/Governance/Documents/GO05/LEA/13-14/Reports/Item-5-USRI-Subcommittee-Final-Report-June-2013-FINAL.pdf\nhttp://www.governance.ualberta.ca/en/GeneralFacultiesCouncil/CommitteeontheLearningEnvironm/~/media/Governance/Documents/GO05/LEA/13-14/Reports/Item-5-USRI-Subcommittee-Final-Report-June-2013-FINAL.pdf\nhttps://www.ualberta.ca/centre-for-teaching-and-learning/events/symposium-series/past-symposia/multifaceted-summative-evaluation-teaching/peer-review-of-teaching\nhttp://www.thestudentsurvey.com/\nhttps://www.ualberta.ca/-/media/ualberta/centre-for-teaching-and-learning/symposium/evaluating-teaching-2009/symposiumevaluating-teaching-at-the-u-of-a-taskforce-report.pdf\nhttps://www.ualberta.ca/centre-for-teaching-and-learning/events/symposium-series/past-symposia/multifaceted-summative-evaluation-teaching\nhttp://www.gfcpolicymanual.ualberta.ca/\nhttps://vptl.stanford.edu/teaching-learning/teaching-practices/evaluation-feedback/stanfords-new-course-evaluations/standard\nhttp://www.renaissance.ualberta.ca/\nhttp://www.governance.ualberta.ca/en/GeneralFacultiesCouncil/CommitteeontheLearningEnvironm/~/media/Governance/Documents/GO05/LEA/13-14/Reports/Item-5-USRI-Subcommittee-Final-Report-June-2013-FINAL.pdf\nhttps://docs.google.com/document/d/1KpLMK5kN4r6Mp_BSEoYiZ1xOrbdI9shhScBDAc2NPdI/edit\nhttps://docs.google.com/document/d/1KpLMK5kN4r6Mp_BSEoYiZ1xOrbdI9shhScBDAc2NPdI/edit\nhttp://www.aasua.ca/wp-content/uploads/2014/03/AASUA_Position_Statement_on_USRIs.pdf\nhttps://d1pbog36rugm0t.cloudfront.net/-/media/ualberta/centre-for-teaching-and-learning/instructional-resources/teaching-dossier/teachingdossierguide-1.pdf\nhttps://www.ualberta.ca/centre-for-teaching-and-learning/events/symposium-series/past-symposia/multifaceted-summative-evaluation-teaching\nhttps://www.i-graduate.org/services/student-barometer/\nhttps://d1pbog36rugm0t.cloudfront.net/-/media/ualberta/centre-for-teaching-and-learning/instructional-resources/teaching-dossier/teachingdossierguide-1.pdf\nhttps://vptl.stanford.edu/teaching-learning/teaching-practices/evaluation-feedback/stanfords-new-course-evaluations/standard\nhttps://www.ualberta.ca/centre-for-teaching-and-learning/events/symposium-series/past-symposia/multifaceted-summative-evaluation-teaching/peer-review-of-teaching\nUniversity of Alberta.​ (2016). ​For the public good: Institutional strategic plan 2016-2021. \nRetrieved from ​https://www.ualberta.ca/strategic-plan \nUniversity of Sydney. (n.d.). Teaching insight: Possible data sources to draw on when providing \nevidence about your teaching. Retrieved from \nhttp://sydney.edu.au/education-portfolio/ei/programs/teaching_insights/pdf/insight7_evid\nence.pdf \nUniversity of Sydney. (2016a). ​Student Barometer (SB/IB)​. Retrieved from:  \nhttp://sydney.edu.au/education-portfolio/ei/studentbarometer/ \nUniversity of Sydney. (2016b). ​Student Experience Survey (SES)​. Retrieved from:  \nhttp://sydney.edu.au/education-portfolio/ei/ses/ \nUniversity of Sydney. (2016c). ​Unit of Study Survey (USS)​. Retrieved from:  \nhttp://sydney.edu.au/education-portfolio/ei/USS/default.htm \nUniversity of Oxford. (2015). ​Procedures for the Annual Monitoring of Courses. ​Retrieved from: \nhttps://www.admin.ox.ac.uk/edc/qa/pamc/ \n6. Appendices  \n● Appendix A: Table of Reviewed Literature \n● Appendix B: ​Summary of Interviews with Department Chairs \n● Appendix C: Interview Questions \n● Appendix D: Sample USRI Case Studies \n● Appendix E: Summary of Positions and Recommendations Related to USRIs in \nUniversity of Alberta Policy, Documents, and Reports \n● Appendix F: ​Summary of Positions and Recommendations Related to Multifaceted \nEvaluation in University of Alberta Policy, Documents, and Reports \n● Appendix G: References of Reviewed Literature  \n● Appendix H: Abstracts for Reviewed Literature \n● Appendix I: Recommendations Related to Evaluation of Teaching from the 2013 \nRenaissance Committee Report \n12 \nhttps://drive.google.com/open?id=1qNWd1zwfL7qAyGkSK9Duawk2CZa9QxlY8HMrrnOb1kE\nhttp://sydney.edu.au/education-portfolio/ei/ses/\nhttps://drive.google.com/open?id=1zy-uKCxmyykDMGopvkLYVwvn1SN1IVqP56lYGlJbDv0\nhttp://sydney.edu.au/education-portfolio/ei/programs/teaching_insights/pdf/insight7_evidence.pdf\nhttp://sydney.edu.au/education-portfolio/ei/USS/default.htm\nhttps://drive.google.com/open?id=1sYc7CRUexl1NlOl7JGizsYzc97Zfy439A9xbQlx8kKw\nhttps://drive.google.com/open?id=0B5B3IdGb_-gwbTJmUjFvaGhTbkk\nhttp://sydney.edu.au/education-portfolio/ei/programs/teaching_insights/pdf/insight7_evidence.pdf\nhttps://drive.google.com/open?id=11hFvMpGYeT9BWjW7iWcdFrFE0W11oALycSs2MprsaRY\nhttps://drive.google.com/open?id=1eflt4J3IB-5685QR_z2TNCFXhwTlT1jMu2Ce5UHx5Wg\nhttps://drive.google.com/open?id=0B5B3IdGb_-gwbTJmUjFvaGhTbkk\nhttps://www.ualberta.ca/strategic-plan\nhttps://drive.google.com/open?id=12fjibAleuJTHDzU-cUCKuqWSS5HyJA1aAxGq4_NGj-4\nhttps://drive.google.com/open?id=1X6E4VtHWARCopnvqFoGIPb9FSZZpH3HugEBSSrXGFRM\nhttps://drive.google.com/open?id=1X6E4VtHWARCopnvqFoGIPb9FSZZpH3HugEBSSrXGFRM\nhttp://sydney.edu.au/education-portfolio/ei/studentbarometer/\nhttps://drive.google.com/open?id=1WJosw7X5j6mZ5dGFBQY4BCow4HILSK0q7zku0Bm36wI\nhttps://drive.google.com/open?id=11hFvMpGYeT9BWjW7iWcdFrFE0W11oALycSs2MprsaRY\nhttps://drive.google.com/open?id=1zy-uKCxmyykDMGopvkLYVwvn1SN1IVqP56lYGlJbDv0\nhttps://drive.google.com/open?id=1X6E4VtHWARCopnvqFoGIPb9FSZZpH3HugEBSSrXGFRM\nhttps://www.admin.ox.ac.uk/edc/qa/pamc/\nAppendix A: Table of Reviewed Literature \nThis table contains literature referenced in the 2009 CLE report, as well as more recent articles \nrelating to the evaluation of teaching. Due to varied research methodologies, measures, and \nresults, definitive comparisons and conclusions from the literature is not be possible; however, \nthe depth and breadth of the articles can provide a general idea about current academic \nperspectives. Black font indicates literature cited in the 2009 CLE report; ​green font ​indicates \nmore recent articles. Brief summarizing points from each article are provided.  \nClick on the links to move directly to each bookmarked section. For abridged abstracts, see \nAppendix H​. For a complete reference list, see ​Appendix G​. \nBiases  \n● Gender \n● Instructor characteristics \n● Correlation between grades and ratings \n● Nonresponse \n● Non-instructional \n● Other \nValidity  \nImpact on Teaching Quality \nEvaluating Faculty for Tenure and Promotion \nMultifaceted Evaluation  \nhttps://docs.google.com/document/d/1WJosw7X5j6mZ5dGFBQY4BCow4HILSK0q7zku0Bm36wI/edit\nhttps://docs.google.com/document/d/12fjibAleuJTHDzU-cUCKuqWSS5HyJA1aAxGq4_NGj-4/edit\n Biases \nThis category is divided into sub-categories of gender, instructor characteristics, correlation \nbetween grades and ratings, nonresponse, and non-instructional. Also, an “other” category \nincludes articles that focused on multiple biasing factors, biasing factors that do not fit into any \nother category, or biases in general. \n Biases, Gender. ​Most literature, seven articles in this sub-category, reported that an \ninstructor’s gender does influence student evaluations of teaching; however, two articles \nsuggest otherwise. \nGender influences student ratings Gender does not influence student ratings \nBoring, Ottoboni, & Stark (2016): ratings are \nbiased against female instructors by an \namount that is large and statistically \nsignificant \nGehrt, Louie, & Osland (2015): female \nstudents evaluated female lower-ranked \nfaculty most favorably; male students \nevaluations were more favorable for lower \nranked male faculty, but they did not degrade \nhigher ranked female faculty \nHuebner & Magel (2015): variances of the \nclass average responses between male and \nfemale faculty were higher for male faculty \nLaube, Massoni, Sprague, & Ferber (2007): \nthe inconsistency on the question of whether \nstudent evaluations are gendered is itself an \nartifact of the way that quantitative measures \ncan mask underlying gender bias \nMacNell, Driscoll, & Hunt (2015): students \nrate males significantly higher than females \nMiles & House (2015): lower ratings for \nfemale instructors teaching larger required \nclasses \nWilson, Beyer, & Monteiro (2014): lower \nratings for older instructors, but more so for \nfemales than males \nCentra & Gaubatz (2000): only small \nsame-gender preferences found, particularly \nwith females \nSmith, Yoo, Farr, Salmon, & Miller (2007): \nmale and female students rated female \ninstructors more highly; effect was small but \nsignificant due to sample size  \nWright & Jenkins-Guarieri (2012): SETs \nappear to be valid and free from gender bias \n Biases, Instructor characteristics​ ​(appearance, personality, age, and/or rank). Article \nfindings in this sub-category, seven articles total, were that: instructor personality positively \ncorrelates with student evaluations; instructor physical attractiveness positively correlates with \nstudent evaluations; instructor age negatively correlates with student evaluations; instructor \nrank does affect student evaluations; and instructor rank does not affect student evaluations.  \nInstructor characteristics influence \nstudent ratings \nInstructor characteristics do not \ninfluence student ratings \nCho & Otani (2014): students give higher \nratings for limited-term lecturers versus \nfull-time faculty \nClayson (2013): students’ first perceptions of \nan instructor’s personality are significantly \nrelated to ratings at the end of the semester \nFelton, Mitchell, & Stinson (2004): students \ngive attractively-rated professors higher \nquality and easiness scores  \nKim & MacCann (2016): students’ expressed \neducational satisfaction was related to \nperceptions of instructor personality \nStonebraker & Stone (2015): age has a \nnegative impact on student ratings of faculty \nmembers; begins around mid-forties; offset by \nattractiveness \nWilson, Beyer, & Monteiro (2014): lower \nratings for older instructors, but more so for \nfemales than males \nCheng (2015): tenure does not have a \nsignificant impact on student ratings of \nteaching performance \n Biases, Correlation between grades and ratings. ​Most literature, seven articles in this \nsub-category, reported that students receiving higher grades tend to provide more favourable \nevaluations of teaching; however, two articles suggest otherwise. \nThere is a correlation between higher \ngrades and higher ratings \nThere is not a correlation between higher \ngrades and higher ratings \nBacker (2012): some students punish \nacademics for failing grades with low ratings \nBlackhart, Peruche, DeWall, & Joiner (2006): \nhigher ratings given to instructors who give \nhigher grades, and also to graduate teaching \nassistant rank \nBoring, Ottoboni, & Stark (2016): ratings​ are \nmore sensitive to students’ grade \nexpectations than they are to teaching \neffectiveness \nCho, Baek, & Cho (2015): students with better \ngrades than their expected grades provide a \npsychological “gift” to their teachers by giving \nhigher ratings \nGreenwald & Gillmore (1997): the \ngrades-ratings correlation is due to an \nunwanted influence of instructors' grading \nleniency; there are 5 theories of the \ngrades-ratings correlation \nMaurer (2006): cognitive dissonance may be \na theory to explain the grades-ratings \ncorrelation \nMiles & House (2015): higher expected \ngrades may lead to higher ratings \nCentra (2003): expected grades generally do \nnot affect student evaluations \nGump (2007): questions the validity of \nresearch done on the leniency hypothesis \n Biases, Nonresponse.​ ​Nonresponse bias occurs when students choose not to participate in \nevaluation of teaching, and the missing data may cause skewed results. Three articles in this \nsub-category reported that nonresponse bias does influence student evaluations of teaching. \nNo articles suggested otherwise. \nNonresponse bias influences student \nratings \nNonresponse bias does not influence \nstudent ratings \nKuwaiti, AlQuraan, & Subbarayalu (2016): \nratings are affected by class size and \nresponse rate \nMacfadyen, Dawson, Prest, & Gasevic \n(2016): ratings affected by who is completing \nthe surveys \nReisenwitz (2015): ​there are significant \ndifferences between those who complete \nonline student evaluations and those who do \nnot \nNo articles found. \n Biases, Non-Instructional. ​Non-instructional bias occurs when circumstances beyond the \ncontrol of an instructor, such as class type, time, size, and semester, influence student \nevaluation of teaching. The four articles in this sub-category varied in their investigations and \nconclusions. \nNon-instructional factors influence \nstudent ratings \nNon-instructional factors do not influence \nstudent ratings \nKuwaiti, AlQuraan, & Subbarayalu (2016): \nratings are affected by class size and \nresponse rate \nNargundkar & Shrikhande (2014): combined \nimpact of all the noninstructional factors \nstudied is statistically significant \nRoyal & Stockdale (2015): students give \nlower ratings to instructors of quantitative \nmethods subjects \nReardon, Leierer, & Lee (2014): class \nschedule does not affect ratings \n Biases, Other.​ ​This sub-category includes literature that focused on multiple biasing factors, \nbiasing factors that do not fit into any other category, or biases in general.  \nThe factors influence student ratings  \nBlackhart, Peruche, DeWall, & Joiner (2006): \nvarying results for investigation if class size, \nclass level, instructor gender, number of \npublications (faculty instructors), average \ngrade given by the instructor, and instructor \nrank predicted teaching evaluation ratings \nKeeley, English, Irons, & Henslee (2013): \nfound halo and ceiling/floor effects to be \npresent and persistent; (Halo effect occurs \nwhen a positive rating on one aspect of the \nSET influences the other aspects. Ceiling and \nfloor effects are issues when the SET \ninstrument scale is limited.) \nMerritt (2012): covers biases in general, \nincluding race minority \nPounder (2007): identifies and organizes \nfactors influencing SET scores \nZumback & Funke (2014): students’ mood \naffects ratings \n Validity \nLiterature within this category equally supports opposing viewpoints as to whether or not student \nevaluations of teaching are valid measures of teaching quality, whether or not students have the \nknowledge, skills, or motivation to measure teaching quality. \nStudent Evaluations are (Mostly) Valid \nMeasures of Teaching; Students are able \nto measure aspects of teaching quality \nStudent Evaluations are not/may not be \nValid Measures of Teaching; Students \nmay not be able to measure teaching \nquality \nAl-Eidan, Baig, Magzoub, & Omair (2016): \nthe faculty evaluation tool was found to be \nreliable, but validity has to be interpreted with \ncaution because of low response \nBedggood & Donovan (2012): student \nsatisfaction does not equal teaching quality; \nboth student satisfaction and student learning \nare relevant measures \nChen & Hoshower (2003): student motivation \nto participate in SET affects ratings \nCohen (1981): student ratings are a valid \nmeasure of teaching effectiveness; this is the \npaper included in a ​meta-analysis​ by Uttl et \nal. (2016) \nDolmans, Janssen-Noordman, & Wolfhagen \n(2006): students can distinguish excellent and \npoor teaching quality \nGinns, Prosser, & Barrie (2007): the SET tool \nstudied supports quality assurance and \nimprovement processes at the university \nGrammatikopoulos, Linardakis, Gregoriadis, \n& Oikonomidis (2015): provides evidence of a \nvalid SET instrument; evaluating test validity \nis a continuous process, not a one-time event \nKhong (2014): SET is a valid instrument in \nevaluating teaching effectiveness \nBrown, Wood, Ogden, & Maltby (2014): \nstudents’ satisfaction rating is context \ndependent; objective quality and subjective \nsatisfaction are different things and should be \nassessed accordingly \nChonko, Tanner, & Davis (2002): students \nfocus more on qualities that make a course \nappealing, not learning \nd'Apollonia & Abrami (1997): student ratings \nare moderately valid; however, they are \naffected by administrative, instructor, and \ncourse characteristics \nDodeen (2013): validity of SET is \nquestionable \nGrayson (2015): questions student’s ability to \ngive accurate ratings \nGreenwald (1997): student rating measures \nhave validity concerns \nLama, Arias, Mendoza, & Manahan (2015): \nlack of student diligence when rating \ninstructors raises validity concerns \nMartin, Dennehy, & Morgan (2013): validity of \nSET is questioned; student focus groups \nsuggested as an alternative \nMorley (2012): ​student evaluations in this \nstudy were generally unreliable \nValidity,​ continued \nStudent Evaluations are (Mostly) Valid \nMeasures of Teaching; Students are able \nto measure aspects of teaching quality \nStudent Evaluations are not/may not be \nValid Measures of Teaching; Students \nmay not be able to measure teaching \nquality \nMarsh & Roche (1997): evaluations are \nrelatively valid and unaffected by \nhypothesized biases; student ratings \ncorrelate with those of peer evaluators and \ntrained evaluators \nMcKeachie (1997): student ratings are valid \nbut affected by contextual variables such as \ngrading leniency \nNargundkar & Shrikhande (2012): an \ninstrument that was validated 20 years ago is \nstill valid \nSocha (2013): a SET instrument was found to \nhave overall good reliability and validity with \nrelatively few biases \nWright & Jenkins-Guarieri (2012): SETs \nappear to be valid and free from gender bias \nRantanen (2013): reliability of SET is \nquestionable; multiple feedbacks required \nSpooren, Brockx, & Mortelmans (2013): the \nutility and validity of SET is questionable \nUttl, White, & Gonzalez (2016): SETs do not \nindicate teaching quality, ​meta-analysis \nUijtdehaage & O’Neal (2015): many students \nrate instructors mindlessly \nImpact on Teaching Quality \nThe five articles in this category are divided as to whether or not results from student \nevaluations of teaching have a positive impact on teaching quality. \nEvaluation results may have an impact on \nteaching quality \nEvaluation results may not have an impact \non teaching quality \nCurwood, Tomitsch, Thomson, & Hendry \n(2015): provide an example of support for \nacademics’ learning from SETs \nMakondo & Ndebele (2014): SETs are \nbeneficial for improving teaching quality \nAsassfeh, Al-Ebous, Khwaileh, & Al-Zoubi \n(2014): students’ perceptions include lack of \nimpact of evaluations on teaching behaviors \nCampbell & Bozeman (2008): questions the \neffect student evaluations have on teaching \nquality \nStein, Spiller, Harris, Deaker, & Kennedy \n(2013): there are gaps in the way academics \nengage with student evaluation \nEvaluating Faculty for Tenure and Promotion \nLiterature in this category includes seven more recent articles (2012 onward) that express \nconcern about the use of evaluation results for summative purposes, misinterpretation of results \nleading to incorrect conclusions. \nSupport for use of student evaluations for \ntenure and promotion decisions \nConcerns related to the use of  student \nevaluations for tenure and promotion \ndecisions \nFraile & Bosch-Morell (2015): present a \nreliable approach to SET interpretation \nBoysen (2015): faculty and administrators \ncan over-interpret small variations \nBoysen, Raesly, & Casner (2014): ratings are \nmisinterpreted by faculty and administrators \nJackson & Jackson (2015): concerns with use \nof SETs for summative purposes \nJones, Gaffney-Rhys, & Jones (2015): \npresents issues if decision-makers use SET \nresults summatively \nMitry & Smith (2014): conclusions drawn from \nevaluations may be invalid and harmful \nPalmer (2012): presents examples of \nineffective responses to evaluation results \n Multifaceted Evaluation \nThis category amalgamates the concepts of effective tools and multifaceted evaluations into one \ntheme, since effective tools provide the ingredients for multifaceted evaluations. The ten articles \nin this category recognize the need for instruments that are of high psychometric quality, and \nalso that evaluations should include multiple sources of information, such as surveys, peer \nevaluations, self-evaluations, focus groups, and more. \nBerk (2013): covers several issues, including multifactorial evaluations \nCox, Peeters, Stanford, & Seifert (2013): a peer assessment instrument was piloted; formative \npeer assessment seems important \nHughes II & Pate (2013): present a multisource evaluation method \nIqbal (2013): faculty express concerns with peer reviews \nLyde, Grieshaber, & Byrns (2016): a multisource method of evaluating is a useful tool \nMarsh & Roche (1997): multidimensional aspects of teaching should be evaluated; suggest \nnine factors; “homemade” surveys are of questionable quality \nMartin, Dennehy, & Morgan (2013): validity of SET is questioned; student focus groups \nsuggested as an alternative \nRidley & Collins (2015): suggests a comprehensive performance evaluation instrument \nStupans, McGuren, & Babey (2016): present a tool for analyzing free-form comments on \nratings forms \nZimmerman (2008): some tools may encourage students to focus on negative aspects of \nteaching; anonymous feedback means students are not accountable for their comments \nEVALUATION\tOF\tTEACHING\t\nAT\tTHE\tUNIVERSITY\tOF\tALBERTA\t\nA\tSUMMARY\tOF\tDEPARTMENT\tCHAIR\tINTERVIEWS\tACROSS\tCAMPUS\t\nSarah\tForgie\t&\tNorma\tNocente\t Principal\tInvestigators\t\nL.\tFrancisco\tVargas\tM.\t Research\tCoordinator\t\nRebecca\tBest-Bertwistle\t Research\tAssistant\t\n2017\t\n\t 2\t\n“I\tthink\tthese\tmeasures\tare\tuseful,\tas\tlong\t\nas\t they’re\t not\t used\t by\t themselves.\t They\t\nneed\t to\t be\t supplemented\t by\t all\t kinds\t of\t\nother\tthings”\t(Department\tChair).\t\n\t 3\t\nTable\tof\tContents\t\n1.\t Executive\tSummary\t............................................................................................................................................................\t5\t\n2.\t Introduction\t........................................................................................................................................................................\t6\t\n3.\t Methods\t..............................................................................................................................................................................\t6\t\n3.1.\t Participants\t................................................................................................................................................................\t7\t\n3.2.\t Data\tAnalysis\t..............................................................................................................................................................\t7\t\n4.\t Results\t.................................................................................................................................................................................\t9\t\n4.1.\t Use\tof\tUSRI\tto\tEvaluate\tTeaching\t..............................................................................................................................\t9\t\n4.2.\t Use\tof\tAdditional\tTools\t&\tInformation\tto\tEvaluate\tTeaching\t.................................................................................\t11\t\n4.3.\t Perceived\tFEC\tWeighting\tof\tTeaching,\tResearch\t&\tService\t....................................................................................\t13\t\n4.4.\t Need\tfor\tAdditional\tSupports\tto\tBetter\tEvaluate\tTeaching\t....................................................................................\t14\t\n4.5.\t Difference\tBetween\tTeaching\tEvaluation\tfor\tAnnual\tReview\t&\tPromotion\t..........................................................\t16\t\n4.6.\t Characteristics\tof\tEffective\t&\tExcellent\tTeachers\t...................................................................................................\t16\t\n4.7.\t Experiences\tTransitioning\tto\te-USRI\tCompared\tto\tPaper-Based\tUSRI\t...................................................................\t17\t\n5.\t Conclusions\t.......................................................................................................................................................................\t19\t\n6.\t Appendix\t1:\tSemi-Structured\tInterview\tQuestions\t..........................................................................................................\t21\t\n7.\t Appendix\t2:\tSample\tUSRI\tResults\tfor\tDepartment\tChairs\t...............................................................................................\t23\t\n\t 4\t\n\t 5\t\n1. Executive\tSummary\t\nIn\tMay\t2016,\tGeneral\tFaculties\tCouncil\ttasked\tthe\tCommittee\ton\tLearning\tEnvironment\tto\treport\ton\tthe\t“…\tresearch\tinto\t\nthe\tuse\tof\tstudent\trating\tmechanisms\tof\tinstruction\tin\tuniversity\tcourses.\tThis\twill\tbe\tinformed\tby\ta\tcritical\treview\tof\tthe\t\nUniversity\t of\t Alberta’s\t existing\t Universal\t Student\t Ratings\t of\t Instruction\t (USRIs)\t and\t their\t use\t for\t assessment\t and\t\nevaluation\t of\t teaching\t as\t well\t as\t a\t broad\t review\t of\t possible\t methods\t of\t multifaceted\t assessment\t and\t evaluation\t of\t\nteaching.”\t\nMethods\t\n• Qualitative\t research.\tDepartment\t chairs\t (or\t their\t equivalents\t in\t non-departmental\t faculties)\twere\t asked\t to\t\nparticipate\tin\tshort\t30-45\tminute\t(audio-recorded)\tsemi-structured\tinterviews\twith\tquestions\tregarding\ttheir\t\nexperiences\tevaluating\tteaching.\t\n• Data\twas\tcollected\tfrom\tJanuary\tto\tMarch\t2017,\twith\ta\tresponse\trate\tof\t59%.\t\nOur\tcommittee\tsought\tto\taddress\tthe\tGFC\tmotion\tby\tanswering\tthe\tfollowing\tthree\tquestions:\t\n1. What\tdoes\tthe\tresearch\thave\tto\tsay\tabout\tstudent\tratings\tof\tteaching?\t\n• A\t literature\t review\ton\tstudent\t rating\tsystems\tpreviously\tpresented\t in\ta\t2009\tUniversity\tof\tAlberta\t report\t\nwas\tupdated\t(Evaluation\tof\tTeaching\tat\tthe\tU\tof\tA:\tReport\tof\tthe\tSub-Committee\tof\tthe\tCommittee\ton\tthe\t\nLearning\tEnvironment).\t\n2. How\tare\tthe\tUSRIs\tand\tother\ttools\tused\tin\tthe\tevaluation\tof\tteaching\tevaluation\tat\tthe\tUniversity\tof\tAlberta?\t\n• Participants\t from\t all\t faculties\t other\t than\t FOMD\t use\t USRI\t scores\t and\t comments\t (and\t only\t a\t portion\t of\t\nparticipants\tfrom\tFOMD)\tto\tevaluate\tteaching.\t\n• Statement\t221\t (overall\t the\t instructor\twas\texcellent),\t and\t statement\t25\t (overall\t the\tquality\tof\t the\t course\t\ncontent\twas\texcellent)\tare\tthe\tmost\tcommonly\tused\tUSRI\titems\tto\tevaluate\tteaching.\t\n• Most\tparticipants\ttry\tto\tcontextualize\ttheir\tinterpretation\tof\tUSRI\tresults.\t\n3. What\tare\tsome\tapproaches\tfor\tmulti-faceted\tevaluation\tof\tteaching?\t\n• In-class\t peer\t teaching\t observations\t were\t the\t most\t commonly\t used\t additional\t source\t of\t information,\t\nfollowed\tby\tannual\tinstructor\tpedagogical\tself-reflections.\t\n• Most\t participants\t obtain\t these\t resources\t on\t a\t voluntary\t basis,\t only\twhen\t professors\t agree\t to\t give\t them\t\nthese\tsupplementary\tresources.\t\n• Some\t participants\t have\t implemented\t yearly\t faculty\t audits,\t in\t which\t a\t manageable\t portion\t of\t their\t\nprofessorate’s\tteaching\tis\tevaluated\tusing\tadditional\tinformation.\t\n• Even\t when\t participants\t obtain\t these\t resources,\t not\t all\t reported\t to\t bring\t them\t to\t FEC.\t When\t this\t\ninformation\tmakes\tit\tto\tFEC,\tit\tis\tused\tto\tinform\ttheir\tnarrative,\tand\tis\tonly\texplicitly\tbrought\tup\twhen\tthere\t\nis\ta\tconcern\twith\tthe\tnumerical\tscores.\t\n• Despite\t more\t value\t being\t placed\t in\t teaching,\t most\t participants\t still\t described\t a\t strong\t bias\t towards\t\nresearch\tat\ttheir\trespective\tFECs.\t\n• Most\tparticipants\tvoiced\ttheir\tneed\tfor\tadditional\tsupports\tto\tbetter\tevaluate\tteaching.\t\n• Most\t participants\t identified\t some\t issues\t when\t evaluating\t teaching\t exclusively\t with\t USRI,\t and\t some\t\nrecommended\tpossible\talternatives\tto\tsupplement\tthese\tscores,\tbut\tthey\tstill\thope\tthe\tinstitution\twill\t\nprovide\tsolutions\tfor\ttheir\tconcerns.\t\n6\t\n2. Introduction\nThe\t University\t of\t Alberta’s\t Institutional\t Strategic\t Plan,\tFor\t the\t Public\t Good,\t underscores\t its\t strong\t commitment\t to\t\nteaching\t and\t learning.\t The\t University\t community\t values\t the\t intellectual\t and\t engaging\t learning\t environment\t that\t is\t\ncultivated\tby\tour\tinspiring\tteachers.\t\tAccordingly,\tthe\tevaluation\tof\tteaching\tis\tessential\tin\tupholding\tthese\tvalues.\t\nTeaching\tevaluations\tnot\tonly\taffect\tthe\tcareers\tof\tindividuals\tat\tthe\tUniversity\tof\tAlberta,\tthey\talso\tshape\tthe\tquality\tof\t\ninstruction\tbeing\toffered\tto\tstudents.\tUniversal\tStudent\tRatings\tof\tInstruction\t(USRI)\tare\toften\tused\tto\tevaluate\tteaching\t\nquality\t for\t faculty\t annual\t review\t and\t tenure\t and\t promotion\t (summative\t evaluation).\t Also,\t USRIs\t can\t provide\t insight\t\n(formative\t evaluation)\t into\t specific\t areas\t of\t strength\t or\t improvement\t related\t to\t different\t aspects\t of\t teaching\t such\t as\t\nplanning\t and\torganization,\t communication,\t assessment,\t etc.\tHowever,\t the\tdual\t purpose\tof\tUSRIs\t is\t often\t contentious,\t\nparticularly\tbecause\tof\tthe\tperceived\tweight\tthey\tcarry\twith\tFaculty\tEvaluation\tCommittees.\t\nConsequently,\t in\tMay\t 2016,\t General\t Faculties\t Council\t (GFC)\t tasked\t the\t Committee\t on\t Learning\t Environment\t (CLE)\t to\t\nreport\t on\t the\t “…\t research\t into\t the\t use\t of\t student\t rating\tmechanisms\t of\t instruction\t in\t university\t courses.\t This\twill\t be\t\ninformed\tby\ta\tcritical\t review\tof\t the\tUniversity\tof\tAlberta’s\texisting\tUniversal\tStudent\tRatings\tof\t Instruction\t (USRIs)\tand\t\ntheir\t use\t for\t assessment\t and\t evaluation\t of\t teaching\t as\t well\t as\t a\t broad\t review\t of\t possible\t methods\t of\t multifaceted\t\nassessment\tand\tevaluation\tof\t teaching.\tThe\tultimate\tobjective\twill\tbe\t to\t satisfy\t the\t Institutional\tStrategic\tPlan:\tFor\t the\t\nPublic\t Good\t strategy\t to:\t Provide\t robust\t supports,\t tools,\t and\t training\t to\t develop\t and\t assess\t teaching\t quality,\t using\t\nqualitative\tand\tquantitative\tcriteria\tthat\tare\tfair,\tequitable,\tand\tmeaningful\tacross\tdisciplines.”\t\nOur\tcommittee\tsought\tto\taddress\tthe\tGFC\tmotion\tby\tanswering\tthe\tfollowing\tthree\tquestions:\t\n1. What\tdoes\tthe\tresearch\thave\tto\tsay\tabout\tstudent\tratings\tof\tteaching?\n2. How\tare\tthe\tUSRIs\tand\tother\ttools\tused\tin\tthe\tevaluation\tof\tteaching\tevaluation\tat\tthe\tUniversity\tof\tAlberta?\n3. What\tare\tsome\tapproaches\tfor\tmulti-faceted\tevaluation\tof\tteaching?\nFor\tthe\tfirst\tquestion,\twe\tupdated\ta\tliterature\treview\ton\tstudent\trating\tsystems\tpreviously\tpresented\tin\ta\t2009\tUniversity\t\nof\tAlberta\treport\t(Evaluation\tof\tTeaching\tat\tthe\tU\tof\tA:\tReport\tof\tthe\tSub-Committee\tof\tthe\tCommittee\ton\tthe\tLearning\t\nEnvironment).\t To\t partially\t address\t the\t third\t question,\t we\t resurrected\t previous\t work\t completed\t at\t the\t University\t of\t\nAlberta\t on\t the\t multi-faceted\t evaluation\t of\t teaching.\t This\t information\t was\t presented\t to\t CLE\t in\t September\t 2016.\t This\t\nreport\tprimarily\t addresses\t the\t second\tand\t third\tquestion\t through\t information\tcollected\t in\t interviews\twith\tdepartment\t\nchairs\tacross\tcampus.\t\nWhile\tUniversity\tpolicy\tsuggests\tthat\tdepartments\tutilize\ta\tmulti-faceted\tapproach\tto\tevaluating\tteaching,\twe\tdo\tnot\thave\t\na\t clear\t picture\t of\t the\t tools\t used\t other\t than\t the\t mandated\t Universal\t Student\t Rating\t System\t (USRI).\t These\t interviews\t\nhelped\tto\tuncover\thow\tdepartment\tchairs\tutilize\tUSRIs\tto\tmake\tpersonnel\tdecisions\tand\tthe\thelped\tto\tdetermine\twhich\t\nother\ttools\tthey\tused\tto\tevaluate\tthe\tquality\tof\tteaching\tin\ttheir\trespective\tdepartments.\t\t\nThe\t purpose\t of\t this\t study\t is\t to\t describe\t the\t current\t state\t of\t teaching\t evaluation\t at\t the\t University\t of\t Alberta.\t More\t\nspecifically\tit\twill\thelp\tus\tunderstand\tthe\ttools\tused\tto\tevaluate\tteaching\tat\tthe\tUniversity\tof\tAlberta.\t\n3. Methods\nEthics\tapproval\tfor\tthis\tqualitative\tstudy\twas\tsought\tfrom\tthe\tHuman\tResearch\tEthics\tBoard\tat\tthe\tUniversity\tof\tAlberta,\t\nand\tobtained\tDecember\t7,\t2016\t(Pro00069070).\t \tA\tqualitative\tapproach\twith\t interviews\twas\tused\tto\telicit\tthe\tdepth\tof\t\nresponse\tnecessary\tfor\tunderstanding\tthe\tnuances\tand\tvariety\tin\tpossible\tanswers.\t\t\t\nDepartment\tchairs\t(or\ttheir\tequivalents\tin\tnon-departmental\tfaculties)\twere\temailed\tdirectly\twith\tinformation\tabout\tthe\t\nstudy,\tand\twith\tcopy\tof\tthe\tresearch\tletter\tof\tinvitation.\tThey\twere\tasked\tto\tparticipate\tin\ta\tshort\t30-45\tminute\t(audio-\nrecorded)\tsemi-structured\tinterview\t(see\tAppendix\t1).\tThe\tinterview\tprotocol\twas\tpre-approved\tby\tCLE,\tand\tit\tconsisted\t\nof\t questions\t regarding\t the\t chairs’\t experiences\t evaluating\t teaching.\t Participants\twere\t also\t given\t two\t sample\tUSRI\t case\t\nstudies\tbased\ton\treal\tteaching\tscores\t(see\tAppendix\t2)\tand\tasked\tto\tinterpret\tthe\tscores.\tThey\twere\tdirected\tto\treflect\ton\t\nboth\tscores\tas\tif\tboth\tinstructors\twere\tteaching\tdifferent\tsections\tof\tthe\tsame\tcourse\twithin\ttheir\tdepartment.\t\t\nhttp://www.governance.ualberta.ca/GeneralFacultiesCouncil/CommitteeontheLearningEnvironm/~/media/Governance/Documents/GO05/LEA/16-17/USRI-Reference-Material/Executive_Summary-Teaching_Evaluation_at_the_UofA_-_September_2016.pdf\n\t 7\t\nData\twas\tcollected\tfrom\tJanuary\tto\tMarch\t2017.\t\n3.1. Participants\t\nParticipants\twere\t43\tdepartment\tchairs\t(or\ttheir\tequivalents\tin\tnon-departmental\tfaculties)\twhich\tis\ta\t59%\tresponse\trate.\t\nThe\tdistribution\twas\t9.3%\tfrom\tAgricultural,\tLife\tand\tEnvironmental\tSciences\t(ALES),\t4.7%\tfrom\tAlberta\tSchool\tof\tBusiness\t\n(BUS),\t 20.9%\t from\t Arts\t (ART),\t 4.7%\t from\t Augustana\t Campus\t (AUG),\t 7%\t from\t Education\t (EDU),\t 7%\t from\t Engineering\t\n(ENG),\t23.3%\tfrom\tMedicine\tand\tDentistry\t(FOMD),\t4.7%\tfrom\tRehabilitation\tMedicine\t(RM),\t7%\tfrom\tScience\t(SCI),\tand\t\n11.6%\t from\t all\t non-departmental\t faculties\t (ND)\t (see\t Figure\t 1).\t Response\t rate\t reached\t a\tminimum\t of\t 50%\twithin\t the\t\ndifferent\tfaculties\t(see\tFigure\t2).\t\nParticipants\treported\thaving\tan\taverage\tof\t32.07\t(SD\t=\t22.42)\tfaculty\tand\tFSO,\t23.18\t(SD\t=\t27.03)\tsessional\tor\tcontract\t\ninstructors,\t and\t 3.06\t (SD\t =\t 3.82)\t graduate\t students\t teaching\t in\t their\t departments.\t They\t mentioned\t working\t for\t an\t\naverage\tof\t4.34\t(SD\t=\t3.61)\tyears\tas\tdepartment\tchairs\t(or\ttheir\tequivalents\tin\tnon-departmental\tfaculties),\tand\t9.3%\tof\t\nthe\ttotal\tindicated\thaving\tan\tinterim\tappointment.\t\n3.2. Data\tAnalysis\t\nConfidentiality\t and\t anonymity\t were\t guaranteed\t by\t assigning\t pseudonyms\t to\t each\t audio\t file\t before\t it\t was\t sent\t for\t\ntranscription.\t Transcripts\twere\t further\t anonymized\tby\t removing\t any\t information\t that\t identified\t the\tdepartment\t under\t\ndiscussion\t(i.e.,\tmention\tof\tdisciplines,\tcourses,\tspecific\tindividuals,\tand\tothers).\tParticipants\tfrom\tdepartmental\tfaculties\t\nwere\t grouped\t together\t and\t those\t from\t non-departmental\t faculties\t were\t combined\t to\t protect\t their\t identity.\t The\t\ncomplete\t list\t of\t participants,\t as\twell\t as\t assigned\t pseudonyms,\t is\t only\t available\t to\t the\t research\t coordinator.\t Interview\t\ntranscripts\twere\t then\t coded\twith\t the\tqualitative\tdata\t analysis\t software\tNVivo\t11,\t using\t the\tmain\tquestions\t as\t general\t\nguidelines\tthat\tinformed\tthe\tdifferent\tcodes/nodes.\tAn\texternal\tresearch\tassistant\tdetermined\tan\tinter-coder\tpercentage\t\nagreement\tof\t.95\twith\t10%\tof\tthe\ttotal\tnumber\tof\tinterviews\tfor\tthe\tqualitative\tdata,\tand\tof\t.98\twith\t100%\tof\tinterviews\t\nfor\tthe\tquantitative\trepresentation\tof\tthe\tdata.\t\n9.3% \n4.\n7%\n20.9% \n4.\n7%\n7.0% 7.0% 23.3% \n4.\n7%\n7.0% 11.6% \nFigure\t1.\tDistribution\tof\tParticipants\tby\tFaculty\nALES BUS ART AUG EDU ENG FOMD RM SC ND\n100.0% \n50.0% \n60.0% \n66.0% \n60.0% \n60.0% \n50.0% \n66.0% \n50.0% \n62.5% \nALES\nBUS\nART\nAUG\nEDU\nENG\nFOMD\nRM\nSCI\nND\nFigure\t2.\tResponse\tRate\tby\tFaculty\n\t 8\t\n\t 9\t\n4. Results\t\nThis\tsection\toffers\tboth\ta\tquantitative\tand\ta\tqualitative\tsummary\tof\tall\tparticipant\tresponses,\texcept\tsection\t4.1.,\tsection\t\n4.2.,\tand\tsection\t4.7.,\tin\twhich\tresults\tonly\tconsider\tparticipants\twho\treported\tusing\tUSRI.\tInformation\tin\tthese\tsections\t\nexcludes\tparticipants\tfrom\tFOMD\twho\tindicated\tnot\tusing\tUSRI,\tor\twhose\tapplication\twas\tnot\tclear\t(see\tFigure\t3).\t\n4.1. Use\tof\tUSRI\tto\tEvaluate\tTeaching\t\nParticipants\t from\t all\t faculties\t other\t than\t FOMD\t reported\t using\t USRI\t scores\t and\t comments\t as\t part\t of\t their\t teaching\t\nevaluation\tprocess\t(100%).\tDepartment\tchairs\tfrom\tFOMD\teither\tmentioned\tusing\tthe\tUSRI\tscores\t(40%),\tnot\tusing\tthem\t\n(20%),\tor\tdid\tnot\tprovide\ta\tdefinite\tanswer\t(40%)\t(see\tFigure\t3).\t\t\nAdditionally,\t department\t chairs\t from\t FOMD\t either\t indicated\t using\t USRI\t comments\t (30%),\t not\t taking\t them\t into\t\nconsideration\t (30%),\t or\t their\t responses\t were\t unclear\t (40%)\t (see\t Figure\t 4).\t “I\t have\t never\t seen\t it,\t but\t our\t largest\t\nundergraduate\tprogram\thas\ta\tdifferent\tevaluation\tsystem,\twhich\tis\tmainly\tbased\ton\tnarrative\tcomments.\tSo,\tyour\temail,\t\nas\t I\t said,\twas\t the\t first\t time\tthat\t I\theard\t the\t term\tever.”\tThey\twere\toften\tunsure\t if\t their\tdepartment\tused\tUSRI,\tor\thad\t\nnever\theard\tabout\tUSRI,\tor\thad\tnever\tseen\tthe\tscores\t(see\tAppendix\t2).\t\nFROM\tTHIS\tPOINT\tON\tINFORMATION\tONLY\tCONSIDERS\tPARTICIPANTS\tWHO\tREPORTED\tUSING\tUSRI\t\nWhen\t asked\t which\t USRI\t statements\t were\t most\t commonly\t used\t in\t their\t teaching\t evaluation\t process,\t statement\t 221\t\n(overall\t this\t instructor\twas\t excellent)\twas\t identified\t by\t 97.3%\t of\t participants,\t statement\t 25\t (overall\t the\t quality\t of\t the\t\n40.0% 20% 40% \nFigure\t3.\tParticipants\t\tfrom\tFOMD\tthat\tReported\tUsing\tUSRI\tScores\tto\tEvaluate\tTeaching\nYes No Unclear\n30.0% 30.0% 40.0% \nFigure\t4.\tParticipants\tfrom\tFOMD\tthat\tReported\tUsing\tUSRI\tComments\tto\tEvaluate\tTeaching\nYes No Unclear\n21.6% \n16.2% \n24.3% \n18.9% \n67.6% \n2.7% \n16.2% \n35.1% \n10.8% \n97.3% \n21:\tThe\tgoals\tand\tobjectives\tof\tthe\tcourse\twere\tclear\n22:\tIn-class\ttime\twas\tused\teffectively\n23:\tI\tam\tmotivated\tto\tlearn\tmore\tabout\tthese\tsubject\tareas\n24:\tI\tIncreased\tmy\tknowledge\tof\tthe\tsubject\tareas\tin\tthis\tcourse\n25:\tOverall\tthe\tquality\tof\tthe\tcourse\tcontent\twas\texcellent\n674:\tThe\tinstructor\tspoke\tclearly\n51:\tThe\tinstructor\twas\twell\tprepared\n9:\tThe\tinstructor\ttreated\tstudents\twith\trespect\n26:\tThe\tinstructor\tprovided\tconstructive\tfeedback\tthroughout\tthis\t…\n221:\tOverall\tthe\tinstructor\twas\texcellent\nFigure\t5.\tUSRI\tStatements\tMost\tCommonly\tUsed\tto\tEvaluate\tTeaching\n\t 10\t\ncourse\tcontent\twas\texcellent)\twas\tselected\tby\t67.6%,\tand\tstatement\t9\t(the\tinstructor\ttreated\tstudents\twith\trespect)\twas\t\nidentified\t by\t 35.1%\t (see\t Figure\t 5).\t In\t general,\t participants\t revealed\t that\t one\t or\t two\t items\t are\t used\t as\t an\t indicator\t of\t\neffective\tteaching.\tThey\tseem\tto\thave\tbenchmarks\tin\tmind\tas\tthey\treview\tUSRI\tscores:\t\nWe\tconsider\tall\tof\tthem,\tbut\tof\tcourse\twe\tkey\tin\tright\taway\ton\t‘the\tinstructor\twas\texcellent.’\tYou\talways\tlook\tat\tthat\t\none\tfirst.\tAnd\toverall\tthe\tcourse\tcontent\twas\texcellent\tis\tthe\tsecond\tthing\tyou\tlook\tat.\tAnd\tthen,\tif\tthere’s\tproblems\t\nin\t either\t of\t those\t two\t scores\t you\t look\t in\tmore\t detail\t at\t the\t other\t questions.\t There’s\t something\t like\t 300\t faculty\t\nmembers\tin\tthe\tFaculty\tof\tScience\tfor\tFEC,\tso\twe’re\tonly\tfinding\tways\tto\tefficiently\tgo\tthrough\tthese\tthings.\t\nParticipants\talso\treflected\ton\tthe\tUSRI\tcase\tstudies\t(see\tAppendix\t2).\tInstructor\tA\thad\t6\tUSRI\titems\ton\tthe\t25th\tpercentile\t\nor\tbelow,\tand\t1\titem\tbelow\tthe\tTukey\tfence.\tThis\tinstructor\tscored\t4.0\ton\tstatement\t221,\t3.8\ton\tstatement\t25,\tand\t4.0\ton\t\nstatement\t 9.\t Instructor\t B\t had\t7\tUSRI\t items\tbetween\t the\t50th\t and\t25th\t percentile,\t but\t no\t items\twere\tbelow\t the\t Tukey\t\nfence.\tThis\tinstructor\tscored\t4.5\ton\tstatement\t221,\t4.2\ton\tstatement\t25,\tand\t4.8\ton\tstatement\t9.\tAfter\treflecting\ton\tthese\t\nsample\tcase\tstudies,\t8.1%\tof\tparticipants\tgave\tInstructor\tA\t‘unsatisfactory’\treviews,\t13.5%\tthought\tthe\tscores\twere\t‘okay’,\t\nand\t 24.3%\t considered\t the\t scores\t were\t ‘good’\t (see\t Figure\t 6).\t Instructor\t B\t received\t more\t positive\t reviews,\t with\t 8.1%\t\nconsidering\tthe\tscores\twere\t‘okay’,\t27%\tthinking\tthey\twere\t‘good’,\tand\t10.8%\tdeeming\tthem\tas\t‘excellent’\t(see\tFigure\t7).\t\nMoreover,\tbelieving\tthe\tUSRI\tdata\t indicated\ttheir\tteaching\twas\t ‘okay’,\t45.9%\tof\tparticipants\tmentioned\tthat\tcontextual\t\nfactors\t should\t be\t considered\t in\t the\t evaluation\t of\t teaching\t (see\t Figure\t 6\t and\t 7),\t and\t that\t to\t provide\t an\t informed\t\ninterpretation\tof\tthese\tUSRI\tscores,\tthey\trequired\tmore\tinformation\tthan\tthe\tone\tprovided:\t\nTo\tbe\tperfectly\thonest,\tin\tthe\tabstract\tI\tdon’t\tknow\twhat\tI\twould\tsay.\tWithout\tknowing\tthe\tcircumstances,\tif\tone\tof\t\nthose\t instructors\t is\t in\t her\t or\t his\t first\t year\t of\t teaching,\t and\t the\t other\twas\t an\t experienced\t professor,\t I\t think\t that\t\ninterpretation\tis\tdramatically\tdifferent\tthan\tif\tthey’re\tboth\texperienced\tprofessors\tor\tif\tthey’re\tboth\tnew\tprofessors.\tI\t\ncan\tsay,\tif\twe\tlook\tat\tthe\toverall\taverages\tthey’re\tboth\tscoring\tin\tthe\tlower\tpercentile,\tand\tthat\tsort\tof\tdata,\tbut\tto\t\nbe\tperfectly\thonest\tthat\tmeans\tvery\tlittle\tto\tme\tbecause\tI\tthink\tthat\tunderstanding\ta\tperson’s\tposition\tis\tcrucial\tto\t\nbeing\table\tto\tread\tany\tof\tthese\tnumbers.\t\nAdditionally,\t18.9%\twould\tonly\t follow\tup\twith\t Instructor\tA\tto\taddress\t issues\trelated\tto\t their\t teaching\tscores,\tand/or\t to\t\nprovide\t supplementary\t guidance\t to\t help\t them\t improve\t their\t results;\t 24.3%\twould\t follow\t up\t with\t both\t instructors\t to\t\ndiscuss\ttheir\tconcerns;\t8.1%\twould\tnot\tfollow\tup\twith\teither\tinstructor,\tdue\tto\twhat\tthey\tconsider\ta\tlack\tof\tany\tteaching\t\n8.1% 13.5% 24.3% 45.9% \n2.\n7%\n5.4% \nFigure\t6.\tParticipant\tInterpretation\tof\tInstructor\tA's\tUSRI\tScores\nNot\tsatisfactory Okay Good Contextual No\tcomments Not\tasked\n8.1% 27.0% 10.8% 45.9% \n2.\n7%\n5.4% \nFigure\t7.\tParticipant\tInterpretation\tof\tInstructor\tB's\tUSRI\tScores\nOkay Good Excellent Contextual No\tcomments Not\tasked\n18.9% 24.3% 8.1% 45.9% 5.4% \nFigure\t8.\tParticipant\tReported\tCase\tStudies\tFollow-Up\t\nInstructor\tA Both None Contextual Not\tasked\n\t 11\t\nred\tflags;\tand\t45.9%\tstill\tmentioned\tthat\tsince\tUSRI\tneeds\tto\tbe\tinterpreted\tin\ta\tcontextual\tway,\tthey\tneed\tto\tlook\tinto\t\nthe\tcircumstances\tof\tboth\tinstructors\tas\tpart\tof\ttheir\tnormal\tprocess\t(see\tFigure\t8).\t\nParticipants\t also\t had\t access\t to\t two\tpieces\t of\t reference\t data\twhen\t given\t these\t case\t studies.\t The\t Tukey\t fence\twas\t not\t\nreferenced\t by\t 81.1%\t of\t the\t participants,\t even\t though\t Instructor\t A\t had\t one\t score\t below\t the\t Tukey\t fence,\t and\t not\t all\t\nparticipants\t(5.4%)\tseemed\tfamiliar\twith\tits\tapplication\t(see\tFigure\t9).\tThe\tTest\tScoring\t&\tQuestionnaire\tServices\t(TSQS)\t\nOffice\tmentioned\t that\t they\tgenerate\tdiverse\t reports\t for\tdifferent\t faculties\tand\tdepartments,\t and\tbased\ton\t that,\t some\t\nparticipants\tmight\tnot\tbe\tgetting\tthe\tcomplete\tset\tof\tdata\tavailable.\tParticipants\twere\tmore\tfamiliar\twith\tquartiles\tdata,\t\nhowever,\t as\t37.8%\tof\tparticipants\tmade\texplicit\t reference\t to\t them,\t13.5%\tstated\tdepartmental\texpectations\t regarding\t\nUSRI\t scores\twithout\tmaking\t explicit\t reference\t to\t the\t quartiles,\t and\t 43.2%\t did\t not\t provide\t any\t definite\t comment\t (see\t\nFigure\t10).\t\nIn\tgeneral,\tparticipants\tfrom\tall\tfaculties\tother\tthan\tFOMD\tuse\tUSRI\tscores\tand\tcomments\t(and\tonly\ta\tportion\tof\tFOMD\t\nparticipants\t reported\t using\t this\t tool)\t to\t evaluate\t teaching.\t And\t even\t when\t one\t or\t two\t items\t are\t mainly\t used\t as\t an\t\nindicator\tof\teffective\tteaching,\tmost\tparticipants\ttry\tto\tcontextualize\ttheir\tinterpretations\tof\tUSRI\tresults.\t\n4.2. Use\tof\tAdditional\tTools\t&\tInformation\tto\tEvaluate\tTeaching\t\nWhen\tasked\tabout\tthe\tuse\tof\tadditional\ttools\tand\tinformation\tto\tevaluate\tteaching,\t in-class\tpeer\tteaching\tobservations\t\nwere\t the\t most\t commonly\t implemented\t resource\t (70.3%),\t followed\t by\t annual\t instructor\t self-reflections\t about\t their\t\npedagogical\tpractices\t(37.8%),\treview\tof\tclass\tmaterials\t(e.g.,\tsyllabi,\tassignments,\tand\texams)\t(29.7%),\tand\tdepartmental\t\nspecific\ttools\tthat\thave\tbeen\tcreated\tto\taccommodate\tto\tthe\tuniqueness\tof\ttheir\tdepartments\t(21.6%)\t(see\tFigure\t11).\t\n8.1% 81.1% 5.4% 5.4% \nFigure\t9.\tParticipant\tReference\tto\tTukey\tFence\tData\nYes No\tcomments Not\tknow Not\tasked\n37.8% 13.5% 43.2% 5.4% \nFigure\t10.\tParticipant\tReference\tto\tQuartile\tData\nYes Departmental Unclear Not\tasked\n70.3% \n37.8% \n29.7% \n21.6% \nIn-Class\tPeer\tTeaching\tObservations\nAnnual\tInstructor\tSelf-Reflections\nClass\tMaterials\nDepartmental-Specific\tTools\nFigure\t11.\tAdditional\tTools\t&\tInformation\tMost\tCommonly\tUsed\tto\tEvaluate\tTeaching\n\t 12\t\nBut\t the\t implementation\tof\t these\t tools\t varies\tbetween\tdepartments.\t Some\tparticipants\t (35.1%)\tonly\t employ\tadditional\t\nresources\t on\t a\t voluntary\t basis,\t encouraging\t professors\t to\t provide\t further\t information,\t but\t reportedly\t are\t not\t able\t to\t\nengage\teveryone\tin\tthe\tdepartment.\tAnother\tgroup\t(27%)\tuses\tadditional\tinformation\tas\ta\tstandard,\tobtaining\tit\tthrough\t\ndepartmental\t specific\t tools.\t Some\t of\t them\t (8.1%)\t have\t already\t implemented\t yearly\t departmental\t audits\t that\t include\t\nadditional\ttools\tand\tinformation.\tFurthermore,\t18.9%\tonly\tgo\tbeyond\tUSRI\twhen\tthey\tneed\tto\tevaluate\tteaching\tpractices\t\nof\tprofessors\tgoing\tup\tfor\tpromotion/tenure;\t10.8%\tonly\timplement\tadditional\tstrategies\tto\tassess\tsessional\tinstructors\tor\t\nnew\tprofessors;\tand\t8.1%\tacknowledged\tthey\tdid\tnot\tuse\tany\tadditional\ttools\tor\tinformation\t(see\tFigure\t12).\t\nAmong\tthe\tparticipants\twho\tused\tadditional\ttools\tand\tinformation\tin\tany\tway,\t42.8%\tused\tone\tof\tthe\tlisted\tresources\t(see\t\nFigure\t 11),\t 42.8%\t used\t two,\t and\t 14.4%\t used\t three.\t Nevertheless,\t most\t participants\t share\t a\t common\t rationale\t for\t\nincluding\t other\t tools\t recognize\t the\t need\t to\t include\t other\t tools\t are\t very\tmuch\t alike,\t as\t one\t of\t them\tmentioned\twhen\t\nreflecting\ton\trelying\texclusively\ton\tUSRI\tto\tevaluate\tteaching:\t\nI\tdon’t\tthink\tthat’s\tvery\tuseful\tby\titself,\tit’s\tincomplete.\tI’d\tfeel\tuncomfortable\tjudging\tsomebody’s\tfate\tjust\tbased\ton\t\nthat.\t I’m\t not\t saying\t it’s\t wrong\t but\t it’s\t only\t one\t piece.\t It’s\t one\t piece\t of\t understanding,\t and\t we\t take\t teaching\t\nseriously.\tIt’s\tnot\tjust\ta\tbunch\tof\tsimple\tnumbers\tpouring\tat\tus.\tWe\tdon’t\t just\tlook\tat\tyou’re\tabove\tthis\tnumber\tor\t\nbelow\tthis\tnumber,\tand\twe’re\tdone.\tWe’re\tlooking\tat\tyou\tmuch\tmore\tcarefully\tthan\tthat,\tbut\tit’s\ta\tgood\tstart.\t\nParticipants,\tfurthermore,\tmentioned\ttools\tand\tinformation\tthey\thave\tutilized\tin\ttheir\tdepartments\tto\tsupport\tteaching.\t\nFor\t instance,\t40.5%\thave\torganized\tpeer\tsupport\t initiatives\t(e.g.,\tmentoring,\tteaching\ttriads,\tand\tsupport\tgroups\twhere\t\ninstructors\t find\t a\t safe\t space\t to\t talk\t about\t their\t teaching\t practices).\t Another\t 13.5%\t have\t referred\t struggling\t faculty\t to\t\ndepartmental\t specific\t training\t and/or\tworkshops,\t or\t to\t other\t units\t on\t campus\t that\t offer\t pedagogical\t guidance;\t 13.5%\t\nhave\tinstituted\tfaculty\tgatherings\tto\topen\tcasual\tconversations\tabout\tteaching\tpractices\tand\tproblems.\tAdditionally,\t8.1%\t\nhave\tproduced\tdepartmental\tteaching\thandbooks\t(see\tFigure\t13).\t\nALES\nALES\nALES\nBUS\nBUS\nART\nART\nART\nART\nAUG\nAUG\nEDU\nEDU\nEDU\nENG\nENG\nFOMD\nFOMD\nFOMD\nRM\nRM\nSCI\nSCI\nSCI\nND\nND\nND\nND\nVoluntary\tBasis\nDepartment\tStandard\nOnly\tfor\tTenure\tPurposes\nOnly\tfor\tLower\tRank\tProfessors\nNo\tAdditional\tTools\nFigure\t12.\tDistribution\tof\tAdditional\tTools\t&\tInformation\tUse\tby\tFaculty\n40.5% \n13.5% \n13.5% \n8.1% \nPeer\tSupport\nTraining\t&\tWorkshops\nFaculty\tGatherings\nHandbook\nFigure\t13.\tAdditional\tTools\t&\tInformation\tUsed\tto\tSupport\tTeaching\n37.8% \n27.0% \n18.9% \n10.8% \n5.4% \n\t 13\t\nWhen\tit\tcomes\tto\tbringing\tthis\tadditional\ttools\tand\tinformation\tto\tFEC,\t45.9%\tindicated\tthat\tthese\tsources\tplay\ta\trole\tin\t\ntheir\t annual\t teaching\t evaluation,\t by\t informing\t a\t narrative\t and/or\t the\t reasoning\t with\t other\t FEC\t members\t if\t their\t\nrecommendation\tgets\tchallenged;\t21.6%\tacknowledged\tnot\tbringing\tthese\tresources\tto\tFEC,\tand\t32.4%\tdid\tnot\tcomment\t\nor\ttheir\tresponses\twere\tunclear\t(see\tFigure\t14).\tThus,\teven\twhen\tparticipants\tindicated\tusing\tone\tor\ttwo\tadditional\ttools\t\nto\tevaluate\tteaching,\tmost\tacknowledged\tusing\tthem\ton\ta\tvoluntary\tbasis,\t receiving\tthis\t information\tonly\twhen\tfaculty\t\nagrees\tto\tprovide\tthese\tsupplementary\tresources.\t\n4.3. Perceived\tFEC\tWeighting\tof\tTeaching,\tResearch\t&\tService\t\nFROM\tTHIS\tPOINT\tON\tINFORMATION\tCONSIDERS\tALL\tPARTICIPANTS\t\nMost\t participants\t recognized\t that\t there\t is\t a\t strong\t bias\t towards\t research\t (60.5%),\t despite\t their\t FEC’s\t best\t efforts\t to\t\nweight\tthem\tequally\t(14%)\t(see\tFigure\t19):\t\nI\twould\tsay\tthat\tthere’s\tstill\ta\tbias\ttowards\tresearch.\tAlthough\tmy\texperience\twas\tthat\tteaching\twas\ttaken\tseriously,\t\nand\twe\t looked\tat\t those\t things\ta\t lot,\tand\t they\twere\t raised\t in\t terms\tof\t the\tkinds\tof\t things\tpeople\twere\tdoing,\t the\t\namount\tof\tteaching\tthey\twere\tdoing,\ttheir\tscores,\tand\tall\t that\tstuff\twas\ttaken\t into\tconsideration,\t I\twould\tstill\tsay\t\nthat\tthe\tpublications\tand\tother\tresearch\tactivities\tand\toutcomes\twere\tprobably\tweighed\tmore\tseriously.\tSo,\tI’d\tsay\t\nit’d\tbe\tmore\tlike\t50%,\t30%,\t20%\trather\tthan\t40%,\t40%,\t20%.\t\nAn\tadditional\t14%\tmentioned\t that\tFEC\tweights\t the\t importance\tof\t teaching,\t research\tand\tservice\tbased\ton\t the\tspecific\t\ntime\t allocation\t of\t the\t individual\t (mostly\t in\t health-related\t disciplines\t where\t their\t contracts\t have\t different\t time\t\nallocations),\tand\t11.6%\tthought\tthat\ttheir\tFEC\tweights\tteaching\tmore\theavily\tthan\tresearch\t(see\tFigure\t15).\t\n45.9% 21.6% 32.4% \nFigure\t14.\tPercentage\tof\tParticipants\tthat\tBring\tAdditional\tTools\t&\tInformation\tto\tFEC\nYes No Unclear\nALES\nAL\nES\nBUS ART\nAR\nT\nAUG\nEDU\nENG\nEN\nG\nFOMD\nFOMD\nFO\nM\nD\nRM\nSC ND\nND\nND\nPredominantly\tResearch\nEqually\tWeighted\nSpecific\tTime\tAllocation\nPredominantly\tTeaching\nFigure\t15.\tDistribution\tof\tPerceived\tFEC\tWeighting\n60.5% \n14.0% \n14.0% \n11.6% \n\t 14\t\n4.4. Need\tfor\tAdditional\tSupports\tto\tBetter\tEvaluate\tTeaching\t\nMost\tparticipants\talso\tvoiced\ttheir\turgent\tneed\tfor\tadditional\tsupports\tto\tbetter\tevaluate\tteaching.\tOne\tparticipant,\tfor\t\nexample,\tremarked\tthat\t“I\twas\tlooking\tto\tyou\tto\tfind\tthis\tout,\tto\tfind\tout\tif\tthe\tresult\tof\tthis\tsurvey\twould\tgive\tme\tsome\t\nideas\tof\twhat\tthis\tis”;\tand\tanother\tcommented\tthat\tin\ttheir\tdepartment\t“We’re\thoping\tthe\tuniversity\twill\tsolve\tthis\tissue.”\t\nIndeed,\t 83.7%\t of\t participants\t mentioned\t needing\t some\t support,\t whereas\t 9.3%\t indicated\t not\t needing\t additional\t\nresources\t(see\tFigure\t16).\t\nSome\tparticipants\texplicitly\trecognized\ttheir\tconcerns\tabout\tdepending\texclusively\ton\tUSRI,\tand\tthe\tinability\tof\tUSRIs\tto\t\neffectively\tevaluate\tdiverse\tapproaches\tto\tteaching\t(46.5%),\tother\tmentioned\tnot\thaving\tenough\ttime\tand\tresources\tto\t\nadopt\tsupplementary\ttools\tin\tthe\tteaching\tevaluation\tprocess\t(27.9%).\tParticipants\talso\texpressed\tconcerns\tabout\tlower\t\nUSRI\tscores\tfor\twomen\tand\tvisible\tminorities\t(11.6%),\tas\twell\tas\tthe\tdifficulties\tof\tcompelling\tsenior\tfaculty\t(usually\twith\t\nfull\tprofessor\trank)\tto\timprove\ttheir\tteaching\tpractices\t(9.3%)\t(see\tFigure\t17):\t\nThat\tquestion\tset\tdoesn’t\tserve\tthe\tdiversity\tand\tthe\tkind\tof\tpedagogy\twe\thave\tnow,\tand\treally\tneeds\tfixing.\tI\tthink\t\nthere\tneeds\tto\tbe\ta\tconversation\tabout\twhat\tthis\t is\tgoing\tto\t look\t like\tover\ttime.\t I\talso\t think\tthe\tUniversity\thas\tto\t\ntake\tvery\tseriously\tthe\tconcerns\tthat\tequity\tseeking\tgroups\thave\tabout\twhat\thappens\tin\tteaching\tevaluations.\tWhat\t\nhappens\tto\twomen?\tWhat\thappens\tto\tvisible\tminority?\tWhat\thappens\tto\tpeople\tthat\tare\tperceived\tto\thave\tstrong\t\naccents?\tAnd\tI\tthink\tthere’s\ta\thuge\tresponsibility\ton\tchairs\tand\tpeople\ton\tFEC\tto\treally\tbe\teducated\tin\thow\tmuch\tyou\t\ncan\textrapolate\tfrom\tUSRI.\t\nTSQS\t conducted\t descriptive\t analyses\t that\t generated\t gender-specific\t USRI\t scores\t using\t data\t from\t the\t academic\t years\t\n2011/2012\t to\t 2015/2016.\t Results\t show\t there\t is\t no\t overt\t difference\t between\t scores\t for\t males\t(N\t=\t 18576,\tMdn\t=\t\n4.53)\tand\tfemales\t(N\t=\t13679,\tMdn\t=\t4.57)\tfor\tstatement\t211.\tAdditionally,\tTSQS\tmeasures\tthe\treliability\tof\tthe\tUSRI\tby\t\ncomparing\tmedians\tto\tthe\tprevious\tacademic\tyears.\t\tOur\tresearch\tteam\twas\tnot\table\tto\tfind\tinformation\ton\tthe\tvalidity\tof\t\nthe\tUSRI.\t\n83.7% 9.3% 7.0% \nFigure\t16.\tPerceived\tNeed\tfor\tAdditional\tSupports\tto\tBetter\tEvaluate\tTeaching\nYes No Unclear\n46.5% \n27.9% \n11.6% \n9.3% \nUSRI\tDeficiency\tfor\tDifferent\tClass\tMethods\nNot\tEnough\tTime\t&\tResources\tfor\tAdditional\tTools\nUSRI\tIssues\twith\tGender\t&\tMinorities\nIssues\twith\tSenior\tFaculty\nFigure\t17.\tIssues\tEncountered\twhen\tEvaluating\tTeaching\n\t 15\t\nAmong\tthe\tmost\tcommonly\tlisted\ttypes\tof\tsupports\tto\tbetter\tevaluate\tteaching,\tparticipants\tmentioned\tthat\tideally,\tthey\t\nwould\t implement\t peer\t in-class\t observations\t not\t only\t for\t promotion\t purposes,\t but\t across\t their\t department\t (41.9%),\t\nobtain\tuniversity\tguidelines\tto\tunderstand\thow\tto\taccurately\tand\teffectively\tevaluate\tteaching\t(27.9%)\t(see\tFigure\t18):\t\nMy\tlearning\tcurve\tcoming\tin\tto\tthe\tchair\trole\thas\tbeen\thuge.\tWe\tused\tto\thave\ta\tchair’s\tschool\tkind\tof\tthing.\tNow\t\nthere’s\tthe\tgold\tand\tgreen\tleadership\tcollege\tor\twhatever\tit’s\tcalled,\tand\tit’s\ta\tvery\tdifferent\tthing.\tSo,\tyou\ttransition\t\ninto\tchair\tnow\tand\tyou’re\ton\tyour\town.\tYou’ve\tgot\tto\tgo\tfigure\tit\tout,\task\tpeople\tfor\tcoffee,\tand\tlearn\tup,\tbut\tthere’s\t\nno\torientation\tto\tbeing\ta\tchair.\t\nSome\t also\t indicated\t that\t it\t would\t be\t useful\t to\t gain\t access\t to\t teaching\t training\t and\t workshops\t that\t they\t could\t refer\t\nstruggling\tprofessors\tto\t(when\tnot\tavailable\tin\ttheir\tdepartments)\t(20.9%),\thave\tdiscipline\tspecific\tconcept\tinventories\tto\t\nbetter\t determine\t the\t knowledge\t increase\t in\t students\t (11.6%),\t implement\t peer\t support\t initiatives\t to\t improve\t teaching\t\npractices\t (11.6%),\t video\t record\t lectures\t for\t later\t analysis\t of\t the\t quality\t of\t teaching\t (7%),\t request\t pedagogical\t self-\nreflections\t in\twhich\tprofessors\t give\t a\t thoughtful\t summary\tof\t their\t teaching\t (7%),\t and\t review\tclass\tmaterials\t to\thave\ta\t\nbetter\tpanorama\tof\tthe\tinstructor\t(4.7%)\t(see\tFigure\t18).\tHaving\tmore\tresources\tto\tbetter\tevaluate\tteaching\tis\timportant,\t\nas\tone\tof\tthem\tmentioned:\t\nI\tthink\twe\tneed\tsupport\tto\tdevelop\tour\town\tteaching\tskills\tmore\tcomfortably\tso\twe\tcan\tbe\texcellent\tteachers,\tbut\t\nalso\tit\twould\tbe\timportant\tto\tmake\tsure\tour\tinstruments\tare\tvalid\tand\tthat\twe\tcan\tactually\tuse\tthem\ton\ta\tjourney\tof\t\nself-improvement,\tand\tdepartmental\tculture\tand\timprovement.\tAnd\tto\tdo\tthat\thaving\tsome\tfacilitation\tfrom\tpeople\t\nwho\tknow\tthe\tart\tand\twho\tcan\twork\twith\tus\twould\tbe\tbetter\tthan\tjust\thaving\ta\tlist\tof\tstuff\ton\ta\twebsite\twhere\tyou\t\ndo\tclick,\tclick,\tand\taccess\twhat\tyou\twant.\tThat’s\tnot\tenough.\t\n41.9% \n27.9% \n20.9% \n11.6% \n11.6% \n7.0% \n7.0% \n4.7% \nImplement\tPeer\tObservations\nObtain\tGuidelines\tto\tEvaluate\tTeaching\nAccess\tTraining\t&\tWorkshops\tfor\tStruggling\tProfessors\nDiscipline\tSpecific\tConcept\tInventories\nGenerate\tPeer\tSupport\tInitiatives\nVideo\tRecord\tLectures\nRequest\tPedagogical\tSelf-Reflections\nReview\tClass\tMaterials\nFigure\t18.\tMost\tCommon\tIdeal\tTypes\tof\tSupports\tto\tBetter\tEvaluate\tTeaching\n\t 16\t\n4.5. Difference\tBetween\tTeaching\tEvaluation\tfor\tAnnual\tReview\t&\tPromotion\t\nEven\tthough\tevaluation\tof\tteaching\tfor\tannual\treview\tand\tfor\tpromotion\twas\ta\tdifferent\tprocess\tfor\t68.3%,\tand\tthe\tsame\t\nprocess\tfor\t26.8%\tof\tparticipants\t(see\tFigure\t19),\tboth\tends\tof\tthe\tspectrum\tseem\tto\tagree\tthat\tmore\tcomponents\twere\t\ntaking\tinto\tconsideration\twhen\tthey\twere\tdealing\twith\tpromotion:\t\nThe\tannual\treview\tlooks\tonly\tat\tthat\tyear,\tand\tif\tthere’s\treal\tconcerns\tthen\tyou’ll\t look\tfor\ttrends,\twhereas\twhen\tit\t\ncomes\tto\tpromotion,\t it\t looks\tto\ta\tcareer,\twhat\thas\tthis\t individual\tbeen\tdoing\twith\tteaching,\tand\tnot\tjust\tthis\tyear\t\nbut\t intentionally\t over\t the\t entire\t career.\tWhen\t it\t comes\t to\t application\t promotion,\t there\t is\t a\t larger\t view\t taken\t of\t\nteaching.\t\n4.6. Characteristics\tof\tEffective\t&\tExcellent\tTeachers\t\nEven\tthough\tmost\tparticipants\tstruggled\twith\tthe\tbreadth\tof\tthis\tquestion,\tfor\tthem\tan\teffective\tand/or\texcellent\tteacher\t\nappropriately\tconveys\tthe\tknowledge\tand\tthe\tskills\t that\tstudents\tneed\tto\tobtain\t(58.1%),\tengages\tstudents\tdespite\tthe\t\ndifficulty\tof\tthe\tcourse\tmaterial\t(46.5%),\tgets\thigh\tUSRI\tscores\tand\tteaching\tawards\t(30.2%),\t innovates\tin\ttheir\tteaching\t\npractices\t(23.3%),\tknows\thow\tto\tchallenge\tstudents\twithout\tburning\tthem\tout\t(18.6%),\tregularly\tupdates\tthe\tinformation\t\nand\t the\tmaterial\t of\t the\t course\t (18.6%),\t and\tengages\t in\t scholarship\tof\t teaching\t and\t learning\t related\t activities\t (18.6%).\t\nOther\t participants\t indicated\t that\t being\t supportive\t of\t students\t was\t also\t important\t (14%),\t seeking\t professional\t\ndevelopment\topportunities\tto\timprove\ttheir\tpedagogical\tpractices\t(7%),\tand\tlearning\tfrom\tstudents\tas\tmuch\tas\tstudents\t\nlearn\tfrom\tthem\t(4.7%)\t(see\tFigure\t21):\t\nI\ttry\tto\tavoid\tdefinitions\tif\tthat\tinvolves\tany\tkind\tof\texplicit\tcriteria.\tWhat\tI\tlook\tfor,\twhat\tI\tthink\tis\tmost\timportant\tin\t\nteaching\tis\tthat\tall\tgood\tteaching\tis\ttransformative.\tAnd\tit’s\tmostly\ttransformative\tfor\tthe\tstudent,\talthough\ttruth\tbe\t\nknown\tgood\tteaching\tis\ttransformative\tfor\tboth\tstudent\tand\tteacher.\t\nALES BUS ART\nART\nART\nAU\nG\nAU\nG\nEDU EN\nG\nENG\nFOMD\nFOMD\nRM\nRM\nSCI\nSCI\nND\nND\nA\tDifferent\tProcess\nThe\tSame\tProcess\nUnclear\nFigure\t19.\tPerceived\tDifferences\tbetween\tEvaluation\tof\tTeaching\tfor\tAnnual\tReview\t&\tPromotion\n58.1% \n46.5% \n30.2% \n23.3% \n18.6% \n18.6% \n18.6% \n14.0% \n7.0% \n4.7% \nConvey\tKnowledge\t&\tSkills\tto\tStudents\nEngage\tStudents\nGet\tHigh\tUSRI\tScores\t&\tAwards\nInnovate\nChallenge\tStudents\nUpdate\tInformation\t&\tMaterial\nEngage\tin\tthe\tSoTL\nSupportive\tof\tStudents\nSeek\tProfessional\tDevelopment\nLearn\tfrom\tStudents\nFigure\t20.\tCharacteristics\tof\tEffective\t&\tExcellent\tTeachers\n68.3% \n26.8% \n4.9% \n\t 17\t\n4.7. Experiences\tTransitioning\tto\te-USRI\tCompared\tto\tPaper-Based\tUSRI\t\nFROM\tTHIS\tPOINT\tON\tINFORMATION\tONLY\tCONSIDERS\tPARTICIPANTS\tWHO\tREPORTED\tUSING\tUSRI\t\nMost\tparticipants\tbelieved\tthat\tresponse\trates\thave\tdecreased\tsince\tthe\timplementation\tof\tthe\te-USRI:\t48.6%\thad\tsome\t\ndata\t to\t back\t up\t this\t claim,\t such\t as\t their\t personal\t USRI\t response\t rates,\t or\t the\t actual\t number\t of\t students\t that\t now\t\ncomplete\tthe\tevaluations\tcompared\tto\tprevious\tyears;\tand\t18.9%\tbelieved\tthat\tthe\tresponse\trates\thad\tdeclined,\tbut\thad\t\nno\tdata\t to\tsupport\t this\tclaim.\tAlternatively,\t21.6%\tof\tparticipants\tbelieved\t there\twas\ta\tsimilar\t response\t rate\twith\tboth\t\nmethods\tof\tdelivery,\t8.1%\tthought\tthat\t it\t increased\twith\tthe\tswitch\tto\telectronic,\tbut\tdid\tnot\toffer\tdata\tto\tsupport\tthis\t\nclaim\t (see\tFigure\t21).\tMoreover,\t some\tparticipants\t (8.1%)\tbelieved\t that\ta\tmajor\t issue\twith\tUSRI\t response\t rates\t is\t that\t\nstudents\tare\tasked\tto\tcomplete\ta\tlarge\tamount\tof\tassessments:\t\nI\t think\t they\t get\t completely\t annoyed\t because\t they’re\t being\t bombarded\twith\t e-mails\t in\t their\t last\tweek\t of\t classes\t\nreminding\tthem\tto\tdo\tUSRIs,\tand\tprofessors\treminding\tthem\tto\tdo\tUSRIs\tto\tthe\tpoint\twhere\tI\tthink\tthey\tjust\tgo:\tI’m\t\nreally\tannoyed.\tI’m\tnot\tgoing\tto\tdo\tthem\tat\tall.\tI\tdon’t\tknow\twhat\tkind\tof\ta\tsystem\tthey\tuse\tto\tsend\tthem\tout,\tbut\t\nit’s\talmost\tlike\tthey\tsend\tout\tone\tfor\tevery\tclass,\tfor\tevery\tstudent,\tso\tthey’re\tjust\tharassing\tthem\tto\tdeath\tand\tthey\t\nget\tmad\tabout\tit.\t\n18.9% 48.6% 21.6% 8.1% \n2.\n7%\nFigure\t21.\tReported\tResponse\tRate\tExperiences\twith\te-USRI\tcompared\tto\tPaper-Based\tUSRI\nDecline\t(no\tdata) Decline\t(some\tdata) Same Increase Unclear\n\t 18\t\n\t 19\t\n5. Conclusions\t\nHow\tare\tthe\tUSRIs\tand\tother\ttools\tused\tin\tthe\tevaluation\tof\tteaching\tevaluation\tat\tthe\tUniversity\tof\tAlberta?\t\n• Participants\t from\t all\t faculties\t other\t than\t FOMD\t use\tUSRI\t scores\t and\t comments\t (and\t only\t a\t portion\t of\t\nparticipants\tfrom\tFOMD)\tto\tevaluate\tteaching.\t\n• Statement\t221\t(overall\tthe\tinstructor\twas\texcellent),\tand\tstatement\t25\t(overall\tthe\tquality\tof\tthe\tcourse\t\ncontent\twas\texcellent)\tare\tthe\tmost\tcommonly\tused\tUSRI\titems\tto\tevaluate\tteaching.\t\n• Most\tparticipants\ttry\tto\tcontextualize\ttheir\tinterpretation\tof\tUSRI\tresults.\t\nWhat\tare\tsome\tapproaches\tfor\tmulti-faceted\tevaluation\tof\tteaching?\t\n• In-class\tpeer\tteaching\tobservations\twere\tthe\tmost\tcommonly\tused\tadditional\tsource\tof\tinformation,\tfollowed\t\nby\tannual\tinstructor\tpedagogical\tself-reflections.\t\n• Most\tparticipants\tobtain\tthese\tresources\ton\ta\tvoluntary\tbasis,\tonly\twhen\tprofessors\tagree\tto\tgive\tthem\tthese\t\nsupplementary\tresources.\t\n• Some\t participants\t have\t implemented\t yearly\t faculty\t audits,\t in\t which\t a\t manageable\t portion\t of\t their\t\nprofessorate’s\tteaching\tis\tevaluated\tusing\tadditional\tinformation.\t\n• Even\twhen\tparticipants\tobtain\tthese\tresources,\tnot\tall\treported\tto\tbring\tthem\tto\tFEC.\tWhen\tthis\tinformation\t\nmakes\tit\tto\tFEC,\tit\tis\tused\tto\tinform\ttheir\tnarrative,\tand\tis\tonly\texplicitly\tbrought\tup\twhen\tthere\tis\ta\tchallenge.\t\n• Participants\trecognized\tthat\tthere\tis\tstill\ta\tstrong\tbias\ttowards\tresearch\tat\ttheir\trespective\tFEC.\t\n• Most\tparticipants\tvoiced\ttheir\tneed\tfor\tadditional\tsupports\tto\tbetter\tevaluate\tteaching.\t\n• They\t have\t identified\t some\t issues\t when\t evaluating\t teaching\t exclusively\t with\t USRI,\t and\t possible\t\nalternatives\tto\tsupplement\tthese\tscores,\tbut\tstill\tthey\thope\tthe\tinstitution\tprovides\ta\tsolution\tfor\ttheir\t\nconcerns.\t\n\t 20\t\n\t 21\t\n6. Appendix\t1:\tSemi-Structured\tInterview\tQuestions\t\nStudy\tTitle:\tEvaluation\tof\tTeaching\tat\tthe\tUniversity\tof\tAlberta\t\n1. Demographics\t\t\na. Identify\tdepartment/faculty\t\t\nb. Number\tof\tfaculty/\tFSOs\twho\tteach\t\t\nc. Number\tof\tsessionals\twho\tteach\t\nd. Number\tof\tgraduate\tstudents\twho\tteach\t\n2. How\tdo\tyou\tevaluate\tteaching?\t\t\t\na. Do\tyou\t(or\tyour\tFEC)\tuse\tUSRIs\tto\tevaluate\tthe\tteaching\tof\tyour\tfaculty\tmembers?\t\t\nb. If\tyes,\twhich\tof\tthe\tfollowing\tstandard\tUSRI\tstatements\tare\tconsidered\tin\tyour\tfaculty’s\tteaching\tevaluation\t\nprocess?\t\ni. the\tgoals\tand\tobjectives\tof\tthe\tcourse\twere\tclear\t\t\nii. in-class\ttime\twas\tused\teffectively\t\t\niii. I\tam\tmotivated\tto\tlearn\tmore\tabout\tthese\tsubject\tareas\t\t\niv. I\tincreased\tmy\tknowledge\tof\tthe\tsubject\tareas\tin\tthis\tcourse\t\t\nv. Overall\tthe\tquality\tof\tthe\tcourse\tcontent\twas\texcellent\t\t\nvi. the\tinstructor\tspoke\tclearly\t\t\nvii. the\tinstructor\twas\twell\tprepared\t\t\nviii. the\tinstructor\ttreated\tstudents\twith\trespect\t\t\nix. the\tinstructor\tprovided\tconstructive\tfeedback\tthroughout\tthis\tcourse\t\t\nx. overall\tthis\tinstructor\twas\texcellent\t\t\n3. How\tdo\tyou\tcompare\tyour\texperience\twith\te-USRIs\tand\tin-class\tpaper-based\tUSRIs?\t\n4. What,\tif\tany,\tadditional\ttools\tdo\tyou\tregularly\tuse,\tother\tthan\tUSRI\tto\tevaluate\tteaching?\tIf\tyou\tdon’t,\twhy\tnot?\t\t\n5. Do\tyou\tuse\tadditional\tsources\tof\tinformation\tto\tevaluate\tteaching?\tIf\tso,\twhat\tinformation\tdo\tyou\tuse\tand\thow\tare\t\nthese\tsources\tof\tinformation\tweighted\tin\tteaching\tevaluations?\tWhy?\t\n6. Do\tyou\tbelieve\tmost\tof\tthe\tFEC\tmembers\tweight\tteaching,\tresearch\tand\tservice\tequally?\tIf\tnot,\tdescribe\tthe\taverage\t\nweighting,\tin\tyour\topinion.\t\t\n7. How\tis\tevaluation\tof\tteaching\tdifferent\t(or\tnot)\tfor\tannual\treview,\tor\tfor\tpromotion?\t\n8. How\tdo\tyou\tdefine\teffective\tand/or\texcellent\tteaching?\tDo\tyou\thave\tset\tstandards,\tor\tdo\tyou\tmake\ta\trelative\t\ncomparison?\t\t\n9. What\tadditional\tsupports\twould\tbe\tuseful\tto\tyou\tto\tbetter\tevaluate\tteaching?\t\n\t 22\t\n\t 23\t\n7. Appendix\t2:\tSample\tUSRI\tResults\tfor\tDepartment\tChairs\t\nStudy\tTitle:\tEvaluation\tof\tTeaching\tat\tthe\tUniversity\tof\tAlberta\t\nPlease\t look\t at\t the\t USRI\t information\t provided\t for\t two\t different\t instructors\t teaching\t the\t same\t course.\t How\twould\t you\t\ndescribe\tthe\tinstructors’\tteaching\tto\tFEC?\t\t\tOR\t\t\tIn\tterms\tof\tevaluating\tteaching,\twhat\tis\tyour\tinterpretation\tof\tthis\tdata\tfor\t\neach\tinstructor?\t\nInstructor\tA\t\n\t \t \t \t \t \t \t \t \t Reference\tData\t\nQuestion\t\nMedian\t Tukey\t\t\nFence\t 25%\t 50%\t 75%\t\nThe\tgoals\tand\tobjectives\tof\tthe\tcourse\twere\tclear\t 3.4\t 2.7\t 3.9\t 4.3\t 4.7\t\nIn-class\ttime\twas\tused\teffectively.\t 3.6\t 2.5\t 3.8\t 4.3\t 4.7\t\nI\tam\tmotivated\tto\tlearn\tmore\tabout\tthese\tsubject\tareas.\t 3.5\t 2.9\t 4.1\t 4.5\t 4.8\t\nI\tincreased\tmy\tknowledge\tof\tthe\tsubject\tareas\tin\tthis\tcourse.\t 4.4\t 3.0\t 4.1\t 4.6\t 4.8\t\nOverall,\tthe\tquality\tof\tthe\tcourse\tcontent\twas\texcellent.\t 3.8\t 2.4\t 3.8\t 4.3\t 4.8\t\nThe\tinstructor\tspoke\tclearly.\t 4.5\t 3.8\t 4.5\t 4.8\t 4.9\t\nThe\tinstructor\twas\twell\tprepared.\t 4.6\t 3.4\t 4.3\t 4.8\t 4.9\t\nThe\tinstructor\ttreated\tthe\tstudents\twith\trespect.\t 4.0\t 4.2\t 4.7\t 4.9\t 5.0\t\nThe\tinstructor\tprovided\tconstructive\tfeedback\tthroughout\tthis\tcourse.\t 4.5\t 2.8\t 4.0\t 4.5\t 4.8\t\nOverall,\tthis\tinstructor\twas\texcellent.\t 4.0\t 3.2\t 4.2\t 4.7\t 4.9\t\nInstructor\tB\t\n\t \t \t \t \t \t \t \t \t \t \t \t Reference\tData\t\nQuestion\t\nMedian\t Tukey\t\t\nFence\t 25%\t 50%\t 75%\t\nThe\tgoals\tand\tobjectives\tof\tthe\tcourse\twere\tclear\t 4.0\t 2.7\t 3.9\t 4.3\t 4.7\t\nIn-class\ttime\twas\tused\teffectively.\t 4.2\t 2.5\t 3.8\t 4.3\t 4.7\t\nI\tam\tmotivated\tto\tlearn\tmore\tabout\tthese\tsubject\tareas.\t 3.7\t 2.9\t 4.1\t 4.5\t 4.8\t\nI\tincreased\tmy\tknowledge\tof\tthe\tsubject\tareas\tin\tthis\tcourse.\t 4.1\t 3.0\t 4.1\t 4.6\t 4.8\t\nOverall,\tthe\tquality\tof\tthe\tcourse\tcontent\twas\texcellent.\t 4.2\t 2.4\t 3.8\t 4.3\t 4.8\t\nThe\tinstructor\tspoke\tclearly.\t 4.7\t 3.8\t 4.5\t 4.8\t 4.9\t\nThe\tinstructor\twas\twell\tprepared.\t 4.4\t 3.4\t 4.3\t 4.8\t 4.9\t\nThe\tinstructor\ttreated\tthe\tstudents\twith\trespect.\t 4.8\t 4.2\t 4.7\t 4.9\t 5.0\t\nThe\tinstructor\tprovided\tconstructive\tfeedback\tthroughout\tthis\tcourse.\t 4.0\t 2.8\t 4.0\t 4.5\t 4.8\t\nOverall,\tthis\tinstructor\twas\texcellent.\t 4.5\t 3.2\t 4.2\t 4.7\t 4.9\t\nAppendix C: Interview Questions \nStudy Title: ​Evaluation of Teaching at the University of Alberta \n1. Demographics \na.​   ​Identify department/faculty \nb.​  ​Number of faculty/ FSOs who teach \nc.​   ​Number of sessionals who teach \nd.​  ​Number of graduate students who teach \n2. How do you evaluate teaching?  \na.​   ​Do you (or your FEC) use USRIs to evaluate the teaching of your faculty members? \nb.​  ​If yes, which of the following standard USRI statements are considered in your \nfaculty’s teaching evaluation process? \n                                        ​i.​              ​the goals and objectives of the course were clear \nii.​           ​in-class time was used effectively \niii.​          ​I am motivated to learn more about these subject areas \niv.​         ​I increased my knowledge of the subject areas in this course \nv.​          ​Overall the quality of the course content was excellent \nvi.​         ​the instructor spoke clearly \nvii.​        ​the instructor was well prepared \nviii.​       ​the instructor treated students with respect \nix.​         ​the instructor provided constructive feedback throughout this course \nx.​          ​overall this instructor was excellent \n3. How do you compare your experience with e-USRIs and in-class paper-based USRIs? \n4. What, if any, additional tools do you regularly use, other than USRI to evaluate teaching? If \nyou don’t, why not? \n5. Do you use additional sources of information to evaluate teaching? If so, what information \ndo you use and how are these sources of information weighted in teaching evaluations? \nWhy? \n6. Do you believe most of the FEC members weight teaching, research and service equally? If \nnot, describe the average weighting, in your opinion. \n7. How is evaluation of teaching different (or not) for annual review, or for promotion? \n8. How do you define effective and/or excellent teaching? Do you have set standards, or do \nyou make a relative comparison? \n9.    What additional supports would be useful to you to better evaluate teaching? \nAppendix D: Sample USRI Case Studies \nStudy Title: ​Evaluation of Teaching at the University of Alberta \nPlease look at the USRI information provided for two different instructors teaching the same \ncourse. How would you describe the instructors’ teaching to FEC?   OR   In terms of evaluating \nteaching, what is your interpretation of this data for each instructor? \nInstructor A \nReference Data \nQuestion Median Tukey \nFence \n25% 50% 75% \nThe goals and objectives of the course were clear 3.4 2.7 3.9 4.3 4.7 \nIn-class time was used effectively. 3.6 2.5 3.8 4.3 4.7 \nI am motivated to learn more about these subject areas. 3.5 2.9 4.1 4.5 4.8 \nI increased my knowledge of the subject areas in this course. 4.4 3.0 4.1 4.6 4.8 \nOverall, the quality of the course content was excellent. 3.8 2.4 3.8 4.3 4.8 \nThe instructor spoke clearly. 4.5 3.8 4.5 4.8 4.9 \nThe instructor was well prepared. 4.6 3.4 4.3 4.8 4.9 \nThe instructor treated the students with respect. 4.0 4.2 4.7 4.9 5.0 \nThe instructor provided constructive feedback throughout this \ncourse. \n4.5 2.8 4.0 4.5 4.8 \nOverall, this instructor was excellent. 4.0 3.2 4.2 4.7 4.9 \nInstructor B \nReference Data \nQuestion Median Tukey \nFence \n25% 50% 75% \nThe goals and objectives of the course were clear 4.0 2.7 3.9 4.3 4.7 \nIn-class time was used effectively. 4.2 2.5 3.8 4.3 4.7 \nI am motivated to learn more about these subject areas. 3.7 2.9 4.1 4.5 4.8 \nI increased my knowledge of the subject areas in this course. 4.1 3.0 4.1 4.6 4.8 \nOverall, the quality of the course content was excellent. 4.2 2.4 3.8 4.3 4.8 \nThe instructor spoke clearly. 4.7 3.8 4.5 4.8 4.9 \nThe instructor was well prepared. 4.4 3.4 4.3 4.8 4.9 \nThe instructor treated the students with respect. 4.8 4.2 4.7 4.9 5.0 \nThe instructor provided constructive feedback throughout this \ncourse. \n4.0 2.8 4.0 4.5 4.8 \nOverall, this instructor was excellent. 4.5 3.2 4.2 4.7 4.9 \nAppendix E: Summary of Positions and Recommendations Related to USRIs in University \nof Alberta Policy, Documents, and Reports \nStudent input should be \nsought in teaching \nevaluation using USRIs or \nsimilar instruments \nX  X    \nPurpose of USRI must be \nclarified X X     \nOpen-ended comments \nshould be included  X     \nOpen-ended comments \nshould not be included   X    \nOpen-ended comments: \nstudent identities should not \nbe included in reports to \ninstructors but kept on \nrecord (for the protection of \ninstructors and students) \n  X X   \nUse and administration of \nUSRI must be considered in \nbroader context (not just \nfocused on teaching) \nX X     \nUSRI is outdated, lacks \nvalidation, and needs \nredevelopment \nX X X    \n(Table continued on next page) \n1 \n(Table, continued) \nRequired​ USRI items need \nto be modified to apply to \nmultiple teaching contexts; \nadditional (optional) question \nvariants should be \ndeveloped that apply to \ndiverse teaching contexts \n(e.g. labs, clinical, blended) \n    X  \nA professionally developed \ninstrument should be \ncreated to ensure validity \nand reliability \nX X X    \nA moratorium on USRI use \nshould be implemented until \nredevelopment occurs; \ndeadline end of 2015 Fall \nterm \n  X    \nUSRIs should be used as \npart of a broader teaching \nevaluation, not the sole \nmeasure of teaching \nperformance \nX  X X  X \nConcern that “the instructor \nwas excellent” is the only \nUSRI item used in FEC \nassessments \n X X    \n(Table continued on next page) \n2 \n(Table, continued) \nThere are aspects of \nteaching that students \ncannot evaluate \nX   X   \n(End of table) \n3 \nAppendix F: ​Summary of Positions and Recommendations Related to Multifaceted \nEvaluation in University of Alberta Policy, Documents, and Reports \nTeaching evaluation should \nbe multifaceted X X X X  X \nChairs, Deans, Supervisors \nand Faculty may struggle \nwith implementing \nmultifaceted evaluation and \nrequire support \nX X     \nA multifaceted teaching \nevaluation guide should be \ndeveloped, including \ndefinitions, strategies, and \nexamples \nX X X    \nFEC decisions regarding \npromotion and tenure must \nbe based on multiple \nindicators of teaching; this \nmay not have been \nconsistently applied in the \npast \nX  X X  X \nPeer review should be a part \nof evaluation for tenure and \npromotion \n  X    \n(Table continued on next page) \n1 \n(Table, continued) \nEvaluation of teaching \nshould include broader \nteaching duties, such as \ngraduate student supervision \nand mentoring, course \ndesign, curriculum \ndevelopment, etc. \n  X    \nOpportunities for teacher \ntraining and support are \nneeded \n  X X   \n(End of table) \n2 \nAppendix G: References for Reviewed Literature \nThese are the references used to review the literature only. Other references consulted for \npreparation of the report (such as University of Alberta reports and documents) are included at \nthe end of the report. \nAl-Eidan, F., Baig, L. A., Magzoub, M., & Omair, A. (2016). Reliability and validity of the faculty \nevaluation instrument used at King Saud bin Abdulaziz University for Health Sciences: \nResults from the haematology course. ​The Journal of the Pakistan Medical Association, \n66​(4), 453-457. ​http://www.jpma.org.pk/full_article_text.php?article_id=7711 \nBacker, E. (2012). Burnt at the student evaluation stake – the penalty for failing students. \nE-Journal of Business Education & Scholarship of Teaching, 6​(1), 1-13. Retrieved from \nhttp://www.ejbest.org/upload/eJBEST_Backer_2012_1.pdf \nBedggood, R. E., & Donovan, J. D. (2012). University performance evaluations: What are we \nreally measuring? ​Studies in Higher Education, 37​(7), 825-842. \nhttp://dx.doi.org/10.1080/03075079.2010.549221 \nBerk, R. A. (2013). Top five flashpoints in the assessment of teaching effectiveness. ​Medical \nTeacher, 35​(1), 15-26.​ ​http://dx.doi.org/10.3109/0142159X.2012.732247 \nBlackhart, G. C., Peruche, B. M., DeWall, C. N., & Joiner, T. E., Jr. (2006). Faculty forum: \nFactors influencing teaching evaluations in higher education. ​Teaching of Psychology, \n33​(1), 37-39. ​http://dx.doi.org/10.1207/s15328023top3301_9 \nBlair, E., & Valdez Noel, K. (2014). Improving higher education practice through student \nevaluation systems: is the student voice being heard? ​Assessment & Evaluation in \nHigher Education, 39​(7), 879-894.​ ​http://dx.doi.org/10.1080/02602938.2013.875984 \nBoring, A., Ottoboni, K., & Stark, P. B. (2016). Student evaluations of teaching (mostly) do not \nmeasure teaching effectiveness. ​ScienceOpen Research, 2016​(1). \nhttp://dx.doi.org/10.14293/S2199-1006.1.SOR-EDU.AETBZC.v1  \nBoysen, G.A. (2015). Uses and misuses of student evaluations of teaching: The interpretation of \ndifferences in teaching evaluation means irrespective of statistical information. ​Teaching \nof Psychology, 42​(2), 109-118.​ ​http://dx.doi.org/10.1177/0098628315569922 \nBoysen, G. A., Kelly, T. J., Raesly, H. N., & Casner, R. W. (2014). The (mis)interpretation of \nteaching evaluations by college faculty and administrators. ​Assessment & Evaluation in \nHigher Education, 39​(6), 641-656.​ ​http://dx.doi.org/10.1080.02602938.2013.860950 \nBrown, G. D. A., Wood, A. M., Ogden, R. S., & Maltby, J. (2014). Do student evaluations of \nuniversity reflect inaccurate beliefs or actual experience? A relative rank model.​ Journal \nof Behavioral Decision Making, 28​, 14-26. ​http://dx.doi.org/10.1002/bdm.1827 \nCampbell, J. P., & Bozeman, W. C. (2008). The value of student ratings: Perceptions of \nstudents, teachers, and administrators. ​Community College Journal of Research and \nPractice, 32​, 13-24.​ ​http://dx.doi.org/10.1080/10668920600864137 \nCentra, J.A. (2003). Will teachers receive higher student evaluations by giving higher grades \nand less course work? ​Research in Higher Education, 44​(5), 495-518. \nhttp://www.jstor.org.login.ezproxy.library.ualberta.ca/stable/40197319 \nCentra, J. A., & Gaubatz, N. B. (2000). Is there gender bias in student evaluations of teaching? \nhttp://dx.doi.org/10.1080.02602938.2013.860950\nhttp://dx.doi.org/10.1080/10668920600864137\nhttp://dx.doi.org/10.1080/03075079.2010.549221\nhttp://dx.doi.org/10.1002/bdm.1827\nhttp://www.ejbest.org/upload/eJBEST_Backer_2012_1.pdf\nhttp://www.jstor.org.login.ezproxy.library.ualberta.ca/stable/40197319\nhttp://dx.doi.org/10.1080/02602938.2013.875984\nhttp://dx.doi.org/10.1080/02602938.2013.875984\nhttp://dx.doi.org/10.1080/10668920600864137\nhttp://dx.doi.org/10.3109/0142159X.2012.732247\nhttp://dx.doi.org/10.1207/s15328023top3301_9\nhttp://dx.doi.org/10.3109/0142159X.2012.732247\nhttp://dx.doi.org/10.1177/0098628315569922\nhttp://dx.doi.org/10.1177/0098628315569922\nhttp://dx.doi.org/10.14293/S2199-1006.1.SOR-EDU.AETBZC.v1\nhttp://dx.doi.org/10.1080.02602938.2013.860950\nhttp://www.jpma.org.pk/full_article_text.php?article_id=7711\nThe Journal of Higher Education, 71​(1), 17-44. \nhttp://login.ezproxy.library.ualberta.ca/login?url=http://search.ebscohost.com/login.aspx?\ndirect=true&db=edsjsr&AN=edsjsr.10.2307.2649280&site=eds-live&scope=site \nChen, Y., & Hoshower, L. B. (2003). Student evaluation of teaching effectiveness: an \nassessment of student perception and motivation. ​Assessment & Evaluation in Higher \nEducation, 28​(1), 71-88.​ ​http://dx.doi.org/10.1080/0260293032000033071 \nCheng, D. A. (2015). Effects of professorial tenure on undergraduate ratings of teaching \nperformance. ​Education Economics, 23​(3), 338-357. \nhttp://dx.doi.org/10.1080/09645292.2013.826632 \nCho, D., Baek, W., & Cho, J. (2015). Why do good performing students highly rate their \ninstructors? Evidence from a natural experiment. ​Economics of Education Review, 49​, \n172-179. ​http://dx.doi.org/10.1016/j.econedurev.2015.10.001 \nCho, J., & Otani, K. (2014). Differences in student evaluations of limited-term lecturers and \nfull-time faculty. ​Journal on Excellence in College Teaching, 25​(2), 5-24. \nhttp://opus.ipfw.edu/profstudies_facpubs/64 \nChonko, L. B., Tanner, J. F., & Davis, R. (2002). What are they thinking? Students’ expectations \nand self-assessments. ​Journal of Education for Business, 77​(5), 271-281. Retrieved \nfrom \nhttp://login.ezproxy.library.ualberta.ca/login?url=http://search.ebscohost.com/login.aspx?\ndirect=true&db=bth&AN=7214031&site=eds-live&scope=site \nClayson, D. E. (2013). Initial impressions and the student evaluation of teaching. ​Journal of \nEducation for Business, 88​(1), 26-53. ​http://dx.doi.org/10.1080/08832323.2011.633580 \nCohen, E. H. (2005). Student evaluations of course and teacher: factor analysis and SSA \napproaches. ​Assessment & Evaluation in Higher Education, 30​(2), 123-136. \nhttp://dx.doi.org/10.1080/0260293042000264235 \nCohen, P. A. (1981). Student ratings of instruction and student achievement: A meta-analysis of \nmultisection validity studies. ​Review of Educational Research, 51​(3), 281-309. \nCox, C.D., Peeters, M. J., Stanford, B. L., & Seifert, C. F. (2013). Pilot of peer assessment \nwithin experiential teaching and learning. ​Currents in Pharmacy Teaching and Learning, \n5​(4), 311-320.​ ​http://dx.doi.org/10.1016/j.cptl.2013.02.003 \nCurwood, J.S., Tomitsch, M., Thomson, K., & Hendry. G.D. (2015). Professional learning in \nhigher education: Understanding how academics interpret student feedback and access \nresources to improve their teaching. ​Australasian Journal of Educational Technology, \n31​(5).​ ​http://dx.doi.org/10.14742/ajet.2516 \nd’Apollonia, S., & Abrami, P. C. (1997). Navigating student ratings of instruction. ​American \nPsychologist, 52​(11), 1198-1208. ​http://dx.doi.org/10.1037/0003-066X.52.11.1198 \nDolmans, D. M., Janssen-Noordman, A., & Wolfhagen, H. P. (2006). Can students differentiate \nbetween PBL tutors with different tutoring deficiencies? Medical Teacher, 28(6), \n156-161. doi: 10.1080/01421590600776545 \nDodeen, H. (2013). Validity, reliability, and potential bias of short forms of students’ evaluation \nof teaching: The case of UAE University. ​Educational Assessment, 18​(4), 235-250. \nhttp://dx.doi.org/10.1080/10627197.2013.846670 \nFelton, J., Mitchell, J., & Stinson, M. (2004). Web-based student evaluations of professors: the \nhttp://dx.doi.org/10.14742/ajet.2516\nhttp://dx.doi.org/10.1080/0260293032000033071\nhttp://login.ezproxy.library.ualberta.ca/login?url=http://search.ebscohost.com/login.aspx?direct=true&db=edsjsr&AN=edsjsr.10.2307.2649280&site=eds-live&scope=site\nhttp://login.ezproxy.library.ualberta.ca/login?url=http://search.ebscohost.com/login.aspx?direct=true&db=bth&AN=7214031&site=eds-live&scope=site\nhttp://dx.doi.org/10.1016/j.cptl.2013.02.003\nhttp://dx.doi.org/10.1080/0260293042000264235\nhttp://dx.doi.org/10.14742/ajet.2516\nhttp://opus.ipfw.edu/profstudies_facpubs/64\nhttp://dx.doi.org/10.1080/08832323.2011.633580\nhttp://login.ezproxy.library.ualberta.ca/login?url=http://search.ebscohost.com/login.aspx?direct=true&db=edsjsr&AN=edsjsr.10.2307.2649280&site=eds-live&scope=site\nhttp://dx.doi.org/10.1016/j.econedurev.2015.10.001\nhttp://dx.doi.org/10.1080/0260293042000264235\nhttp://dx.doi.org/10.1037/0003-066X.52.11.1198\nhttp://login.ezproxy.library.ualberta.ca/login?url=http://search.ebscohost.com/login.aspx?direct=true&db=edsjsr&AN=edsjsr.10.2307.2649280&site=eds-live&scope=site\nhttp://login.ezproxy.library.ualberta.ca/login?url=http://search.ebscohost.com/login.aspx?direct=true&db=bth&AN=7214031&site=eds-live&scope=site\nhttp://dx.doi.org/10.1080/0260293032000033071\nhttp://dx.doi.org/10.1016/j.cptl.2013.02.003\nhttp://dx.doi.org/10.1080/10627197.2013.846670\nhttp://dx.doi.org/10.1080/10627197.2013.846670\nhttp://dx.doi.org/10.1080/09645292.2013.826632\nrelations between perceived quality, easiness and sexiness. ​Assessment & Evaluation in \nHigher Education, 29​(1), 91-108.​ ​http://dx.doi.org/10.1080/0260293032000158180 \nFraile, R., & Bosch-Morell, F. (2015). Considering teaching history and calculating confidence \nintervals in student evaluations of teaching quality: An approach based on Bayesian \ninference. ​Higher Education, 70​(1), 55-72.​ ​http://dx.doi.org/10.1007/s10734-014-9823-0 \nGehrt, K., Louie, T. A., & Osland, A. (2015). Student and professor similarity: Exploring the \neffects of gender and relative age. ​Journal of Education for Business, 90​, 1-9. \nhttp://dx.doi.org/10.1080/08832323.2014.968514  \nGinns, P., Prosser, M., & Barrie, S. (2007). Students’ perceptions of teaching quality in higher \neducation: the perspective of currently enrolled students. ​Studies in Higher Education, \n32​(5), 603-615. ​http://dx.doi.org/10.1080/03075070701573773 \nGrammatikopoulos, V., Linardakis, M., Gregoriadis, A., & Oikonomidis, V. (2015). Assessing the \nstudents’ evaluations of educational quality (SEEQ) questionnaire in Greek higher \neducation. ​Higher Education, 70​(3), 395-408. \nhttp://dx.doi.org/10.1007/s10734-014-9837-7 \nGrayson, J. P. (2015). Repeated low teaching evaluations: A form of habitual behavior? \nCanadian Journal of Higher Education, 45​(4), 298-321. \nhttp://journals.sfu.ca/cjhe/index.php/cjhe/article/view/184404 \nGreenwald, A. G. (1997). Validity concerns and usefulness of student ratings of instruction. \nAmerican Psychologist, 52​(11), 1182-1186. \nhttp://dx.doi.org/10.1037/0003-066X.52.11.1182 \nGreenwald, A. G., Gillmore, G. M. (1997). Grade leniency is a removable contaminant of student \nratings. ​American Psychologist, 52​(11), 1209-1217. \nhttp://dx.doi.org/10.1037/0003-066X.52.11.1209 \nGreimel-Fuhrmann, B. (2014). Student’s perception of teaching behaviour and its effect on \nevaluation. ​International Journal for Cross-Disciplinary Subjects in Education, 5​(1), \n1557-1563.​ ​http://dx.doi.org/10.20533/ijcdse.2042.6364.2014.0218 \nGump, S.E. (2007). Student evaluations of teaching effectiveness and the leniency hypothesis: \nA literature review. ​Education Research Quarterly, 30​(3), 55-68. Retrieved from \nhttp://eric.ed.gov.login.ezproxy.library.ualberta.ca/?id=EJ787711 \nHuebner, L., & Magel, R. C. (2015). A gendered study of student ratings of instruction. ​Open \nJournal of Statistics, 5,​ 552-567. ​http://dx.doi.org/10.4236/ojs.2015.56058  \nHughes II, K. E., & Pate, G. R. (2013). Moving beyond student ratings: A balanced scorecard \napproach for evaluating teaching performance. Issues in ​Accounting Education, 28​(1), \n49-75.​ ​http://dx.doi.org/10.2308/iace-50302 \nIqbal, I. (2013). Academics’ resistance to summative peer review of teaching: questionable \nrewards and the importance of student evaluations. ​Teaching in Higher Education, 18​(5), \n557-569.​ ​http://dx.doi.org/10.1080/13562517.2013.764863 \nJackson, M. J., & Jackson, W. T. (2015). The misuse of student evaluations of teaching: \nImplications, suggestions and alternatives. ​Academy of Educational Leadership Journal, \n19​(3), 165-173. \nhttp://www.alliedacademies.org/academy-of-educational-leadership-journal/ \nJones, J., Gaffney-Rhys, R., & Jones, E. (2014). Handle with care! An exploration of the \nhttp://dx.doi.org/10.1037/0003-066X.52.11.1209\nhttp://dx.doi.org/10.1080/08832323.2014.968514\nhttp://dx.doi.org/10.2308/iace-50302\nhttp://dx.doi.org/10.1080/13562517.2013.764863\nhttp://dx.doi.org/10.1080/03075070701573773\nhttp://dx.doi.org/10.1007/s10734-014-9837-7\nhttp://www.alliedacademies.org/academy-of-educational-leadership-journal/\nhttp://dx.doi.org/10.1007/s10734-014-9823-0\nhttp://dx.doi.org/10.1080/0260293032000158180\nhttp://psycnet.apa.org/doi/10.1037/0003-066X.52.11.1182\nhttp://dx.doi.org/10.20533/ijcdse.2042.6364.2014.0218\nhttp://www.alliedacademies.org/academy-of-educational-leadership-journal/\nhttp://dx.doi.org/10.2308/iace-50302\nhttp://dx.doi.org/10.1080/13562517.2013.764863\nhttp://eric.ed.gov.login.ezproxy.library.ualberta.ca/?id=EJ787711\nhttp://journals.sfu.ca/cjhe/index.php/cjhe/article/view/184404\nhttp://psycnet.apa.org/doi/10.1037/0003-066X.52.11.1182\nhttp://journals.sfu.ca/cjhe/index.php/cjhe/article/view/184404\nhttp://dx.doi.org/10.1080/0260293032000158180\nhttp://dx.doi.org/10.1007/s10734-014-9823-0\nhttp://dx.doi.org/10.20533/ijcdse.2042.6364.2014.0218\nhttp://dx.doi.org/10.4236/ojs.2015.56058\nhttp://eric.ed.gov.login.ezproxy.library.ualberta.ca/?id=EJ787711\npotential risks associated with the publication and summative usage of student \nevaluation of teaching (SET) results. ​Journal of Further and Higher Education, 38​(1), \n37-56.​ ​http://dx.doi.org/10.1080/0309877X.2012.699514 \nKeeley, J. W., English, T., Irons, J., & Henslee, A. M. (2013). Investigating halo and ceiling \neffects in student evaluations of instruction. ​Educational and Psychological \nMeasurement, 73​(3), 440-457.​ ​http://dx.doi.org/10.1177/0013164412475300 \nKhong, T. L. (2014). The validity and reliability of the student evaluation of teaching: A case in a \nprivate higher educational institution in Malaysia. ​International Journal for Innovation \nEducation and Research, 2​(9), 57-63.​ ​http://www.ijier.net/index.php/ijier/article/view/317 \nKim, L. E., MacCann, C. (2016). What is students’ ideal university instructor personality? An \ninvestigation of absolute and relative personality preferences. ​Personality and Individual \nDifferences, 102​, 190-203. ​http://dx.doi.org/10.1016/j.paid.2016.06.068 \nKuwaiti, A. A., AlQuraan, M., & Subbarayalu, A. V. (2016). Understanding the effect of response \nrate and class size interaction on students evaluation of teaching in a higher education. \nEducational Assessment & Evaluation, 3​, \nhttps://doi.org/10.1080/2331186X.2016.1204082 \nLama, T., Arias, P., Mendoza, K. & Manahan, J. (2015). Student evaluation of teaching surveys: \ndo students provide accurate and reliable information? ​e-Journal of Social & Behavioural \nResearch in Business, 6​(1), 30-39.​ ​http://www.ejsbrb.org/a.php?/content/issue/10 \nLaube, H., Massoni, K., Sprague, J., & Ferber, A. L. (2007). The impact of gender on the \nevaluation of teaching: What we know and what we can do. ​NWSA Journal,​ ​19​(3), \n87-104. Retrieved from ​http://www.jstor.org/stable/40071230  \nLyde, A.R., Grieshaber, D.C., Byrns, G. (2016). Faculty teaching performance: Perceptions of a \nmulti-source method for evaluation (MME). ​Journal of the Scholarship of Teaching and \nLearning, 16​(3), 82-94.​ ​http://dx.doi.org/10.14434/josotl.v16i3.18145 \nMacfadyen, L. P., Dawson, S., Prest, S., & Gasevic, D. (2016). Whose feedback? A multilevel \nanalysis of student completion of end-of-term teaching evaluations. ​Assessment & \nEvaluation in Higher Education, 41​(6), 821-839. \nhttp://dx.doi.org/10.1080/02602938.2015.1044421 \nMacNell, L., Driscoll, A., & Hunt, A. N. (2015). What’s in a name: Exposing gender bias in \nstudent ratings of teaching. ​Innovative Higher Education, 40​, 291-303. \nhttp://dx.doi.org/10.1007/s10755-014-9313-4  \nMakondo, L., & Ndebele, C. (2014). University lecturers’ views on student-lecturer evaluations. \nAnthropologist, 17​(2), 377-386. \nhttp://www.krepublishers.com/02-Journals/T-Anth/Anth-17-0-000-14-Web/Anth-17-0-000\n-14-Contents/Anth-17-0-000-14-Contents.htm \nMarsh, H. W., & Roche, L. A. (1997). Making students’ evaluations of teaching effectiveness \neffective: The critical issues of validity, bias, and utility. ​American Psychologist, 52​(11), \n1187-1197. ​http://dx.doi.org/10.1037/0003-066X.52.11.1187 \nMartin, L. R., Dennehy, R., & Morgan, S. (2013). Unreliability in student evaluation of teaching \nquestionnaires: Focus groups as an alternative approach. ​Organization Management \nJournal, 10​(1), 66-74.​ ​http://dx.doi.org/10.1080/15416518.2013.781401 \nhttp://www.ijier.net/index.php/ijier/article/view/317\nhttp://www.jstor.org/stable/40071230\nhttp://dx.doi.org/10.1016/j.paid.2016.06.068\nhttps://doi.org/10.1080/2331186X.2016.1204082\nhttp://dx.doi.org/10.14434/josotl.v16i3.18145\nhttp://www.ejsbrb.org/a.php?/content/issue/10\nhttp://dx.doi.org/10.1177/0013164412475300\nhttp://dx.doi.org/10.1007/s10755-014-9313-4\nhttp://www.krepublishers.com/02-Journals/T-Anth/Anth-17-0-000-14-Web/Anth-17-0-000-14-Contents/Anth-17-0-000-14-Contents.htm\nhttp://dx.doi.org/10.1037/0003-066X.52.11.1187\nhttp://dx.doi.org/10.1080/0309877X.2012.699514\nhttp://dx.doi.org/10.1177/0013164412475300\nhttp://dx.doi.org/10.14434/josotl.v16i3.18145\nhttp://dx.doi.org/10.1080/15416518.2013.781401\nhttp://www.krepublishers.com/02-Journals/T-Anth/Anth-17-0-000-14-Web/Anth-17-0-000-14-Contents/Anth-17-0-000-14-Contents.htm\nhttp://www.krepublishers.com/02-Journals/T-Anth/Anth-17-0-000-14-Web/Anth-17-0-000-14-Contents/Anth-17-0-000-14-Contents.htm\nhttp://www.ijier.net/index.php/ijier/article/view/317\nhttp://dx.doi.org/10.1080/15416518.2013.781401\nhttp://www.ejsbrb.org/a.php?/content/issue/10\nhttp://dx.doi.org/10.1080/02602938.2015.1044421\nhttp://dx.doi.org/10.1080/0309877X.2012.699514\nhttp://dx.doi.org/10.1080/02602938.2015.1044421\nMaurer, T. W. (2006). Cognitive dissonance or revenge? Student grades and course \nevaluations. ​Teaching of Psychology, 33​(3), 176-179. \nhttp://dx.doi.org/10.1207/s15328023top3303_4 \nMcKeachie, W. J. (1997). Student ratings: The validity of use. ​American Psychologist, 52​(11), \n1218-1225. ​http://dx.doi.org/10.1037/0003-066X.52.11.1218 \nMerritt, D. J. (2012). Bias, the brain, and student evaluations of teaching. ​St. John’s Law \nReview, 82​(1), Article 6, 235-288. \nhttp://scholarship.law.stjohns.edu/lawreview/vol82/iss1/6 \nMiles, P., & House, D. (2015). The tail wagging the dog: An overdue examination of student \nteaching evaluations. ​International Journal of Higher Education, 4​(2). \nhttp://dx.doi.org/10.5430/ijhe.v4n2p116  \nMitry, D. J., & Smith, D. E. (2014). Student evaluations of faculty members: A call for analytical \nprudence. ​Journal on Excellence in College Teaching, 25​(2), 56-67. \nhttp://celt.miamioh.edu/ject/issue.php?v=25&n=2 \nMorley, D. D. (2012). Claims about the reliability of student evaluations of instruction: The \necological fallacy rides again. ​Studies in Educational Evaluation, 38​(1), 15-20. \nhttp://dx.doi.org/10.1016/j.stueduc.2012.01.001 \nNargundkar, S., & Shrikhande, M. (2012). An empirical investigation of student evaluations of \ninstruction: The relative importance of factors. ​Decision Sciences Journal of Innovative \nEducation, 10​(1), 117-135.​ ​http://dx.doi.org/10.1111/j.1540-4609.2011.00328.x \nNargundkar, S., & Shrikhande, M. (2014). Norming of student evaluations of instruction: Impact \nof noninstructional factors. ​Decision Sciences Journal of Innovative Education, 12​(1), \n55-72. ​http://dx.doi.org/10.1111/dsji.12023 \nO​tani, K., Kim, J., & Cho, J. (2012). Student evaluation of teaching (SET) in higher education: \nHow to use SET more effectively and efficiently in public affairs education. ​Journal of \nPublic Affairs Education, 18​(3), 531-544. \nhttp://www.naspaa.org/JPAEMessenger/index_2012summer.asp \nPalmer, S. (2012). Student evaluation of teaching: keeping in touch with reality. ​Quality in \nHigher Education, 18​(3), 297-311.​ ​http://dx.doi.org/10.1080/13538322.2012.730336 \nPepe, J.W., & Wang, M.C. (2012). What instructor qualities do students reward? ​College \nStudent Journal, 46​(3), 603-614. ​http://www.projectinnovation.biz/csj_2006.html \nPounder, J. S. (2007). Is student evaluation of teaching worthwhile? An analytical framework for \nanswering the question. ​Quality Assurance in Education, 15​(2), 178-191. \nhttp://dx.doi.org/10.1108/09684880710748938 \nRantanen, P. (2013). The number of feedbacks needed for reliable evaluation. A multilevel \nanalysis of the reliability, stability and generalizability of students’ evaluation of teaching. \nAssessment & Evaluation in Higher Education, 38​(2), 224-239. \nhttp://dx.doi.org/10.1080/02602938.2011.625471 \nReardon, R. C., Leierer, S. J., & Lee, D. (2014). Class meeting schedules in relation to students’ \ngrades and evaluations of teaching. ​The Professional Counselor, 2​(1), 81-89. \nhttp://dx.doi.org/10.15241/rcr.2.1.81 \nReisenwitz, T.H. (2015). Student evaluation of teaching: An investigation of nonresponse bias in \nan online context. ​Journal of Marketing Education, 38​(1), 7-17. \nhttp://celt.miamioh.edu/ject/issue.php?v=25&n=2\nhttp://dx.doi.org/10.1108/09684880710748938\nhttp://dx.doi.org/10.1080/13538322.2012.730336\nhttp://dx.doi.org/10.1111/j.1540-4609.2011.00328.x\nhttp://www.projectinnovation.biz/csj_2006.html\nhttp://www.naspaa.org/JPAEMessenger/index_2012summer.asp\nhttp://scholarship.law.stjohns.edu/lawreview/vol82/iss1/6\nhttp://celt.miamioh.edu/ject/issue.php?v=25&n=2\nhttp://dx.doi.org/10.1111/j.1540-4609.2011.00328.x\nhttp://dx.doi.org/10.5430/ijhe.v4n2p116\nhttp://dx.doi.org/10.1080/02602938.2011.625471\nhttps://doi.org/10.1177/0273475315596778\nhttp://dx.doi.org/10.1016/j.stueduc.2012.01.001\nhttp://dx.doi.org/10.1207/s15328023top3303_4\nhttp://dx.doi.org/10.1108/09684880710748938\nhttp://dx.doi.org/10.1080/13538322.2012.730336\nhttp://dx.doi.org/10.1037/0003-066X.52.11.1218\nhttp://dx.doi.org/10.15241/rcr.2.1.81\nhttp://dx.doi.org/10.1080/02602938.2011.625471\nhttp://dx.doi.org/10.1111/dsji.12023\nhttp://dx.doi.org/10.1016/j.stueduc.2012.01.001\nhttp://scholarship.law.stjohns.edu/lawreview/vol82/iss1/6\nhttp://www.naspaa.org/JPAEMessenger/index_2012summer.asp\nhttps://doi.org/10.1177/0273475315596778 \nRidley, D., & Collins, J. (2015). A suggested evaluation metric instrument for faculty members at \ncolleges and universities. ​International Journal of Education Research, 10​(1), 97-114. \nRetrieved from \nhttp://eds.a.ebscohost.com.login.ezproxy.library.ualberta.ca/eds/pdfviewer/pdfviewer?sid\n=9ff24389-d34d-43d1-83fc-6ef82bd1ad47%40sessionmgr4009&vid=2&hid=4102 \nRoyal, K. D., & Stockdale, M. R. (2015). Are teacher course evaluations biased against faculty \nthat teach quantitative methods courses? ​International Journal of Higher Education, 4​(1), \n217-224. ​http://dx.doi.org/10.5430/ijhe.v4n1p217 \nSmith, S. W., Yoo, J. H., Farr, A. C., Salmon, C. T., & Miller, V. D. (2007). The influence of \nstudent sex and instructor sex on student ratings of instructors: Results from a college of \ncommunication. ​Women's Studies in Communication, 30​(1), 64-77. \nhttp://dx.doi.org/10.1080/07491409.2007.10162505  \nSocha, A. (2013). A hierarchical approach to students’ assessment of instruction. ​Assessment & \nEvaluation in Higher Education, 38​(1), 94-113. \nhttp://dx.doi.org/10.1080/02602938.2011.604713 \nSpooren, P., Brockx, B., & Mortelmans, D. (2013). On the validity of student evaluation of \nteaching: The state of the art. ​Review of Educational Research, 83​(4), 598-642. \nhttp://dx.doi.org/10.3102/0034654313496870 \nStein, S. J., Spiller, D., Terry, S., Harris, T., Deaker, L., & Kennedy, J. (2013). Tertiary teachers \nand student evaluations: never the twain shall meet? ​Assessment & Evaluation in Higher \nEducation, 38​(7), 892-904.​ ​http://dx.doi.org/10.1080/02602938.2013.767876 \nStonebraker, R. J., & Stone, G. S. (2015). Too old to teach? The effect of age on college and \nuniversity professors. ​Research in Higher Education, 56​(8), 793-812. \nhttp://dx.doi.org/​10.1007/s11162-015-9374-y \nStupans, I., McGuren, T., & Babey, A. M. (2016). Student evaluation of teaching: A study \nexploring student rating instrument free-form text comments. ​Innovative Higher \nEducation, 41​(1), 33-52. ​http://10.1007/s10755-015-9328-5 \nUijtdehaage, S., & O’Neal, C. (2015). A curious case of the phantom professor: mindless \nteaching evaluations by medical students. ​Medical Education, 49​(9), 928-932. \nhttp://dx.doi.org/10.1111/medu.12805 \nUttl, B., White, C. A., Gonzalez, D. W. (2016). Meta-analysis of faculty’s teaching effectiveness: \nStudent evaluation of teaching ratings and student learning are not related. ​Studies in \nEducational Evaluation,​ (in press, available online September 19, 2106). \nhttp://dx.doi.org/10.1016/j.stueduc.2016.08.007 \nWilson, J. H., Beyer, D., & Monteiro, H. (2014). Professor age affects student ratings: Halo \neffect for younger teachers. ​College Teaching, 62​, 20-24. \nhttp://dx.doi.org/10.1080/87567555.2013.825574  \nWright, S. L., & Jenkins-Guarieri, M. A. (2012). Student evaluations of teaching: combining the \nmeta-analyses and demonstrating further evidence for effective use. ​Assessment & \nEvaluation in Higher Education, 37​(6), 683-699. \nhttp://dx.doi.org/10.1080/02602938.2011.563279 \nZimmerman, B. (2008). Course evaluations - students’ revenge? ​University Affairs.​ Retrieved \nhttp://dx.doi.org/10.5430/ijhe.v4n1p217\nhttp://dx.doi.org/10.1080/02602938.2013.767876\nhttp://dx.doi.org/10.1111/medu.12805\nhttp://dx.doi.org/10.1080/02602938.2011.604713\nhttp://eds.a.ebscohost.com.login.ezproxy.library.ualberta.ca/eds/pdfviewer/pdfviewer?sid=9ff24389-d34d-43d1-83fc-6ef82bd1ad47%40sessionmgr4009&vid=2&hid=4102\nhttp://dx.doi.org/10.1016/j.stueduc.2016.08.007\nhttp://dx.doi.org/10.1007/s11162-015-9374-y\nhttp://dx.doi.org/10.1080/02602938.2011.563279\nhttp://dx.doi.org/10.3102/0034654313496870\nhttp://dx.doi.org/10.3102/0034654313496870\nhttp://dx.doi.org/10.1080/02602938.2011.604713\nhttp://dx.doi.org/10.1080/02602938.2011.563279\nhttp://dx.doi.org/10.1080/87567555.2013.825574\nhttps://doi.org/10.1177/0273475315596778\nhttp://eds.a.ebscohost.com.login.ezproxy.library.ualberta.ca/eds/pdfviewer/pdfviewer?sid=9ff24389-d34d-43d1-83fc-6ef82bd1ad47%40sessionmgr4009&vid=2&hid=4102\nhttp://dx.doi.org/10.1080/07491409.2007.10162505\nhttp://dx.doi.org/10.1080/02602938.2013.767876\nhttp://dx.doi.org/10.1007/s11162-015-9374-y\nhttp://dx.doi.org/10.1111/medu.12805\nfrom \nhttp://www.universityaffairs.ca/opinion/in-my-opinion/course-evaluations-students-reveng\ne/ \nZumbach, J., & Funke, J. (2014). Influences of mood on academic course evaluations. ​Practical \nAssessment, Research & Evaluation, 19​(4). \nhttp://pareonline.net/genpare.asp?wh=0&abt=19 \nhttp://www.universityaffairs.ca/opinion/in-my-opinion/course-evaluations-students-revenge/\nhttp://pareonline.net/genpare.asp?wh=0&abt=19\nhttp://dx.doi.org/10.1080/02602938.2011.563279\nhttp://pareonline.net/genpare.asp?wh=0&abt=19\nhttp://www.universityaffairs.ca/opinion/in-my-opinion/course-evaluations-students-revenge/\nAppendix H: Abstracts for Reviewed Literature \nClick on the links to move directly to each bookmarked section. For brief summarizing points of \neach article, see Appendix A \nBiases \n● Gender \n● Instructor characteristics \n● Correlation between grades and ratings \n● Nonresponse \n● Non-instructional \n● Other \nValidity \nImpact on Teaching Quality \nEvaluating Faculty for Tenure and Promotion \nMultifaceted Evaluation \n Biases, Gender \nBoring, Ottoboni, & Stark​ (2016): ratings are biased against female instructors by an \namount that is large and statistically significant \nBoring, A., Ottoboni, K., & Stark, P. B. (2016). Student evaluations of teaching (mostly) do not \nmeasure teaching effectiveness. ​ScienceOpen Research, 2016​(1). \nhttp://dx.doi.org/10.14293/S2199-1006.1.SOR-EDU.AETBZC.v1  \n[Abstract, abridged] We show: SET are biased against female instructors by an amount that is \nlarge and statistically significant; The bias affects how students rate even putatively objective \naspects of teaching, such as how promptly assignments are graded; The bias varies by \ndiscipline and by student gender, among other things; It is not possible to adjust for the bias, \nbecause it depends on so many factors; SET are more sensitive to students’ gender bias and \ngrade expectations than they are to teaching effectiveness; Gender biases can be large \nenough to cause more effective instructors to get lower SET than less effective instructors. \nCentra & Gaubatz​ (2000): only small same-gender preferences found, particularly with \nfemales \nCentra, J. A., Gaubatz, N. B. (2000). Is there gender bias in student evaluations of teaching? \nThe Journal of Higher Education, 71​(1), 17-44. \nhttp://login.ezproxy.library.ualberta.ca/login?url=http://search.ebscohost.com/login.aspx?direct\n=true&db=edsjsr&AN=edsjsr.10.2307.2649280&site=eds-live&scope=site \n[Abstract] In an attempt to determine whether male and female students rate teachers \nhttp://login.ezproxy.library.ualberta.ca/login?url=http://search.ebscohost.com/login.aspx?direct=true&db=edsjsr&AN=edsjsr.10.2307.2649280&site=eds-live&scope=site\nhttp://login.ezproxy.library.ualberta.ca/login?url=http://search.ebscohost.com/login.aspx?direct=true&db=edsjsr&AN=edsjsr.10.2307.2649280&site=eds-live&scope=site\nhttp://login.ezproxy.library.ualberta.ca/login?url=http://search.ebscohost.com/login.aspx?direct=true&db=edsjsr&AN=edsjsr.10.2307.2649280&site=eds-live&scope=site\nhttp://dx.doi.org/10.14293/S2199-1006.1.SOR-EDU.AETBZC.v1\ndifferently depending on the gender of the teacher, we analyzed data from 741 classes in \nwhich there were at least 10 male and 10 female students. The results revealed small same \ngender preferences, particularly in female students rating female teachers. Teaching style \nrather than gender may well explain these preferences. \nGehrt, Louie, & Osland​ (2015): female students evaluated female lower-ranked faculty most \nfavorably; male students evaluations were more favorable for lower ranked male faculty, but \nthey did not degrade higher ranked female faculty \nGehrt, K., Louie, T. A., & Osland, A. (2015). Student and professor similarity: Exploring the \neffects of gender and relative age. ​Journal of Education for Business, 90​, 1-9. \nhttp://dx.doi.org/10.1080/08832323.2014.968514  \n[Abstract, abridged] It was hypothesized that students would more favorably evaluate faculty \nwho were similar in gender and in relative age (as reflected in faculty rank). As anticipated, \nfemale students evaluated female lower ranked faculty most favorably, and male higher \nranked faculty least favorably. However, male students showed mixed effects. Although their \nevaluations were more favorable for lower ranked male faculty, they unexpectedly did not \ndegrade higher ranked female faculty. \nHuebner & Magel​ (2015): variances of the class average responses between male and \nfemale faculty were higher for male faculty \nHuebner, L., & Magel, R. C. (2015). A gendered study of student ratings of instruction. ​Open \nJournal of Statistics, 5,​ 552-567. ​http://dx.doi.org/10.4236/ojs.2015.56058  \n[Abstract, abridged] This research tests for differences in mean class averages between male \nand female faculty for questions on a student rating of instruction form at one university in the \nMidwest. Differences in variances of class averages are also examined for male and female \nfaculty. Tests are conducted by first considering all classes across the entire university and \nthen classes just within the College of Science and Mathematics. The proportion of classes \ntaught by female instructors in which the average male student rating was higher than the \naverage female student rating was compared to the proportion of classes taught by male \ninstructors in which the average male student rating was higher than the average female \nstudent rating. \nLaube, Massoni, Sprague, & Ferber​ (2007): the inconsistency on the question of whether \nstudent evaluations are gendered is itself an artifact of the way that quantitative measures can \nmask underlying gender bias \nLaube, H., Massoni, K., Sprague, J., & Ferber, A. L. (2007). The impact of gender on the \nevaluation of teaching: What we know and what we can do. ​NWSA Journal,​ ​19​(3), 87-104. \nRetrieved from ​http://www.jstor.org/stable/40071230  \nhttp://www.jstor.org/stable/40071230\nhttp://dx.doi.org/10.1080/08832323.2014.968514\nhttp://dx.doi.org/10.4236/ojs.2015.56058\n[Abstract, abridged] Scholars who have attempted to determine whether/how gender enters \ninto students' evaluations of their teachers generally fall into two camps: those who find \ngender to have no (or very little) influence on evaluations, and those who find gender to affect \nevaluations significantly. Drawing on insights developed from sociological scholarship on \ngender and evaluation, we argue that the apparent inconsistency on the question of whether \nstudent evaluations are gendered is itself an artifact of the way that quantitative measures can \nmask underlying gender bias. \nMacNell, Driscoll, & Hunt​ (2015): students rate males significantly higher than females \nMacNell, L., Driscoll, A., & Hunt, A. N. (2015). What’s in a name: Exposing gender bias in \nstudent ratings of teaching. ​Innovative Higher Education, 40​, 291-303. \nhttp://dx.doi.org/10.1007/s10755-014-9313-4  \n[Abstract, abridged] Although instructor gender has been shown to play an important role in \ninfluencing student ratings, the extent and nature of that role remains contested. While difficult \nto separate gender from teaching practices in person, it is possible to disguise an instructor’s \ngender identity online. In our experiment, assistant instructors in an online class each \noperated under two different gender identities. Students rated the male identity significantly \nhigher than the female identity, regardless of the instructor’s actual gender, demonstrating \ngender bias. \nMiles & House​ (2015): lower ratings for female instructors teaching larger required classes \nMiles, P., & House, D. (2015). The tail wagging the dog: An overdue examination of student \nteaching evaluations. ​International Journal of Higher Education, 4​(2). \nhttp://dx.doi.org/10.5430/ijhe.v4n2p116  \n[Abstract, abridged] Purpose: The purpose of this research is to examine the impact of \nseveral factors beyond the professor's control and their unique impact on Student Teaching \nEvaluations (STEs). The present research pulls together a substantial amount of data to \nstatistically analyze several academic historical legends about just how vulnerable STEs are \nto the effects of: class size, course type, professor gender, and course grades. \nDesign/methodology/approach: This research is utilizes over 30,000 individual student \nevaluations of 255 professors, spanning six semesters, during a three year time period to test \nsix hypotheses. The final sample represents 1057 classes ranging in size between 10 and \n190 students. Each hypothesis is statistically analyzed, with either analysis of variance or a \nRegression model. Findings: This study finds support for 5 out of 6 hypotheses. Specifically, \nthese data suggest STEs are likely to be closest to \"5\" (using a 1-5 scale with 5 being highest) \nin small elective classes, and lowest in large required classes taught by females. As well we \nfind support for the notion that higher expected course grades may lead to higher STEs.  \nhttp://dx.doi.org/10.5430/ijhe.v4n2p116\nhttp://dx.doi.org/10.1007/s10755-014-9313-4\nSmith, Yoo, Farr, Salmon, & Miller​ ​(2007): male and female students rated female \ninstructors more highly; effect was small but significant due to sample size \nSmith, S. W., Yoo, J. H., Farr, A. C., Salmon, C. T., & Miller, V. D. (2007). The influence of \nstudent sex and instructor sex on student ratings of instructors: Results from a college of \ncommunication. ​Women's Studies in Communication, 30​(1), 64-77. \nhttp://dx.doi.org/10.1080/07491409.2007.10162505  \n[Abstract, abridged] ​We posed research questions as to whether male and female students \nwould rate male or female instructors more highly on five dimensions of student rating forms, \none of which was instructor interaction. Results indicated that male and female students rated \nfemale instructors more highly on all five dimensions. The effect sizes of these results were \nextremely small, but significant due to the large sample size (almost 12,000). These findings \nsuggest that administrators should not assume one sex to provide better or poorer instruction, \nand they should reward instructors on the basis of individual course performance rather than \naccording to instructor sex. \nWilson, Beyer, & Monteiro​ (2014): lower ratings for older instructors, but more so for \nfemales than males \nWilson, J. H., Beyer, D., & Monteiro, H. (2014). Professor age affects student ratings: Halo \neffect for younger teachers. ​College Teaching, 62​, 20-24. \nhttp://dx.doi.org/10.1080/87567555.2013.825574  \n[Abstract, abridged] In the present study, we examined the potential effects of professor age \nand gender on student perceptions of the teacher as well as their anticipated rapport in the \nclassroom. We also asked students to rate each instructor’s attractiveness based on societal \nbeliefs about age and beauty. We expected students to rate a picture of a middle-aged female \nprofessor more negatively (and less attractive) than the younger version of the same woman. \nFor the young versus old man offered in a photograph, we expected no age effects. Although \nage served as a detriment for both genders, evaluations suffered more based on aging for \nfemale than male professors. \nWright & Jenkins-Guarieri​ (2012): SETs appear to be valid and free from gender bias \nWright, S. L., & Jenkins-Guarieri, M. A. (2012). Student evaluations of teaching: combining \nthe meta-analyses and demonstrating further evidence for effective use. ​Assessment & \nEvaluation in Higher Education, 37​(6), 683-699. \nhttp://dx.doi.org/10.1080/02602938.2011.563279 \n[Abstract, abridged] Given that there is not one study summarising all these domains of \nresearch, a comprehensive overview of SETs was conducted by combining all prior \nmeta-analyses related to SETs. Eleven meta-analyses were identified, and nine \nmeta-analyses covering 193 studies were included in the analysis, which yielded a \nhttp://dx.doi.org/10.1080/02602938.2011.563279\nhttp://dx.doi.org/10.1080/87567555.2013.825574\nhttp://dx.doi.org/10.1080/02602938.2011.563279\nhttp://dx.doi.org/10.1080/07491409.2007.10162505\nsmall-to-medium overall weighted mean effect size (r = .26) between SETs and the variables \nstudied. Findings suggest that SETs appear to be valid, have practical use that is largely free \nfrom gender bias and are most effective when implemented with consultation strategies. \n Biases, Instructor Characteristics \nCheng​ (2015): ​tenure does not have a significant impact on student ratings of teaching \nperformance \nCheng, D. A. (2015). Effects of professorial tenure on undergraduate ratings of teaching \nperformance. ​Education Economics, 23​(3), 338-357. \nhttp://dx.doi.org/10.1080/09645292.2013.826632 \n[Abstract, abridged] This study estimates the effect of professorial tenure on undergraduate \nratings of learning, instructor quality, and course quality at the University of California, San \nDiego from Summer 2004 to Spring 2012. During this eight-year period, 120 assistant \nprofessors received tenure and 83 associate professors attained full rank. A \ndifferences-in-differences model controlling for teaching experience, study hours, response \nrate, and unobserved heterogeneity among terms, courses, and professors suggests that for \na given professor, tenure does not have a significant impact on student ratings of teaching \nperformance, at least in the immediate years after advancement. The results are similar for \nthe promotion from associate to full professor. \nCho & Otani​ (2014): students give higher ratings for limited-term lecturers versus full-time \nfaculty \nCho, J., & Otani, K. (2014). Differences in student evaluations of limited-term lecturers and \nfull-time faculty. ​Journal on Excellence in College Teaching, 25​(2), 5-24. \nhttp://opus.ipfw.edu/profstudies_facpubs/64 \n[Abstract, abridged] This study compared student evaluations of teaching (SET) for \nlimited-term lecturers (LTLs) and full-time faculty (FTF) using a Likert-scaled survey \nadministered to students (N = 1,410) at the end of university courses. Data were analyzed \nusing a general linear regression model to investigate the influence of multi-dimensional \nevaluation items on the overall rating item (Overall, I would rate the instructor of this course as \noutstanding) on the SET. Results showed that students provided higher ratings for LTLs than \nFTF, but they value different items when rating the overall evaluation of LTLs and FTF. Some \nsurvey items (for instance, those about instructor planning and enthusiasm) influence more on \nthe rating of the overall item for LTLs than for FTF, whereas other, multi-dimensional items \n(for instance, those about assessment strategies and instructor's availability) influence more \non the overall rating for FTF than for LTLs. \nClayson​ (2013): students’ first perceptions of an instructor’s personality are significantly \nrelated to ratings at the end of the semester \nhttp://opus.ipfw.edu/profstudies_facpubs/64\nhttp://dx.doi.org/10.1080/09645292.2013.826632\nClayson, D. E. (2013). Initial impressions and the student evaluation of teaching. ​Journal of \nEducation for Business, 88​(1), 26-53. ​http://dx.doi.org/10.1080/08832323.2011.633580 \n[Abstract, abridged] The author looked at the initial student perceptions and conditions of a \nclass and compared these with conditions and evaluations 16 weeks later at the end of the \nterm. It was found that the first perceptions of the instructor and the instructor’s personality \nwere significantly related to the evaluations made at the end of the semester. \nFelton, Mitchell, & Stinson​ (2004): students give attractively-rated professors higher quality \nand easiness scores \nFelton, J., Mitchell, J., & Stinson, M. (2004). Web-based student evaluations of professors: \nthe relations between perceived quality, easiness and sexiness. ​Assessment & Evaluation in \nHigher Education, 29​(1), 91-108.​ ​http://dx.doi.org/10.1080/0260293032000158180 \n[Abstract, abridged] College students critique their professors’ teaching at \nRateMyProfessors.com, a web page where students anonymously rate their professors on \nQuality, Easiness, and Sexiness. Using the self-selected data from this public forum, we \nexamine the relations between quality, easiness, and sexiness for 3190 professors at 25 \nuniversities. For faculty with at least ten student posts, the correlation between quality and \neasiness is 0.61, and the correlation between quality and sexiness is 0.30. Using simple linear \nregression, we find that about half of the variation in quality is a function of easiness and \nsexiness. When grouped into sexy and non-sexy professors, the data reveal that students \ngive sexy-rated professors higher quality and easiness scores.  \nKim & MacCann​ (2016): students’ expressed educational satisfaction was related to \nperceptions of instructor personality \nKim, L. E., MacCann, C. (2016). What is students’ ideal university instructor personality? An \ninvestigation of absolute and relative personality preferences. ​Personality and Individual \nDifferences, 102​, 190-203. ​http://dx.doi.org/10.1016/j.paid.2016.06.068 \n[Abstract, abridged] The current two studies investigate students' descriptions of “ideal” \ninstructor personality using the Five-Factor Model of personality. Both absolute personality \npreferences (certain traits are universally desired) and relative personality preferences \n(certain traits are desired relative to students' own level of the trait) are examined among 137 \nfirst year mathematics students (Study 1) and 378 first year psychology students (Study 2). \nStudents provided Big Five personality ratings for themselves, their actual instructor, and their \nideal instructor. Supporting the absolute preference hypothesis, students rated their ideal \ninstructor as having significantly higher levels than both themselves and the general \npopulation on all five personality domains (except for openness in Study 1), with particularly \nlarge effect sizes for emotional stability and conscientiousness. Supporting the relative \npreference hypothesis, students also rated their ideal instructor as having a similar Big Five \nprofile to themselves. Moreover, if their actual instructor's personality was similar to their ideal \ninstructor's personality, students showed greater educational satisfaction (but not higher \nperformance self-efficacy nor academic achievement). \nhttp://dx.doi.org/10.1080/0260293032000158180\nhttp://dx.doi.org/10.1080/08832323.2011.633580\nhttp://dx.doi.org/10.1080/0260293032000158180\nhttp://dx.doi.org/10.1016/j.paid.2016.06.068\nStonebraker & Stone​ (2015): age has a negative impact on student ratings of faculty \nmembers; begins around mid-forties; offset by attractiveness \nStonebraker, R. J., & Stone, G. S. (2015). Too old to teach? The effect of age on college and \nuniversity professors. ​Research in Higher Education, 56​(8), 793-812. \nhttp://dx.doi.org/​10.1007/s11162-015-9374-y \n[Abstract, abridged] Using data from the RateMyProfessors.com website for a large sample of \ninstructors in a broad cross-section of colleges and universities, we find that age does affect \nteaching effectiveness, at least as perceived by students. Age has a negative impact on \nstudent ratings of faculty members that is robust across genders, groups of academic \ndisciplines and types of institutions. However, the effect does not begin until faculty members \nreach their mid-forties and does not seem to increase even when they reach the former \nretirement ages of 65 or 70. Moreover, the quantitative impact of age on student ratings is \nsmall and can be offset by other factors, especially the physical appearance of professors and \nhow easy students consider them to be. When we restrict our sample to those professors \ndeemed hot by student raters, the effect of age disappears completely. \nWilson, Beyer, & Monteiro​ (2014): lower ratings for older instructors, but more so for \nfemales than males \nWilson, J. H., Beyer, D., & Monteiro, H. (2014). Professor age affects student ratings: Halo \neffect for younger teachers. ​College Teaching, 62​, 20-24. \nhttp://dx.doi.org/10.1080/87567555.2013.825574  \n[Abstract, abridged] In the present study, we examined the potential effects of professor age \nand gender on student perceptions of the teacher as well as their anticipated rapport in the \nclassroom. We also asked students to rate each instructor’s attractiveness based on societal \nbeliefs about age and beauty. We expected students to rate a picture of a middle-aged female \nprofessor more negatively (and less attractive) than the younger version of the same woman. \nFor the young versus old man offered in a photograph, we expected no age effects. Although \nage served as a detriment for both genders, evaluations suffered more based on aging for \nfemale than male professors. \n Biases, Correlation Between Grades and Ratings \nBacker​ (2012): some students punish academics for failing grades with low ratings \nBacker, E. (2012). Burnt at the student evaluation stake – the penalty for failing students. \nE-Journal of Business Education & Scholarship of Teaching, 6​(1), 1-13. Retrieved from \nhttp://www.ejbest.org/upload/eJBEST_Backer_2012_1.pdf \n[Abstract, abridged] Despite the wealth of research in the area of SETs, little has been done \nhttp://www.ejbest.org/upload/eJBEST_Backer_2012_1.pdf\nhttp://dx.doi.org/10.1080/87567555.2013.825574\nhttp://dx.doi.org/10.1007/s11162-015-9374-y\nhttp://dx.doi.org/10.1007/s11162-015-9374-y\nto examine student and academic perceptions of SETs. This research examined student \n(n=235) and academic (n=49) perceptions concerning SETs at one Australian regional \nuniversity. Almost one-third of respondents felt that some students punish academics for \nfailing their work by giving the lecturer low scores on the SET form. Thus, academics can \nessentially be burnt at the student evaluation stake as punishment for failing students. \nBlackhart, Peruche, DeWall, & Joiner​ (2006): higher ratings given to instructors who give \nhigher grades, and also to graduate teaching assistant rank \nBlackhart, G. C., Peruche, B .M., DeWall, C. N., & Joiner, T. E., Jr. (2006). Faculty forum: \nFactors influencing teaching evaluations in higher education. ​Teaching of Psychology, 33​(1), \n37-39. ​http://dx.doi.org/10.1207/s15328023top3301_9 \n[Abstract, abridged] Past research indicates several factors influencing teaching evaluation \nratings instructors receive. We analyzed teaching evaluations from psychology courses during \nfall and spring semesters of 2003– 2004 to determine if class size, class level, instructor \ngender, number of publications (faculty instructors), average grade given by the instructor, \nand instructor rank predicted teaching evaluation ratings. Entering predictor variables into a \nmultiple regression analysis concurrently, results indicated that only average grade given and \ninstructor rank significantly predicted instructor ratings. Specifically, higher average grades \ngiven by the instructor predicted higher ratings, and graduate teaching assistants received \nhigher overall ratings than faculty instructors. \nBoring, Ottoboni, & Stark​ (2016): ratings​ are more sensitive to students’ grade expectations \nthan they are to teaching effectiveness \nBoring, A., Ottoboni, K., & Stark, P. B. (2016). Student evaluations of teaching (mostly) do not \nmeasure teaching effectiveness. ​ScienceOpen Research, 2016​(1). \nhttp://dx.doi.org/10.14293/S2199-1006.1.SOR-EDU.AETBZC.v1 \n[Abstract, abridged] ​We show: SET are biased against female instructors by an amount that is \nlarge and statistically significant; The bias affects how students rate even putatively objective \naspects of teaching, such as how promptly assignments are graded; The bias varies by \ndiscipline and by student gender, among other things; It is not possible to adjust for the bias, \nbecause it depends on so many factors; SET are more sensitive to students’ gender bias and \ngrade expectations than they are to teaching effectiveness; Gender biases can be large \nenough to cause more effective instructors to get lower SET than less effective instructors. \nCentra​ (2003): expected grades generally do not affect student evaluations \nCentra, J.A. (2003). Will teachers receive higher student evaluations by giving higher grades \nand less course work? ​Research in Higher Education, 44​(5), 495-518. \nhttp://www.jstor.org.login.ezproxy.library.ualberta.ca/stable/40197319 \n[Abstract, abridged] This study investigated whether mean expected grades and the level of \ndifficult/workload in courses, as reported by students, unduly influence student ratings \nhttp://www.jstor.org.login.ezproxy.library.ualberta.ca/stable/40197319\nhttp://dx.doi.org/10.14293/S2199-1006.1.SOR-EDU.AETBZC.v1\nhttp://dx.doi.org/10.1207/s15328023top3301_9\ninstruction. Over 50,000 college courses were analyzed. After controlling for learning \noutcomes, expected grades generally did not affect student evaluations. In fact, contrary to \nwhat some faculty think, courses in natural sciences with expected grades of A were rated \nlower, not higher. Courses were rated lower when they were rated as either difficult or too \nelementary. Courses rated at the “just right” level received the highest evaluations. \nCho, Baek, & Cho​ (2015): students with better grades than their expected grades provide a \npsychological “gift” to their teachers by giving higher ratings \nCho, D., Baek, W., & Cho, J. (2015). Why do good performing students highly rate their \ninstructors? Evidence from a natural experiment. ​Economics of Education Review, 49​, \n172-179. ​http://dx.doi.org/10.1016/j.econedurev.2015.10.001 \n[Abstract, abridged] This article analyzes the behavior of students in a college classroom with \nregard to their evaluation of teacher performance. As some students are randomly able to see \ntheir grades prior to the evaluation, the “natural” experiment provides a unique opportunity for \ntesting the hypothesis as to whether there exists a possibility of a hedonic (implicit) exchange \nbetween the students’ grades and teaching evaluations. Students with good grades tend to \nhighly rate the teaching quality of their instructors, in comparison with those who receive \nrelatively poor grades. This study finds that students with better grades than their expected \ngrades provide a psychological “gift” to their teachers by giving a higher teacher evaluation, \nwhereas it is the opposite with those students receiving lower grades than their expectation. \nGreenwald & Gillmore​ (1997): the grades-ratings correlation is due to an unwanted influence \nof instructors' grading leniency; there are 5 theories of the grades-ratings correlation \nGreenwald, A. G., Gillmore, G. M. (1997). Grade leniency is a removable contaminant of \nstudent ratings. ​American Psychologist, 52​(11), 1209-1217. \nhttp://dx.doi.org/10.1037/0003-066X.52.11.1209 \n[Abstract] It is well established that students' evaluative ratings of instruction correlate \npositively with expected course grades. The authors identify 4 additional data patterns that, \ncollectively, discriminate among 5 theories of the grades-ratings correlation. The presence of \nall 4 of these markers in student ratings data (obtained at University of Washington) was most \nconsistent with the theory that the grades-ratings correlation is due to an unwanted influence \nof instructors' grading leniency on ratings. This conclusion justifies use of a statistical \ncorrection – illustrated here with actual ratings data – to remove the unwanted inflation of \nratings produced by lenient grading. Additional research can profitably seek other \ninappropriate influences on ratings to identify more opportunities for validity-enhancing \nadjustments. \nGump​ (2007): questions the validity of research done on the leniency hypothesis \nhttp://dx.doi.org/10.1016/j.econedurev.2015.10.001\nhttp://dx.doi.org/10.1037/0003-066X.52.11.1209\nGump, S.E. (2007). Student evaluations of teaching effectiveness and the leniency \nhypothesis: A literature review. ​Education Research Quarterly, 30​(3), 55-68. Retrieved from \nhttp://eric.ed.gov.login.ezproxy.library.ualberta.ca/?id=EJ787711 \n[Abstract, abridged] ​This review presents an overview of selected articles on the leniency \nhypothesis: the idea that students give higher evaluations to instructors who grade more \nleniently. In this diverse literature, research methods and aims have frequently affected the \noutcomes and conclusions, since SETs are typically context-specific instruments whose \nresults, in isolated instances, do not generalize well. Thus this review questions the very \ngeneralizability of the massive and often contradictory SET-related literature on the leniency \nhypothesis and argues that future research must be designed and carried out in light of the \nimplicit problems existing in the majority of earlier studies. \nMaurer​ (2006): cognitive dissonance may be a theory to explain the grades-ratings \ncorrelation \nMaurer, T. W. (2006). Cognitive dissonance or revenge? Student grades and course \nevaluations. ​Teaching of Psychology, 33​(3), 176-179. \nhttp://dx.doi.org/10.1207/s15328023top3303_4 \n[Abstract] I tested 2 competing theories to explain the connection between students’ expected \ngrades and ratings of instructors: cognitive dissonance and revenge. Cognitive dissonance \ntheory holds that students who expect poor grades rate instructors poorly to minimize ego \nthreat whereas the revenge theory holds that students rate instructors poorly in an attempt to \npunish them. I tested both theories via an experimental manipulation of the perceived ability to \npunish instructors through course evaluations. Results indicated that student ratings appear \nunrelated to the ability to punish instructors, thus supporting cognitive dissonance theory. \nAlternative interpretations of the data suggest further research is warranted. \nMiles & House​ (2015): higher expected grades may lead to higher ratings \nMiles, P., & House, D. (2015). The tail wagging the dog: An overdue examination of student \nteaching evaluations. ​International Journal of Higher Education, 4​(2). \nhttp://dx.doi.org/10.5430/ijhe.v4n2p116  \n[Abstract, abridged] Purpose: The purpose of this research is to examine the impact of \nseveral factors beyond the professor's control and their unique impact on Student Teaching \nEvaluations (STEs). The present research pulls together a substantial amount of data to \nstatistically analyze several academic historical legends about just how vulnerable STEs are \nto the effects of: class size, course type, professor gender, and course grades. \nDesign/methodology/approach: This research is utilizes over 30,000 individual student \nevaluations of 255 professors, spanning six semesters, during a three year time period to test \nsix hypotheses. The final sample represents 1057 classes ranging in size between 10 and \n190 students. Each hypothesis is statistically analyzed, with either analysis of variance or a \nRegression model. Findings: This study finds support for 5 out of 6 hypotheses. Specifically, \nhttp://eric.ed.gov.login.ezproxy.library.ualberta.ca/?id=EJ787711\nhttp://dx.doi.org/10.1207/s15328023top3303_4\nhttp://dx.doi.org/10.5430/ijhe.v4n2p116\nhttp://eric.ed.gov.login.ezproxy.library.ualberta.ca/?id=EJ787711\nthese data suggest STEs are likely to be closest to \"5\" (using a 1-5 scale with 5 being highest) \nin small elective classes, and lowest in large required classes taught by females. As well we \nfind support for the notion that higher expected course grades may lead to higher STEs. \n Biases, Nonresponse \nKuwaiti, AlQuraan, & Subbarayalu​ (2016): ratings are affected by class size and response \nrate \nKuwaiti, A. A., AlQuraan, M., & Subbarayalu, A. V. (2016). Understanding the effect of \nresponse rate and class size interaction on students evaluation of teaching in a higher \neducation. ​Educational Assessment & Evaluation, 3​, \nhttps://doi.org/10.1080/2331186X.2016.1204082 \n[Abstract, abridged] This study aims to investigate the interaction between response rate and \nclass size and its effects on students’ evaluation of instructors and the courses offered at a \nhigher education Institution in Saudi Arabia. It is observed that when the class size is at the \nmedium level, the ratings of instructors and courses increase as the response rate increases. \nOn the contrary; when the class size is small, a high response rate is required for the \nevaluation of instructors and at least medium response rate is required for evaluation of \ncourses. The study suggests that the interaction between response rate and class size is an \nimportant factor that needs to be taken into account while interpreting the students’ evaluation \nof instructors and courses. \nMacfadyen, Dawson, Prest, & Gasevic​ (2016): much bias based on who is completing the \nsurveys \nMacfadyen, L. P., Dawson, S., Prest, S., & Gasevic, D. (2016). Whose feedback? A multilevel \nanalysis of student completion of end-of-term teaching evaluations. ​Assessment & Evaluation \nin Higher Education, 41​(6), 821-839.​ ​http://dx.doi.org/10.1080/02602938.2015.1044421 \n[Abstract, abridged] While much research has examined the validity of SETs for measuring \nteaching quality, few studies have investigated the factors that influence student participation \nin the SET process. This study aimed to address this deficit through the analysis of an SET \nrespondent pool at a large Canadian research-intensive university. The findings were largely \nconsistent with available research (showing influence of student gender, age, specialisation \narea and final grade on SET completion). However, the study also identified additional \ninfluential course-specific factors such as term of study, course year level and course type as \nstatistically significant. Collectively, such findings point to substantively significant patterns of \nbias in the characteristics of the respondent pool. \nReisenwitz​ (2015): ​there are significant differences between those who complete online \nstudent evaluations and those who do not \nReisenwitz, T.H. (2015). Student evaluation of teaching: An investigation of nonresponse bias \nhttp://dx.doi.org/10.1080/02602938.2015.1044421\nhttp://dx.doi.org/10.1080/02602938.2015.1044421\nhttps://doi.org/10.1080/2331186X.2016.1204082\nin an online context. ​Journal of Marketing Education, 38​(1), 7-17. \nhttps://doi.org/10.1177/0273475315596778 \n[Abstract, abridged] This study examines nonresponse bias in online student evaluations of \ninstruction, that is, the differences between those students who complete online evaluations \nand those who decide not to complete them. It builds on the work of Estelami that revealed a \nresponse bias based on the timing in which the evaluations were completed, that is, \ndifferences in early evaluations versus later evaluations. In contrast, this study examines the \ndemographic variables that have contributed to nonresponse bias in online student \nevaluations, namely gender, grade point average, and ethnicity. It also examines multiple \npsychographic variables that may contribute to nonresponse bias: time poverty, complaining \nbehavior, and technology savviness. This study found that there are significant differences \nbetween those who complete online student evaluations and those who do not. \n Biases, Non-instructional \nKuwaiti, AlQuraan, & Subbarayalu​ (2016): ratings are affected by class size and response \nrate \nKuwaiti, A. A., AlQuraan, M., & Subbarayalu, A. V. (2016). Understanding the effect of \nresponse rate and class size interaction on students evaluation of teaching in a higher \neducation. ​Educational Assessment & Evaluation, 3​, \nhttps://doi.org/10.1080/2331186X.2016.1204082 \n[Abstract, abridged] This study aims to investigate the interaction between response rate and \nclass size and its effects on students’ evaluation of instructors and the courses offered at a \nhigher education Institution in Saudi Arabia. It is observed that when the class size is at the \nmedium level, the ratings of instructors and courses increase as the response rate increases. \nOn the contrary; when the class size is small, a high response rate is required for the \nevaluation of instructors and at least medium response rate is required for evaluation of \ncourses. The study suggests that the interaction between response rate and class size is an \nimportant factor that needs to be taken into account while interpreting the students’ evaluation \nof instructors and courses. \nNargundkar & Shrikhande​ (2014): combined impact of all the noninstructional factors \nstudied is statistically significant \nNargundkar, S., & Shrikhande, M. (2014). Norming of student evaluations of instruction: \nImpact of noninstructional factors. ​Decision Sciences Journal of Innovative Education, 12​(1), \n55-72. ​http://dx.doi.org/10.1111/dsji.12023 \n[Abstract, abridged] Student Evaluations of Instruction (SEIs) from about 6,000 sections over \n4 years representing over 100,000 students at the college of business at a large public \nuniversity are analyzed, to study the impact of noninstructional factors on student ratings. \nAdministrative factors like semester, time of day, location, and instructor attributes like gender \nhttps://doi.org/10.1080/2331186X.2016.1204082\nhttps://doi.org/10.1177/0273475315596778\nhttp://dx.doi.org/10.1111/dsji.12023\nhttps://doi.org/10.1177/0273475315596778\nand rank are studied. The combined impact of all the noninstructional factors studied is \nstatistically significant. Our study has practical implications for administrators who use SEIs to \nevaluate faculty performance. SEI scores reflect some inherent biases due to noninstructional \nfactors. Appropriate norming procedures can compensate for such biases, ensuring fair \nevaluations. \nReardon, Leierer, & Lee​ (2014): class schedule does not affect ratings \nReardon, R. C., Leierer, S. J., & Lee, D. (2014). Class meeting schedules in relation to \nstudents’ grades and evaluations of teaching. ​The Professional Counselor, 2​(1), 81-89. \nhttp://dx.doi.org/10.15241/rcr.2.1.81 \n[Abstract, abridged] A six-year retrospective study of a university career course evaluated the \neffect of four different class schedule formats on students' earned grades, expected grades \nand evaluations of teaching. Some formats exhibited significant differences in earned and \nexpected grades, but significant differences were not observed in student evaluations of \ninstruction.  \nRoyal & Stockdale​ (2015): students give lower ratings to instructors of quantitative methods \nsubjects \nRoyal, K. D., & Stockdale, M. R. (2015). Are teacher course evaluations biased against faculty \nthat teach quantitative methods courses? ​International Journal of Higher Education, 4​(1), \n217-224. ​http://dx.doi.org/10.5430/ijhe.v4n1p217 \n[Abstract, abridged] The present study investigated graduate students’ responses to \nteacher/course evaluations (TCE) to determine if students’ responses were inherently biased \nagainst faculty who teach quantitative methods courses. Item response theory (IRT) and \nDifferential Item Functioning (DIF) techniques were utilized for data analysis. Results indicate \nstudents in non-methods courses preferred the structure of quantitative courses, but tend to \nbe more critical of quantitative instructors. \n Biases, Other \nBlackhart, Peruche, DeWall, & Joiner​ (2006): varying results for investigation if class size, \nclass level, instructor gender, number of publications (faculty instructors), average grade \ngiven by the instructor, and instructor rank predicted teaching evaluation ratings \nBlackhart, G. C., Peruche, B. M., DeWall, C. N., & Joiner, T. E., Jr. (2006). Faculty forum: \nFactors influencing teaching evaluations in higher education. ​Teaching of Psychology, 33​(1), \n37-39. ​http://dx.doi.org/10.1207/s15328023top3301_9 \n[Abstract, abridged] Past research indicates several factors influencing teaching evaluation \nratings instructors receive. We analyzed teaching evaluations from psychology courses during \nhttp://dx.doi.org/10.5430/ijhe.v4n1p217\nhttp://dx.doi.org/10.1207/s15328023top3301_9\nhttp://dx.doi.org/10.15241/rcr.2.1.81\nfall and spring semesters of 2003-2004 to determine if class size, class level, instructor \ngender, number of publications (faculty instructors), average grade given by the instructor, \nand instructor rank predicted teaching evaluation ratings. Entering predictor variables into a \nmultiple regression analysis concurrently, results indicated that only average grade given and \ninstructor rank significantly predicted instructor ratings. Specifically, higher average grades \ngiven by the instructor predicted higher ratings, and graduate teaching assistants received \nhigher overall ratings than faculty instructors. \nKeeley, English, Irons, & Henslee​ (2013): found halo and ceiling/floor effects to be present \nand persistent \nKeeley, J. W., English, T., Irons, J., & Henslee, A. M. (2013). Investigating halo and ceiling \neffects in student evaluations of instruction. ​Educational and Psychological Measurement, \n73​(3), 440-457.​ ​http://dx.doi.org/10.1177/0013164412475300 \n[Abstract, abbreviated, and other article text] ​Many measurement biases affect student \nevaluations of instruction (SEIs). However, two have been relatively understudied: halo effects \nand ceiling/floor effects. This study examined these effects in two ways. Both biases were \nrobust and remained despite characteristics of the measure designed to combat them. \n“halo effects occur when a rater’s opinion about one aspect of the teacher influences the \nremainder of that person’s ratings” \n“Ceiling and floor effects (also referred to as maximizing and minimizing effects) occur when a \nscale does not have a sufficient range to produce meaningful variability at the upper or lower \nends of possible scores.” \nMarsh & Roche​ (1997): evaluations are valid and unaffected by hypothesized biases \nMarsh, H. W., & Roche, L. A. (1997). Making students’ evaluations of teaching effectiveness \neffective: The critical issues of validity, bias, and utility. ​American Psychologist, 52​(11), \n1187-1197. ​http://dx.doi.org/10.1037/0003-066X.52.11.1187 \n[Abstract, abridged] This article reviews research indicating that, under appropriate conditions, \nstudents' evaluations of teaching (SETs) are (a) multidimensional; (b) reliable and stable; (c) \nprimarily a function of the instructor who teaches a course rather than the course that is \ntaught; (d) relatively valid against a variety of indicators of effective teaching; (e) relatively \nunaffected by a variety of variables hypothesized as potential biases (e.g., grading leniency, \nclass size, workload, prior subject interest); and (f) useful in improving teaching effectiveness \nwhen SETS are coupled with appropriate consultation. The authors recommend rejecting a \nnarrow criterion-related approach to validity and adopting a broad construct-validation \napproach, recognizing that effective teaching and SETs that reflect teaching effectiveness are \nmultidimensional; no single criterion of effective teaching is sufficient; and tentative \ninterpretations of relations with validity criteria and potential biases should be evaluated \ncritically in different contexts, in relation to multiple criteria of effective teaching, theory, and \nexisting knowledge. \nhttp://dx.doi.org/10.1177/0013164412475300\nhttp://dx.doi.org/10.1037/0003-066X.52.11.1187\nhttp://dx.doi.org/10.1177/0013164412475300\nMerritt​ (2012): covers biases in general, including race minority \nMerritt, D. J. (2012). Bias, the brain, and student evaluations of teaching. ​St. John’s Law \nReview, 82​(1), Article 6, 235-288.​ ​http://scholarship.law.stjohns.edu/lawreview/vol82/iss1/6 \n[It seems that a 2008 version of this article was used in the UA report, but the version now \nonline is 2012. No abstract.] \nPounder​ (2007): identifies and organizes factors influencing SET scores; literature review \nPounder, J. S. (2007). Is student evaluation of teaching worthwhile? An analytical framework \nfor answering the question. ​Quality Assurance in Education, 15​(2), 178-191. \nhttp://dx.doi.org/10.1108/09684880710748938 \n[Abstract, abridged] Identifies student related, course related and teacher related aspects of \nresearch on teaching evaluations. Factors commonly addressed within these aspects are also \nidentified. On the basis of a comprehensive survey of the literature, this paper identifies and \ndiscusses the central factors influencing SET scores. These factors are then presented in a \ncomprehensible table that can be used as a reference point for researchers and practitioners \nwishing to examine the effectiveness of the SET system. \nZumback & Funke​ (2014): students’ mood affects ratings \nZumbach, J., & Funke, J. (2014). Influences of mood on academic course evaluations. \nPractical Assessment, Research & Evaluation, 19​(4). \nhttp://pareonline.net/genpare.asp?wh=0&abt=19 \n[Abstract, abridged] In two subsequent experiments, the influence of mood on academic \ncourse evaluation is examined. By means of facial feedback, either a positive or a negative \nmood was induced while students were completing a course evaluation questionnaire during \nlectures. Results from both studies reveal that a positive mood leads to better ratings of \ndifferent dimensions of lecture quality. While in Study 1 (N=109) mood was not directly \ncontrolled, Study 2 (N=64) replicates the findings of the prior study and reveals direct \ninfluences of positive and negative mood on academic course evaluation. \n Validity \nAl-Eidan, Baig, Magzoub, & Omair​ (2016): the faculty evaluation tool was found to be \nreliable, but validity has to be interpreted with caution because of low response \nAl-Eidan, F., Baig, L. A., Magzoub, M., & Omair, A. (2016). Reliability and validity of the \nfaculty evaluation instrument used at King Saud bin Abdulaziz University for Health Sciences: \nResults from the haematology course. ​The Journal of the Pakistan Medical Association, 66​(4), \n453-457. ​http://www.jpma.org.pk/full_article_text.php?article_id=7711 \nhttp://scholarship.law.stjohns.edu/lawreview/vol82/iss1/6\nhttp://dx.doi.org/10.1108/09684880710748938\nhttp://scholarship.law.stjohns.edu/lawreview/vol82/iss1/6\nhttp://pareonline.net/genpare.asp?wh=0&abt=19\nhttp://www.jpma.org.pk/full_article_text.php?article_id=7711\nhttp://dx.doi.org/10.1108/09684880710748938\nhttp://pareonline.net/genpare.asp?wh=0&abt=19\n[Abstract, abridged] Objectives: To assess reliability and validity of evaluation tool using \nHaematology course as an example. Results: Of the 116 subjects in the study, 80(69%) were \nmales and 36(31%) were females. Reliability of the questionnaire was Cronbach's alpha 0.91. \nFactor analysis yielded a logically coherent 7 factor solution that explained 75% of the \nvariation in the data. The factors were group dynamics in problem-based learning (alpha0.92), \nblock administration (alpha 0.89), quality of objective structured clinical examination (alpha \n0.86), block coordination (alpha 0.81), structure of problem-based learning (alpha 0.84), \nquality of written exam (alpha 0.91), and difficulty of exams (alpha0.41). Female students' \nopinion on depth of analysis and critical thinking was significantly higher than that of the \nmales (p=0.03). Conclusion: The faculty evaluation tool used was found to be reliable, but its \nvalidity, as assessed through factor analysis, has to be interpreted with caution as the \nresponders were less than the minimum required for factor analysis. \nBedggood & Donovan​ (2012): student satisfaction does not equal teaching quality; both \nstudent satisfaction and student learning are relevant measures \nBedggood, R. E., & Donovan, J. D. (2012). University performance evaluations: What are we \nreally measuring? ​Studies in Higher Education, 37​(7), 825-842. \nhttp://dx.doi.org/10.1080/03075079.2010.549221 \n[Abstract, abridged] Despite the criticisms surrounding whether measures associated with \nthese surveys are indeed valid, university managers continue to utilise them in key decision \nmaking. However, some argue that universities are misdirected in measuring satisfaction as a \nproxy for teaching quality, possibly subverting the potentially conflicting objective of student \nlearning. Even so, both student satisfaction and student learning can be relevant performance \nmeasures. Accordingly, we have developed two robust measures of these constructs. We \nargue that student learning can be measured and used to provide formative feedback for \nimproving teaching effectiveness. Alternatively, student satisfaction can be appropriate for \ndetermining whether students are ‘enjoying’ their studies, and likewise offers distinct benefits \nto university managers measuring performance outcomes. \nBrown, Wood, Ogden, & Maltby​ (2014): students’ satisfaction rating is context dependent; \nobjective quality and subjective satisfaction are different things and should be assessed \naccordingly \nBrown, G. D. A., Wood, A. M., Ogden, R. S., & Maltby, J. (2014). Do student evaluations of \nuniversity reflect inaccurate beliefs or actual experience? A relative rank model.​ Journal of \nBehavioral Decision Making, 28​, 14-26. ​http://dx.doi.org/10.1002/bdm.1827 \n[Abstract] It was shown that student satisfaction ratings are influenced by context in ways that \nhave important theoretical and practical implications. Using questions from the UK’s National \nStudent Survey, the study examined whether and how students’ expressed satisfaction with \nissues such as feedback promptness and instructor enthusiasm depends on the context of \ncomparison (such as possibly inaccurate beliefs about the feedback promptness or \nenthusiasm experienced at other universities) that is evoked. Experiment 1 found strong \neffects of experimentally provided comparison context—for example, satisfaction with a given \nfeedback time depended on the time’s relative position within a context. Experiment 2 used a \nhttp://dx.doi.org/10.1080/03075079.2010.549221\nhttp://dx.doi.org/10.1002/bdm.1827\nnovel distribution-elicitation methodology to determine the prior beliefs of individual students \nabout what happens in universities other than their own. It found that these beliefs vary widely \nand that students’ satisfaction was predicted by how they believed their experience ranked \nwithin the distribution of others’ experiences. A third study found that relative judgment \nprinciples also predicted students’ intention to complain. An extended model was developed \nto show that purely rank-based principles of judgment can account for findings previously \nattributed to range effects. It was concluded that satisfaction ratings and quality of provision \nare different quantities, particularly when the implicit context of comparison includes beliefs \nabout provision at other universities. Quality and satisfaction should be assessed separately, \nwith objective measures (such as actual times to feedback), rather than subjective ratings \n(such as satisfaction with feedback promptness), being used to measure quality wherever \npracticable.  \nChen & Hoshower​ (2003): student motivation to participate in SET affects ratings \nChen, Y., & Hoshower, L. B. (2003). Student evaluation of teaching effectiveness: an \nassessment of student perception and motivation. ​Assessment & Evaluation in Higher \nEducation, 28​(1), 71-88.​ ​http://dx.doi.org/10.1080/0260293032000033071 \n[Abstract, abridged] Very few studies have looked into students’ perception of the teaching \nevaluation system and their motivation to participate. This study employs expectancy theory \nto evaluate some key factors that motivate students to participate in the teaching evaluation \nprocess. The results show that students generally consider an improvement in teaching to be \nthe most attractive outcome of a teaching evaluation system. The second most attractive \noutcome was using teaching evaluations to improve course content and format. Using \nteaching evaluations for a professor’s tenure, promotion and salary rise decisions and making \nthe results of evaluations available for students’ decisions on course and instructor selection \nwere less important from the students’ standpoint. Students’ motivation to participate in \nteaching evaluations is also impacted significantly by their expectation that they will be able to \nprovide meaningful feedback. \nChonko, Tanner, & Davis​ (2002): students focus more on qualities that make a course \nappealing, not learning \nChonko, L. B., Tanner, J. F., & Davis, R. (2002). What are they thinking? Students’ \nexpectations and self-assessments. ​Journal of Education for Business, 77​(5), 271-281. \nRetrieved from \nhttp://login.ezproxy.library.ualberta.ca/login?url=http://search.ebscohost.com/login.aspx?direct\n=true&db=bth&AN=7214031&site=eds-live&scope=site \n[Abstract] Student teacher evaluations have been the subject of a great deal of research. In \nthis study, the authors surveyed 750 freshmen in an Introduction to Business class. The \nauthors found that students' actual perceptions often diverged from what they were assessing \non teaching evaluations and that their expectations of the teacher and the class, as well as \ntheir self-assessments, were very related to how students rate classes and teachers. The \nauthors suggest that caution should be exercised in the use of student evaluations. \nhttp://dx.doi.org/10.1080/0260293032000033071\nhttp://dx.doi.org/10.1080/0260293032000033071\nhttp://login.ezproxy.library.ualberta.ca/login?url=http://search.ebscohost.com/login.aspx?direct=true&db=bth&AN=7214031&site=eds-live&scope=site\nhttp://login.ezproxy.library.ualberta.ca/login?url=http://search.ebscohost.com/login.aspx?direct=true&db=bth&AN=7214031&site=eds-live&scope=site\nCohen​ (1981): student ratings are a valid measure of teaching effectiveness; this is the \nmeta-analysis targeted by Uttl et al., 2016 \nCohen, P. A. (1981). Student ratings of instruction and student achievement: A meta-analysis \nof multisection validity studies. ​Review of Educational Research, 51​(3), 281-309. \n[Abstract, abridged] The data for the meta-analysis came from 41 independent validity studies \nreporting on 68 separate multisection courses relating student ratings to student achievement. \nA hierarchical multiple regression analysis showed that rating/achievement correlations were \nlarger for full-time faculty when students knew their final grades before rating instructors and \nwhen an external evaluator graded students' achievement tests. The results of the \nmeta-analysis provide strong support for the validity of student ratings as measures of \nteaching effectiveness. \nd'Apollonia & Abrami​ (1997): student ratings are moderately valid; however, they are \naffected by administrative, instructor, and course characteristics \n d’Apollonia, S., & Abrami, P. C. (1997). Navigating student ratings of instruction. ​American \nPsychologist, 52​(11), 1198-1208. ​http://dx.doi.org/10.1037/0003-066X.52.11.1198 \n[Abstract, abridged] Many colleges and universities have adopted the use of student ratings of \ninstruction as one (often the most influential) measure of instructional effectiveness. In this \narticle, the authors present evidence that although effective instruction may be \nmultidimensional, student ratings of instruction measure general instructional skill, which is a \ncomposite of three subskills: delivering instruction, facilitating interactions, and evaluating \nstudent learning.The authors subsequently report the results of a meta-analysis of the \nmultisection validity studies that indicate that student ratings are moderately valid; however, \nadministrative, instructor, and course characteristics influence student ratings of instruction. \nDodeen​ (2013): validity of SET is questionable \nDodeen, H. (2013). Validity, reliability, and potential bias of short forms of students’ evaluation \nof teaching: The case of UAE University. ​Educational Assessment, 18​(4), 235-250. \nhttp://dx.doi.org/10.1080/10627197.2013.846670 \n[Abstract, abridged] Students' opinions continue to be a significant factor in the evaluation of \nteaching in higher education institutions. The purpose of this study was to psychometrically \nassess short students evaluation of teaching (SET) forms using the UAE University form as a \nmodel. The study evaluated the form validity, reliability, the overall question, and potential \nbias with respect to gender, college, grade point average, expected grade, and class size. A \ntotal of 3,661 students participated in this study in different random samples. Results \nindicated that the short SET form lacked content validity and could not identify key dimensions \nof evaluating teaching effectiveness. The form showed stability over time and acceptable \ninternal reliability. Results indicated also that there was a potential bias due to college, \nexpected grade, and class size, but there was no relationship between grade point average \nand students' ratings. It was concluded that short SET forms do not cover all domain content \nhttp://dx.doi.org/10.1080/10627197.2013.846670\nhttp://dx.doi.org/10.1080/10627197.2013.846670\nhttp://dx.doi.org/10.1037/0003-066X.52.11.1198\nand unable to provide teachers with enough information for the improvement of teaching. \nDolmans, Janssen-Noordman, & Wolfhagen​ (2006): students can distinguish excellent and \npoor teaching quality \nDolmans, D. M., Janssen-Noordman, A., & Wolfhagen, H. P. (2006). Can students \ndifferentiate between PBL tutors with different tutoring deficiencies? Medical Teacher, 28(6), \n156-161. doi: 10.1080/01421590600776545 \n[Abstract, abridged] Although everyone will agree that students are able to distinguish \nbetween poor and excellent tutors, one can question whether students are also able to \ndifferentiate between tutors with different tutoring deficiencies—tutors who perform badly on a \nspecific key aspect of their performance. The aim of this study was to investigate to what \ndegree students are able to differentiate between tutors with different tutoring deficiencies, \nhow effective tutors are with different deficiencies and what kind of tips students give for \nimprovement of a tutor's behaviour. The results of this study demonstrate that students are \nnot only able to distinguish between poor and excellent tutors, but are also able to diagnose \ntutors with different tutoring deficiencies and are able to provide tutors with specific feedback \nto improve their performance. \nGinns, Prosser, & Barrie​ (2007): the SET tool studied supports quality assurance and \nimprovement processes at the university \nGinns, P., Prosser, M., & Barrie, S. (2007). Students’ perceptions of teaching quality in higher \neducation: the perspective of currently enrolled students. ​Studies in Higher Education, 32​(5), \n603-615. ​http://dx.doi.org/10.1080/03075070701573773 \n[Abstract, abridged] The psychometric properties of a version of the Course Experience \nQuestionnaire revised for students currently enrolled at the University of Sydney, the Student \nCourse Experience Questionnaire (SCEQ), were assessed, gathering students’ perceptions \non a number of scales, including Good Teaching, Clear Goals and Standards, Appropriate \nAssessment, Appropriate Workload, and an outcome scale measuring Generic Skills \ndevelopment. Confirmatory factor analyses supported the hypothesised factor structure, and \nestimates of inter-rater agreement on SCEQ scales indicated student ratings of degrees can \nbe meaningfully aggregated up to the faculty level. Derived from a substantial research base, \nlinking the student experience to approaches to study and learning outcomes, its goal is to \nsupport both quality assurance and improvement processes within the university, at both the \ndegree level and faculty level. The analyses described above indicate that the SCEQ is \nappropriate for these purposes. \nGrammatikopoulos, Linardakis, Gregoriadis, & Oikonomidis​ (2015): provides evidence of \na valid SET instrument; evaluating test validity is a continuous process, not a one-time event \nGrammatikopoulos, V., Linardakis, M., Gregoriadis, A., & Oikonomidis, V. (2015). Assessing \nthe students’ evaluations of educational quality (SEEQ) questionnaire in Greek higher \neducation. ​Higher Education, 70​(3), 395-408. ​http://dx.doi.org/10.1007/s10734-014-9837-7 \nhttp://dx.doi.org/10.1080/03075070701573773\nhttp://dx.doi.org/10.1007/s10734-014-9837-7\n[Abstract, abridged] The aim of the current study was to provide a valid and reliable \ninstrument for the evaluation of the teaching effectiveness in the Greek higher education \nsystem. Other objectives of the study were (a) the examination of the dimensionality and the \nhigher-order structure of the Greek version of Students’ Evaluation of Educational Quality \n(SEEQ) questionnaire, and (b) the investigation of the effects of several background variables \non students’ evaluations of teaching (SET) scores provided by the Greek version of SEEQ. A \ntotal of 1,264 students participated by filling in the questionnaires administered to them. The \nresults showed solid evidence of the applicability of the Greek version of SEEQ, by confirming \nthe factor structure of the instrument and reassuring the multidimensionality of the teaching \neffectiveness construct. Additionally, the effects of several background variables on teaching \neffectiveness further supported the validity of SET scores. \nGrayson​ (2015): questions student’s ability to give accurate ratings \nGrayson, J. P. (2015). Repeated low teaching evaluations: A form of habitual behavior? \nCanadian Journal of Higher Education, 45​(4), 298-321. \nhttp://journals.sfu.ca/cjhe/index.php/cjhe/article/view/184404 \n[Abstract, abridged] In this article, comparisons were made between first- and third-year \ncollective evaluations of professors’ performance at the University of British Columbia, York \nUniversity, and McGill University. Overall, it was found that students who provided low \nevaluations in their first year were also likely to do so in their third year. Given that over the \ncourse of their studies, students likely would have been exposed to a range of different \nbehaviours on the part of their professors, it is argued that the propensity of a large number of \nstudents to give consistently low evaluations was a form of “habitual behaviour. \nGreenwald​ (1997): student rating measures have validity concerns \nGreenwald, A. G. (1997). Validity concerns and usefulness of student ratings of instruction. \nAmerican Psychologist, 52​(11), 1182-1186.​ ​http://dx.doi.org/10.1037/0003-066X.52.11.1182 \n[Abstract] The validity of student rating measures of instructional quality was severely \nquestioned in the 1970s. By the early 1980s, however, most expert opinion viewed student \nrating measures as valid and as worthy of widespread use. In retrospect, older \ndiscriminant-validity concerns were not so much resolved as they were displaced from \nresearch attention by accumulating evidence for convergent validity. This article introduces a \nCurrent Issues section that gives new attention to validity concerns associated with student \nratings. The section's 4 articles deal, respectively, with (a) conceptual structure (are student \nratings unidimensional or multidimensional?), (b) convergent validity (how well do ratings \ncorrelate with other indicators of effective teaching?), (c) discriminant validity (are ratings \ninfluenced by factors other than teaching effectiveness?), and (d) consequential validity (are \nratings used effectively in personnel development and evaluation?). Although all 4 articles \nfavor the use of ratings, they disagree on controversial points associated with interpretation \nand use of ratings data. \nKhong​ (2014): SET is a valid instrument in evaluating teaching effectiveness \nhttp://psycnet.apa.org/doi/10.1037/0003-066X.52.11.1182\nhttp://journals.sfu.ca/cjhe/index.php/cjhe/article/view/184404\nhttp://psycnet.apa.org/doi/10.1037/0003-066X.52.11.1182\nhttp://journals.sfu.ca/cjhe/index.php/cjhe/article/view/184404\nKhong, T. L. (2014). The validity and reliability of the student evaluation of teaching: A case in \na private higher educational institution in Malaysia. ​International Journal for Innovation \nEducation and Research, 2​(9), 57-63.​ ​http://www.ijier.net/index.php/ijier/article/view/317 \n[Abstract, abridged] Most universities are using the Student Evaluation of Teaching (SET) as \nan instrument for students to assess a lecturer’s teaching performance. It is an essential \ninstrument to reflect the feedback in enhancing the quality of teaching and learning. The \npurpose of this paper is to examine the validity and reliability of the SET as a valid instrument \nin evaluating teaching effectiveness in a private higher education institution in Malaysia. \nExploratory Factor Analysis and Confirmatory Factor Analysis have validated all 10 items of \nSET whereby all items indicated high reliability and internal consistency. \nThe conclusion of this study showed that the SET is a valid instrument in evaluating teaching \neffectiveness. \nLama, Arias, Mendoza, & Manahan​ (2015): lack of student diligence when rating instructors \nraises validity concerns \nLama, T., Arias, P., Mendoza, K. & Manahan, J. (2015). Student evaluation of teaching \nsurveys: do students provide accurate and reliable information? ​e-Journal of Social & \nBehavioural Research in Business, 6​(1), 30-39.​ ​http://www.ejsbrb.org/a.php?/content/issue/10 \n[Abstract, abridged] This paper explores patterns of students' response behaviour of \ninternational students studying in an Australian university when filling out student surveys \nevaluating lecturers and courses. The study focuses on whether information obtained through \nthe survey process can be relied upon to make management decisions. The results of the \nstudy seem to suggest a reasonable level of diligence is lacking on the students' part in \nanswering the surveys, raising a concern about the reliability of information. This tendency \nseems to be prevalent among all students irrespective of their gender and nationality. \nMarsh & Roche​ (1997): evaluations are relatively valid and unaffected by hypothesized \nbiases \nMarsh, H. W., & Roche, L. A. (1997). Making students’ evaluations of teaching effectiveness \neffective: The critical issues of validity, bias, and utility. ​American Psychologist, 52​(11), \n1187-1197. ​http://dx.doi.org/10.1037/0003-066X.52.11.1187 \n[Abstract, abridged] This article reviews research indicating that, under appropriate conditions, \nstudents' evaluations of teaching (SETs) are (a) multidimensional; (b) reliable and stable; (c) \nprimarily a function of the instructor who teaches a course rather than the course that is \ntaught; (d) relatively valid against a variety of indicators of effective teaching; (e) relatively \nunaffected by a variety of variables hypothesized as potential biases (e.g., grading leniency, \nclass size, workload, prior subject interest); and (f) useful in improving teaching effectiveness \nwhen SETS are coupled with appropriate consultation. The authors recommend rejecting a \nnarrow criterion-related approach to validity and adopting a broad construct-validation \napproach, recognizing that effective teaching and SETs that reflect teaching effectiveness are \nmultidimensional; no single criterion of effective teaching is sufficient; and tentative \nhttp://dx.doi.org/10.1037/0003-066X.52.11.1187\nhttp://www.ijier.net/index.php/ijier/article/view/317\nhttp://www.ijier.net/index.php/ijier/article/view/317\nhttp://www.ejsbrb.org/a.php?/content/issue/10\nhttp://www.ejsbrb.org/a.php?/content/issue/10\ninterpretations of relations with validity criteria and potential biases should be evaluated \ncritically in different contexts, in relation to multiple criteria of effective teaching, theory, and \nexisting knowledge.  \nMartin, Dennehy, & Morgan​ (2013): validity of SET is questioned; student focus groups \nsuggested as an alternative \nMartin, L. R., Dennehy, R., & Morgan, S. (2013). Unreliability in student evaluation of teaching \nquestionnaires: Focus groups as an alternative approach. ​Organization Management Journal, \n10​(1), 66-74.​ ​http://dx.doi.org/10.1080/15416518.2013.781401 \n[Abstract, abridged] Research on the validity and reliability of SETs is vast, though riddled \nwith inconsistencies. The many “myths” of SETs are investigated and the incongruities are \ndemonstrated. We hypothesize that the discrepancies in empirical studies come from \nmisunderstanding and inappropriate actions by students. To address the complexity inherent \nin these problems, we suggest the use of focus groups as an alternative approach or \ncomplement to the standard SETs. A recommended format and guidelines for running \nclassroom focus groups are provided. Institutional constraints and implementation concerns \nare addressed as well. This article lays the foundation for implementing a change in student \nassessment of teaching by proposing a method to compensate for bias in SETs, using focus \ngroups as an evaluation tool, either as a stand-alone process or as a supplement to current \nmethods. \nMcKeachie​ (1997): student ratings are valid but affected by contextual variables such as \ngrading leniency \nMcKeachie, W. J. (1997). Student ratings: The validity of use. ​American Psychologist, 52​(11), \n1218-1225. ​http://dx.doi.org/10.1037/0003-066X.52.11.1218 \n[Abstract, abridged] In this article, the author discusses the other articles in this Current \nIssues section and concludes that all of the authors agree that student ratings are valid but \nthat contextual variables such as grading leniency can affect the level of ratings. The authors \ndisagree about the wisdom of applying statistical corrections for such contextual influences. \nThis article argues that the problem lies neither in the ratings nor in the correction but rather in \nthe lack of sophistication of personnel committees who use the ratings. Thus, more attention \nshould be directed toward methods of ensuring more valid use.  \nMorley​ (2012): ​student evaluations in this study were generally unreliable \nMorley, D. D. (2012). Claims about the reliability of student evaluations of instruction: The \necological fallacy rides again. ​Studies in Educational Evaluation, 38​(1), 15-20. \nhttp://dx.doi.org/10.1016/j.stueduc.2012.01.001 \n[Abstract, abridged] The vast majority of the research on student evaluation of instruction has \nassessed the reliability of groups of courses and yielded either a single reliability coefficient \nfor the entire group, or grouped reliability coefficients for each student evaluation of teaching \n(SET) item. This manuscript argues that these practices constitute a form of ecological \nhttp://dx.doi.org/10.1080/15416518.2013.781401\nhttp://dx.doi.org/10.1037/0003-066X.52.11.1218\nhttp://dx.doi.org/10.1016/j.stueduc.2012.01.001\nhttp://dx.doi.org/10.1016/j.stueduc.2012.01.001\nhttp://dx.doi.org/10.1080/15416518.2013.781401\ncorrelation and therefore yield incorrect estimates of reliability. Intraclass reliability and \nagreement coefficients were proposed as appropriate for making statements about the \nreliability of SETs in specific classes. An analysis of 1073 course sections using inter-rater \ncoefficients found that students using this particular instrument were generally unable to \nreliably evaluate faculty. In contrast, the traditional ecologically flawed multi-class “group” \nreliability coefficients had generally acceptable reliability. \nNargundkar & Shrikhande​ (2012): an instrument that was validated 20 years ago is still valid \nNargundkar, S., & Shrikhande, M. (2012). An empirical investigation of student evaluations of \ninstruction: The relative importance of factors. ​Decision Sciences Journal of Innovative \nEducation, 10​(1), 117-135.​ ​http://dx.doi.org/10.1111/j.1540-4609.2011.00328.x \n[Abstract, abridged] We analyzed over 100,000 student evaluations of instruction over 4 years \nin the college of business at a major public university. We found that the original instrument \nthat was validated about 20 years ago is still valid, with factor analysis showing that the six \nunderlying dimensions used in the instrument remained relatively intact. Also, we found that \nthe relative importance of those six factors in the overall assessment of instruction changed \nover the past two decades, reflecting changes in the expectations of the current millennial \ngeneration of students. The results were consistent across four subgroups \nstudied—Undergraduate Core, Undergraduate Noncore, Graduate Core, and Graduate \nNoncore classes, with minor differences. \nRantanen​ (2013): reliability of SET is questionable; multiple feedbacks required \nRantanen, P. (2013). The number of feedbacks needed for reliable evaluation. A multilevel \nanalysis of the reliability, stability and generalizability of students’ evaluation of teaching. \nAssessment & Evaluation in Higher Education, 38​(2), 224-239. \nhttp://dx.doi.org/10.1080/02602938.2011.625471 \n[Abstract, abridged] A multilevel analysis approach was used to analyse students’ evaluation \nof teaching (SET). The low value of inter-rater reliability stresses that any solid conclusions on \nteaching cannot be made on the basis of single feedbacks. To assess a teacher’s general \nteaching effectiveness, one needs to evaluate four randomly chosen course implementations. \nTwo implementations are needed when one course is evaluated, and if one implementation is \nevaluated, up to 15 feedbacks are needed. The stability of students’ ratings is very high, \nwhich reflects students’ stable rating criteria. There is an obvious rating paradox: from the \nstudent’s point of view, each rating is very precise, stable and justifiable, but from the \nteacher’s point of view a single feedback reflects the quality of teaching to just a moderate \nextent. Cross-hierarchical analysis reveals that there are large discrepancies between the \nuses of rating scales; some students are systematically more lenient in their rating whereas \nothers are systematically more severe. The study also reveals that some courses are \ngenerally rated more favourably and that some courses are more suitable for certain teachers. \nSocha​ (2013): a SET instrument was found to have overall good reliability and validity with \nrelatively few biases \nhttp://dx.doi.org/10.1111/j.1540-4609.2011.00328.x\nhttp://dx.doi.org/10.1111/j.1540-4609.2011.00328.x\nhttp://dx.doi.org/10.1080/02602938.2011.625471\nhttp://dx.doi.org/10.1080/02602938.2011.625471\nSocha, A. (2013). A hierarchical approach to students’ assessment of instruction. ​Assessment \n& Evaluation in Higher Education, 38​(1), 94-113. \nhttp://dx.doi.org/10.1080/02602938.2011.604713 \n[Abstract, abridged] Since students are extensively exposed to course elements, students’ \nevaluation of instruction should be one of several components in the teacher evaluation \nsystem. Since traditional methods, such as Cronbach’s alpha and ordinary least squares \nregression, do not address the hierarchical data of the classroom, the current study used the \nstatistical techniques of confirmatory factor analysis and hierarchical linear modelling in order \nto properly investigate the reliability and validity of the Students’ Assessment of Instruction \n(SAI) instrument. Overall, the SAI was found to have good reliability and validity with relatively \nfew biases and could be used to extract five distinguishable traits of instructional \neffectiveness. \nSpooren, Brockx, & Mortelmans​ (2013): the utility and validity of SET is questionable \nSpooren, P., Brockx, B., & Mortelmans, D. (2013). On the validity of student evaluation of \nteaching: The state of the art. ​Review of Educational Research, 83​(4), 598-642. \nhttp://dx.doi.org/10.3102/0034654313496870 \n[Abstract] This article provides an extensive overview of the recent literature on student \nevaluation of teaching (SET) in higher education. The review is based on the SET \nmeta-validation model, drawing upon research reports published in peer-reviewed journals \nsince 2000. Through the lens of validity, we consider both the more traditional research \nthemes in the field of SET (i.e., the dimensionality debate, the ‘bias’ question, and \nquestionnaire design) and some recent trends in SET research, such as online SET and bias \ninvestigations into additional teacher personal characteristics. The review provides a clear \nidea of the state of the art with regard to research on SET, thus allowing researchers to \nformulate suggestions for future research. It is argued that SET remains a current yet delicate \ntopic in higher education, as well as in education research. Many stakeholders are not \nconvinced of the usefulness and validity of SET for both formative and summative purposes. \nResearch on SET has thus far failed to provide clear answers to several critical questions \nconcerning the validity of SET. \nUttl, White, & Gonzalez​ (2016): SETs do not indicate teaching quality, meta-analysis \nUttl, B., White, C. A., Gonzalez, D. W. (2016). Meta-analysis of faculty’s teaching \neffectiveness: Student evaluation of teaching ratings and student learning are not related. \nStudies in Educational Evaluation,​ (in press, available online September 19, 2106). \nhttp://dx.doi.org/10.1016/j.stueduc.2016.08.007 \n[Abstract, abridged] We re-analyzed previously published meta-analyses of the multisection \nstudies and found that their findings were an artifact of small sample sized studies and \npublication bias. Whereas the small sample sized studies showed large and moderate \ncorrelation, the large sample sized studies showed no or only minimal correlation between \nSET ratings and learning. Our up-to-date meta-analysis of all multisection studies revealed no \nsignificant correlations between the SET ratings and learning. These findings suggest that \nhttp://dx.doi.org/10.1080/02602938.2011.604713\nhttp://dx.doi.org/10.3102/0034654313496870\nhttp://dx.doi.org/10.3102/0034654313496870\nhttp://dx.doi.org/10.1080/02602938.2011.604713\nhttp://dx.doi.org/10.1016/j.stueduc.2016.08.007\ninstitutions focused on student learning and career success may want to abandon SET ratings \nas a measure of faculty's teaching effectiveness.  \nWright & Jenkins-Guarieri​ (2012): SETs appear to be valid and free from gender bias \nWright, S. L., & Jenkins-Guarieri, M. A. (2012). Student evaluations of teaching: combining \nthe meta-analyses and demonstrating further evidence for effective use. ​Assessment & \nEvaluation in Higher Education, 37​(6), 683-699. \nhttp://dx.doi.org/10.1080/02602938.2011.563279 \n[Abstract, abridged] Given that there is not one study summarising all these domains of \nresearch, a comprehensive overview of SETs was conducted by combining all prior \nmeta-analyses related to SETs. Eleven meta-analyses were identified, and nine \nmeta-analyses covering 193 studies were included in the analysis, which yielded a \nsmall-to-medium overall weighted mean effect size (r = .26) between SETs and the variables \nstudied. Findings suggest that SETs appear to be valid, have practical use that is largely free \nfrom gender bias and are most effective when implemented with consultation strategies. \n Impact on Teaching Quality \nBlair & Valdez Noel​ (2014): little evidence that student feedback is leading to improved \nteaching \nBlair, E., & Valdez Noel, K. (2014). Improving higher education practice through student \nevaluation systems: is the student voice being heard? ​Assessment & Evaluation in Higher \nEducation, 39​(7), 879-894.​ ​http://dx.doi.org/10.1080/02602938.2013.875984 \n[Abstract, abridged] This paper examines the student evaluations at a university in Trinidad \nand Tobago in an effort to determine whether the student voice is being heard. The research \nfocused on students’ responses to the question, ‘How do you think this course could be \nimproved?’ Student evaluations were gathered from five purposefully selected courses taught \nat the university during 2011–2012 and then again one year later, in 2012–2013. This allowed \nfor an analysis of the selected courses. Whilst the literature suggested that student evaluation \nsystems are a valuable aid to lecturer improvement, this research found little evidence that \nthese evaluations actually led to any real significant changes in lecturers’ practice. \nCampbell & Bozeman​ (2008): questions the effect student evaluations have on teaching \nquality \nCampbell, J. P., & Bozeman, W. C. (2008). The value of student ratings: Perceptions of \nstudents, teachers, and administrators. ​Community College Journal of Research and Practice, \n32​, 13-24.​ ​http://dx.doi.org/10.1080/10668920600864137 \n[Abstract, abridged] This research responded to the lack of emphasis on more effective use of \nthe data for the purpose of improving teaching effectiveness by questioning the opinions and \nhttp://dx.doi.org/10.1080/10668920600864137\nhttp://dx.doi.org/10.1080/10668920600864137\nhttp://dx.doi.org/10.1080/02602938.2011.563279\nhttp://dx.doi.org/10.1080/02602938.2013.875984\nhttp://dx.doi.org/10.1080/02602938.2011.563279\nhttp://dx.doi.org/10.1080/02602938.2013.875984\npractices of students, faculty, and administrators. More importantly, this research questioned \nthe value of student ratings of teaching: Is the effort of doing student evaluations worth the \ninstitutional investment or is it simply a routine process which has little or no effect on \nimproving teaching? \nCurwood, Tomitsch, Thomson, & Hendry​ (2015): provide an example of support for \nacademics’ learning from SETs \nCurwood, J.S., Tomitsch, M., Thomson, K., & Hendry. G.D. (2015). Professional learning in \nhigher education: Understanding how academics interpret student feedback and access \nresources to improve their teaching. ​Australasian Journal of Educational Technology, 31​(5). \nhttp://dx.doi.org/10.14742/ajet.2516 \n[Abstract, abridged] Previous research on professional learning has identified that face-to-face \nconsultation is an effective approach to support academics’ learning from student feedback. \nHowever, this approach is labour and time intensive, and does not necessarily provide all \nacademics with just-in-time support. In this article, we describe an alternative approach, which \ninvolves the creation of ​Ask Charlie​, a mobile website that visually represents results from \nstudent evaluation of teaching (SET), and provides academics with personalised \nrecommendations for teaching resources. ​Ask Charlie​ was developed and evaluated by \ndrawing on design-based research methods with the aim to support professional learning \nwithin higher education. \nMakondo & Ndebele​ (2014): SETs are beneficial for improving teaching quality \nMakondo, L., & Ndebele, C. (2014). University lecturers’ views on student-lecturer \nevaluations. ​Anthropologist, 17​(2), 377-386. \nhttp://www.krepublishers.com/02-Journals/T-Anth/Anth-17-0-000-14-Web/Anth-17-0-000-14-C\nontents/Anth-17-0-000-14-Contents.htm \n[Abstract, abridged] This paper discusses university lecturers’ views on student-lecturer \nevaluation of teaching and learning process. Specific reference is given to the university \nlecturers’ views on the usefulness of the evaluation exercise, the evaluation process, items in \nthe evaluation questionnaires and evaluation feedback reports at a formerly disadvantaged \nSouth African University. A total of 118 (53.8%) lecturers out of a staff establishment of 219 \nteaching staff volunteered their participation in this study. The findings of the study show that \ninsights from student-lecturer evaluations are an important source of information for university \nteaching staff and administration to consider in their quest to improve on the quality of \nuniversity teaching and learning moves that can help improve on throughput rates.  \nStein, Spiller, Harris, Deaker, & Kennedy​ (2013): there are gaps in the way academics \nengage with student evaluation \nStein, S. J., Spiller, D., Terry, S., Harris, T., Deaker, L., & Kennedy, J. (2013). Tertiary \nteachers and student evaluations: never the twain shall meet? ​Assessment & Evaluation in \nHigher Education, 38​(7), 892-904.​ ​http://dx.doi.org/10.1080/02602938.2013.767876 \nhttp://www.krepublishers.com/02-Journals/T-Anth/Anth-17-0-000-14-Web/Anth-17-0-000-14-Contents/Anth-17-0-000-14-Contents.htm\nhttp://www.krepublishers.com/02-Journals/T-Anth/Anth-17-0-000-14-Web/Anth-17-0-000-14-Contents/Anth-17-0-000-14-Contents.htm\nhttp://www.krepublishers.com/02-Journals/T-Anth/Anth-17-0-000-14-Web/Anth-17-0-000-14-Contents/Anth-17-0-000-14-Contents.htm\nhttp://dx.doi.org/10.1080/02602938.2013.767876\nhttp://dx.doi.org/10.14742/ajet.2516\nhttp://dx.doi.org/10.1080/02602938.2013.767876\nhttp://dx.doi.org/10.14742/ajet.2516\n[Abstract, abridged] While extensive research has been done on student evaluations, there is \nless research-based evidence about teachers’ perceptions of and engagement with student \nevaluations, the focus of the research reported in this paper. Results highlighted the general \nacceptance of the notion of student evaluations, recurring ideas about the limitations of \nevaluations and significant gaps in the way academics engage with student evaluation \nfeedback. \n Evaluating Faculty for Tenure and Promotion \nBoysen​ (2015): faculty and administrators can over-interpret small variations \nBoysen, G. A. (2015). Uses and misuses of student evaluations of teaching: The \ninterpretation of differences in teaching evaluation means irrespective of statistical \ninformation. ​Teaching of Psychology, 42​(2), 109-118. \nhttp://dx.doi.org/10.1177/0098628315569922 \n[Abstract] Student evaluations of teaching are among the most accepted and important            \nindicators of college teachers’ performance. However, faculty and administrators can          \noverinterpret small variations in mean teaching evaluations. The current research examined           \nthe effect of including statistical information on the interpretation of teaching evaluations.            \nStudy 1 (​N = 121) showed that faculty members interpreted small differences between mean              \ncourse evaluations even when confidence intervals and statistical tests indicated the absence            \nof meaningful differences. Study 2 (​N = 183) showed that differences labeled as             \nnonsignificant still influenced perceptions of teaching qualifications and teaching ability. The           \nresults suggest the need for increased emphasis on the use of statistics when presenting and               \ninterpreting teaching evaluation data. \nBoysen, Raesly, & Casner​ (2014): ratings are misinterpreted by faculty and administrators \nBoysen, G. A., Kelly, T. J., Raesly, H. N., & Casner, R. W. (2014). The (mis)interpretation of \nteaching evaluations by college faculty and administrators. ​Assessment & Evaluation in \nHigher Education, 39​(6), 641-656.​ ​http://dx.doi.org/10.1080.02602938.2013.860950 \n[Abstract, abridged] The current research consisted of three studies documenting the effect of \nsmall mean differences in teaching evaluations on judgements about teachers. Differences in \nmeans small enough to be within the margin of error significantly impacted faculty members’ \nassignment of merit-based rewards (Study 1), department heads’ evaluation of teaching \ntechniques (Study 2) and faculty members’ evaluation of specific teaching skills (Study 3). \nThe results suggest that faculty and administrators do not apply appropriate statistical \nprinciples when evaluating teaching evaluations and instead use a general heuristic that \nhigher evaluations are better. \nFraile & Bosch-Morell​ (2015): present a reliable approach to SET interpretation \nFraile, R., & Bosch-Morell, F. (2015). Considering teaching history and calculating confidence \nhttp://dx.doi.org/10.1177/0098628315569922\nhttp://dx.doi.org/10.1080.02602938.2013.860950\nhttp://dx.doi.org/10.1080.02602938.2013.860950\nhttp://dx.doi.org/10.1177/0098628315569922\nintervals in student evaluations of teaching quality: An approach based on Bayesian \ninference. ​Higher Education, 70​(1), 55-72.​ ​http://dx.doi.org/10.1007/s10734-014-9823-0 \n[Abstract, abbreviated, edited] Student evaluations of teaching quality are among the most \nused and analysed sources of such information [for lecturer promotion and tenure decisions]. \nHowever, to date little attention has been paid in how to process them in order to be able to \nestimate their reliability. Within this paper we present an approach that provides estimates of \nsuch reliability in terms of confidence intervals. This approach, based on Bayesian inference, \nalso provides a means for improving reliability even for lecturers having a low number of \nstudent evaluations. Such improvement is achieved by using past information in every year’s \nevaluations.  \nJackson & Jackson​ (2015): concerns with use of SETs for summative purposes \nJackson, M. J., & Jackson, W. T. (2015). The misuse of student evaluations of teaching: \nImplications, suggestions and alternatives. ​Academy of Educational Leadership Journal, \n19​(3), 165-173.​ ​http://www.alliedacademies.org/academy-of-educational-leadership-journal/ \n[Abstract, abridged] A five year longitudinal study of the results from Student Evaluations of \nTeaching (SETs) was accomplished within the business school of a small southwestern state \nuniversity. Based upon the findings of the study, the authors argue that prior practices in \napplying the results of SETs for summative purposes have not been based upon a sound \nstatistical foundation. Results from both instructor samples and populations are compared and \nindicate that the use of means to measure and compare instructor effectiveness requires \nassumptions of normality which the data does not meet. \nJones, Gaffney-Rhys, & Jones​ (2015): presents issues if decision-makers use SET results \nsummatively \nJones, J., Gaffney-Rhys, R., & Jones, E. (2014). Handle with care! An exploration of the \npotential risks associated with the publication and summative usage of student evaluation of \nteaching (SET) results. ​Journal of Further and Higher Education, 38​(1), 37-56. \nhttp://dx.doi.org/10.1080/0309877X.2012.699514 \n[Abstract, abridged] This article presents a synthesis of previous ideas relating to student \nevaluation of teaching (SET) results in higher education institutions (HEIs), with particular \nfocus upon possible validity issues and matters that HEI decision-makers should consider \nprior to interpreting survey results and using them summatively. Furthermore, the research \nexplores relevant legal issues (namely, defamation, breach of the duty to take reasonable \ncare for an employee’s welfare, breach of the duty of trust and confidence, breach of the right \nto privacy and, if the lecturer is forced to resign as a consequence of such infringements, \nconstructive dismissal) that decision-makers, in UK HEIs, should appreciate if survey results \nare widely published or used to inform employment decisions. \nMitry & Smith​ (2014): conclusions drawn from evaluations may be invalid and harmful \nMitry, D. J., & Smith, D. E. (2014). Student evaluations of faculty members: A call for \nhttp://dx.doi.org/10.1080/0309877X.2012.699514\nhttp://dx.doi.org/10.1007/s10734-014-9823-0\nhttp://www.alliedacademies.org/academy-of-educational-leadership-journal/\nhttp://www.alliedacademies.org/academy-of-educational-leadership-journal/\nhttp://dx.doi.org/10.1007/s10734-014-9823-0\nhttp://dx.doi.org/10.1080/0309877X.2012.699514\nanalytical prudence. ​Journal on Excellence in College Teaching, 25​(2), 56-67. \nhttp://celt.miamioh.edu/ject/issue.php?v=25&n=2 \n[Abstract, abridged] The authors of this article express concern about the use of parametric \ntechniques to report faculty performance based on categorical Likert survey data gleaned \nfrom student responses to teaching evaluations. They argue that these surveys often violate \nprimary statistical requirements for evaluative application. Therefore, the conclusions drawn \nfrom such evaluations may be invalid and even harmful to faculty members over time. The \nauthors conclude that it is imprudent for university administrators to support questionable \nanalysis methods simply because they have, on the surface, the appearance of rigor, or \nbecause the practice has become commonplace. \nPalmer​ (2012): presents examples of ineffective responses to evaluation results \nPalmer, S. (2012). Student evaluation of teaching: keeping in touch with reality. ​Quality in \nHigher Education, 18​(3), 297-311.​ ​http://dx.doi.org/10.1080/13538322.2012.730336 \n[Abstract, abridged] This article used publicly available student evaluation of teaching data to \npresent examples of where institutional responses to evaluation processes appeared to be \neducationally ineffective and where the pursuit of the ‘right’ student evaluation results appears \nto have been mistakenly equated with the aim of improved teaching and learning. If the vast \nresources devoted to student evaluation of teaching are to be effective, then the data \nproduced by student evaluation systems must lead to real and sustainable improvements in \nteaching quality and student learning, rather than becoming an end in itself. \n Multifaceted Evaluation \nBerk​ (2013): covers several issues, including multifactorial evaluations \nBerk, R. A. (2013). Top five flashpoints in the assessment of teaching effectiveness. ​Medical \nTeacher, 35​(1), 15-26.​ ​http://dx.doi.org/10.3109/0142159X.2012.732247 \n[Berk is also the author of the 2013 book “Top 10 Flashpoints in Student Ratings and the \nEvaluation of Teaching”] \n[Abstract, abridged] Five flashpoints are defined, the salient issues and research described, \nand, finally, specific, concrete recommendations for moving forward are proffered. Those \nflashpoints are: (1) student ratings vs. multiple sources of evidence; (2) sources of evidence \nvs. decisions: which come first?’ (3) quality of ‘‘home-grown’’ rating scales vs. \ncommercially-developed scales; (4) paper-and-pencil vs. online scale administration; and (5) \nstandardized vs. unstandardized online scale administrations. Conclusions: Multiple sources \nof evidence collected through online administration, when possible, can furnish a solid \nfoundation from which to infer teaching effectiveness and contribute to fair and equitable \ndecisions about faculty contract renewal, merit pay, and promotion and tenure. \nhttp://celt.miamioh.edu/ject/issue.php?v=25&n=2\nhttp://dx.doi.org/10.3109/0142159X.2012.732247\nhttp://dx.doi.org/10.1080/13538322.2012.730336\nhttp://dx.doi.org/10.1080/13538322.2012.730336\nhttp://celt.miamioh.edu/ject/issue.php?v=25&n=2\nhttp://dx.doi.org/10.3109/0142159X.2012.732247\nCox, Peeters, Stanford, & Seifert​ (2013): a peer assessment instrument was piloted; \nformative peer assessment seems important \nCox, C.D., Peeters, M. J., Stanford, B. L., & Seifert, C. F. (2013). Pilot of peer assessment \nwithin experiential teaching and learning. ​Currents in Pharmacy Teaching and Learning, 5​(4), \n311-320.​ ​http://dx.doi.org/10.1016/j.cptl.2013.02.003 \n[Abstract, abridged] Objectives of this study were as follows: (1) to pilot test an instrument for \npeer assessment of experiential teaching, (2) to compare peer evaluations from faculty with \nstudent evaluations of their preceptor (faculty), and (3) to determine the impact of qualitative, \nformative peer assessment on faculty’s experiential teaching. Faculty at Texas Tech \nUniversity Health Sciences Center School of Pharmacy implemented a new peer assessment \ninstrument focused on assessing experiential teaching. Eight faculty members participated in \nthis pilot. Conclusion: A peer assessment of experiential teaching was developed and \nimplemented. Aside from evaluation, formative peer assessment seemed important in \nfostering feedback for faculty in their development. \nHughes II & Pate​ (2013): present a multisource evaluation method \nHughes II, K. E., & Pate, G. R. (2013). Moving beyond student ratings: A balanced scorecard \napproach for evaluating teaching performance. Issues in ​Accounting Education, 28​(1), 49-75. \nhttp://dx.doi.org/10.2308/iace-50302 \n[Abstract, abridged] This position paper proposes a viable alternative to higher education’s \ncurrent focus on student ratings as the primary metric for summative teaching evaluations \n(i.e., for personnel decisions). In contrast to the divergent opinions among educational \nresearchers about the validity of student ratings, a strong consensus exists that summative \nmeasures derived from the student ratings process represent a necessary rather than a \nsufficient source for evaluating teaching performance (Cashin 1990; Berk 2005). Accordingly, \nto more completely describe annual teaching performance, we propose a multisource, \nmultiple-perspective Teaching Balanced Scorecard (TBSC), fashioned from the ‘‘classic’’ \nBalanced Scorecard developed by Kaplan and Norton (1992a). The TBSC can guide \nacademic administrators to expand their conceptual view of teaching performance beyond the \nboundaries of the classroom, while coherently communicating the department’s teaching \nexpectations to the faculty; consistent with this proposition, we provide supporting evidence \nfrom a successful TBSC implementation in an academic department. \nIqbal​ (2013): faculty express concerns with peer reviews \nIqbal, I. (2013). Academics’ resistance to summative peer review of teaching: questionable \nrewards and the importance of student evaluations. ​Teaching in Higher Education, 18​(5), \n557-569.​ ​http://dx.doi.org/10.1080/13562517.2013.764863 \n[Abstract, abridged] This study draws from 30 semi-structured interviews with tenure-track \nfaculty members in a research-intensive university to examine their lack of engagement in the \nsummative peer review of teaching. Findings indicate that most academics in the study do not \nthink peer review outcomes contribute meaningfully to decisions about career advancement \nhttp://dx.doi.org/10.1016/j.cptl.2013.02.003\nhttp://dx.doi.org/10.1080/13562517.2013.764863\nhttp://dx.doi.org/10.1080/13562517.2013.764863\nhttp://dx.doi.org/10.2308/iace-50302\nhttp://dx.doi.org/10.1016/j.cptl.2013.02.003\nhttp://dx.doi.org/10.2308/iace-50302\nand believe that, in comparison, student evaluation of teaching scores matter more. The \nfindings suggest that faculty member resistance to summative peer reviews will persist unless \nacademics are confident that the results will be seriously considered in decisions about tenure \nand promotion. \nLyde, Grieshaber, & Byrns​ (2016): a multisource method of evaluating is a useful tool \nLyde, A.R., Grieshaber, D.C., Byrns, G. (2016). Faculty teaching performance: Perceptions of \na multi-source method for evaluation (MME). ​Journal of the Scholarship of Teaching and \nLearning, 16​(3), 82-94.​ ​http://dx.doi.org/10.14434/josotl.v16i3.18145 \n[Abstract, abridged] A holistic system of evaluating university teaching is necessary for \nreasons including the limitations of student evaluations and the complexity of assessing \nteaching performance. University faculty members were interviewed to determine their \nperceptions of the multisource method of evaluating (MME) teaching performance after a \nrevision of policies and procedures was approved. The MME is comprised of three primary \ndata sources: student evaluations, instructor reflections describing attributes of their own \nteaching such as the teaching philosophy, and a formative external review. While the faculty \nperceived the MME as a useful tool, they still believe it operates more to produce a \nsummative product than work as a formative process. According to the results, a more \nformative process would be supported by addressing several factors, including timing of \nreflections, accountability from year to year, and mentoring. Improving these constraints may \nmake the proposed MME a more appropriate tool for formative review of teaching.  \nMarsh & Roche​ (1997): multidimensional aspects of teaching should be evaluated; suggest \nnine factors \nMarsh, H. W., & Roche, L. A. (1997). Making students’ evaluations of teaching effectiveness \neffective: The critical issues of validity, bias, and utility. ​American Psychologist, 52​(11), \n1187-1197. ​http://dx.doi.org/10.1037/0003-066X.52.11.1187 \nThis article has been included in previous themes. For this theme, Marsh & Roche (1997) \nbelieve that effective evaluation tools should consider nine factors: “Learning/Value, Instructor \nEnthusiasm, Organization/Clarity, Group Interaction, Individual Rapport, Breadth of Coverage, \nExaminations/Grading, Assignments/Readings, and Workload/Difficulty” (p.1187). The \nauthors also comment on the nature of “homemade” evaluation instruments being of \nquestionable quality (p. 1188).  \nMartin, Dennehy, & Morgan​ (2013): validity of SET is questioned; student focus groups \nsuggested as an alternative \nMartin, L. R., Dennehy, R., & Morgan, S. (2013). Unreliability in student evaluation of teaching \nquestionnaires: Focus groups as an alternative approach. ​Organization Management Journal, \n10​(1), 66-74.​ ​http://dx.doi.org/10.1080/15416518.2013.781401 \n[Abstract, abridged] Research on the validity and reliability of SETs is vast, though riddled \nhttp://dx.doi.org/10.14434/josotl.v16i3.18145\nhttp://dx.doi.org/10.14434/josotl.v16i3.18145\nhttp://dx.doi.org/10.1080/15416518.2013.781401\nhttp://dx.doi.org/10.1037/0003-066X.52.11.1187\nhttp://dx.doi.org/10.1080/15416518.2013.781401\nwith inconsistencies. The many “myths” of SETs are investigated and the incongruities are \ndemonstrated. We hypothesize that the discrepancies in empirical studies come from \nmisunderstanding and inappropriate actions by students. To address the complexity inherent \nin these problems, we suggest the use of focus groups as an alternative approach or \ncomplement to the standard SETs. A recommended format and guidelines for running \nclassroom focus groups are provided. Institutional constraints and implementation concerns \nare addressed as well. This article lays the foundation for implementing a change in student \nassessment of teaching by proposing a method to compensate for bias in SETs, using focus \ngroups as an evaluation tool, either as a stand-alone process or as a supplement to current \nmethods. \nRidley & Collins​ (2015): suggests a comprehensive performance evaluation instrument \nRidley, D., & Collins, J. (2015). A suggested evaluation metric instrument for faculty members \nat colleges and universities. ​International Journal of Education Research, 10​(1), 97-114. \nRetrieved from \nhttp://eds.a.ebscohost.com.login.ezproxy.library.ualberta.ca/eds/pdfviewer/pdfviewer?sid=9ff2\n4389-d34d-43d1-83fc-6ef82bd1ad47%40sessionmgr4009&vid=2&hid=4102 \n[Abstract, abridged] This study puts forth a comprehensive performance evaluation method \nfor university faculty members. The instrument is comprised of a teaching evaluation metric, a \nresearch evaluation metric, and a service evaluation metric. This study provides a unique \nmethod for measuring the performance of university faculty members by regressing \ncumulative student grade point average on the fraction of the total number of credit hours that \nstudents are taught by each faculty member. The study postulates that the resulting \nregression coefficients measure the average rate at which each faculty member contributes to \nstudent learning as measured by cumulative grade points earned per contact hour of \ninstruction. Since this model of teaching effectiveness is based on grades, freely assigned by \nindividual faculty members, it is a no contact, non-intrusive, non-confrontational, \nnon-threatening, non-coercive evaluation of teaching. \nStupans, McGuren, & Babey​ (2016): present a tool for analyzing free-form comments on \nratings forms \nStupans, I., McGuren, T., & Babey, A. M. (2016). Student evaluation of teaching: A study \nexploring student rating instrument free-form text comments. ​Innovative Higher Education, \n41​(1), 33-52. ​http://10.1007/s10755-015-9328-5 \n[Abstract] Student rating instruments are recognised to be valid indicators of effective \ninstruction, providing a valuable tool to improve teaching. However, free-form text comments \nobtained from the open-ended question component of such surveys are only infrequently \nanalysed comprehensively. We employed an innovative, systematic approach to the analysis \nof text-based feedback relating to student perceptions of and experiences with a recently \ndeveloped university program. The automated nature of the semantic analysis tool \n\"Leximancer\" enabled a critical interrogation across units of study, mining the cumulative text \nfor common themes and recurring core concepts. The results of this analysis facilitated the \nidentification of issues that were not apparent from the purely quantitative data, thus providing \nhttp://eds.a.ebscohost.com.login.ezproxy.library.ualberta.ca/eds/pdfviewer/pdfviewer?sid=9ff24389-d34d-43d1-83fc-6ef82bd1ad47%40sessionmgr4009&vid=2&hid=4102\nhttp://eds.a.ebscohost.com.login.ezproxy.library.ualberta.ca/eds/pdfviewer/pdfviewer?sid=9ff24389-d34d-43d1-83fc-6ef82bd1ad47%40sessionmgr4009&vid=2&hid=4102\na deeper understanding of the curriculum and teaching effectiveness that was constructive \nand detailed. \n[Link from ​Zimmerman​ (2008): some tools may encourage students to focus on negative \naspects of teaching; anonymous feedback means that students are not held accountable for \ntheir comments \nZimmerman, B. (2008). Course evaluations - students’ revenge? ​University Affairs.​ Retrieved \nfrom \nhttp://www.universityaffairs.ca/opinion/in-my-opinion/course-evaluations-students-revenge/ \nThis is an online opinion article.  \n“Even choosing the right questions is difficult. Instead of ‘What did you like least about the \nlectures?’ shouldn’t we be asking, ‘Is there something you liked least about the lectures?’ \nWhen we manipulate students into providing negative responses, we encourage them to cast \nabout for some negative remark, ​any​ negative remark, when they might otherwise have been \ndeclined” (paragraph 7). \n“Many students don’t need any encouragement to bash their teachers. The exercise is meant \nin part to ensure that instructors are held accountable, yet students engage in libel with \nimpunity. The student who referred to a colleague as a “cow” was not held accountable” \n(paragraph 8). \nhttp://www.universityaffairs.ca/opinion/in-my-opinion/course-evaluations-students-revenge/\nAppendix I: Recommendations Related to Evaluation of Teaching from the 2013 \nRenaissance Committee Report \nThese recommendations are taken from pages 11 and 12 of the report. \nSource: ​Cheeseman, C., MacLaren, I., Carey, J., Glanfield, F., Liu, L., McFarlane, L., Cahill, J. \nC., Garneau, T., Supernant, K., & Szeman, I. (2013, December 9). ​Report of the Renaissance \nCommittee.​ Retrieved from ​http://www.renaissance.ualberta.ca/ \n3-2 That all scholars be evaluated using the same evaluation structure, with \nconstituency-specific evaluation committees.  Non-scholarly activities should be evaluated \nseparately. \n3-3 That the number of committees evaluating the excellence of scholarly activities performed \nby a single constituency be substantially reduced from 3 to 6. Such committees will be formed \naround scholarly discipline, not faculty boundaries. Cultural practices within the unit should not \nbe allowed to influence the salary trajectories nor the process by which scholars are evaluated. \n3-4 That there be greater consistency in the size of comparator groups used for evaluation, at \nboth the small and large unit levels. \n3-8 That all scholars, which include tenure-track faculty, librarians, and specialized scholars, be \nevaluated in accordance with the broad definition of Scholarship provided in Section 2 of this \nreport. These constituencies should be evaluated equitably based on the Scholarship \nperformance measures and the extent to which Scholarship comprises a part of their duties. \n3-9 That all scholarly activities be evaluated using more than simple metrics (e.g. Impact \nFactors, USRI); that multifaceted evaluations be applied to all scholarly activities to allow for \nidentification of scholarly excellence.  \n3-11 Establishment of a Teaching Strategy for the University of Alberta that reviews and \nupdates the teaching and learning policies currently in place in the GFC Policy Manual, and \ndetermined implementation of those policies. \n3-12 Creation of specific, transparent policies for teaching evaluation to guide annual reviews, \ncontract renewal decisions, and decisions on tenure and promotion.  (As, for example, \ndelineated in the CAUT model policy on the evaluation of teaching performance, create policies \nand procedures that allow recognition of all aspects of teaching duties performed by academic \nstaff.) \n3-13 Establish a committee to redesign the USRI questions, ensuring a reliable and valid tool \nthat meets international standards for summative evaluation, provides a degree of formative \nfeedback, minimizes the potential for derogatory feedback, ensures value to the students who \nhttp://www.renaissance.ualberta.ca/\nparticipate in the process, and is in alignment with the University’s Teaching Strategy. To \nensure movement on this recommendation, establish a two-year limit on implementation. \n3-14 If changes to the USRI are not accomplished within two years (end of Fall term, 2015), \n(AASUA and Administration) declare a moratorium on their use. \n3-15 Provide leadership, support, and resources further to encourage teaching development \nand teaching Scholarship at the University of Alberta. \n3-16 Standardize reporting periods for all evaluation committees. \n3-22 require all scholarly evaluation committees to use external standards for the assessment of \nScholarship, reaching decisions by reference to agreed-upon external standards rather than to \ncolleagues’ performance.  \nItem No. 9 \nGENERAL FACULTIES COUNCIL \nFor the Meeting of October 30, 2017 \nOUTLINE OF ISSUE \nAction Item \nAgenda Title: Proposed Revisions to Standing Committee Terms of Reference GFC Campus Law \nReview Committee (CLRC) including a name change to GFC Student Conduct Policy Committee \n(SCPC) \nMotion:  THAT General Faculties Council approve the proposed changes to the GFC Campus Law Review \nTerms of Reference including a name change to GFC Student Conduct Policy Committee (SCPC) as set \nforth in Attachment 1, to take effect upon approval. \nItem   \nAction Requested Approval Recommendation   \nProposed by Steven Penney, Chair, GFC Campus Law Review Committee \nPresenter Steven Penney, Chair, GFC Campus Law Review Committee \nDetails \nResponsibility General Faculties Council \nThe Purpose of the Proposal is \n(please be specific) \nTo approve the revised terms of reference for the GFC Campus Law \nReview Committee. \nThe Impact of the Proposal is The committee terms of reference are being amended to reflect the GFC \nprinciples on delegated authority and committee composition approved \nby GFC on April 21, 2017. \nThe Report of the ad hoc Committee on Academic Governance including \nDelegated Authority, endorsed by GFC on April 21, 2017, noted that \nCLRC currently works within a well defined mandate and the delegated \nauthority given to the committee is also well defined. The benefits to \nhaving a Chair with legal training was emphasized in the report and has \nbeen added to the proposed terms of reference. No major changes were \nrecommended.  \nReplaces/Revises (eg, policies, \nresolutions) \nCurrent committee terms of reference. \nTimeline/Implementation Date To be effective upon approval. \nEstimated Cost and funding \nsource \nN/A \nNext Steps (ie.: \nCommunications Plan, \nImplementation plans) \nMembership changes will be phased in to allow current members to \ncomplete their terms. \nReference to the committee name in the Code of Student Behaviour, \nCode of Applicant Behaviour, and Practicum Intervention Policy will be \nchanged effective July 1, 2018. \nSupplementary Notes and \ncontext \nThe proposed terms of reference reflect a standard template that will be \nused for all GFC standing committees which has been designed to \nprovide increased clarity on mandate, responsibilities, and delegated \nauthority.  \nFurther changes to the CLRC terms of reference include: \n1. Reference to student residence codes has been removed in \naccordance with the Board’s delegation of creation and revision of \nthese codes to Residence Services (February 2011).  \nItem No. 9 \nGENERAL FACULTIES COUNCIL \nFor the Meeting of October 30, 2017 \n2. The addition that preference be given for a Chair who has legal \ntraining, which the Committee has discussed and agreed upon \npreviously (CLRC meetings of January 25 and May 25, 2017). \n3. The addition of one elected academic staff member from GFC to the \ncommittee composition in accordance with principle 1 of the \nPrinciples for Standing Committee Composition: \n“Wherever possible, the majority of elected members of each \nstanding committee should be drawn from the membership of \nGFC to provide tangible links between GFC and its standing \ncommittees and increase engagement of the greater GFC \ncommunity.” \n4. The voting status of ex-officio members has been revised to reflect \ntheir voting status in accordance with principle 3 of the Principles for \nStanding Committee Composition on GFC. \n5. The terms will now note that CLRC makes recommendations to \nGeneral Faculties Council, rather than to GFC Executive Committee. \nEngagement and Routing (Include meeting dates) \nParticipation: \n(parties who have seen the \nproposal and in what capacity) \n<For further information see \nthe link posted on the \nGovernance Toolkit section \nStudent Participation Protocol> \nThose who have been informed: \n Campus Law Review Committee \n General Faculties Council \n Board of Governors has been provided with brief highlights of the \nwork of the ad hoc Committee on Academic Governance \nincluding Delegated Authority \nThose who have been consulted: \n Report of the ad hoc Committee on Academic Governance \nIncluding Delegated Authority Appendix 6: List of Consultations \n Campus Law Review Committee \n General Faculties Council \n GFC Executive Committee \nThose who are actively participating: \n ad hoc Committee on Academic Governance Including Delegated \nAuthority \n Campus Law Review Committee \n General Faculties Council \n GFC Executive Committee \nApproval Route (Governance) \n(including meeting dates) \nGFC Campus Law Review Committee - September 28, 2017 \nGFC Executive Committee - October 16, 2017 \nGeneral Faculties Council - October 30, 2017 \nFinal Approver General Faculties Council  \nAlignment/Compliance \nAlignment with Guiding \nDocuments \nFor the Public Good \nObjective 21: Encourage continuous improvement in administrative, \ngovernance, planning, and stewardship systems, procedures, and \npolicies that enable students, faculty, staff, and the institution as a whole \nto achieve shared strategic goals. \nPrinciples for General Faculties Council Delegation of Authority \nhttp://www.governance.ualberta.ca/GovernanceToolkit/Toolkit.aspx\nhttp://www.governance.ualberta.ca/GovernanceToolkit/Toolkit.aspx\nhttp://www.governance.ualberta.ca/~/media/Governance/Documents/GO04/ReportoftheadhoccommitteevEndorsedApril212017.pdf\nhttp://www.governance.ualberta.ca/~/media/Governance/Documents/GO04/ReportoftheadhoccommitteevEndorsedApril212017.pdf\nhttp://www.governance.ualberta.ca/en/~/media/Governance/Documents/GO05/GEN/Linked%20Documents%20on%20GFC%20Home%20Page/Principles_for_Delegation_of_Authority.pdf\nItem No. 9 \nGENERAL FACULTIES COUNCIL \nFor the Meeting of October 30, 2017 \nPrinciples for General Faculties Council Standing Committee \nComposition \nCompliance with Legislation, \nPolicy and/or Procedure \nRelevant to the Proposal \n(please quote legislation and \ninclude identifying section \nnumbers) \n1. Post-Secondary Learning Act (PSLA) \n“Powers of general faculties council” \n26(1) Subject to the authority of the board, a general faculties council \nis responsible for the academic affairs of the university […] \n(3) A general faculties council may delegate any of its powers, duties \nand functions under this Act, including the powers referred to in \nsection 31, as it sees fit and may prescribe conditions governing the \nexercise or performance of any delegated power, duty or function, \nincluding the power of subdelegation.” \n2. GFC Executive Committee Terms of Reference \n“5. Agendas of General Faculties Council  \nGFC has delegated to the Executive Committee the authority to \ndecide which items are placed on a GFC Agenda, and the order in \nwhich those agenda items appear on each GFC agenda.  \nWith respect to recommendations from other bodies and other GFC \ncommittees, however, the role of the Executive Committee shall be to \nexamine and debate the substance of reports or recommendations \nand to decide if an item is ready to be forwarded to the full governing \nbody.” \nAttachment: \n1. Attachment 1:  Draft Terms of Reference \n2. Attachment 2:  Current Terms of Reference \nPrepared by: University Governance \nhttp://www.governance.ualberta.ca/en/~/media/Governance/Documents/GO05/GEN/Linked%20Documents%20on%20GFC%20Home%20Page/Principles_of_Committee_Composition.pdf\nhttp://www.governance.ualberta.ca/en/~/media/Governance/Documents/GO05/GEN/Linked%20Documents%20on%20GFC%20Home%20Page/Principles_of_Committee_Composition.pdf\nUniversity Governance is the official copy holder for files of the Board of Governors, GFC, and their standing committees. \n1 of 3 \nGFC STUDENT CONDUCT POLICY COMMITTEE \nTerms of Reference \n1. Mandate and Role of the Committee\nThe Student Conduct Policy Committee (SCPC) is a standing committee of General Faculties \nCouncil charged with providing oversight to the university’s student discipline codes. The committee \nreviews and recommends on new codes, and policies and procedures related to discipline. SCPC \nmay be called upon to provide advice to the Provost and Vice-President (Academic) on items which \nmay include, but are not limited to, rules and regulations other than discipline codes.    \n2. Areas of Responsibility\na. Review and recommend changes to General Faculties Council on:\n- the Code of Student Behaviour and student discipline procedures \n- the Code of Applicant Behaviour \n- the Practicum Intervention Policy \n- the Residence Community Standards Policy \nb. Discuss annual residence discipline statistics and forward reports to GFC for information.\nc. Discuss annual statistical reports on discipline cases dealt with by Faculties, the Discipline\nOfficer, the Registrar, Unit Directors, the University Appeal Board (UAB), GFC Academic\nAppeals Committee (AAC), and the GFC Practice Review Board (PRB) and forward reports to\nGFC for information.\n3. Composition\nVoting Members (13) \nEx-officio (1) \n-Vice-Provost and Dean of Students \nAppointed (4) \n- 1 academic staff (A1.1, A1.5, A1.6, A1.7) to serve as Chair; appointed by GFC Executive \nCommittee for a two year term. Strong preference is given to an individual with legal training. \n- 1 representative from each of the following (3 total): \n-   Students' Union Executive, appointed by the Students' Union Executive \n- Graduate Students' Association Executive, appointed by the Graduate Students’ \nAssociation Executive \n-   Residences, appointed by Council of Residence Association \nCross Appointed (1) \n-  Dean (or designate) from the GFC Academic Standards Committee (ASC), elected by ASC \nfor a one year term \nElected by GFC (7) \n-  2 student members of GFC (graduate or undergraduate)  \n-  2 academic staff (A1.1, A1.5, A1.6, A1.7) at least 1 of whom is a member of GFC  \n- 1 academic staff (A1.1, A1.5, A1.6 , A1.7) who is a former Associate Dean or a former \nUniversity Appeals Board (UAB) Chair \n-  2 staff members (A1.0, A2.0 and/or S1.0, S2.0) \nNote: The Vice-Chair will be appointed by the GFC Executive Committee from amongst the \nelected academic staff (A1.1, A1.5, A1.6, A1.7) of SCPC for a one year term. \nAttachment 1\nGFC STUDENT CONDUCT POLICY COMMITTEE \nTerms of Reference  \nUniversity Governance is the official copy holder for files of the Board of Governors, GFC, and their standing committees.  \n2 of 3 \nNon-Voting Members \n-  Discipline Officer  \n- Appeals Coordinator as defined in the Code of Student Behaviour, Code of Applicant \nBehaviour and the Practicum Intervention Policy \n-  Director of University of Alberta Protective Services \n-  Assistant Dean of Students (Residence) \n-  GFC Secretary   \n-  University Secretary \n-  Representative from the Office of the Student Ombuds  \n4. Delegated Authority from General Faculties Council \nShould be reviewed at least every three years and reported to GFC. \n4.1  Approve editorial amendments to: \na. the Code of Student Behaviour (except as listed under 7. Limitations to Authority)  \nb. the Code of Applicant Behaviour (except as listed in 7. Limitations to Authority)  \nc. the Practicum Intervention Policy (except as listed in 7. Limitations to Authority)  \n5. Responsibilities Additional to Delegated Authority \n5.1  To recommend to GFC on proposals for substantive changes to the Code of Student \nBehaviour, the Code of Applicant Behaviour, and the Practicum Intervention Policy.  \n6. Sub-delegations from GFC SCPC \nShould be reviewed at least every three years and reported to GFC. \nNone. \n7. Limitations to Authority \nThe following further refines or places limitations on authorities held by or delegated to SCPC: \n7.1 Substantive Amendments, as determined by SCPC, are forwarded to General Faculties \nCouncil for recommendation to the Board of Governors: \na. the Code of Student Behaviour  \nb. the Code of Applicant Behaviour  \nc. the Practicum Interventon Policy  \n7.2  All Amendments to the following sections are forwarded to General Faculties Council for \nrecommendation to the Board of Governors: \na.  the Code of Student Behaviour  \n30.6: Procedures for Appeal of Decisions to the University Appeal Board (UAB) \nb. the Code of Applicant Behaviour  \n11.8.9: Appeals Against Decisions of the Registrar \nc. the Practicum Intervention Policy \n87.5: Appeals to the GFC Practice Review Board (PRB) \n87.6: GFC PRB Terms of Reference, Powers and Jurisdiction \n87.7: Composition of the GFC PRB \n87.8: Procedures Prior to GFC PRB Hearings \n87.9: Procedures at the GFC PRB Hearing \n87.10: Confidentiality of Hearing and Material) \nGFC STUDENT CONDUCT POLICY COMMITTEE \nTerms of Reference  \nUniversity Governance is the official copy holder for files of the Board of Governors, GFC, and their standing committees.  \n3 of 3 \n8. Reporting to GFC \nThe Committee should regularly report to GFC with respect to its activities and decisions. \n9. Definitions \nEditorial and Substantive – The Student Conduct Policy Committee determines which amendments are \neditorial and which are substantive. \nAcademic staff – as defined by the Recruitment Policy (Appendix A) Definition and Categories of \nAcademic Staff, Administrators and Colleagues in UAPPOL \nNon-Academic staff – as defined by the Recruitment Policy (Appendix B) Definition and Categories of \nSupport Staff in UAPPOL \n10. Links \nCode of Student Behaviour \nCode of Applicant Behaviour \nPracticum Intervention Policy \nResidence Community Standards  \nApproved by General Faculties Council: <> \nhttps://policiesonline.ualberta.ca/PoliciesProcedures/Procedures/Recruitment-Policy-Appendix-A-Definition-and-Categories-of-Academic-Staff-Administrators-and-Colleagues.pdf\nhttps://policiesonline.ualberta.ca/PoliciesProcedures/Procedures/Recruitment-Policy-Appendix-A-Definition-and-Categories-of-Academic-Staff-Administrators-and-Colleagues.pdf\nhttps://policiesonline.ualberta.ca/PoliciesProcedures/Procedures/Recruitment-Policy-Appendix-B-Definition-and-Categories-of-Support-Staff.pdf\nhttps://policiesonline.ualberta.ca/PoliciesProcedures/Procedures/Recruitment-Policy-Appendix-B-Definition-and-Categories-of-Support-Staff.pdf\nhttp://www.governance.ualberta.ca/CodesofConductandResidenceCommunityStandards/%7E/media/Governance/Documents/Codes%20of%20Conduct%20and%20Residence%20Community%20Standards/Code%20of%20Student%20Behaviour/COSB-Updated-May-30-2016.pdf\nhttp://www.governance.ualberta.ca/CodesofConductandResidenceCommunityStandards/%7E/media/Governance/Documents/Codes%20of%20Conduct%20and%20Residence%20Community%20Standards/Code%20of%20Applicant%20Behaviour/COAB-Updated-May-30-2016.pdf\nhttp://www.governance.ualberta.ca/StudentAppeals/%7E/media/Governance/Documents/SA03/Practicum%20Intervention%20Policy/PIP-Updated-May-30-2016.pdf\nhttp://www.governance.ualberta.ca/CodesofConductandResidenceCommunityStandards/%7E/media/Governance/Documents/Codes%20of%20Conduct%20and%20Residence%20Community%20Standards/Residence%20Community%20Standards%20-%20PR01/Community-standards-policy-Feb2016.pdf\nGFC Campus Law Review Committee Terms of Reference \n1. Authority\nThe Post-Secondary Learning Act gives General Faculties Council (GFC) responsibility, subject to the \nauthority of the Board of Governors, over \"academic affairs\" (section 26(1)) and \"general supervision of \nstudent affairs\" (section 31), including authority concerning \"student discipline.\" GFC has thus \nestablished a Campus Law Review Committee (GFC CLRC) and a University Appeal Board (GFC \nUAB), as set out below.  \nThe complete wording of the section(s) of the Post-Secondary Learning Act, as referred to above, and \nany other related sections, should be checked in any instance where formal jurisdiction needs to be \ndetermined. \n2. Composition of the Committee\nThe GFC Executive Committee will appoint a faculty member to chair the CLRC, and the faculty \nmember will be appointed for more than two years in order to provide continuity. The Chair may be \nappointed from among the elected faculty members of the CLRC or may be appointed at-large from \ncategories A1.1 and A1.6 and their counterparts in A1.5 and A1.7*.  If the Chair is appointed from \namong the faculty members on the CLRC, upon appointment by the GFC Executive Committee that \nseat shall be declared vacant, to be replenished by GFC. (EXEC 30 JUN 2000) (EXEC 04 DEC 2006) \nThe GFC Executive Committee also appoints the Vice-Chair of the CLRC. The Vice-Chair must be \nappointed from among the elected faculty members of the CLRC. (EXEC 08 APR 2002) (EXEC 04 \nDEC 2006) \nOne non-student member of the Committee must have legal training.  (EXEC 04 DEC 2006) \nEx Officio  \nDiscipline Officer (EXEC 09 SEP 2002) \nVice-Provost and Dean of Students  \nDirector of Campus Security Services  \nDirector of Residence Services \nOne representative from each of the following:  \n- Students' Union Executive or their designee, appointed by the Students' Union Executive  \n- Graduate Students' Association, appointed by the GSA Executive  \n- Residences, elected by the University of Alberta Residence Hall Association \n- Student Ombudservice, to be appointed by the members of the Student Ombudservice (EXEC 09 \nDEC 2002) \nElected by GFC  \nTwo students-at-large (graduate or undergraduate)  \nOne staff member elected from Categories A1.1 and A1.6 and their counterparts in A1.5 and A1.7* \n(EXEC 03 MAY 2010) \nOne staff member elected from Categories A1.1 and A1.6 and their counterparts in A1.5 and A1.7* who \nis a current Associate Dean (EXEC 03 MAY 2010) \nOne staff member elected from Categories A1.1 and A1.6 and their counterparts in A1.5 and A1.7* who \nis a former Associate Dean or a former Discipline Officer or a former University Appeals Board (UAB) \nChair \n(EXEC 03  MAY 2010) \nTwo staff members selected from Categories A1.0, A2.0 and/or S1.0* and S2.0* (EXEC 04 DEC 2006) \n1 \nAttachment 2\nNon-voting Resource Members \nAppeals Coordinator, University Appeal Board  \nDirector, General Faculties Council Services and Secretary to GFC  \nDean (or designate) cross-representative from the GFC Academic Standards Committee (ASC), \nappointed by the Chair of GFC ASC \n* See UAPPOL Recruitment Policy (Appendixes A) Definition and Categories of Academic Staff and \nColleagues and (Appendix B) Definition and Categories of Support Staff for definitions of these \ncategories of staff. \n3. Mandate of the Committee \nA. Code of Student Behavior  \n1. To review, from time to time, the Code of Student Behavior and student discipline \nprocedures.  \n2. On delegated authority from GFC, to approve all editorial amendments to the Code of \nStudent Behaviour except editorial amendments to Section 30.6. (EXEC 02 MAY 2005) \n3. Amendments to the Code of Student Behaviour deemed substantive by CLRC are forwarded \nto the GFC Executive Committee, which will decide whether or not it can act on behalf of GFC.  \n(See Amendment of the Code, Section 30.7 of the GFC Policy Manual (Code of Student \nBehaviour.)) \nB. Code of Applicant Behavior  \n1. To review, from time to time, the Code of Applicant Behaviour. \n2. On delegated authority from GFC, to approve all editorial amendments to the Code of \nApplicant Behaviour except editorial amendments to Section 11.8.8. (EXEC 02 MAY 2005) \n3. Amendments to the Code of Applicant Behaviour deemed substantive by CLRC are \nforwarded to the GFC Executive Committee, which will decide whether or not it can act on \nbehalf of GFC.  (See Amendment of the Code of Applicant Behaviour, Section 11.8.9 of the \nGFC Policy Manual.) \nC. Practicum Intervention Policy \n1. To review, from time to time, the Practicum Intervention Policy  (EXEC 02 MAY 2005) (GFC \n31 MAR 2008) (EXEC 02 MAR 2009) \n2. On delegated authority from GFC, to approve all editorial amendments to the Practicum \nIntervention Policy as noted in Section 87.14. (EXEC 02 MAY 2005) (EXEC 02 MAR 2009) \nD. Residence Codes and Community Standards  \n1. To review, from time to time, the community standards of the University student residence \nassociations, with a full review of Residence Community Standards to be considered every \nthree years (beginning in 2005).  \n2. New student residence codes shall be submitted to the GFC Campus Law Review Committee \nwhich will make a recommendation to the GFC Executive Committee. The GFC Executive has \nthe delegated authority from General Faculties Council to approve new residence codes.  \n3. Any changes to existing student residence codes shall be submitted to the GFC Campus Law \nReview Committee. The CLRC has the delegated authority from General Faculties Council to \napprove changes which in its view are editorial or minor; all such approvals will be filed with the \nGFC Executive Committee. Any major changes to existing student residence codes shall be \nforwarded with the recommendation of the CLRC to the GFC Executive for final approval.  \n2 \nE. Other GFC Regulations  \n1. From time to time the Chair of GFC CLRC will bring forward to GFC CLRC items where the \nOffice of the Provost and Vice-President (Academic), in consultation with other units or officers \nof the University, is seeking the advice of the committee. These matters may include, but are \nnot limited to, rules and regulations, other than discipline codes. (EXEC 02 MAY 2005) \n4. Committee Procedures \nQuorum \nThe quorum for the Campus Law Review Committee shall conform to the quorum requirements \nset out in the General Terms of Reference - Standing and Other Committees of General \nFaculties Council (GFC) General Terms of Reference, with at least two voting members from \neach of the following three groups of members:  \n- ex officio members who hold administrative positions;  \n- ex officio and elected students;  \n- elected staff. (GFC 22 JUN 1987)(EXEC 23 JUL 1990) \n5.  Reporting Requirements \nResidence Discipline Reports: To receive annually reports from the student residence associations \non the number and disposition of discipline cases in the residences, and forward the reports to the GFC \nExecutive Committee. (EXEC 14 JUL 1997)  \nAny student residence with a code or similar set of regulations is required to report annually on the \noperation of that code to General Faculties Council through its Campus Law Review Committee and its \nExecutive Committee. (GFC 22 SEP 1997)  \nDiscipline Cases: University Governance has been asked by the GFC Executive to attempt to have all \nappeal Boards (UAB, GFC AAC and GFC PRB) report to GFC at the same meeting, through the GFC \nCampus Law Review Committee (CLRC).  (EXEC 02 MAR 2009) \nThe Appeals Coordinator on behalf of the Campus Law Review Committee will submit annually to GFC \nin the fall, statistical information on discipline cases dealt with by Faculties, the Discipline Officer, the \nRegistrar, Unit Directors, the University Appeal Board and the GFC Practice Review Board. The \ndiscipline reports will include the year of the student, the offence with which they were charged and the \noutcome, but not any personally identifying information.  When reporting statistics for applicants, the \noffence with which the applicant is charged and the outcome, but not any personally identifying \ninformation, will be provided.  As far as is practical, comparative information from the most recent \nreporting period will be included. (EXEC 10 DEC 1990) (EXEC 15 MAY 1995) (EXEC 14 JAN \n2001)(EXEC 08 APR 2002) (EXEC 02 MAR 2009) \nThe Appeals Coordinator shall place an ad in the Gateway in the fall and spring.  The ad can target a \nparticular area of concern or provide educational information regarding student discipline.  These \nmaterials may also appear in other University publications. (EXEC 02 MAR 2009) \nR:\\GO04 General Faculties Council - General\\PRO\\TER\\CAM\\Campus-Law-Review-Committee-Amended.doc \n3 \nItem No. 10 \nGENERAL FACULTIES COUNCIL \nFor the Meeting of October 30, 2017 \nOUTLINE OF ISSUE \nAction Item \nAgenda Title: Proposed Revisions to Standing Committee Terms of Reference - GFC Facilities \nDevelopment Committee (FDC) \nMotion:  THAT General Faculties Council approve the proposed changes to the GFC Facilities Development \nCommittee Terms of Reference as set forth in Attachment 1, to take effect upon approval. \nItem   \nAction Requested Approval Recommendation   \nProposed by Wendy Rodgers, Chair \nPresenter Wendy Rodgers, Chair \nDetails \nResponsibility General Faculties Council \nThe Purpose of the Proposal is \n(please be specific) \nTo approve the revised terms of reference for the GFC Facilities \nDevelopment Committee (FDC). \nThe Impact of the Proposal is The committee terms of reference are being amended to reflect the GFC \nprinciples on delegated authority and committee composition approved \nby GFC on April 21, 2017. \nThe Report of the ad hoc Committee on Academic Governance including \nDelegated Authority, endorsed by GFC on April 21, 2017, did not \nrecommend any substantive changes to the GFC FDC terms of \nreference. \nReplaces/Revises (eg, policies, \nresolutions) \nCurrent committee terms of reference. \nTimeline/Implementation Date To be effective upon approval. \nEstimated Cost and funding \nsource \nN/A \nNext Steps (ie.: \nCommunications Plan, \nImplementation plans) \nMembership changes will be phased in to allow current members to \ncomplete their terms. Therefore, as the terms of the elected academic \nstaff and elected student members expire, these positions will be filled, \nwherever possible, with elected GFC members. \nSupplementary Notes and \ncontext \nThe proposed terms of reference reflect a standard template that will be \nused for all GFC standing committees which has been designed to \nprovide increased clarity on mandate, responsibilities, and delegated \nauthority.  \nFurther changes to the FDC terms of reference include: \n1. Various changes to update office names and position titles for \nmembers \n2. Reference to the Long Range Development Plan (LRDP) and \njoint-use facilities \n3. The inclusion of a comprehensive Definitions section and links to \nrelevant institutional policies and procedures \n4. Stipulation that three of the five academic staff members must be \na members of GFC, as per Principle 1 of the Principles for \nStanding Committee Composition: \n“Wherever possible, the majority of elected members of each \nItem No. 10 \nGENERAL FACULTIES COUNCIL \nFor the Meeting of October 30, 2017 \nstanding committee should be drawn from the membership of \nGFC to provide tangible links between GFC and its standing \ncommittees and increase engagement of the greater GFC \ncommunity.” \n5. The voting status of ex-officio members has been revised to \nreflect their voting status in accordance with principle 3 of the \nPrinciples for Standing Committee Composition on GFC. \nEngagement and Routing (Include meeting dates) \nParticipation: \n(parties who have seen the \nproposal and in what capacity) \n<For further information see \nthe link posted on \nthe Governance Toolkit section \nStudent Participation Protocol> \nThose who have been informed: \n• Facilities Development Committee \n• General Faculties Council \n• Board of Governors has been provided with brief highlights of the \nwork of the ad hoc Committee on Academic Governance \nincluding Delegated Authority \nThose who have been consulted: \n• Report of the ad hoc Committee on Academic Governance \nIncluding Delegated Authority Appendix 6: List of Consultations \n• Facilities Development Committee \n• General Faculties Council \n• GFC Executive Committee \nThose who are actively participating: \n• ad hoc Committee on Academic Governance Including Delegated \nAuthority \n• Facilities Development Committee \n• General Faculties Council \n• GFC Executive Committee \nApproval Route (Governance) \n(including meeting dates) \nGFC Facilities Development Committee (September 28, 2017) \nGFC Executive Committee (October 16, 2017) \nGeneral Faculties Council (October 30, 2017) \nFinal Approver General Faculties Council  \nAlignment/Compliance \nAlignment with Guiding \nDocuments \nFor the Public Good \nObjective 21: Encourage continuous improvement in administrative, \ngovernance, planning, and stewardship systems, procedures, and \npolicies that enable students, faculty, staff, and the institution as a whole \nto achieve shared strategic goals. \nPrinciples for General Faculties Council Delegation of Authority \nPrinciples for General Faculties Council Standing Committee \nComposition \nCompliance with Legislation, \nPolicy and/or Procedure \nRelevant to the Proposal \n(please quote legislation and \ninclude identifying section \nnumbers) \n1. Post-Secondary Learning Act (PSLA) \n“Powers of general faculties council” \n26(1) Subject to the authority of the board, a general faculties council \nis responsible for the academic affairs of the university […] \n(3) A general faculties council may delegate any of its powers, duties \nhttp://www.governance.ualberta.ca/GovernanceToolkit/Toolkit.aspx\nhttp://www.governance.ualberta.ca/GovernanceToolkit/Toolkit.aspx\nhttp://www.governance.ualberta.ca/%7E/media/Governance/Documents/GO04/ReportoftheadhoccommitteevEndorsedApril212017.pdf\nhttp://www.governance.ualberta.ca/%7E/media/Governance/Documents/GO04/ReportoftheadhoccommitteevEndorsedApril212017.pdf\nhttp://www.governance.ualberta.ca/en/%7E/media/Governance/Documents/GO05/GEN/Linked%20Documents%20on%20GFC%20Home%20Page/Principles_for_Delegation_of_Authority.pdf\nhttp://www.governance.ualberta.ca/en/%7E/media/Governance/Documents/GO05/GEN/Linked%20Documents%20on%20GFC%20Home%20Page/Principles_of_Committee_Composition.pdf\nhttp://www.governance.ualberta.ca/en/%7E/media/Governance/Documents/GO05/GEN/Linked%20Documents%20on%20GFC%20Home%20Page/Principles_of_Committee_Composition.pdf\nItem No. 10 \nGENERAL FACULTIES COUNCIL \nFor the Meeting of October 30, 2017 \nand functions under this Act, including the powers referred to in \nsection 31, as it sees fit and may prescribe conditions governing the \nexercise or performance of any delegated power, duty or function, \nincluding the power of subdelegation.” \n2. GFC Executive Committee Terms of Reference \n“5. Agendas of General Faculties Council  \nGFC has delegated to the Executive Committee the authority to \ndecide which items are placed on a GFC Agenda, and the order in \nwhich those agenda items appear on each GFC agenda.  \nWith respect to recommendations from other bodies and other GFC \ncommittees, however, the role of the Executive Committee shall be to \nexamine and debate the substance of reports or recommendations \nand to decide if an item is ready to be forwarded to the full governing \nbody.” \nAttachment: \n1. Attachment 1:  Draft Terms of Reference \n2. Attachment 2: Current Terms of Reference  \nPrepared by: University Governance \nUniversity Governance is the official copy holder for files of the Board of Governors, GFC, and their standing committees. \n1 of 3 \nGFC FACILITIES DEVELOPMENT COMMITTEE \nTerms of Reference \n1. Mandate and Role of the Committee\nThe GFC Facilities Development Committee (FDC) is a standing committee of GFC with delegated \nauthority to make recommendations to General Faculties Council and the Board of Governors. The \ncommittee reviews and recommends on general space and functional programs, the design and \nuse of facilities, and policies related to facilities and planning. \nIn addition, the President, Provost and Vice-President (Academic), and the Vice-President \n(Facilities and Operations) may refer matters to FDC for consideration or advice. \n2. Areas of Responsibility\na. Policy with respect to planning and facilities\nb. General Space Programs for Academic Units\nc. Design and use of all new facilities and repurposing of existing facilities\nd. Other matters within the purview of the committee\n3. Composition\nVoting Members (13) \nEx Officio (5) \n- Provost and Vice-President (Academic), Chair \n- Vice-President (Facilities and Operations)  \n- Vice-President (Academic), Students' Union  \n- Vice-President (Academic), Graduate Students' Association \n- Vice-Provost and University Registrar  \nElected by GFC (7) \n- 5 academic staff (A1.0), of which 3 are members of GFC (with no more than one \nrepresentative from any Faculty); one of whom will be elected by the committee to serve \nas Vice-Chair for a one year term \n- 1 non-academic staff (S1.0, S2.0)  \n- 1 undergraduate student member of GFC \nCross Appointed (1) \n- 1 academic staff member of the GFC Academic Planning Committee (APC) elected by \nAPC to serve a one year term \nNon-voting Members \n- University Architect  \n- Associate Vice-President (Facilities and Operations) \n- University Secretary \n- GFC Secretary \n4. Delegated Authority from General Faculties Council and/or the Board of Governors\nShould be reviewed at least every three years and reported to GFC.\n4.1  To approve proposed General Space Programs for academic units \n4.2  To approve proposals concerning the design and use of all new facilities and the repurposing of \nexisting facilities and to routinely report these decisions for information to the Board of \nGovernors. In considering such proposals, FDC may provide advice, upon request, to the \nAttachment 1\nUniversity Governance is the official copy holder for files of the Board of Governors, GFC, and their standing committees.  \n2 of 3 \nGFC FACILITIES DEVELOPMENT COMMITTEE \nTerms of Reference  \n Provost and Vice-President (Academic), Vice-President (Facilities and Operations), and/or the \nUniversity Architect on the siting of such facilities.   \n5. Responsibilities Additional to delegated Authority \nFDC is responsible for making recommendations to APC concerning policy matters with respect to the \nfollowing:  \n5.1  Planning  \na. Comprehensive facilities development plan \nb. Long Range Development Plan (LRDP) \n5.2  Facilities \na. Planning and use of physical facilities including parking facilities and transportation \nb. Use of land owned or leased by the University \nc. Standards, systems and procedures for planning and designing physical facilities \n5.3  Other \na. Any other matter deemed by FDC to be within the purview of its general responsibility.  \nTo initiate studies and make reports and recommendations on matters within the purview of FDC \n6. Sub-Delegations from GFC Facilities Development Committee \nShould be reviewed at least every three years and reported to GFC. \nNone. \n7. Limitations to Authority \nThe following further refines or places limitations on authorities held by or delegated to FDC: \nNone. \n8. Reporting to GFC \nThe Committee should regulary report to GFC with respect to its activities and decisions. \n9. Definitions \nUniversity Facilities:  All lands, buildings, and space owned, operated, or leased by or from the \nUniversity of Alberta. (as per UAPPOL) \nGeneral Space Program:  A general space program describes the current state of an academic, \nresearch and/or administrative unit's activities in terms of their space needs, including student, staffing \nand support requirements. A space program includes a space budget that outlines how much space the \nunit has currently, how much it will require in the near future, and also predicts what amount of space \nmay be required over a long-term planning period. (as per UAPPOL) \nRepurposing:  Significant changes to the use of a facility, as determined by the Vice-President (Facilities \nand Operations) or delegate.  \nSpace/Systems Renewal:  Upgrades and improvements to space that involve renewed surface finishes \nand systems improvements. Renewal projects would apply to areas in which there is no change in use \nand would be used to upgrade large base building system deferred maintenance issues in order to \nsupport current usage and operation. Examples of renewal include the following: repairs as repainting, \nUniversity Governance is the official copy holder for files of the Board of Governors, GFC, and their standing committees.  \n3 of 3 \nGFC FACILITIES DEVELOPMENT COMMITTEE \nTerms of Reference  \n replacement of flooring, replacing of piping, replacement of air systems, rebuilding of sidewalks, or \nupgrading a building envelope. (as per UAPPOL) \nRenovation or Alteration:  Any physical change to space that relates to more than renewed surface \nfinishes. (as per UAPPOL) \nMajor Maintenance:  Unplanned repairs and replacement that must be accomplished, but that is not \nfunded by normal maintenance resources received in the annual operating budget cycle, and includes \nsignificant repairs and building system/component replacement in-kind. Examples include replacement \nof skylights, fire alarm systems, complete replacement of flooring for a department. (as per UAPPOL) \nRepairs:  Work to restore damaged or worn-out facilities (e.g., large-scale roof replacement after a wind \nstorm) to normal operating condition. (as per UAPPOL) \nAcademic Staff:  As defined by the Recruitment Policy (Appendix A) Definition and Categories of \nAcademic Staff, Administrators and Colleagues in UAPPOL \nNon-Academic Staff: As defined by the Recruitment Policy (Appendix B) Definition and Categories of \nSupport Staff in UAPPOL \n10.  Links \nPlanning and Renovation of Existing Facilities Policy \nLong Range Development Plan (LRDP) \nSector Plans \nCurrent Construction Projects \nApproved by General Faculties Council: <> \nhttps://policiesonline.ualberta.ca/PoliciesProcedures/Procedures/Recruitment-Policy-Appendix-A-Definition-and-Categories-of-Academic-Staff-Administrators-and-Colleagues.pdf\nhttps://policiesonline.ualberta.ca/PoliciesProcedures/Procedures/Recruitment-Policy-Appendix-A-Definition-and-Categories-of-Academic-Staff-Administrators-and-Colleagues.pdf\nhttps://policiesonline.ualberta.ca/PoliciesProcedures/Procedures/Recruitment-Policy-Appendix-B-Definition-and-Categories-of-Support-Staff.pdf\nhttps://policiesonline.ualberta.ca/PoliciesProcedures/Procedures/Recruitment-Policy-Appendix-B-Definition-and-Categories-of-Support-Staff.pdf\nhttps://policiesonline.ualberta.ca/policiesprocedures/policies/planning-and-renovation-of-existing-facilities-policy.pdf\nhttp://www.facilities.ualberta.ca/Planning_Project_Delivery/University_Architect/%7E/media/facilities/Documents/PlanningProjDelDOCS/LRDP_2002.pdf\nhttps://facilities.sitecore.ualberta.ca/FormsAndDocuments/DDSForms/CampusPlanningDocs.aspx#SectorPlans\nhttp://www.facilities.ualberta.ca/Planning_Project_Delivery/ConstProjects.aspx\nGFC Facilities Development Committee Terms of Reference \n1. Authority\nThe Post-Secondary Learning Act gives General Faculties Council (GFC) responsibility, subject \nto the authority of the Board of Governors, over \"academic affairs\" (section 26(1)), and provides \nthat GFC may make recommendations to the Board of Governors on a \"building program\" \n(section 26(1)(o)). Section 19 requires that the Board of Governors “consider the \nrecommendations of the general faculties council, if any, on matters of academic import prior to \nproviding for (a) the support and maintenance of the university, (b) the betterment of existing \nbuildings, (c) the construction of any new buildings the board considers necessary to the \npurposes of the university.”  GFC has thus established a Facilities Development Committee \n(FDC), as set out below. Subject to the authority of the Board of Governors, GFC delegates \ncertain of its powers to its Facilities Development Committee. \nThe complete wording of the section(s) of the Post-Secondary Learning Act, as referred to, \nshould be checked in any instance where formal jurisdiction needs to be determined. \n2. Composition of the Committee\nChair - Provost and Vice-President (Academic) or Delegate (Ex Officio Member) \nNote Regarding the Vice-Chair – The Vice-Chair will be appointed by the GFC Executive \nCommittee from among the faculty members on FDC. \nEx Officio (see above): \nStudents' Union Vice-President (Academic) or Delegate \nGraduate Students' Association Vice-President (Academic) or Delegate \nVice-President (Facilities and Operations) or Delegate (EXEC 03 FEB 2003) \nMembers Elected by GFC \nFive members from Category A1.0*, plus one cross-representative appointed by the Chair of \nAPC from that committee.  There shall be no more than one representative from any Faculty \n(except for the cross-representative).   \nOne member of the support staff (Categories S1.0 and S2.0*), elected by GFC \nOne undergraduate student (EXEC 14 JUN 2004) \nNon-voting members: \nDirector of Engineering Infrastructure or Delegate  \nUniversity Architect or Delegate \nAssociate Vice-President (Facilities and Operations) \nVice-Provost and University Registrar or Delegate (EXEC 23 JUN 2003) \n* See UAPPOL Recruitment Policy (Appendix A) Definition and Categories of Academic Staff\nand Colleagues and (Appendix B) Definition and Categories of Support Staff for definitions of \nthese categories of staff. \n3. Mandate of the Committee\n1. Policy Matters\nAttachment 2\nThe Facilities Development Committee is responsible for making recommendations to the \nAcademic Planning Committee or the Board of Governors concerning policy matters with \nrespect to the following. (GFC 29 SEP 2003) \nA.    Planning \n1.     Comprehensive facilities development plan. \nB.    Facilities \n1.    Planning and use of physical facilities, including parking facilities and transportation. \n(GFC 29 SEP 2003) \n2.   Use of land owned or leased by the University. \n3.   Standards, systems and procedures for planning and designing physical facilities. \nC.    Other \nAny other matter deemed by the FDC to be within the purview of its general \nresponsibility. \n2.  Delegation of Authority \nNotwithstanding anything to the contrary in the terms of reference above, the Board of \nGovernors and General Faculties Council have delegated to the Facilities Development \nCommittee the following powers and authority: \nA.    Facilities \n1.  To approve proposed General Space Programmes (Programs) for academic units. \n2.     (i)  To approve proposals concerning the design and use of all new facilities and the \nrepurposing of existing facilities and to routinely report these decisions for \ninformation to the Board of Governors.   \n(ii)  In considering such proposals, GFC FDC may provide advice, upon request, to \nthe Provost and Vice-President (Academic), Vice-President (Facilities and \nOperations), and/or the University Architect (or their respective delegates) on the \nsiting of such facilities.  (GFC SEP 29 2003) \nB.  Other Matters \nThe Chair of FDC will bring forward to FDC items where the Office of the Provost and \nVice-President (Academic) and/or the Office of the Vice-President (Facilities and \nOperations), in consultation with other units or officers of the University, is seeking the \nadvice of the Committee.  \nC.   Studies \nIn light of the academic priorities set by General Faculties Council, to initiate studies, and \nrespond to requests for studies, opinion, and information within the purview of its general \nresponsibilities and make reports and recommendations to the appropriate office or \ncommittee. (GFC 29 SEP 2003) \nD.  Sub-Delegation  \nTo appoint such subcommittees, and to delegate to such subcommittees or to the Vice-\nPresident (Facilities and Operations) such of its powers, duties and functions, or any part \nthereof, including the power of sub-delegation and subject to such conditions as it deems \nnecessary. (GFC 29 SEP 2003) \n4. Committee Procedures \nSee General Terms of Reference. \n5. Additional Reporting Requirements \nNone. \nR:\\GO04 General Faculties Council - General\\PRO\\TER\\FAC\\Facilities-Development-Committee-Amended.doc \nItem No. 11 \nGENERAL FACULTIES COUNCIL \nFor the Meeting of October 30, 2017 \nOUTLINE OF ISSUE \nInformation Item \nAgenda Title: Proposed Changes to the Admission of Aboriginal Students Calendar Section and \nupdates to Faculty Sections \nMotion:  THAT  General Faculties Council approve the proposed changes to the calendar sections related to \nthe admission of First Nations, Métis and Inuit students as set forth in Attachments 1 and 2, and as \nrecommended by the GFC Academic Planning Committee and the GFC Academic Standards Committee, to \ntake effect in 2018/19. \nItem \nAction Requested Approval Recommendation \nProposed by Lisa Collins, Vice-Provost and University Registrar \nPresenter Lisa Collins, Vice-Provost and University Registrar \nChris Andersen, Dean, Faculty of Native Studies \nDetails \nResponsibility Provost and Vice-President (Academic) \nThe Purpose of the Proposal is \n(please be specific) \nTo update impacted calendar sections on Aboriginal Admissions. \nThe Impact of the Proposal is In order to achieve consistency across Faculties, calendar sections are \nbeing updated to indicate that proof of Aboriginal identity will be required. \nReplaces/Revises (eg, policies, \nresolutions) \nImpacted sections of the University of Alberta Calendar. \nTimeline/Implementation Date For implementation and publication in the 2018/19 University Calendar. \nEstimated Cost and funding \nsource \nN/A \nNext Steps (ie.: \nCommunications Plan, \nImplementation plans) \nThe Council on Aboriginal Initiatives requested that a First Nations, \nMetis, Inuit (FNMI) Working Group review the Admission of Aboriginal \nStudents calendar entry and prepare any recommended changes. This \nwill be communicated back to CAI at their next meeting. \nSupplementary Notes and \ncontext \nFaculty specific sections were approved by faculty councils. \nEngagement and Routing (Include meeting dates) \nParticipation: \n(parties who have seen the \nproposal and in what capacity) \n<For further information see \nthe link posted on \nthe Governance Toolkit section \nStudent Participation Protocol> \nThose who have been informed: \n• \nThose who have been consulted: \nOctober 27, 2014 - FNMI Definitions Working Group (Subcommittee of \nthe Council on Aboriginal Initiatives) – Collaboration on changes \nNovember 17, 2014 - Vice-Provosts’ Council - Advice \nDecember 1, 2014 – Vice Provosts’ Council - Advice \nDecember 11, 2014 -Council on Aboriginal Initiatives – \nReporting/Consultation \nFebruary 2, 2015 – Aboriginal Students’ Association – Consultation \nFebruary 9 , 2015 – Native Studies Students’ Association - Consultation \nFebruary 10, 2015 - University Legal Counsel - Advice \nFebruary 13, 2015 – Council on Aboriginal Initiatives - \nhttp://www.governance.ualberta.ca/GovernanceToolkit/Toolkit.aspx\nhttp://www.governance.ualberta.ca/GovernanceToolkit/Toolkit.aspx\nItem No. 11 \nGENERAL FACULTIES COUNCIL \nFor the Meeting of October 30, 2017 \nReporting/Consultation \nMarch 9, 2015 – Safe Disclosure and Human Rights - Advice \nApril 1, 2015 – Faculty of Medicine and Dentistry Indigenous Health \nInitiatives - Consultation \nMay 5, 2015 - Students’ Union - Consultation \nMay 5, 2015 - Graduate Students Association – Consultation \nNovember 16, 2015 - Consultation with Catherine Bell, Faculty of Law  \nNovember 10,2015 Consultation with Faculty of Rehabilitation Medicine \nNovember 17, 2015 – Law Faculty Councils – Approval \nNovember 17, 2015 – Medicine and Dentistry Faculty Councils – \nApproval \nNovember 23, 2015 – Vice-Provosts’ Council - Advice \nNovember 25, 2015 – FGSR Council - Approval of Occupational Therapy \nSection \nNovember 26, 2015 - President’s Executive Committee – Operational – \nConsultation \nNovember 26, 2015 - General Council - Consultation \nDecember 2, 2015 - Deans’ Council  -Consultation \nDecember 15, 2015 - FNS Executive Meeting - Consultation \nDecember 17, 2015 – Council on Aboriginal Initiatives - Consultation \nNovember, 2016 Approval by Faculty of Native Studies Faculty Council \nMay 9, 2017 Approval by Nursing Faculty Council \nJune 1, 2017 Academic Standards Committee Subcommittee on \nStandards – Consultation \nJune 15, 2017 – GFC Academic Standards Committee (ASC) \nSeptember 13, 2017 – GFC Academic Planning Committee (APC) \nThose who are actively participating: \nSeptember 13, 2017 – GFC Academic Planning Committee (APC) \nApproval Route (Governance) \n(including meeting dates) \nAcademic Standards Committee - June 15, 2017  \nAcademic Planning Committee – June 14, 2017 \nGFC Executive Committee (for information) – October 16, 2017 \nGeneral Faculties Council – October 30, 2017 \nFinal Approver General Faculties Council \nAlignment/Compliance \nAlignment with Guiding \nDocuments \nOBJECTIVE: Build a diverse, inclusive community of exceptional \nundergraduate and graduate students from Edmonton, Alberta, Canada, \nand the world. \nStrategy: Develop and implement an undergraduate and graduate \nrecruitment and retention strategy to attract Indigenous students from \nacross Alberta and Canada. \nCompliance with Legislation, \nPolicy and/or Procedure \nRelevant to the Proposal \n(please quote legislation and \ninclude identifying section \nnumbers) \n1. Post-Secondary Learning Act (PSLA): The Post-Secondary \nLearning Act (PSLA) gives GFC responsibility, subject to the \nauthority of the Board of Governors, over academic affairs Section \n26(1)).  \n2. PSLA: The PSLA gives Faculty Councils power to “provide for the \nadmission of students to the faculty” (29(1)(c)).  \n3. UAPPOL Admissions Policy: “Admission to the University of \nItem No. 11 \nGENERAL FACULTIES COUNCIL \nFor the Meeting of October 30, 2017 \nAlberta is based on documented academic criteria established by \nindividual Faculties and approved by GFC. This criteria may be \ndefined in areas such as subject requirements, minimum entrance \naverages, and language proficiency requirements. In addition to \nacademic requirements for admission, GFC authorizes each Faculty \nto establish such other reasonable criteria for admission of \napplicants as the Faculty may consider appropriate to its programs \nof study, subject to the approval of GFC (e.g. interview, audition, \nportfolio, etc.)  \nThe admission requirements for any Faculty will be those approved \nby GFC as set forth in the current edition of the University Calendar. \nIn addition to the admission requirements, selection criteria for quota \nprograms, where they exist, will also be published in the current \nedition of the University Calendar.  \nThe responsibility for admission decisions will be vested in the \nFaculty Admission Committees or in the Deans of the respective \nFaculties, as the councils of such Faculties will determine.”  \n4. UAPPOL Admissions Procedure:  \n“PROCEDURE  \n 1. EFFECTIVE DATE OF CHANGES TO ADMISSION \nREGULATIONS  \nFollowing approval by GFC:  \na. Where changes to admission regulations may disadvantage \nstudents in the current admission cycle, normally implementation will \nbe effective after the change has been published in the University \nCalendar for one full year (i.e., effective the second year that the \ninformation is published in the University Calendar).  \nFor example, a change approved in May 2005 would be first \npublished in the 2006-2007 University Calendar in March 2006. \nTherefore the statement cannot come into effect until September \n2007 (affecting applicants who apply for the September 2007 term \nbeginning July 2006).”  \nb. Where changes to admission regulations are deemed by the  \napproving body to be ‘advantageous to students’, normally the date \nof implementation will be effective immediately or at the next \navailable intake for the admitting Faculty.”  \n5. GFC Academic Standards Committee (ASC) Terms of Reference \n(Mandate): “B. Admission and Transfer, Academic Standing, \nMarking and Grading, Term Work, Examinations, International \nBaccalaureate (IB), Advanced Placement (AP)  \ni. All proposals from the Faculties or the Administration related to \nadmission and transfer, to the academic standing of students, to \ninstitutional marking and grading policies and/or procedures and to \nterm work policies and procedures are submitted to the Provost and \nItem No. 11 \nGENERAL FACULTIES COUNCIL \nFor the Meeting of October 30, 2017 \nVice-President (Academic) (or delegate) who chairs the GFC \nAcademic Standards Committee. ASC will consult as necessary with \nthe Faculties and with other individuals and offices in its \nconsideration of these proposals.  \nii. ASC acts for GFC in approving routine and/or editorial changes to \nboth admission/transfer policies […] \niv. ASC provides advice or recommends to the GFC Academic \nPlanning Committee (APC) on proposals which involve substantial \nchange to admission/transfer regulations or to academic standing \nregulations. \n6. GFC Academic Planning Committee (APC) Terms of Reference \n(Mandate): Admission, Transfer and Academic Standing  \na. To consider advice or recommendation from the GFC ASC on \nproposals for the establishment of or change to general University \nadmission or transfer policies affecting students, including policies \naffecting Open Studies students, and to act for GFC in approving \npolicies which in APC's view are minor or routine; and to recommend \nto GFC on proposals involving major change  \nb. To consider advice or recommendation from the GFC ASC on \nproposals which involve substantial change to admission/transfer \nregulations or to academic standing regulations. \n7.  GFC Executive Committee Terms of Reference: Agendas of \nGeneral Faculties Council \nGFC has delegated to the Executive Committee the authority to \ndecide which items are placed on a GFC agenda, and the order in \nwhich those agenda items appear on each GFC agenda. \nWhen ordering items, the GFC Executive Committee will be mindful \nof any matters that are of particular concern to students during \nMarch and April so that the student leaders who bring those items \nforward are able to address these items at GFC before their terms \nend. \nWhen recommendations are forwarded to General Faculties Council \nfrom APC, the role of the Executive shall be to decide the order in \nwhich items should be considered by GFC. The  Executive \nCommittee is responsible for providing general advice to the Chair \nabout proposals being forwarded from APC to GFC. \n1.  Attachment 1 (page(s) 1 - 7) Admission of Aboriginal Students Calendar Section  \n2.  Attachment 2 (page(s) 1 - 5) Faculty Calendar Sections \nPrepared by: Kate Peters, Portfolio Initiatives Manager, Office of the Provost and Vice-President (Academic) \nkate.peters@ualberta.ca \nItem No. 11 \nGENERAL FACULTIES COUNCIL \nFor the Meeting of October 30, 2017 \nOffice of the Registrar\nFor Implementation and Publication in the 2018-19 Calendar\nCurrent Proposed\nFaculty of Law\nSpecial Applicants \n No applicant can elect to be placed in any \ncategory. Allocation to such category shall be the \nresponsibility of the Committee. \n(1) Aboriginal Applicants: For the purpose of \napplication and admission to the University of \nAlberta, and in accordance with the \nConstitution Act, 1982, Part II, Section 35(2), an \nAboriginal Applicant is an Indian, Inuit or Métis \nperson of Canada, or a person who is accepted \nby one of the Aboriginal peoples of Canada as a \nmember of their community. Refer to §14.1.2 \nfor further details regarding proof of \nAboriginal ancestry. \nFaculty of Medicine and Dentistry\nBSc in Medical Laboratory Science \nIV. Aboriginal Applicants\n The Division of Medical Laboratory Science will \ngive up to one position within the quota for the \nBSc MLS program to Aboriginal applicants. \nStudents of Aboriginal ancestry within the \nmeaning of the Constitution Act, 1982, Section 35, \nPart 2, or a person accepted by one of the \nAboriginal peoples of Canada as a member of their \ncommunity, will be considered in this category. \n Candidates will be subject to normal minimum \nadmission requirements as outlined in §15.9.2 and \napproval by the Divisional Admissions Committee. \nIf there are no qualified Aboriginal applicants in \nany given year, the position will be allocated to the \ngeneral applicant pool. \nAboriginal applicants should contact the \nFaculty of Law\nSpecial Applicants \n No applicant can elect to be placed in any \ncategory. Allocation to such category shall be the \nresponsibility of the Committee. \n(1) Aboriginal Applicants: For the purpose of \napplication and admission to the University of \nAlberta, and in accordance with the \nConstitution Act, 1982, Part II, Section 35(2), an \nAboriginal Applicant is an Indian, Inuit or Métis \nperson of Canada, or a person who is accepted \nby one of the Aboriginal peoples of Canada as a \nmember of their community. Refer to §14.1.2 \nfor further details regarding proof of \nAboriginal identity. \nFaculty of Medicine and Dentistry\nBSc in Medical Laboratory Science \nIV. Aboriginal Applicants\n The Division of Medical Laboratory Science will \ngive up to one position within the quota for the \nBSc MLS program to Aboriginal applicants. \nStudents of Aboriginal identity within the meaning \nof the Constitution Act, 1982, Section 35, Part 2, or \na person accepted by one of the Aboriginal \npeoples of Canada as a member of their \ncommunity, will be considered in this category. \n Candidates will be subject to normal minimum \nadmission requirements as outlined in §15.9.2 and \napproval by the Divisional Admissions Committee. \nIf there are no qualified Aboriginal applicants in \nany given year, the position will be allocated to the \ngeneral applicant pool. \nAboriginal applicants should contact the \nAttachment 1\nCoordinator, Division of Medical Laboratory \nScience, for career planning. \nDental Hygiene Diploma \nIV.  Aboriginal Applicants \n Besides the regular quota positions, additional \nposition(s) per year are available in the Dental \nHygiene program for a qualified student of \nAboriginal ancestry, within the meaning of the \nConstitution Act of 1982, Section 35(2). Applicants \ninterested in this program should contact the \nAdministrator, Indigenous Health Initiatives, \nFaculty of Medicine and Dentistry. See also §14.1. \nDoctor of Dental Surgery (DDS) \nIV.  Aboriginal Applicants \n Besides the regular quota positions, an \nadditional position per year is available in the DDS \nprogram for a qualified student of \nAboriginal ancestry, within the meaning of the \nConstitution Act of 1982, Section 35, Part 2. \nApplicants interested in this program should \ncontact the Administrator, Indigenous Health \nInitiatives, Faculty of Medicine and Dentistry. See \nalso §14.1. \nDoctor of Medicine (MD) \nIII.  Aboriginal Applicants \n The Faculty of Medicine and Dentistry may \nprovide up to five positions within quota for the \nMD program to qualified Aboriginal applicants \nover and above Aboriginal applicants who were \nadmitted in the regular process. Candidates will be \nsubject to normal minimum admission \nrequirements as outlined in §15.9.9 and to \napproval by the Faculty of Medicine and Dentistry \nAdmissions Committee. For more information, \ncontact the Faculty of Medicine and Dentistry \nUndergraduate Admissions Office. \nCoordinator, Division of Medical Laboratory \nScience, for career planning. \nDental Hygiene Diploma \nIV.  Aboriginal Applicants \n Besides the regular quota positions, additional \nposition(s) per year are available in the Dental \nHygiene program for a qualified student of \nAboriginal identity, within the meaning of the \nConstitution Act of 1982, Section 35(2). Applicants \ninterested in this program should contact the \nAdministrator, Indigenous Health Initiatives, \nFaculty of Medicine and Dentistry. See also §14.1. \nDoctor of Dental Surgery (DDS) \nIV.  Aboriginal Applicants \n Besides the regular quota positions, an \nadditional position per year is available in the DDS \nprogram for a qualified student of \nAboriginal identity, within the meaning of the \nConstitution Act of 1982, Section 35, Part 2. \nApplicants interested in this program should \ncontact the Administrator, Indigenous Health \nInitiatives, Faculty of Medicine and Dentistry. See \nalso §14.1. \nDoctor of Medicine (MD) \nIII.  Aboriginal Applicants \n The Faculty of Medicine and Dentistry may \nprovide up to five positions within quota for the \nMD program to qualified Aboriginal applicants \nover and above Aboriginal applicants who were \nadmitted in the regular process. Candidates will be \nsubject to normal minimum admission \nrequirements as outlined in Doctor of Medicine \nand to approval by the Faculty of Medicine and \nDentistry Admissions Committee. For more \ninformation, contact the Faculty of Medicine and \nDentistry Undergraduate Admissions Office. \n Students who are of Aboriginal ancestry within \nthe meaning of the Constitution Act, 1982, Section \n35(2) will be considered in this category. \n Aboriginal student applicants and prospective \npre-medical students should contact the \nCoordinator, Aboriginal Health Care Careers, \nFaculty of Medicine and Dentistry for individual \ncounseling and career planning. See also §14.1. \nBachelor of Science in Radiation Therapy \nIV.  Aboriginal Applicants \n The Department of Oncology will provide up to \none position within the quota for the BSc \nRadiation Therapy program to Aboriginal \napplicants. Students of Aboriginal ancestry within \nthe meaning of the Constitution Act, 1982, Section \n35, Part 2, or a person accepted by one of the \nAboriginal peoples of Canada as a member of their \ncommunity, will be considered in this category. \n Candidates will be subject to normal minimum \nadmission requirements as outlined in §15.9.10 \nand approval by the Radiation Therapy Admissions \nCommittee. If there are no qualified Aboriginal \napplicants in any given year, the position will be \nallocated to the general applicant pool. \n Aboriginal applicants should contact the \nDepartment of Oncology in the Faculty of \nMedicine and Dentistry for career planning. \nFaculty of Native Studies \nBA (Native Studies)/BEd Combined Degrees \nThe Bachelor of Arts in Native Studies/Bachelor of \nEducation Combined Degrees program allows \nstudents to complete both degrees in a five-year \nprogram consisting of *150. Students may select \neither the Secondary or the Elementary program. \nThe program is open to both Native and non-\nNative applicants. However, to correct an historic \n Students who are of Aboriginal identity within \nthe meaning of the Constitution Act, 1982, Section \n35(2) will be considered in this category. \n Aboriginal student applicants and prospective \npre-medical students should contact the \nCoordinator, Aboriginal Health Care Careers, \nFaculty of Medicine and Dentistry for individual \ncounseling and career planning. See also Admission \nof Aboriginal Applicants. \nBachelor of Science in Radiation Therapy \nIV.  Aboriginal Applicants \n The Department of Oncology will provide up to \none position within the quota for the BSc \nRadiation Therapy program to Aboriginal \napplicants. Students of Aboriginal identity within \nthe meaning of the Constitution Act, 1982, Section \n35, Part 2, or a person accepted by one of the \nAboriginal peoples of Canada as a member of their \ncommunity, will be considered in this category. \n Candidates will be subject to normal minimum \nadmission requirements as outlined in §15.9.10 \nand approval by the Radiation Therapy Admissions \nCommittee. If there are no qualified Aboriginal \napplicants in any given year, the position will be \nallocated to the general applicant pool. \n Aboriginal applicants should contact the \nDepartment of Oncology in the Faculty of \nMedicine and Dentistry for career planning. \nFaculty of Native Studies \nBA (Native Studies)/BEd Combined Degrees \nThe Bachelor of Arts in Native Studies/Bachelor of \nEducation Combined Degrees program allows \nstudents to complete both degrees in a five-year \nprogram consisting of *150. Students may select \neither the Secondary or the Elementary program. \nThe program is open to both Native and non-\ndisadvantage and in recognition that the demand \nfor students of native ancestry is significant, \nNative students are especially encouraged to \napply. \nFaculty of Nursing \nBSc in Nursing–Collaborative Program \nIV.  Aboriginal Applicants \n(1) In addition to the regular quota positions, up to \nsix more positions per year are available in the \nCollaborative BScN program for qualified \nstudents of Native ancestry within the meaning \nof the Constitutional Act of 1982, Section 35, \nPart 2. Please refer to §14.1 for regulations and \nrequirements. \nFaculty of Pharmacy and \nPharmaceutical Sciences \nAboriginal Applicants \n The Faculty of Pharmacy and Pharmaceutical \nSciences may provide one position to an Aboriginal \napplicant, over the regular quota of 130 students. \nStudents who are of Aboriginal ancestry within the \nmeaning of the Constitution Act, 1982, Section \n35(2) will be considered in this category (§14.1). \nProof of Aboriginal status, to be provided as part \nof the application for admission, is required for \nconsideration of this position [§14.1.2(2)]. \n Candidates will be subject to admission as \noutlined in §15.12.1, and to approval by the \nFaculty of Pharmacy and Pharmaceutical Sciences \nAdmissions Committee. If there are no qualified \nAboriginal students in any given year, this position \nwill not be allocated to other applicants. \n Aboriginal student applicants should contact \nthe Coordinator, Native Health Care Careers, for \nindividual counselling and career planning. See \nalso §14.1. \nNative applicants. However, to correct an historic \ndisadvantage and in recognition that the demand \nfor students of native identity is significant, Native \nstudents are especially encouraged to apply. \nFaculty of Nursing \nBSc in Nursing–Collaborative Program \nIV.  Aboriginal Applicants \n(1) In addition to the regular quota positions, up to \nsix more positions per year are available in the \nCollaborative BScN program for qualified \nstudents of Native identity within the meaning \nof the Constitutional Act of 1982, Section 35, \nPart 2. Please refer to §14.1 for regulations and \nrequirements. \nFaculty of Pharmacy and \nPharmaceutical Sciences \nAboriginal Applicants \n The Faculty of Pharmacy and Pharmaceutical \nSciences may provide one position to an Aboriginal \napplicant, over the regular quota of 130 students. \nStudents who are of Aboriginal identity within the \nmeaning of the Constitution Act, 1982, Section \n35(2) will be considered in this category (§14.1). \nProof of Aboriginal status, to be provided as part \nof the application for admission, is required for \nconsideration of this position [§14.1.2(2)]. \n Candidates will be subject to admission as \noutlined in §15.12.1, and to approval by the \nFaculty of Pharmacy and Pharmaceutical Sciences \nAdmissions Committee. If there are no qualified \nAboriginal students in any given year, this position \nwill not be allocated to other applicants. \n Aboriginal student applicants should contact \nthe Coordinator, Native Health Care Careers, for \nindividual counselling and career planning. See \nalso §14.1. \nOccupational Therapy \nGeneral Information \nAboriginal Applicants \n Two positions in the occupational therapy \nprogram are available to applicants of \naboriginal ancestry as defined in the Constitution \nAct, 1982, Part II, Section 35(2). Applicants must \nmeet all entrance requirements as specified \nbelow. If suitable Aboriginal applicants cannot be \nfound, these positions will be filled by applicants \nfrom the general pool. \nOccupational Therapy \nGeneral Information \nAboriginal Applicants \n Two positions in the occupational therapy \nprogram are available to applicants of \naboriginal identity as defined in the Constitution \nAct, 1982, Part II, Section 35(2). Applicants must \nmeet all entrance requirements as specified \nbelow. If suitable Aboriginal applicants cannot be \nfound, these positions will be filled by applicants \nfrom the general pool. \nOffice of the Registrar\nFor Publication in 2018-19 Calendar\nFor Implementation in 2018-19\nCurrent Proposed Explanation \nAdmission of Aboriginal Students \nGeneral Statement \nThe University of Alberta is \ncommitted to the recruitment, \nretention and graduation of \nAboriginal students. The University \nalso recognizes that Aboriginal \napplicants have traditionally been \nunder represented in higher \neducation and strives towards having \nthe University’s Aboriginal student \npopulation attain a level that is at \nleast proportionate to the Aboriginal \npopulation of the province.  \nIn order to facilitate appropriate \nrepresentation of Aboriginal students \non campus, additional qualified \napplicants may be considered over \nand above the Aboriginal students \nwho are admitted in the regular \ncompetition for places in a Faculty. \nAboriginal applicants who wish to be \nconsidered for such additional places \nmust attain the minimum admission \nrequirements of their chosen \nprogram as prescribed by the \nUniversity and its Faculties and \nSchools. To assist the University in \nachieving this overall goal, Faculties \nare encouraged to set aside places \nspecifically for Aboriginal applicants, \nthe number being consistent with the \navailable pool, student interests, and \navailable teaching and learning \nsupport services. \nAdmission of Aboriginal Students \nGeneral Statement \nThe University of Alberta is \ncommitted to the recruitment, \nretention and graduation of \nAboriginal students. The University \nalso recognizes that Aboriginal \napplicants have traditionally been \nunder represented in higher \neducation and strives towards having \nthe University’s Aboriginal student \npopulation attain a level that is at \nleast proportionate to the Aboriginal \npopulation of the province. All \nAboriginal students are encouraged \nto self-identify. In order to facilitate \nappropriate representation of \nAboriginal students on campus, \nadditional qualified applicants may \nbe considered over and above the \nAboriginal students who are admitted \nin the regular competition for places \nin a Faculty. Aboriginal applicants \nwho wish to be considered for such \nadditional places must attain the \nminimum admission requirements of \ntheir chosen program as prescribed \nby the University and its Faculties and \nSchools. To assist the University in \nachieving this overall goal, Faculties \nare encouraged to set aside places \nspecifically for Aboriginal applicants, \nthe number being consistent with the \navailable pool, student interests, and \navailable teaching and learning \nsupport services. \nDefinition of Aboriginal People for \nAttachment 2\nDefinition of Aboriginal People for \nthe Purpose of Admission \n(1) Definition of an Aboriginal \nApplicant: For the purpose of \napplication and admission to \nthe University of Alberta, and \nin accordance with the \nConstitution Act, 1982, Part \nII, Section 35(2), an \nAboriginal applicant is an \nIndian, Inuit, or Métis person \nof Canada, or a person who is \naccepted by one of the \nAboriginal peoples of Canada \nas a member of their \ncommunity. \n(2) Proof of \nAboriginal Ancestry: Proof of \nAboriginal ancestry may be \nrequired by \nFaculties; candidates will be \nadvised at the time of \napplication if they must \nprovide it. Where proof is \nrequired, documentation will \nbe verified by  \na. the Faculty of Law, if \napplication is made to the \nFaculty of Law; \nb. the Faculty of Medicine and \nDentistry, if the application \nis made to the Dentistry, \nMedicine, Dental Hygiene \nor Medical Laboratory \nScience programs; \nc. the Aboriginal Student \nthe Purpose of Admission \n(1) Definition of an Aboriginal \nApplicant: For the purpose of \napplication and admission to \nthe University of Alberta, and \nin accordance with the \nConstitution Act, 1982, Part \nII, Section 35(2), an \nAboriginal applicant is an \nIndian, Inuit, or Métis person \nof Canada. \n(2) Proof of \nAboriginal Identity: Aborigin\nal applicants who wish to be \nconsidered for places \nreserved for Aboriginal \nstudents will be required to \nprovide proof of Aboriginal \nidentity. Documentation will \nbe verified by  \na. the Faculty of Law, if \napplication is made to the \nFaculty of Law; \nb. the Faculty of Medicine and \nDentistry, if the application \nis made to the Dentistry, \nMedicine, Dental \nHygiene, Radiation Therapy, \nor Medical Laboratory \nScience programs; \nc. the Aboriginal Student \nServices Centre, acting on \nThis changed language \nis consistent with that \nused by other U15 \ninstitutions and keeps \nthe definition \nconsistent with the \nConstitution Act.  \nAdditional clarity \nThe change from \n“ancestry” to “identity” \nreflects evolution of \nlanguage across the \ncountry. \nA requirement to prove \nidentity ensures that \nAboriginal applicants \nare being treated fairly \nand consistently across \nFaculties, where those \napplicants are \ncompeting for places \nreserved for Aboriginal \nstudents.  \nServices Centre, acting on \nbehalf of all other Faculties, \nif application is made to any \nother program.  \n     Aboriginal applicants must be \naware that proof of ancestry does not \nguarantee admission to any program. \nAll positions at the University are \ncompetitive and admission \ncommittees will make their selections \nfrom among the best qualified \ncandidates. Candidates may also \nbe required to demonstrate their \nconnection to an Aboriginal \ncommunity. \nThe following is accepted as proof \nof ancestry, for the purpose of \napplication: \na. a certified copy of a \nStatus or Treaty card; \nb. a certified copy of a Métis \nmembership card; \nc. a certified copy of a \nNunavut Trust Certificate \ncard, roll number or any \nother proof accepted by \nInuit communities; \nd. proof that an ancestor’s \nname has been entered \nbehalf of all other Faculties, \nif application is made to any \nother program.  \nThe following is accepted as proof \nof Aboriginal identity, for the purpose \nof application. Other forms of proof \nmay be considered.  \na. a certified copy of a Status \ncard; \nb. certified copy of citizenship \nor membership in a Metis \nSettlement from one of the \nfive Métis Provincial \nAffiliates: Métis Nation of \nAlberta, Métis Nation of \nOntario, Manitoba Métis \nFederation, Métis Nation-\nSaskatchewan, Métis Nation \nBritish of Columbia. \nc. a certified copy of a \nNunavut Trust Certificate \ncard; \nd. proof that an ancestor’s \nname has been entered \n1) in the Indian Register \nNote: This paragraph \nmoved below. \nMoved below \nThis language provides \ngreater specificity as to \nthe kinds of \nmembership cards that \nMétis applicants may \nhave.  \n1) in the Indian Register \naccording to the \nIndian Act, or \n2) on the band list of an \nindividual band, or \n3) on the Inuit roll;  \ne. evidence of an ancestor \nwho received a land grant \nor a scrip grant under the \nManitoba Act or the \nDominion Lands Act; \nf. written confirmation of \nAboriginal ancestry \nfrom the Department of \nIndian Affairs; \ng. written confirmation of \nmembership by a band \ncouncil which has enacted \nits own band membership \ncode; \nh. a Statutory Declaration by \nan applicant attesting to \nAboriginal ancestry, \nsupplemented by letters or \ndocumentation supporting \nthe Declaration \n1) from an official of a \naccording to the \nIndian Act, or \n2) on the band list of an \nindividual band, or \n3) as beneficiaries of \nthe Nunavut Land \nClaims Agreement or \nother claim regions \nsuch as Nunatsiavut, \nNunavik, and \nInuvialuit; \ne. written confirmation of \nAboriginal identity \nfrom Aboriginal Affairs and \nNorthern Development \nCanada (AANDC) or \nNunavut Tunngavik \nIncorporated; \nf. written confirmation of \nmembership by a band \ncouncil which has enacted \nits own band membership \ncode; \nUpdated language  \nUpdated language  \nStatutory Declarations \nas described here are \ndifficult to verify.  Note \nthat the University \ndoes leave open the \npossibility of other \nforms of proof being \nconsidered.  \nrecognized native \norganization, or \n2) from a relative in an \nAboriginal community, or \n3) from the applicant \ndescribing involvement with \nAboriginal issues. \nOther forms of proof may be \nconsidered. \n(3) Residence \na. Regarding Application: \nResidence regulations \naffecting application to any \nprogram at this University \nshall be waived for \nAboriginal applicants. \nb. Regarding Admission: For \nthe purpose of determining \nadmission to a program, an \nAboriginal applicant who is \nnot resident in Alberta will \nbe considered in the \nfollowing categories and in \nthe order specified:  \n1) First, as a candidate \nfor the positions \nreserved for out-of-\nAboriginal applicants must be aware \nthat proof of Aboriginal identity does \nnot guarantee admission to any \nprogram. All positions at the \nUniversity are competitive and \nadmission committees will make their \nselections from among the best \nqualified candidates. Candidates may \nalso be required to demonstrate their \nconnection to an Aboriginal \ncommunity.  \n(3) Residence \na. Regarding Application: \nResidence regulations \naffecting application to any \nprogram at this University \nshall be waived for \nAboriginal applicants. \nb. Regarding Admission: For \nthe purpose of determining \nadmission to a program, an \nAboriginal applicant who is \nnot resident in Alberta will \nbe considered in the \nfollowing categories and in \nthe order specified:  \n1) First, as a candidate \nfor the positions \nreserved for out-of-\nprovince applicants. \nMoved above. \nMoved from above. \nprovince applicants. \n2) Second, as a \ncandidate for the \npositions reserved for \nAlberta residents. \nResidence regulations \nshall be waived for this \npurpose. \n3) Third, as a candidate \nfor positions set aside \nspecifically for \nAboriginal applicants. \nPreference for these \npositions may be given \nto those who are \nresident in Alberta. \n(4) Appeal on Aboriginal Status \nAppeals regarding Aboriginal status \nfor the purpose of application can be \nmade to the Office of the Provost and \nVice-President (Academic). Appeals \nmay be made on status only and \nmust be received, in writing, within \n30 days of the date on the letter \nadvising that proof submitted in \nsupport of Aboriginal status has not \nbeen accepted for the purpose of \napplication to a program. In the case \nof an appeal, the Office of the \nProvost and Vice-President \n(Academic) shall authorize a panel to \nreview the decision, consisting of the \nfollowing members: \n- in the Chair, the Provost and \nVice-President (Academic) (or \n2) Second, as a \ncandidate for the \npositions reserved for \nAlberta residents. \nResidence regulations \nshall be waived for this \npurpose. \n3) Third, as a candidate \nfor positions set aside \nspecifically for \nAboriginal applicants. \nPreference for these \npositions may be given \nto those who are \nresident in Alberta. \n(4) Appeal  \nAppeals regarding proof of Aboriginal \nidentity for the purpose of \napplication can be made to the Office \nof the Provost and Vice-President \n(Academic). Appeals may be made \non proof of Aboriginal identity only, \nand not on the admission decision, \nand must be received, in writing, \nwithin 30 days of the date on the \nletter advising that proof submitted \nin support of Aboriginal identity has \nnot been accepted for the purpose of \napplication to a program. In the case \nof an appeal, the Office of the \nProvost and Vice-President \n(Academic) shall authorize a panel to \nreview the decision, consisting of the \nfollowing members: \n- in the Chair, the Provost and \nVice-President (Academic) (or \ndelegate) \n- President, Aboriginal Students \nUpdated language \ndelegate) \n- President, Aboriginal Students \nCouncil (or delegate) \n- an Elder (appointed by \nthe University of Alberta Aboriginal \nCouncil) \n- an appropriate representative of \nan Indian, Métis or Inuit community \n(appointed by the University of \nAlberta Aboriginal Council) \n- a member of a Faculty not \nassociated with the case [appointed \nby the Provost and Vice-President \n(Academic)].  \nThe decision of the appeal panel is \nfinal and binding. \nCouncil (or delegate) \n- an Elder (appointed by \nthe Council on Aboriginal Initiatives) \n- an appropriate representative of \na First Nations, Métis or Inuit \ncommunity (appointed by the Council \nof Aboriginal Initiatives) \n- a member of a Faculty not \nassociated with the case [appointed \nby the Provost and Vice-President \n(Academic)].  \nThe decision of the appeal panel is \nfinal and binding. \nGENERAL FACULTIES COUNCIL \nFor the Meeting of October 30, 2017 \nItem 12.1Q \nQuestion from GFC Member Kyle Monda (submitted by email October 19, 2017) \nVP Finance and Administration \n• How many break-ins, thefts, and assaults have occurred in the Fine Arts Building in \n2017? \n• Does anyone respond when door alarms are triggered in the Fine Arts Building? \n• Dedicated campus security staff patrol FAB & HUB now. Has any community \nconsultation occurred regarding the increased presence of security staff in Faculty of \nArts facilities? \n• Have any break-ins, thefts, or assaults occurred in the HUB Art & Design studios or \nNorth Power Plant Art & Design studios in 2017? If so, how many? \n• Have Crime Prevention Through Environmental Design audits ever been completed on \nthe Fine Arts Building, the North Power Plant Art & Design studios, and HUB Art & \nDesign studios? If so, were the recommendations implemented? \nVP Facilities & Operations \n• Are any facilities safety upgrades planned for the Fine Arts Building, such as an updated \naccess control system or CCTV systems? \n• Are any safety and security upgrades planned for the HUB Art & Design studios and \nNorth Power Plant Art & Design studios? \nDean, Arts \n• What steps will the Faculty of Arts take to assure faculty, staff, and students working in \nFine Arts facilities (such as the Fine Arts Building, North Power Plant studios, and \nHUB studios) that their safety is a priority? \nGENERAL FACULTIES COUNCIL \nFor the Meeting of October 30, 2017 \nItem 12.1Q \nQuestion from GFC Member Kyle Monda (submitted by email October 19, 2017) \nVP Finance and Administration \n• How many break-ins, thefts, and assaults have occurred in the Fine Arts Building in \n2017? \n• Does anyone respond when door alarms are triggered in the Fine Arts Building? \n• Dedicated campus security staff patrol FAB & HUB now. Has any community \nconsultation occurred regarding the increased presence of security staff in Faculty of \nArts facilities? \n• Have any break-ins, thefts, or assaults occurred in the HUB Art & Design studios or \nNorth Power Plant Art & Design studios in 2017? If so, how many? \n• Have Crime Prevention Through Environmental Design audits ever been completed on \nthe Fine Arts Building, the North Power Plant Art & Design studios, and HUB Art & \nDesign studios? If so, were the recommendations implemented? \nVP Facilities & Operations \n• Are any facilities safety upgrades planned for the Fine Arts Building, such as an updated \naccess control system or CCTV systems? \n• Are any safety and security upgrades planned for the HUB Art & Design studios and \nNorth Power Plant Art & Design studios? \nDean, Arts \n• What steps will the Faculty of Arts take to assure faculty, staff, and students working in \nFine Arts facilities (such as the Fine Arts Building, North Power Plant studios, and \nHUB studios) that their safety is a priority? \nOffice of the Vice-President (Finance and Administration) \n2-04 South Academic Building (SAB) \nTel: 780.492.2657 \nFax: 780.492.1439 \nwww.uofa.ualberta.ca/vice-president-finance \nDate: October 27, 2017 \nTo: General Faculties Council \nFrom: Gitta Kulczycki \nVice-President (Finance & Administration)  \nc. Kyle Monda, Member, General Faculties Council \nAndrew Sharman, Vice-President (Facilities & Operations) \nLesley Cormack, Dean, Faculty of Arts \nRe: Fine Arts Building Security \nThe following are replies to questions asked by Kyle Monda regarding Security in the Fine Arts building \n(FAB).     \nHow many break-ins, thefts, and assaults have occurred in the Fine Arts Building in 2017? \n● There have been no break and enters reported to UAPS during 2017. \n● There have been three thefts in 2017 (two regarding general property and one was a computer) \n● There have been no assaults reported to UAPS during 2017. \nDoes anyone respond when door alarms are triggered in the Fine Arts Building? \n● The FAB has a hybrid alarm system. Some of the alarms are newer than others. The new \ninstallations are connected with the University Facilities and Operations (F&O) monitored alarm \nprogram while older alarms, which were installed by the faculty, are not monitored. \n● UAPS responded to four monitored alarms during 2017. \n● UAPS has also responded to two non-monitored alarms as a result of being called by FAB staff \n(noise complaints). \nDedicated campus security staff patrol FAB & HUB now. Has any community consultation \noccurred regarding the increased presence of security staff in Faculty of Arts facilities? \n● UAPS peace officers and security guards patrol all of our university campus locations (North, \nCampus St. Jean, South, Michener Park and Augustana). They are directed to different \nlocations based on priority indicators. These directed activities are reviewed on a 24-hour basis \nand resources are deployed to locations that are demonstrating the highest need. \n● There are no \"dedicated\" UAPS resources assigned to any one location. \n● We have a new program that has been very successful since its initiation this September. We \nhave created a security agent program which employs university students who are assigned to \ndedicated locations. These students receive formal training and are provided with a security  \nshirt and radio. Their role is to observe and report to our dispatch centre, who in turn will \ndispatch a UAPS peace officer or security guard as required. This service is on a contract basis \nand we have received positive feedback from areas who have requested the service. \n● Residence Life and Real Estate Services have a contract with UAPS and a security agent is \nbeing deployed at HUB Mall after hours seven days a week. \n● The security agent program has also been deployed to other student residence locations. \n● Director Bill Spinks has previously spoken with Dean Cormack, Faculty of Arts, and followed up \nwith an email offering information on the security agent program. \nHave any break-ins, thefts, or assaults occurred in the HUB Art & Design studios or North \nPower Plant Art & Design studios in 2017? If so, how many? \n● No reports of any crimes have been reported to UAPS during 2017. \nHave Crime Prevention Through Environmental Design (CEPTD) audits ever been completed on \nthe Fine Arts Building, the North Power Plant Art & Design studios, and HUB Art & Design \nstudios? If so, were the recommendations implemented? \n● The following audits have been conducted.  FAB 2015, Hub Mall 2016, Hub Mall 2013. These \nreports are on file and can be made available. \n● Any recommendations made are not the responsibility of UAPS to implement. The CPTED is a \nservice/report provided to the requester to consider and initiate any changes. \nAre any facilities safety upgrades planned for the Fine Arts Building, such as an updated access \ncontrol system or CCTV systems? \n● The scope of any upgrades would need to be determined jointly by the Faculty and F&O. Fine \nArts have applied for video monitoring and UAPS has approved this request. \nAre any safety and security upgrades planned for the HUB Art & Design studios and North \nPower Plant Art & Design studios? \n● The scope of any upgrades would need to be determined jointly by the Faculty and F&O. \nResidence Services have applied for video monitoring for the Hub Mall Vault and UAPS has \napproved this request.  \nWhat steps will the Faculty of Arts take to assure faculty, staff, and students working in Fine \nArts facilities (such as the Fine Arts Building, North Power Plant studios, and HUB studios) that \ntheir safety is a priority? \n● We cannot speak to what steps the Faculty of Arts will take, however, UAPS is available to \nassist. \nGitta Kulczycki \nVice-President (Finance & Administration) \nGENERAL FACULTIES COUNCIL \nFor the Meeting of October 30, 2017 \nItem 12.1Q \nQuestion from GFC Member Kyle Monda  \nResponse from  Vice President Facilities & Operations \nGenerally speaking, the U of A campus is a safe place to learn and work. That said, we all have \na responsibility when it comes to safety and our greatest success in maintaining a safe \nenvironment for everyone comes from each of us taking small steps to thwart undesired \nbehaviour.  As a matter of best practice, consideration of access control or video monitoring is \nbased on a number of factors including risk assessments and security standards applied across \nthe entirety of the university. \nQ. Are any facilities safety upgrades planned for the Fine Arts Building, such as an updated \naccess control system or CCTV systems? \nR. We have received a proposal to implement CCTV upgrades for the Fine Arts Building \nand are currently costing out the project. \nQ. Are any safety and security upgrades planned for the HUB Art & Design studios and \nNorth Power Plant Art & Design studios? \nR. We are also aware of proposed upgrades for the HUB Art & Design Studios and are \ncurrently consulting with the Faculty as to how we can most effectively achieve the \ndesired level of security. \nhttps://www.ualberta.ca/protective-services/information-safety\nGENERAL FACULTIES COUNCIL \nFor the Meeting of October 30, 2017 \nItem 12.1R \nQuestion: What steps will the Faculty of Arts take to assure faculty, staff, and students working \nin Fine Arts facilities (such as the Fine Arts Building, North Power Plant studios, and HUB \nstudios) that their safety is a priority? \nResponse: from Dean of Arts \nAfter a rash of incidents in the Fine Arts Building (FAB) in September, Dean Lesley Cormack \nand her team met with the Director of UAPS in early October to discuss the ongoing security \nissues and concerns. At this meeting, several issues were discussed, including speed of \nresponse and appropriate security measures.  Clarity was provided by UAPS as to when \ncampus security versus the Edmonton Police Services (EPS) should be called in regards to \nsecurity incidents. A memo clarifying the process was sent on October 18 to all departments, \nboth in FAB and in all other Arts buildings. Questions were also raised about the communication \nof serious incidents in the building. UAPS and Central Marketing and Communications are \ncurrently developing communication protocols which will be shared when complete. \nIn addition to the customary safety reminders from the departments to their staff, instructors and \nstudents, the Faculty is pursuing further measures identified through the 2015 Crime Prevention \nthrough Environmental Design Security Survey (CPTED) report for FAB. These measures \ninclude: \n•       Installation of video monitoring at the major entrances to all floors and entrances to swipe \naccess areas. Arts is currently waiting for a quote from F&O for the cost of this video monitoring \nsystem. \n•       Review of building hours and access to the building through additional use of swipe cards \n•       Renovating and refurbishing the lower main floor of FAB to attract more student and staff \ninto the area and make unwanted users feel that they do not belong in a well-maintained and \nwell-defined space \n•       Installing physical barriers in specific stairwells to prevent unauthorized access to the stairs \nleading up to the roof \nSecurity issues due to the building’s proximity to the LRT station and as a through-way to other \nbuildings remain a challenge but the safety of our students and staff are of utmost importance. \nWe continue to work closely with Protective Services and engage with the departments in \nregards to future discussions and decisions to enhance the security of FAB \n In regards to the HUB studio spaces, we are not aware of specific incidences but we are aware \nof building maintenance issues that are causing security concerns that needs to be addressed. \nLesley Cormack \nDean, Faculty of Arts \nItem No. 13 \nGENERAL FACULTIES COUNCIL \nFor the Meeting of October 30, 2017 \n General Faculties Council Standing Committee Report \nGFC Executive Committee  \n1. Since the last GFC meeting, the Executive Committee met on October 16, 2017. \n2. Items Approved Under Delegated Authority \nReport of the GFC Executive ad hoc Transition Committee \n2018-2019 Academic Schedule \nGFC Agenda for October 30, 2017 \n3. Items Recommended to GFC \nProposed Revisions to Standing Committee Terms of Reference GFC Campus Law Review Committee \n(CLRC) including a name change to GFC Student Conduct Policy Committee (SCPC) \nProposed Revisions to Standing Committee Terms of Reference - GFC Facilities Development Committee \n(FDC) \n4. Items that the Committee Discussed or Advised on  \nDebrief - GFC Meeting of September 25, 2017 \nWaiver of Advertising Requirements: Report to General Faculties Council \nPeter Lougheed Leadership College (PLLC) - Next Steps \nEarly Consultation:  Board of Governors / GFC Summit \nTerms of reference and records of meetings for this committee can be found at: \nhttp://www.governance.ualberta.ca/GeneralFacultiesCouncil/ExecutiveCommittee.aspx \nSubmitted by: \nDavid Turpin, Chair \nExecutive Committee \nhttp://www.governance.ualberta.ca/GeneralFacultiesCouncil/ExecutiveCommittee.aspx\nItem No. 14 \nGENERAL FACULTIES COUNCIL \nFor the Meeting of October 30, 2017 \n General Faculties Council Standing Committee Report \nGFC Academic Planning Committee  \n1. Since last reporting to GFC, the Academic Planning Committee met on October 11, 2017. \n2. Items the Committee Discussed or Advised on  \nPeter Lougheed Leadership College (PLLC) - Next Steps  \nDeferred Maintenance  \nUpdate on the Budget  \nAnnual Report on Undergraduate Student Financial Support  \nProposed Changes to the GFC Academic Planning Committee (APC) \nTerms of Reference \nTerms of reference and records of meeting for this committee can be found at: \nhttp://www.governance.ualberta.ca/GeneralFacultiesCouncil/AcademicPlanningCommittee.aspx \nSubmitted by: \nSteven Dew \nChair, GFC Academic Planning Committee \nhttp://www.governance.ualberta.ca/GeneralFacultiesCouncil/AcademicPlanningCommittee.aspx\nItem No. 15 \nGENERAL FACULTIES COUNCIL \nFor the Meeting of October 30, 2017 \n General Faculties Council Standing Committee Report \nGFC Academic Standards Committee  \n1. Since the last GFC meeting, the GFC Academic Standards Committee met on September 21, 2017 and \nOctober 19, 2017. \n2. Actions Taken with Delegated Authority from GFC \nApproval of Transfer Credits for September and October 2017 \nFaculty of Arts: Changes to Existing Admission Requirements for BA Honors Philosophy \nFaculty of Nursing: Changes to Existing Admission Requirements for the BSc in Nursing – Bilingual \nProgram/Baccalauréat ès sciences infirmières (bilingue) \nProposed Changes to International Baccalaureate (IB) and Advanced Placement (AP) Courses for \nAdvanced Standing reflected in Admissions Charts 4 and 5 of the University Calendar \nFaculty of Pharmacy and Pharmaceutical Sciences: Changes to Admission and Re-admission Deadlines \nChanges to Admission, BSc in Medical Laboratory Science, Faculty of Medicine and Dentistry \nFaculty of Graduate Studies and Research: Changes to General Academic Standing Requirements, MSc \nin Physical Therapy, Faculty of Rehabilitation Medicine \nProposal from the Faculty of Graduate Studies & Research for a new course-based MA in History of Art, \nDesign and Visual Culture (HADVC), Department of Art and Design (changes to admission/transfer and \nacademic standing) \nProposal from the Faculty of Graduate Studies & Research for a new combined MSc in Physical \nTherapy/PhD in Rehabilitation Science (MScPT/PhD) program, Department of Physical Therapy and the \nFaculty of Rehabilitation Medicine (changes to admission/transfer and academic standing) \nProposed Changes to Existing Admission Requirements, MSc Occupational Therapy, Faculty of \nGraduate Studies and Research and Faculty of Rehabilitation Medicine (changes to admission/transfer \nand academic standing) \nProposal to add the Canadian Academic English Language Computer Edition (CAEL CE) examination as \na way to fulfill the English Language Proficiency Requirement \n3.  Items Recommended to the GFC Academic Planning Committee (APC) \nProposed Changes to Admission/Transfer and Academic Standing Regulations for the Undergraduate \nNursing Program, Faculty of Nursing \nProposal from the Faculty of Graduate Studies & Research for a new course-based MA in History of Art, \nDesign and Visual Culture (HADVC), Department of Art and Design \nProposal from the Faculty of Graduate Studies & Research for a new combined MSc in Physical \nTherapy/PhD in Rehabilitation Science (MScPT/PhD) program, Department of Physical Therapy and the \nItem No. 15 \nGENERAL FACULTIES COUNCIL \nFor the Meeting of October 30, 2017 \n Faculty of Rehabilitation Medicine \nProposed Changes to Existing Admission Requirements, MSc Occupational Therapy, Faculty of \nGraduate Studies and Research and Faculty of Rehabilitation Medicine \n4. Items Recommended to GFC \nProposal to Waive English Language Proficiency Requirement for the Master of Financial Management \n(MFM) and the Master of Business Administration (MBA) programs delivered in Chinese by the Alberta \nSchool of Business, Faculty of Graduate Studies and Research \n5. Items Discussed \nReview of ASC Terms of Reference \nProposed Changes to Admission and Academic Regulations, BSc in Radiation Therapy, Faculty of \nMedicine and Dentistry \nExternal Programs for Review and Programs in Progress on Campus: Standing Item \nTerms of reference and records of meeting for this committee can be found at: \nhttp://www.governance.ualberta.ca/GeneralFacultiesCouncil/AcademicStandardsCommittee.aspx \nSubmitted by: \nTammy Hopper, Chair \nAcademic Standards Committee \nhttp://www.governance.ualberta.ca/GeneralFacultiesCouncil/AcademicStandardsCommittee.aspx\nGFC NOMINATIONS/ELECTIONS \nItem No. 16 \nSEARCH AND REVIEW COMMITTEES \nPresidential/Vice-Presidential/Decanal Search and Review Committees are regularly established at the University of \nAlberta. General Faculties Council (GFC) is called upon to arrange for the election of staff representatives from at-\nlarge to fill positions on approved search/review committee compositions in accordance to the policies and \nprocedure within the Recruitment Policy (in UAPPOL). \nIt's regular practice by GFC to broadly distribute nomination calls to the relevant constituencies (academic staff, \nnon-academic staff, public members) in order to raise awareness and encourage nominations and/or expressions of \ninterest from eligible nominees. When an election is required to declare a final nominee(s), GFC serves as the \ndelegated electorate as specified within the relevant selection/review procedures. \nRECENT POSITION/S FILLED \n2017-18 Dean Selection Committee - Dean, Alberta School of Business \nSeptember 29, 2017 - the following individual has been declared elected (by GFC) to serve as the one (1) \nacademic staff representative (Category A1.0) from outside the Faculty concerned, as indicated within Section 4 \n(i) of the \"Faculty Deans Review Procedure\" (Appendix A: Dean Selection/Review Committee for Individual \nFaculties)]. \n• Janice Kung (University Libraries) \nWORK IN-PROGRESS \nNOMINATIONS \n2017-18 Selection Committee for Vice-Provost (Learning Services) and Chief Librarian \nCall for Nominations to be distributed week of October 23, 2017 to fill seats with the following representation: \nThree (3) members of the academic staff (Categories A1.1 or A1.5), one from each of the Tri-Council \ngranting agencies areas*, as indicated within Section 10 (f.) of the \"Faculty Deans Selection Procedure\" \n(Appendix A: Dean Selection Committees for Individual Faculties)]. \n*  (the Natural Sciences and Engineering Research Council of Canada [NSERC], the Social Sciences and \nHumanities Research Council of Canada [SSHRC] and the Canadian Institutes of Health Research [CIHR]). \nView Related Links for Updates and Details: \nOffice of the Provost - Deans Selections and Reviews  \nNominations and Elections (General Faculties Council) \nGENERAL FACULTIES COUNCIL \nFor the Meeting of October 30, 2017 \nhttps://www.ualberta.ca/provost/our-initiatives/deans-selections-and-reviews\nhttp://www.governance.ualberta.ca/GeneralFacultiesCouncil/NominatingCommittee/Nominations-and-Elections%20for%20Search%20and%20Review%20Committees.aspx\nhttp://www.governance.ualberta.ca/�\nItem No. 18A \nGENERAL FACULTIES COUNCIL \nFor the Meeting of October 30, 2017 \n OUTLINE OF ISSUE \nAgenda Title: 2018-2019 Academic Schedule \nItem   \nAction Requested For Information \nProposed by Lisa Collins, Vice-Provost and University Registrar \nPresenter Lisa Collins, Vice-Provost and University Registrar; and Anna Vocioni, \nAssistant Registrar (Examinations and Timetabling), Office of the \nRegistrar \nDetails \nResponsibility Provost and Vice-President (Academic) \nThe Purpose of the Proposal is \n(please be specific) \nTo provide term and deadline dates for the 2018-2019 Academic Year. \nThe Impact of the Proposal is Establishment of deadline dates for the 2018 - 2019 Academic Year \nReplaces/Revises (eg, policies, \nresolutions) \nAcademic Schedule section of the University Calendar \nTimeline/Implementation Date For publication in the 2018-2019 University Calendar (the dates of \nAcademic Schedule run from July 1, 2018 – June 30, 2019). \nEstimated Cost and funding \nsource \nN/A \nNext Steps  \nSupplementary Notes and \ncontext \nEngagement and Routing (Include meeting dates) \nParticipation: \n(parties who have seen the \nproposal and in what capacity) \nDistribution list including President, Provost and Vice-President; GFC \nExecutive members; Deans, Associate and Assistant Deans, Students \nUnion, GSA and Office of the Registrar \n• First draft review July 19, 2017 \n• Final version review September 8, 2017 \nApproval Route (Governance) \n(including meeting dates) \nGFC Executive Committee - October 16, 2017  \nGeneral Faculties Council – October 30, 2017 (for information) \nFinal Approver GFC Executive Committee \nAlignment/Compliance \nAlignment with Guiding \nDocuments \nFor the Public Good, Comprehensive Institutional Plan, Institutional \nvalues \nCompliance with Legislation, \nPolicy and/or Procedure \nRelevant to the Proposal \n(please quote legislation and \ninclude identifying section \nnumbers) \n1. Post-Secondary Learning Act (PSLA): GFC is responsible, \ngenerally, for the academic affairs of the University and specifically, for \nthe Academic Schedule of the University (Sections 26(1), 26(1)(d)(e)(g) \nand (j) (Powers of General Faculties Council)). \n2. GFC Executive Committee Terms of Reference (Section 3. \n(Mandate of the Committee)) states: \n“4. Academic Schedule \na. Delegation \nPost-Secondary Learning Act (PSLA) Section 26(l)(j) follows: \nItem No. 18A \nGENERAL FACULTIES COUNCIL \nFor the Meeting of October 30, 2017 \n 26(1) Subject to the authority of the board, a general faculties council \nis responsible for the academic affairs of the university and, without \nrestricting the generality of the foregoing, has the authority to…  (j) \ndetermine the date for the beginning and end of lectures in the \nuniversity and also the beginning and end of each university term…. \nb. Academic Schedule Changes \nThe GFC Executive Committee has delegated authority from General \nFaculties Council to approve the Academic Schedule. Any changes to \nthe Academic Schedule proposed after the Schedule has been \napproved must be submitted to the Executive Committee.  That \ncommittee will determine which changes are sufficiently substantial \nand require, therefore, GFC approval and which ones are routine in \nnature and could be dealt with by the Executive Committee.” \n3. GFC Policy: Section 25 (Calendar Changes) of the GFC Policy \nManual states final editorial authority for minor procedural directions was \ndelegated to the Registrar, who will be responsible for the conformance \nof these directions to the general University policy. (GFC 29 JUN 1981)” \n4. UAPPOL Academic Schedule Policy states:   \n“[…] \n2. ACADEMIC SCHEDULE DELEGATION OF AUTHORITY \nThe authority to determine the Academic Schedule is the responsibility of \nthe GFC Executive Committee, as delegated to that body by General \nFaculties Council.  \nThe Registrar recommends on the Academic Schedule to the GFC \nExecutive Committee.” \n5. UAPPOL Academic Schedule Procedure states: “Each spring, the \nExams and Timetabling Division in the Office of the Registrar will begin \ndrafting the Academic Schedule for the following year[…].   \nTwo drafts will be sent out to a distribution list that includes the \nPresident, Vice-Presidents and senior administrators, Deans, Assistant \nand Associate Deans, Directors and other stakeholders for feedback and \nsuggested changes.  \nThe final draft of the Academic Schedule will be sent to the GFC \nExecutive Committee no later than mid-October for approval.  \nAfter the Academic Schedule has been approved, it will be published in \nthe University Calendar.” \nAttachments (each to be numbered 1 - <>) \n1. Attachment 1 (page 1): 2018-2019 colored month calendar with important dates \n2. Attachment 2 (page 1): 2018-2019 Academic Schedule Hours of Instruction Summary \n3. Attachment 3 (pages 1 – 5): Major Dates and Deadlines from the 2018-2019 Academic Schedule \n4. Attachment 4 (pages 1 – 7): Proposed Academic Schedule for 2018-2019 \nPrepared by: Anna Vocioni, Assistant Registrar (Examinations and Timetabling), anna.vocioni@ualberta.ca \nmailto:anna.vocioni@ualberta.ca\nJuly 2018 – June 2019 \nJuly 2018 \nS M T W T F S \n1 2 3 4 5 6 7 \n8 9 10 11 12 13 14 \n15 16 17 18 19 20 21 \n22 23 24 25 26 27 28 \n29 30 31      \nAugust 2018 \nS M T W T F S \n      1 2 3 4 \n5 6 7 8 9 10 11 \n12 13 14 15 16 17 18 \n19 20 21 22 23 24 25 \n26 27 28 29 30 31   \nSeptember 2018 \nS M T W T F S \n            1 \n2 3 4 5 6 7 8 \n9 10 11 12 13 14 15 \n16 17 18 19 20 21 22 \n23 24 25 26 27 28 29 \n30             \nOctober 2018  \nS M T W T F S \n  1 2 3 4 5 6 \n7 8 9 10 11 12 13 \n14 15 16 17 18 19 20 \n21 22 23 24 25 26 27 \n28 29 30 31     \nNovember 2018 \nS M T W T F S \n        1 2 3 \n4 5 6 7 8 9 10 \n11 12 13 14 15 16 17 \n18 19 20 21 22 23 24 \n25 26 27 28 29 30   \nDecember 2018 \nS M T W T F S \n            1 \n2 3 4 5 6 7 8 \n9 10 11 12 13 14 15 \n16 17 18 19 20 21 22 \n23 24 25 26 27 28 29 \n30 31           \nJanuary 2019 \nS M T W T F S \n   1 2 3 4 5 \n6 7 8 9 10 11 12 \n13 14 15 16 17 18 19 \n20 21 22 23 24 25 26 \n27 28 29 30 31    \nFebruary 2019 \nS M T W T F S \n         1 2 \n3 4 5 6 7 8 9 \n10 11 12 13 14 15 16 \n17 18 19 20 21 22 23 \n24 25 26 27 28    \nMarch 2019 \nS M T W T F S \n         1 2 \n3 4 5 6 7 8 9 \n10 11 12 13 14 15 16 \n17 18 19 20 21 22 23 \n24 25 26 27 28 29 30 \n31       \nApril 2019 \nS M T W T F S \n 1 2 3 4 5 6 \n7 8 9 10 11 12 13 \n14 15 16 17 18 19 20 \n21 22 23 24 25 26 27 \n28 29 30      \n Exams \nFirst/Last day of term \nTerm break \nStatutory Holiday University Buildings Closed  \nMay 2019 \nS M T W T F S \n     1 2 3 4 \n5 6 7 8 9 10 11 \n12 13 14 15 16 17 18 \n19 20 21 22 23 24 25 \n26 27 28 29 30 31   \nJune 2019 \nS M T W T F S \n           1 \n2 3 4 5 6 7 8 \n9 10 11 12 13 14 15 \n16 17 18 19 20 21 22 \n23 24 25 26 27 28 29 \n30       \nhttp://www.calendarpedia.com/\n2018-2019 ACADEMIC SCHEDULE \nHours of Instruction \nFall Term Days  Minutes \nM W F 37 x 50 = 1850 \nT R 26 x 80 = 2080 \nTerm Total 63      3930  \nWinter Term Days  Minutes \nM W F 38 x 50 = 1900 \nT R 25 x 80 = 2000 \nTerm Total 63      3900 \nFall/Winter Total 126 days   7830 minutes \nNumber of Evening Classes in Fall Term \nMonday 11 \nTuesday 13 \nWednesday 13 \nThursday 13 \nFriday 13 \nNumber of Evening Classes in Winter Term \nMonday 13 \nTuesday 13 \nWednesday 13 \nThursday 12 \nFriday 12 \npg. 1 \n2018 Spring-Summer dates and deadlines \nIMPORTANT Not all classes follow the dates listed below; check www.registrarsoffice.ualberta.ca for \nSpring/Summer nonstandard deadline dates and detailed information. \nClasses begin \nSpring Term   May 7, 2018 Summer Term   July 9, 2018 \n  First half May 7, 2018   First half July 9, 2018 \n  Second half May 28, 2018   Second half July 30, 2018 \nSpring/Summer terms (13 week \nA/B, part classes)  May 7, 2018 \nRegistration Add/Delete (no academic record) \nSpring Term   May 10, 2018 Summer Term   July 12, 2018 \n  First half May 10, 2018   First half July 12, 2018 \n  Second half (delete only) May 31, 2018   \nSecond half \n(delete only) August 2, 2018 \nSpring/Summer terms (13 week \nA/B, part classes)  May 10, 2018 \nAudit and Credit to Audit \nSpring Term   May 7-10, 2018 Summer Term   July 9-12, 2018 \nSpring/Summer terms (13 week \nA/B, part classes)  May 7-10, 2018 \nFee Payment (see Note 1) \nSpring Term   May 10, 2018 Summer Term   July 12, 2018 \nSpring/Summer terms (13 week \nA/B, part classes)  May 10, 2018 \nFee Refund – 50% (see Note 2) \nSpring Term   May 22, 2018 Summer Term   July 23, 2018 \n  First half May 14, 2018   First half July 16, 2018 \n  Second half June 4, 2018   Second half August 7, 2018 \nSpring/Summer terms (13 week \nA/B, part classes)  See Note 3 \nWithdrawal (Grade of W) \nSpring Term   June 6, 2018 Summer Term   August 8, 2018 \n  First half May 22, 2018   First half July 24, 2018 \n  Second half June 8, 2018   Second half August 10, 2018 \nSpring/Summer terms (13 week \nA/B, part classes)  July 12, 2018 \npg. 2 \nClasses end \nSpring Term   June 13, 2018 Summer Term   August 15, 2018 \n  First half May 25, 2018   First half July 27, 2018 \n  Second half June 13, 2018   Second half August 15, 2018 \nSpring/Summer terms (13 \nweek, A/B part classes)  August 15, 2018 \nExaminations  \nSpring Term   June 14 - 15, 2018 Summer Term   August 16 - 17, 2018 \nReappraisal requests and Reexaminations applications – refer to “Academic Regulations; Examinations \n(Exams)” in the University Calendar for procedures and application deadline dates. \npg. 3 \nFall 2018-Winter 2019 dates and deadlines     \nApplication to Convocate \n  Undergraduate Graduate   Undergraduate Graduate \nFall Term September 1, 2018 \nSeptember 28, \n2018 Winter term February 1, 2019 April 1, 2019 \nClasses begin \nFall Term   September 4, 2018 Winter Term   January 7, 2019 \n  First half September 4, 2018   First half January 7, 2019 \n  Second half October 22, 2018   Second half March 4, 2019 \nFall/Winter Terms (A/B part \nclasses) September 4, 2018 \nClasses begin date exceptions – additional class begin date exceptions may apply, students must contact their \nFaculty. \nAugustana \nFall Term  3 week classes August 30, 2018 Winter Term 3 week classes January 7, 2019 \n  11 week classes September 24, 2018   11 week classes January 28, 2019 \nLaw \nFall Term   September 5, 2018       \nRegistration Add/Delete (no academic record) \nFall Term   September 17, 2107 Winter Term   January 18, 2019 \n  First half September 17, 2018   First half January 18, 2019 \n  Second half (delete only) November 2, 2018   \nSecond half \n(delete only) March 15, 2019 \nFall/Winter Terms (A/B part \nclasses) September 17, 2018 \nAudit and Credit to Audit \nFall Term September 18-24, 2018 Winter Term January 21-25, 2019 \nFall/Winter Terms (A/B part \nclasses) \nSeptember 18-24, 2018 \nFee Payment (see Note 1) \nFall Term   September 28, 2018 Winter Term   January 31, 2019 \nFall/Winter Terms (A/B part \nclasses) \nSeptember 28, \n2018       \npg. 4 \nFee Refund – 50% (see Note 2) \nFall Term   October 4, 2018 Winter Term   February 6, 2019 \n  First half September 27, 2018   First half January 25, 2019 \n  Second half November 23, 2018   Second half March 22, 2019 \nFall/Winter Terms (A/B part \nclasses) See Note 4 \nWithdrawal (Grade of W) \nFall Term   November 30, 2018 Winter Term   April 3, 2019 \n  First half October 9, 2018   First half February 8, 2019 \n  Second half November 30, 2018   Second half April 3, 2019 \nFall/Winter Terms (A/B part \nclasses)  January 18, 2019 \nClasses end \nFall Term   December 7, 2018 Winter Term   April 10, 2019 \n  First half October 12, 2018   First half February 15, 2019 \n  Second half December 7, 2018   Second half April 10, 2019 \nFall/Winter Terms (A/B part \nclasses) April 10, 2019 \nClasses end date exceptions – additional class end date exceptions may apply, students must contact their \nFaculty. \nAugustana \nFall Term 3 week classes September 18, 2018 Winter Term 3 week classes January 23, 2019 \n  11 week classes December 10, 2018   11 week classes April 16, 2019 \nLaw \nFall Term   December 4, 2018       \nExaminations  \nRefer to the Academic Schedule for Fall and Winter final examination dates \nReappraisal requests and Reexaminations applications – refer to “Academic Regulations; Examinations (Exams)” \nin the University Calendar for procedures and application deadline dates. \npg. 5 \nNotes: \n1. Students who have not paid their fees in full by this date, or made satisfactory alternate arrangements, will be \nassessed late payment penalty charges. To avoid installment charges, all Fall/Winter fees must be paid by the \nFall Term Fee Payment Deadline and Spring/Summer fees must be paid by the Spring Term Fee Payment \nDeadline. Refer to “Deadline for Fee Payments” in the University Calendar for details. \n2. Students withdrawing after this date will be assessed full fees. \n3. If you withdraw from a two-term (A/B part) course from May 22 to July 12, 2018, you will be assessed full fees \nfor the Spring Term. If your Faculty determines that you may have special permission to withdraw from July 13 to \n16, 2018, you will be assessed Spring Term fees and 50% of Summer Term fees. After July 16, 2017, you will be \nassessed full fees for both terms. \n4. If you withdraw from a two-term (A/B part) course from October 4, 2018 to January 18, 2019, you will be \nassessed full fees for Fall Term. If your Faculty determines that you may have special permission to withdraw \nfrom January 21 to February 6, 2019, you will be assessed Fall Term fees and 50% of Winter Term fees. After \nFebruary 6, 2019, you will be assessed full fees for both terms. \npg. 1 \n2018-2019 Academic Schedule  \nDeadline dates in the schedule are marked with a symbol.  \nJuly 2018 \n1 One hundred and twelfth University year begins. \n1 Canada Day; University buildings closed. \n2 Canada Day holiday; University buildings closed. \n3 Students in Phase II of the BSc in Medical Laboratory Science program begin year of \npractical training. \n9 Summer Term classes begin. \n9-12 Auditor registrations for Summer Term courses will be accepted only on these days. \n12  Last day for students enrolled in the University of Alberta Health Insurance Program \n(UAHIP) to opt out of this insurance coverage by providing proof of enrolment in the \nAlberta Health Care Insurance Plan to the International Services Centre. \n12  Summer Term Registration Deadline. Last day to add or drop six-week courses and \ncourses offered in the first three-weeks of the term (Bear Tracks web registration \navailable to midnight). Students wishing to add or drop three-week courses offered \nduring the last three weeks of the term should seek assistance at department offices. \n12  Payment Deadline: Last day for payment of Summer Term fees. Students who have not \npaid their fees in full, or made satisfactory alternate arrangements, will be assessed late \npayment penalty charges. \n13 Summer program ends for students in year one, two and three of the DDS program. \n16  Summer Term Refund Deadline for three-week courses: Students withdrawing from \ncourses taught in the first three weeks of Summer Term will be assessed full fees after \nthis date. \n23  Summer Term Refund Deadline for six-week courses: Students withdrawing from \ncourses taught for six-weeks will be assessed full fees after this date. \n24  Last day for withdrawal from courses taught in the first three weeks of Summer Term. \n27 Last day of classes for courses taught in the first three weeks of Summer Term. \n30 Classes begin for courses taught in the last three weeks of Summer Term. \n31  Deadline to write a special deferred examination for students who have missed a \ndeferred examination for cause. Please refer to University Calendar; University \nRegulations and Information for Students; Academic Regulations; Attendance; Absence \nfrom Final Exams section. \nAugust 2018 \n2  Second half Summer Term Registration Deadline for three-week courses: Last day to \nadd or drop courses offered in the last three weeks of Summer Term. Students must \ncontact Department for assistance. \n6 Heritage Day; University buildings closed. \n7  Summer Term Refund Deadline for three-week courses: Students withdrawing from \ncourses taught in the last three weeks of Summer Term will be assessed full fees after \nthis date. \n8  Last day for withdrawal from six-week courses in Summer Term. \npg. 2 \n10  Last day for withdrawal from courses taught in the last three-weeks of Summer Term. \n13 Orientation and classes begin for students in third and fourth year of the MD program. \n15 Summer Term classes end. \n16-17 Final examinations for Summer Term classes, exceptions may apply. \n16-24 U of A International Undergraduate Academic Success program. \n20 Registration opens for Open Studies students in courses designated for delayed registration.  \n22-24 Orientation for International MBA students. \n27 Orientation and classes begin for all Dentistry program, year two and three of the Dental \nHygiene program, year one and two MD program, year two of the Radiation Therapy program \nand phase I Medical Laboratory Science students. \n27- Sep 1 Orientation for MBA students. \n30 Augustana Faculty Fall Term 3-week classes begin. \n29-31 Orientation for International Students. \n29-31 Orientation for first year Pharmacy students and new students in the School of Public Health. \n31 Augustana Faculty Fall Term 3-week classes registration deadline; students withdrawing \nafter this date through September 6 will be assessed 50% fees. \nSeptember 2018 \n1  Last day for Undergraduate students to apply through Bear Tracks for permission to \ngraduate at Fall Convocation. \n3 Orientation for new Undergraduate students. \n3 Labour Day. University buildings closed. \n4 Orientation for Faculty of Nursing undergraduate students in year one of the After Degree \nprogram and in year two of the Bilingual Nursing program. \n4 Fall Term and Fall/Winter Term classes begin.  Exceptions may apply; students must consult \nwith their Faculty office. \n4 Orientation for students in the Faculty of Law. \n5 Fall Term classes begin for students in the Faculty of Law. \n6  Augustana Faculty Fall Term 3-week classes refund deadline; students withdrawing after \nthis date will be assessed full fees. \n13  Augustana Faculty last day to withdraw from Fall Term 3-week classes. \n17  Fall Term Registration Deadline. Last day to add or drop Fall Term and Fall/Winter Term \ncourses (Bear Tracks web registration system available to midnight): Students \nwithdrawing after this date through October 4 will be assessed 50% fees for withdrawn \ncourses. Exceptions may apply; students must consult with their Faculty office. \n18-24 Registration by undergraduate and graduate students to change to audit or change from \n‘credit’ to ‘audit’ in Fall Term and Fall/Winter Term courses will be accepted only during this \nperiod. \n18  Last day of Fall Term 3-week classes for Augustana Faculty students. \n21 SU Health and Dental Plan Change of Coverage Deadline. Students wishing to opt-out of this \nservice or change their coverage must do so through www.ihaveaplan.ca. \n21-24 Alumni weekend. \n24 Augustana Faculty Fall Term 11-week classes begin. \nhttp://www.ihaveaplan.ca/\npg. 3 \n27  Fall Term Refund Deadline for six-week courses: Students withdrawing from courses \noffered in the first six weeks of Fall Term will be assessed full fees after this date. \n28  Last day for students enrolled in the University of Alberta Health Insurance Program \n(UAHIP) to opt out of this insurance coverage by providing proof of enrolment in the \nAlberta Health Care Insurance Plan to the International Services Centre. \n28  Payment Deadline: Last day for payment of Fall Term fees. Students who have not paid \ntheir fees in full, or made satisfactory alternate arrangements, will be assessed late \npenalty charges. To avoid instalment charges, all Fall/Winter fees must be paid by the \nFall Term Fee Deadline. \n28  Last day for graduate students in thesis-based programs to submit theses to and be \napproved by the Faculty of Graduate Studies to ensure graduation at Fall Convocation.\n28  Last day for Departments to submit Report of Completion of course-based masters, \npostgraduate diploma, or graduate certificate programs to the Faculty of Graduate \nStudies and Research to ensure graduation at Fall Convocation.\n28  Last day for graduate students to apply through Bear Tracks to ensure graduation at Fall \nConvocation.\nOctober 2018 \n3  Augustana Faculty Fall Term 11-week classes drop deadline; students withdrawing after \nthis date through October 19 will be assessed 50% fees . Students must contact a \nFaculty advisor for assistance. \n4  Fall Term Refund Deadline: Students withdrawing after this date will be assessed full \nfees.  Exceptions may apply; students must consult with their Faculty office. \n8 Thanksgiving Day; University buildings closed. \n9  Last day for withdrawal from six-week courses offered in the first half of the Fall Term. \n12  Last day of classes for six-week courses offered in the first half of Fall Term. \n19  Augustana Faculty Fall Term 11-week classes refund deadline; students withdrawing \nafter this date will be assessed full fees. \n22 Classes begin for six-week courses offered in the second half of the Fall Term. \nNovember 2018 \n2  Last day to drop six-week courses offered in the second half of the Fall Term. Students \nmust contact department for assistance. \n11 Remembrance Day; University buildings closed. \n12 Remembrance Day holiday; University buildings closed \n13-14 Fall Term break for students in year two and three Dental Hygiene program. \n13-14 Fall Term break for Augustana Faculty students. \n13-16 Fall Term Reading week. Classes withdrawn for a full week, except for students in Augustana \nFaculty; Faculty of Law; Faculty of Medicine and Dentistry; Faculty of Rehabilitation \nMedicine; and students in Cooperative Education, Experiential Learning Placement, Clinical \nPlacement and Work Placement terms. \n20-21 Fall Convocation, Part I, Parts II and III \n23  Fall Term Refund Deadline for six-week courses: After this date students withdrawing \nfrom courses offered in the last six weeks of Fall Term will be assessed full fees. \npg. 4 \n30  Last day for withdrawal from six-week courses offered in the second half of Fall Term. \n30  Last day for withdrawal from Fall Term courses. Exceptions may apply; students must \nconsult with their Faculty office. \nDecember 2018 \n3  Augustana Faculty last day to withdraw from Fall Term 11-week classes. \n4 Last day of Fall Term classes for students in the Faculty of Law. \n7 Last day of Fall Term classes.  Exceptions may apply; students must consult with their \nFaculty office. \n10 Last day of Fall Term 11-week classes for Augustana Faculty students. \n10-21 Fall Term examinations (including consolidated examinations).  Exceptions may apply; \nstudents must consult with their Faculty office. Examinations other than consolidated \nexaminations are held within the period December 12-21 (inclusive). University-organized \nextracurricular activities will normally not be allowed during this period.  \n11-19 Final exam period for students in the Faculty of Law. \n13-21 Augustana Faculty final examinations in Fall Term courses and mid-year examinations in \ntwo-term courses. Extracurricular activities sponsored by Augustana Faculty will normally not \nbe allowed during this period. \n14 Last day of Fall Term classes for students in the DDS program and students in year one and \ntwo of the MD program. \n17-21 Final exam period for year three and four Dentistry students. \n21 Last day of Fall Term classes for students in year three and four of the MD program. \n25-31 Christmas holiday period; University buildings closed. \nJanuary 2019 \n1 New Year’s Day; University buildings closed. \n2 Winter Term classes begin for the MD and Dentistry programs and year two and three of the \nDental Hygiene program. \n4 Orientation for new International students. \n7 Augustana Faculty Winter Term 3-week classes begin. \n7 Winter Term classes begin.  Exceptions may apply; students must consult with their Faculty \noffice.  \n8 Augustana Faculty Winter Term 3-week classes’ registration deadline; students withdrawing \nafter this date through January 11 will be assessed 50% fees. \n11  Augustana Faculty Winter Term 3-week classes refund deadline; students withdrawing \nafter this date will be assessed full fees. \n17  Augustana Faculty last day to withdraw from Winter Term 3-week classes. \n18  Last day to withdraw from Fall/Winter two-term courses. \n18  Winter Term Registration Deadline. Last day to add or drop Fall Term and Fall/Winter \nTerm courses (Bear Tracks web registration system available to midnight): Students \nwithdrawing after this date through February 6 will be assessed 50% fees for withdrawn \ncourses. Exceptions may apply; students must consult with their Faculty office. \n23 Last day of Winter Term 3-week classes for Augustana Faculty students. \npg. 5 \n21-25 Registration by undergraduate and graduate students to change to audit or change from \n‘credit’ to ‘audit’ in Fall Term and Fall/Winter Term courses will be accepted only during this \nperiod. \n25 Winter Term Refund Deadline for six-week courses: After this date students withdrawing from \ncourses offered in the first six weeks of Winter Term will be assessed full fees. \n28 Augustana Faculty Winter Term 11-week classes begin. \n31  Last day for students enrolled in the University of Alberta Health Insurance Program \n(UAHIP) to opt out of this insurance coverage by providing proof of enrolment in the \nAlberta Health Care Insurance Plan to the International Service Centre. \n31  Payment Deadline: Last day for payment of Winter Term fees. Students who have not \npaid their fees in full, or made satisfactory alternate arrangements, will be assessed late \npayment penalty charges. \nFebruary 2019 \n1  Last day for Undergraduate students to apply through Bear Tracks for permission to \ngraduate at Spring Convocation. \n1  Last day for application for reappraisal of final examinations for Fall Term courses. \n1  Study abroad application deadline for certain University of Alberta International \nadministered Exchange and Summer programs.  \n6  Augustana Faculty Winter Term 11- week classes drop deadline; students withdrawing \nafter this date through February 22 will be assessed 50% fees. Students must contact a \nfaculty advisor for assistance. \n6  Winter Term Refund Deadline: Students withdrawing from courses after this date will be \nassessed full fees. Exceptions may apply; students must consult with their Faculty office. \n8  Last day for withdrawal from six-week courses offered in the first half of Winter Term. \n14 Registration system opens for Spring/Summer 2019. \n15 Last day of classes for six-week courses offered in the first half of Winter Term. \n18 Statutory Provincial holiday; University buildings closed. \n19-22 Winter Term Reading Week. Classes withdrawn for a full week, except for students in \nAugustana Faculty; NURS 495, SC INF 495, Experiential Learning placement, third and \nfourth years of the MD program, fourth year Pharmacy and students in the clinical component \nof the Radiation Therapy program. Exceptions may apply; students must consult with their \nFaculty office. \n22  Augustana Faculty Winter Term 11-week classes refund deadline; students withdrawing \nafter this date will be assessed full fees. \nMarch 2019 \n4 Classes begin for six-week courses offered in the second half of Winter Term. \n4 12:00 to 1:00 pm. Students’ Union Election Forum in the Myer Horowitz Theatre (SUB). \nClasses withdrawn for this time period. \n6-8 Winter Term break for Augustana Faculty students. \n9 Study abroad application deadline for certain University of Alberta International administered \nSummer programs.  \n15 Last day to drop from six-week courses offered in the second half of Winter Term. Students \nmust contact Department for assistance. \npg. 6 \n22 Winter Term Refund Deadline for six-week courses: After this date students withdrawing from \ncourses offered in the last six weeks of Winter Term will be assessed full fees. \nApril 2019 \n1 Last day for students in thesis-based programs to submit theses to and be approved by the \nFaculty of Graduate Studies and Research to ensure graduation at Spring Convocation.  \n1 Last day for departments to submit Report of Completion of course-based master’s, \npostgraduate diploma or graduate certificate programs to the Faculty of Graduate Studies \nand Research to ensure graduation at Spring Convocation. \n1 Last day for Graduate students to apply through Bear Tracks to ensure graduation at Spring \nConvocation.  \n1 Comprehensive examination period begins for students in the fourth year of the MD program. \n3  Last day for withdrawal from six-week courses offered in the second half of Winter Term. \n3  Last day for withdrawal from Winter Term courses. Exceptions may apply; students must \nconsult with their Faculty office. \n9  Augustana Faculty last day to withdraw from Winter Term 11-week classes. \n10 Last day of Winter Term classes. Exceptions may apply; students must consult with their \nFaculty office. \n12-27 Winter Term examinations (including consolidated examinations). Exceptions may apply; \nstudents must consult with their Faculty office. Examinations other than consolidated \nexaminations are held within the period April 15-26 (inclusive). University-organized \nextracurricular activities will normally not be allowed during this period. \n16 Last day of Winter Term 11-week classes for Augustana Faculty students. \n16-26 Final exam period for students in the Faculty of Law. \n18 Last day of classes and clinics for students in the third and fourth year of the DDS program. \n19 Good Friday; University buildings closed. \n21 Easter Day; University buildings closed. \n22 Easter Monday; University buildings closed. \n23-26 Fall/Winter Term final examination period for year three and four Dentistry. \n23-30 Augustana Faculty final examinations period. Extracurricular activities sponsored by the \nAugustana Faculty will normally not be allowed during this period. \nMay 2019 \n3 Last day of classes and examinations for students in year one of the MD program and \nstudents in year one and two of the DDS program. \n5 Orientation for Master of Arts in Communications and Technology (MACT) students. \n6 Spring Term classes begin. \n6 MACT Spring Institute begins (three weeks). \n6-9 Auditor registrations for Spring Term courses will be accepted only on these days.  \n9 Charter Day. \n9  Payment Deadline: Last day for payment of Spring Term fees. Students who have not \npaid their fees in full, or made satisfactory alternate arrangements, will be assessed late \npayment penalty charges.  \n9  Last day for students enrolled in the University of Alberta Health Insurance Program \npg. 7 \n(UAHIP) to opt out of this insurance coverage by providing proof of enrolment in the \nAlberta Health Care Insurance Plan to the International Centre. \n9  Spring Term Registration Deadline. Last day to add or drop six-week courses and \ncourses offered in the first three- weeks of the term: (Bear Tracks web registration \navailable to midnight.) Students wishing to add or drop three-week courses offered \nduring the last three weeks of the term should seek assistance at department offices. \n13  Spring Term Refund Deadline for three-week courses: Students withdrawing from \ncourses taught in the first three weeks of Spring Term will be assessed full fees after this \ndate. \n13 Summer program begins for students in year one, two and three of the DDS program. \n17  Spring Term Registration Deadline for 13-week, A/B part, courses: Last day to add or \ndrop 13-week courses, students must contact the teaching Department for assistance.  \nStudents withdrawing after this date through July 13 will be assessed 50% for withdrawn \ncourses. Exceptions may apply. \n20 Victoria Day. University buildings closed. \n21  Spring Term Refund Deadline for six-week courses: Students withdrawing after this date \nwill be assessed full fees. \n21  Last day for withdrawal from courses taught in the first three weeks of Spring Term. \n24 Last day of classes and examinations for students in the second year of the MD program. \n24 Last day of classes in the MACT Spring Institute. \n24 Last day for classes taught in the first three weeks of Spring Term. \n24 Classes begin for courses taught in the last three weeks of Spring Term. \n30  Spring Term Registration Deadline for three-week courses: Last day to add or drop \ncourses taught in the last three weeks of Spring Term. Students must contact \nDepartment for assistance. \n31  Last day of program for fourth year students in the MD program. \nJune 2019 \n2 Augustana Faculty convocation. \n3  Spring Term Refund Deadline for three-week courses: Students withdrawing from \ncourses taught in the last three weeks of Spring Term will be assessed full fees after this \ndate. \n4-7 Spring Convocation, Parts I to VI. \n5  Last day for withdrawal from six-week courses in Spring Term. \n7  Last day for withdrawal from courses taught in the last three weeks of Spring Term. \n10-14 Spring Convocation, Parts VII to XI. \n12 Last day of Spring Term classes, exceptions may apply. \n13-14 Final examinations for Spring Term classes, exceptions may apply. \n30 One hundred and twelfth University year ends. \nItem No. 18B \nGENERAL FACULTIES COUNCIL \nFor the Meeting of October 30, 2017 \nOUTLINE OF ISSUE \n Information Item  \nAgenda Title: Waiver of Advertising Requirements: Report to General Faculties Council \nItem   \nProposed by Steven Dew, Provost and Vice-President (Academic) \nPresenter Steven Dew, Provost and Vice-President (Academic) \nDetails \nResponsibility Provost and Vice-President (Academic) \nThe Purpose of the item is \n(please be specific) \nTo provide GFC with summary information regarding the number of \nwaiver of advertising for full-time academic staff vacancies as required \nthrough UAPPOL policy.  \nTimeline/Implementation Date N/A \nSupplementary Notes and \ncontext \nLast report to GFC: October 5, 2015 \nEngagement and Routing (Include meeting dates) \nParticipation: \n(parties who have seen the \nproposal and in what capacity) \n<For further information see \nthe link posted on \nthe Governance Toolkit section \nStudent Participation Protocol> \nThose who have been informed: \n• AASUA \n• Steven Dew, Provost and Vice-President (Academic) \nThose who have been consulted: \n• Steven Dew, Provost and Vice-President (Academic) \nThose who are actively participating: \n• Steven Dew, Provost and Vice-President (Academic) \nAlignment/Compliance \nAlignment with Guiding \nDocuments \nFor the Public Good \nGOAL: SUSTAIN \nObjective 21: Encourage continuous improvement in administrative, \ngovernance, planning and stewardship systems, procedures, and \npolicies that enable students, faculty, staff, and the institution as a whole \nto achieve shared strategic goals. \nStrategy i. Encourage transparency and improve communication across \nthe university through clear consultation and decision-making processes, \nsubstantive and timely communication of information, and access to \nshared, reliable institutional data. \nCompliance with Legislation, \nPolicy and/or Procedure \nRelevant to the Proposal \n(please quote legislation and \ninclude identifying section \nnumbers) \n1. The Post-Secondary Learning Act (PSLA) governs the \nappointment, promotion and dismissal of academic staff: “A person shall \nnot be appointed to, promoted to or dismissed from any position on the \nacademic staff at a university except on the recommendation of the \npresident made in accordance with procedures approved by the general \nfaculties council.” (Section 22(2) of the PSLA) \n2. GFC Policy Manual: GFC requests that the GAC report annually to \nCouncil (Section 56.2 (General Appeals Committee) of the GFC Policy \nManual). The GAC is a committee established under Section 15 of the \nhttp://www.governance.ualberta.ca/GovernanceToolkit/Toolkit.aspx\nhttp://www.governance.ualberta.ca/GovernanceToolkit/Toolkit.aspx\nItem No. 18B \nGENERAL FACULTIES COUNCIL \nFor the Meeting of October 30, 2017 \nBoard/AASUA Agreement (Faculty) and, until 1977, was a GFC \ncommittee. Currently, it is one of several non-GFC committees \nrequested to provide an annual report to GFC. GFC requests that the \nreport include a statistical summary of cases and their dispositions and \nprotect the confidentiality of individual cases. \n3. Academic Staff Posting and Advertising Procedure \n“Waivers and Exceptions to Posting \n7.  In exceptional circumstances, the posting requirements for continuing \nacademic positions may be waived with the prior approval of the Provost \nand Vice-President (Academic). The Provost and Vice-President \n(Academic) will advise the AASUA of the decision and report all waivers \nto the General Faculties Council annually. Requests for waiver of posting \nshould be submitted to Human Resource Consulting Services.” \n4. GFC Terms of Reference (GFC Procedures (GFC Agendas) \n(Reports)):  “Reports not requiring action by GFC will be discussed by \nthe Executive Committee (with committee chairs in attendance) and \nplaced on the GFC agenda for information. If a GFC member has a \nquestion about a report, or feels that the report should be discussed by \nGFC, the GFC member should notify the Secretary to GFC, in writing, \ntwo business days or more before GFC meets so that the committee \nchair can be invited to attend. Such reports will be discussed as the last \nof the standing items.” (Section 4.a.) \nAttachments  \n1.  Interdepartmental Correspondence to Meg Brolley from Steven Dew (page 1) \nPrepared by: Susan Buchsdruecker, Faculty Relations Officer, sbuchs@ualberta.ca \nItem No. 18C \nGENERAL FACULTIES COUNCIL \nFor the Meeting of October 30, 2017 \nOUTLINE OF ISSUE \nInformation Item  \nAgenda Title: Annual Report on Undergraduate Student Financial Support \nItem   \nProposed by Lisa Collins, Vice Provost and University Registrar \nPresenter Lisa Collins, Vice Provost and University Registrar \nMelissa Padfield, Deputy Registrar \nDetails \nResponsibility Office of the Registrar \nThe Purpose of the item is \n(please be specific) \nTo discuss the Annual Report on Undergraduate Student Financial \nSupport as per APC’s mandate. This Report provides a snap shot of the \ncurrent state of undergraduate financial supports issued by the Office of \nthe Registrar (RO) in the 2016/2017 fiscal year. \nTimeline/Implementation Date N/A \nSupplementary Notes and \ncontext \nAnnual reporting to administrative and governance committees on \nundergraduate student financial support is part of the Office of the \nRegistrar’s “Financial Five”, a group of foundational building blocks \ndesigned to heighten awareness and serve as pre-cursors to institutional \nstrategy development in this area.  Components of the Financial Five are \nas follows: align student financial supports with enrolment priorities; \nidentify stable and targeted funding; improve technological and \ncommunications supports; explore the development of institutional \npolicy; and create a cross-functional stakeholder advisory group. \nEngagement and Routing (Include meeting dates) \nParticipation: \n(parties who have seen the \nproposal and in what capacity) \n<For further information see \nthe link posted on \nthe Governance Toolkit section \nStudent Participation Protocol> \nThose who have been informed: \nThe following stakeholders have seen the report for discussion and \nfeedback: \n• Dr Wendy Rodgers, Deputy Provost:  August 17, 2017  \n• Dr Tammy Hopper, Vice Provost Programs: August 17, 2017 \n• Kelly Spencer, Office of Advancement:  August 17, 2017 \n• Edith Finczak, Office of the Provost and Vice-President \n(Academic): August 17, 2017 \n• Kate Peters, Policy Initiatives Manager: August 17, 2017 \n• André Costopoulos, Dean of Students: August 17, 2017 \n• Alexis Ksiazkiewicz, Government & Stakeholder Relations: \nAugust 17, 2017 \n• Heather Zwicker, Dean Faculty of Graduate Studies and \nResearch:  August 17, 2017 \n• Britta Baron, Vice Provost and AVP International: August 17, \n2017 \n• Marina Banister, Students’ Union President: August 17, 2017 \n• Babak Soltannia, Graduate Students’ Association President: \nAugust 17, 2017 \n• GFC Executive (for information): Oct 16, 2017 \n• GFC (for information): Oct 30, 2017 \n• BLDC: Dec 1, 2017 \nhttp://www.governance.ualberta.ca/GovernanceToolkit/Toolkit.aspx\nhttp://www.governance.ualberta.ca/GovernanceToolkit/Toolkit.aspx\nItem No. 18C \nGENERAL FACULTIES COUNCIL \nFor the Meeting of October 30, 2017 \nThose who have been consulted: \n• VPC: Sept 18, 2017 \n• PEC-O: Sept 21, 2017 \n• Deans’ Council: Oct 4, 2017 \n• GFC UASC: Oct 10, 2017 \n• GFC APC: Oct 11, 2017  \n• ACEM and ACUS: Oct 27, 2017 \nThose who are actively participating: \n• Lisa Collins, Vice Provost and University Registrar \n• Melissa Padfield, Deputy Registrar \n• Fiona Halbert, Assistant Registrar Student Financial Support \n• Douglas Akhimienmhonan, Assistant Registrar Enrolment \nManagement \n• Kim Uniat, Associate Director RO Communications \nAlignment/Compliance \nAlignment with Guiding \nDocuments \nInstitutional Strategic Plan – For the Public Good \nTo begin, we will attract outstanding students… \n1. OBJECTIVE: Build a diverse, inclusive community of exceptional \nundergraduate and graduate students from Edmonton, Alberta, Canada, \nand the world.  \ni. Strategy: Develop and implement an undergraduate and graduate \nrecruitment strategy to attract top students from across the diverse \ncommunities in Alberta and Canada, leveraging our strengths as a \ncomprehensive research-intensive, multi-campus university with options \nfor francophone and rural liberal arts education. \nii. Strategy: Develop and implement an undergraduate and graduate \nrecruitment and retention strategy to attract top Indigenous students. \niii. Strategy: Optimize our international recruiting strategies to attract \nwell-qualified international students from regions of strategic importance, \nand enhance services and programs to ensure their academic success \nand integration into the activities of the university. \niv. Strategy: Ensure that qualified undergraduate and graduate students \ncan attend the university through the provision of robust student financial \nsupport. \nCompliance with Legislation, \nPolicy and/or Procedure \nRelevant to the Proposal \n(please quote legislation and \ninclude identifying section \nnumbers) \n1. Post-Secondary Learning Act (PSLA): The PSLA (Section \n26(1)(o)) indicates that General Faculties Council (GFC) has the \nauthority to “make recommendations to the board with respect to \naffiliation with other institutions, academic planning, campus \nplanning, a building program, the budget...” \n2. PSLA Section 60(1)(b): “ The board of a public post-secondary \ninstitution shall …  \n(b) develop, manage and operate, alone or in co-operation with \nany person or organization, programs, services and facilities for \nthe economic prosperity of Alberta and for the educational or \ncultural advancement of the people of Alberta,” \n3. GFC Undergraduate Awards and Scholarship Committee \n(UASC) Terms of Reference (3. Mandate):  “GFC UASC has \ndelegated authority from GFC to: \n  1. approve new undergraduate awards[.] […]” \nItem No. 18C \nGENERAL FACULTIES COUNCIL \nFor the Meeting of October 30, 2017 \n4. GFC Academic Planning Committee Terms of Reference \nMandate of the Committee: “The Academic Planning \nCommittee (APC) is GFC’s senior committee dealing with \nacademic, financial and planning issues. […] \nAPC is responsible for making recommendations to GFC and/or \nto the Board of Governors concerning policy matters and action \nmatters with respect to the following: \n1. Planning and Priorities: To recommend to GFC and/or \nthe Board of Governors on planning and priorities with \nrespect to the University’s longer term academic, financial, \nand facilities development. \n[…] \n4. Budget Matters […] \nb. To recommend to the Board of Governors on the annual \nbudget, excluding budgets for ancillary units.” \n5. General Faculties Council Terms of Reference (3. Mandate of \nthe Committee) \n“The issues which remain with GFC or which would be referred \nby a Standing Committee to GFC would generally be in the \nnature of the following: \n● high level strategic and stewardship policy issues or \nmatters of significant risk to the University” \n6. GFC Executive Committee Terms of Reference (3. Mandate \nof the Committee): \n“To act as the executive body of General Faculties Council and, \nin general, carry out the functions delegated to it by General \nFaculties Council. (GFC 08 SEP 1966) (GFC 12 FEB 1996)” \n7. Board Learning and Discovery Committee (BLDC) Terms of \nReference/Mandate of the Committee (Section 3): “Except as \nprovided in paragraph 4 hereof and in the Board’s General \nCommittee Terms of Reference, the Committee shall, in \naccordance with the Committee’s responsibilities with powers \ngranted under the Post-Secondary Learning Act, monitor, \nevaluate, advise and make decisions on behalf of the Board with \nrespect to matters concerning the teaching and research affairs \nof the University, including proposals coming from the \nadministration and from General Faculties Council (the “GFC”), \nand shall consider future educational expectations and \nchallenges to be faced by the University. The Committee shall \nalso include any other matter delegated to the Committee by the \nBoard. \nWithout limiting the generality of the foregoing the Committee \nshall: […] \ng. undertake studies and review academic matters that pertain to \nthe quality of the educational experience at the University; g. \nmonitor educational and research trends, community \nexpectations and demands; \n[…] \nj. ensure that the academic teaching and research activities at \nthe University are administered and undertaken in a manner \nItem No. 18C \nGENERAL FACULTIES COUNCIL \nFor the Meeting of October 30, 2017 \nconsistent with the vision and mission of the University; \nk. consider future educational expectations and challenges to be \nfaced by the University[.] […]” \nm. review recommendations of GFC Academic Planning \nCommittee concerning the Comprehensive Institutional Plan \n(CIP) and/or a similar document as required, and make \nrecommendations to the Board in respect thereof[.] […]” \nAttachments: \n1.  Executive Summary of the Annual Report on Undergraduate Student Financial Support \nPrepared by: Fiona Halbert, Assistant Registrar – Student Financial Support, fiona.halbert@ualberta.ca \nmailto:fiona.halbert@ualberta.ca\n \n \n \n\tItem-1-GFC-Agenda\n\tItem-4-New-Members\n\tItem-5-PLLC-Next-Steps\n\tItem-5-PLLC-Next-Steps\n\tatt-1-pllc-external-review-report-2017\n\tatt-2-synthesis-of-recommendations-and-comments-in-peter-mackinnons-report\n\tItem-6-Exec-report-ad-hoc-recommendations\n\tItem-6-Transition-Committee-Report-OI\n\tStatus of ad hoc Recommendations - Oct 23\n\tItem-7-FGSR-Exam\n\tItem-7-FGSR-Exam-OI\n\tItem-7-FGSR-Examination-ATT1\n\tItem-8-CLE-report-teaching-evaluation\n\tItem-8-USRI-Report-OI-rev\n\tAtt-1-CLE-Recommendations\n\tAtt-2- Report\n\tAtt-2-Appendix A - Table of Reviewed Literature\n\tAtt-2-Appendix B - Summary of Interviews with Department Chairs\n\tAtt-2-Appendix C - Interview Questions\n\tAtt-2-Appendix D - Sample USRI Case Studies\n\tAtt-2-Appendix E - Summary of  Positions+Recommed RE USRIs in UAlberta Policy-Documents-Reports\n\tATT-2-Appendix-F\n\tAtt-2-Appendix G - References for Reviewed Literature\n\tAtt-2-Appendix H - Abstracts for Reviewed Literature\n\tAtt-2-Appendix I - Rec Re Evaluation of Teaching from 2013 Renaissance Ctte Report\n\tItem-9-SCPC-CLRC-ToR\n\tItem-9-CLRC-TOR-OI\n\tatt-1-SCPC-TOR\n\tatt-2-CLRC-TOR\n\tItem-10-FDC-ToR\n\tItem-10-FDC-TOR-OI\n\tatt-1-FDC-TOR\n\tatt-2-FDC-TOR\n\tItem-11-Admission-Aboriginal-Students\n\tItem-11-Admission-Aboriginal-Students-OI\n\tatt-1\n\tatt-2\n\tItem-12-1 Question from K Monda - Fine Arts Building\n\tItem-12-Question-and-Response-KMonda-Fine-Arts\n\tQuestion from K Monda - Fine Arts Building\n\tF&A Response \n\tF&O Response  \n\tArts Response \n\tItem-13-Exec-Report-to-GFC\n\tItem-14-APC-Report-to-GFC\n\tItem-15-ASC-Report-to-GFC\n\tItem16-GFC-Nominations & Elections\n\tItem-18A-Academic-Schedule\n\tItem-18A-2018-19 Academic Schedule-OI\n\tatt-2019-2019 Academic Schedule documents\n\t2018-2019 month calendar\n\t2018-2019 Hours of Instruction\n\tNumber of Evening Classes in Fall Term\n\tNumber of Evening Classes in Winter Term\n\tMajor dates and deadlines\n\tGFC final schedule\n\tItem-18B-Waiver-Advertising\n\tItem-18B-Waiver of Advertising\n\t2017'08'29 2016-17 Report Memo\n\tItem-18C-Report-UG-Financial-Support\n\tItem-18C-Annual-Report-OI\n\tAnnual-Report-of-USFS-ATT1\n",
    "collection title": "GFC"
}