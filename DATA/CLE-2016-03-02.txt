{
    "Committee": "CLE",
    "Date": "2016-03-02",
    "Title": "CLE General Faculties Council - 2016-03-02",
    "Location": "2-31 South Academic Building (SAB)",
    "Time": "2:00 PM - 4:00 PM",
    "Attendees": [
        "Sarah Forgie Chair (Delegate), Provost and Vice-President (Academic)",
        "Shannon Erichsen Member, Support staff representative (Category B1.0), elected by GFC",
        "Roger Graves Member, Director, Centre for Teaching and Learning",
        "Luis Marin Member, Graduate Student at-Large",
        "Navneet Khinda (Delegate) Member, Vice-President (Academic)",
        "Jeff Rawlings Member (Delegate), Vice-Provost and Associate Vice-President of",
        "Information Technology",
        "Norma Rodenburg Member (Delegate), Vice-Provost and University Registrar or Delegate",
        "Toni Samek Member, Major Teaching Award Recipient, Staff Representative",
        "Quinten Starko Member, Undergraduate Student at-Large",
        "Harsh Thaker Member, Vice-President (Academic)",
        "Mani Vaidyanathan Member, Academic Staff",
        "Sarah Forgie Vice-Provost (Learning Initiatives) and Chair, GFC CLE",
        "Roger Graves Interim Director, Centre for Teaching and Learning",
        "Navneet Khinda President, Students' Union (SU)",
        "Karsten Mundel Associate Dean,  Augustana Campus",
        "Toni Samek School of Library and Information Studies, Faculty of Education",
        "Mani Vaidyanathan Electrical & Computer Engineering, Faculty of Engineering"
    ],
    "Items": [
        {
            "Item No.": "5",
            "Agenda Title": "Formative Feedback ",
            "Motion": " N/A ",
            "Action Requested": "Discussion/Advice, Information",
            "Date": "2016-03-02",
            "Committee": "CLE",
            "Proposed By": "N/A ",
            "Presenter": "Roger Graves, GFC Committee on the Learning Environment",
            "Description": "Purpose of the Proposal: For information/discussion. Discussion: Dr Graves noted that teaching is ideally assessed in multiple ways. He spoke to the material distributed noting that Blue Pulse provides a feedback system that allows faculty and students to communicate with each other and allows instructors the time to make changes or improvements during the course. A member reported on midterm evaluations currently in use in the School of Library and Information Studies noting that these are voluntary and provide communication between the instructor and anonymous students which remains between these two parties. Instructors are able to respond to feedback from students and either: institute a change; respond that it is too late in the term for a change; or indicate that a change will not be made and an explanation of why this is. This mid-term evaluation is encouraged for every course and is seen as helpful by students and instructors. A member noted that this functionality is also available through course evaluation but that a culture that values mid-term evaluation is needed for uptake. Mr Rawlings will provide some statistics on current use of this feature. Dr Graves and Mr Rawlings will provide the committee with further information and data on usage of current systems at a subsequent meeting.",
            "Participation": [
                "GFC CLE October 7, 2015 Meeting: Discussion on Topics for 2015-2016 Committee Workplan ",
                "GFC CLE November 4, 2015 Meeting: Draft Template ",
                "GFC CLE January 20, 2016 Meeting: Challenges for CLE – Topics for Discussion "
            ],
            "Approval Route": [
                "N/A"
            ],
            "Final Approver": " N/A"
        },
        {
            "Item No.": "6",
            "Agenda Title": "Mandated USRI Questions for Project Based and Online Courses ",
            "Motion": " N/A ",
            "Action Requested": "Information",
            "Date": "2016-03-02",
            "Committee": "CLE",
            "Proposed By": "N/A ",
            "Presenter": "Mani Vaidyanathan and Toni Samek, GFC Committee on the Learning Environment",
            "Description": "Purpose of the Proposal: To provide additional information on GFC mandated USRI questions for 100% online courses. Discussion: It was noted that courses are being taught in new and different ways and that USRI questions should have the flexibility to reflect this difference. Courses which provide a non-traditional approach include project based courses but also online, advanced research, and practicum courses. A member noted that instructors want a contrast between delivering structured learning and mentoring type opportunities. It was noted that the classic ten questions may be insufficient and a suggestion of retaining five classic questions with the other five questions based on the type of course being evaluated.",
            "Participation": [
                "GFC CLE October 7, 2015 Meeting: Discussion on Topics for 2015-2016 Committee Workplan ",
                "GFC CLE November 4, 2015 Meeting: Draft Template ",
                "GFC CLE January 20, 2016 Meeting: Challenges for CLE – Topics for Discussion "
            ],
            "Approval Route": [
                "N/A"
            ],
            "Final Approver": " N/A"
        },
        {
            "Item No.": "7",
            "Agenda Title": "Proposed Terms of Reference for GFC Committee on the Learning Environment (CLE) Subcommittee to Explore Teaching Tenure Stream at University of Alberta ",
            "Motion": "THAT the GFC Committee on the Learning Environment (CLE) approve, with delegated authority from General Faculties Council, the proposed terms of reference CLE Subcommittee to Explore Teaching Tenure Stream at University of Alberta, as set forth in Attachment 1. ",
            "Action Requested": "Approval",
            "Date": "2016-03-02",
            "Committee": "CLE",
            "Proposed By": "Sarah Forgie, Chair, GFC Committee on the Learning Environment and Fahim Rahman, Vice-President (Academic), Students’ Union ",
            "Presenter": "Navneet Khinda, President, Students’ Union (delegate, Fahim Rahman, Vice-President (Academic), Students’ Union)",
            "Description": "Purpose of the Proposal: To approve the terms of reference to establish a CLE Subcommittee to explore the opportunities and challenges for creating a teaching tenure stream at the University of Alberta. Discussion: Ms Khinda reported that the proposed subcommittee would explore the opportunities and challenges of creating a teaching tenure stream and provide a report reflecting discussions, review of current practices at other institutions and research on the topic. Section 4 of the proposed terms of reference was revised to reflect that a draft report would be presented to CLE for the October 2016 meeting, with the understanding that the committee would determine the next steps at that time.",
            "Participation": [
                "GFC CLE October 7, 2015 Meeting: Discussion on Topics for 2015-2016 Committee Workplan ",
                "GFC CLE November 4, 2015 Meeting: Draft Template ",
                "GFC CLE January 20, 2016 Meeting: Challenges for CLE – Topics for Discussion "
            ],
            "Approval Route": [
                "GFC Committee on the Learning Environment (March 2, 2016) – for approval"
            ],
            "Final Approver": "GFC Committee on the Learning Environment"
        },
        {
            "Item No.": "8",
            "Agenda Title": "Proposal for a new Scheduling Initiative for Augustana Faculty ",
            "Motion": " N/A ",
            "Action Requested": "Discussion/Advice",
            "Date": "2016-03-02",
            "Committee": "CLE",
            "Proposed By": "Dr. Allen Berger, Dean, Augustana Faculty ",
            "Presenter": "Dr. Karsten Mündel, Associate Dean, Academic, Augustana Faculty",
            "Description": "Purpose of the Proposal: To discusses the proposed new scheduling initiative at Augustana Campus. Discussion: Dr Mundel presented the Augustana scheduling initiative which seeks to increase the quantity and quality of experiential learning, connecting with rural communities and international experiences. He noted that this initiative may also address student stress and mental health issues in a small way. He emphasized that this is not a change in the length of the term, but a reorganization within the existing term. Students would take one course in the first three week block, and then take four courses in the following 11 week session. This would allow the three week block to be used strategically for an intensive experience plus lighten the load from five to four courses for the remainder of the term. In response to a question on how an extended or intensive writing experience would be implemented in a three week block, Dr Mundel noted the writing centre has been closely involved in addressing this. A member noted that it was important to ensure students appreciate the time commitment involved in an intensive three week course. On the question of how this initiative will be evaluated, Dr Mundel noted that a faculty member had a TLEF grant to gather two years of baseline data, surveying students in the first few days of classes and another survey mid-term. In addition, focus groups, and other qualitative pieces will be employed with students, faculty and staff. The committee that looks at academic skills will also be involved in the evaluation of the initiative. On the question of transferability of courses, Dr Mundel noted that the credits allocated to the courses will not change, so current transfer status would be maintained. Dr Mundel noted that class time will be lengthened from 50 to 60 min and 75 to 90 min to accommodate the eleven week classes.",
            "Participation": [
                "Augustana Fine Arts and Humanities, Science, and Social Sciences Department meetings – extensive consultation January-April 2015 (all departments include student representatives). ",
                "Augustana Faculty Council – regular discussion in monthly meetings prior to formal approval in May 2015. ",
                "Provost’s office – consultations and discussion ",
                "Dean’s Council – discussion, January 19 2016 ",
                "SU President & VP-Academic – discussion, January 2016. ",
                "Phyllis Clark’s Senior Executive Team – discussion, January 2016 ",
                "AASUA – discussion, January 12, 2016 ",
                "GFC Committee on the Learning Environment – discussion March 2, 2016 ",
                "GFC Academic Standards Committee-Subcommittee on Standards – discussion March 3, 2016 ",
                "GFC Academic Standards Committee – discussion March 17, 2016 ",
                "GFC Executive Committee – discussion April 11, 2016 "
            ],
            "Approval Route": [
                "N/A"
            ],
            "Final Approver": " N/A"
        }
    ],
    "url": "/static/CLE/2016-03-02/Past-Meeting-Material.pdf",
    "content": "This agenda and its corresponding attachments are transitory records. University Governance is the official copy holder for files of the Board of \nGovernors, GFC, and their standing committees. Members are instructed to destroy this material following the meeting. \nCOMMITTEE ON THE LEARNING ENVIRONMENT \nOPEN SESSION AGENDA \nWednesday, March 02, 2016 \n2-31 South Academic Building (SAB) \n2:00 PM - 4:00 PM \nOPENING SESSION                               \n1 Approval of the Agenda Sarah Forgie \n2 Approval of the Open Session Minutes of January 20, 2016 Sarah Forgie \n3 Comments from the Chair (no documents) Sarah Forgie \nDISCUSSION ITEMS  \n4 Universal Classrooms - Update (no documents) Mani Vaidyanathan \n5 Formative Feedback - Update (no documents) Roger Graves \n6 Mandated USRI Questions for Project Based and Online Courses - \nupdate \nMani Vaidyanathan \nToni Samek \nACTION ITEMS  \n7 Proposed Terms of Reference for GFC Committee on the Learning \nEnvironment (CLE) Subcommittee to Explore Teaching Tenure Stream \nat the University of Alberta \nMotion: To Approve \nNavneet Khinda \nDISCUSSION ITEMS  \n8 Proposal for a new scheduling initiative for Augustana Faculty Karsten Mundel \n9 Question Period Sarah Forgie \nINFORMATION REPORTS  \n10 Items Approved by the Committee by E-Mail Ballots (non-debatable) - \nNo items to date \n11 Information Items Forwarded to Committee Members Between \nMeetings - No items to date \nCLOSING SESSION  \n12 Next meeting: April 6, 2016  \n13 Next General Faculties Council meeting: March 21, 2016  \nGFC Committee on the Learning Environment 03/02/2016 \nPage 2 \nDocumentation was before members unless otherwise noted. \nMeeting REGRETS to: Andrea Patrick, Assistant GFC Secretary, apatrick@ualberta.ca, 780-492-1937 \nPrepared by: Meg Brolley, Coordinator, GFC CLE, 780-492-4733, meg.brolley@ualberta.ca \nUniversity Governance www.governance.ualberta.ca \nhttp://www.uofaweb.ualberta.ca/governance/\nItem No. 5 \nGFC COMMITTEE ON THE LEARNING ENVIRONMENT \nFor the Meeting of March 2, 20016 \nOUTLINE OF ISSUE \nAgenda Title: Formative Feedback \nMotion:  N/A  \nItem   \nAction Requested Approval Recommendation  Discussion/Advice Information \nProposed by N/A \nPresenter Roger Graves, GFC Committee on the Learning Environment \nSubject Formative Feedback \nDetails \nResponsibility N/A \nThe Purpose of the Proposal is \n(please be specific) \nTo provide additional information on Formative Feedback \nThe Impact of the Proposal is N/A \nReplaces/Revises (eg, policies, \nresolutions) \nN/A \nTimeline/Implementation Date N/A \nEstimated Cost N/A \nSources of Funding N/A \nNotes  \nAlignment/Compliance \nAlignment with Guiding \nDocuments \nDare to Discover, Dare to Deliver, Institutional values \nCompliance with Legislation, \nPolicy and/or Procedure \nRelevant to the Proposal \n(please quote legislation and \ninclude identifying section \nnumbers) \n1. GFC Committee on the Learning Environment (3. Mandate of the \nCommittee) \n“The Committee on the Learning Environment is a standing committee of \nthe General Faculties Council that promotes an optimal learning \nenvironment in alignment with guiding documents of the University of \nAlberta. (EXEC 04 DEC 2006) \nThe Committee on the Learning Environment is responsible for making \nrecommendations concerning policy matters and action matters with \nrespect of the following: \n[…] \nd) To develop policies that promote ongoing assessment of teaching, \nlearning, and learning services through all Faculties and units. \ne) To nurture the development of innovative and creative learning \nservices and teaching practices. \nf) To encourage the sharing and discussion of evidence about effective \nteaching, learning, and learning services. \ng) To promote critical reflection on the impact of broad societal changes \nin teaching, learning, and the learning environment. \nh) To promote projects with relevant internal and external bodies that \noffer unique teaching and learning opportunities that would benefit the \nuniversity community. \ni) To consider any matter deemed by the GFC Committee on the \nLearning Environment to be within the purview of its general \nresponsibility.” \nItem No. 5 \nGFC COMMITTEE ON THE LEARNING ENVIRONMENT \nFor the Meeting of March 2, 20016 \nRouting (Include meeting dates) \nParticipation: \n(parties who have seen the \nproposal and in what capacity) \n• Those who have been \ninformed \n• Those who have been \nconsulted \n• Those who are actively \nparticipating \nGFC CLE October 7, 2015 Meeting: Discussion on Topics for 2015-2016 \nCommittee Workplan \nGFC CLE November 4, 2015 Meeting: Draft Template \nGFC CLE January 20, 2016 Meeting: Challenges for CLE – Topics for \nDiscussion \nApproval Route (Governance) \n(including meeting dates) \nN/A \nFinal Approver N/A \nAttachments  \n1. Attachment 1 (page 1 - 2) Bluepulse \n2. Attachment 2 (page 1- 15) Learning Experience Management (LEM) for Higher Education \nPrepared by: Meg Brolley, Coordinator, GFC Committee on the Learning Environment, \nmeg.brolley@ualberta.ca \nwww.bluepulsehub.com | www.explorance.com © 2015 by eXplorance® Inc. All rights reserved.\nStart communicating with all \nstudents. Students need a \nfeedback conduit, especially in \nlarge or eLearning courses or when \nthey are not comfortable asking \nquestions aloud. Bluepulse offers \ninstructors a way to understand \nand close learning gaps by \ncommunicating with students in \nclass or on their mobile phone.\nStop surprise end-of-term \nfeedback. Instructors must have a \nway to communicate with \nstudents to gain feedback prior to \nend-of-term evaluations. \nBluepulse offers exclusive access \nto student feedback allowing \ninstructors to build development \nportfolios on real engagement \nstatistics.\nContinue what you’re doing right. \nHaving a ‘pulse’ on student needs \nand knowing that the right \nstrategies are in place is always a \ngreat confidence booster. By \nfocusing on teaching strategies \nthat receive a welcome response \nfrom students, instructors can \nfoster a collaborative \nenvironment that increases \nparticipation and engagement.\nBluepulse® is a unique social feedback platform designed to help educators\nachieve teaching and learning excellence from the first day of class to the last.\nStronger engagement. Quicker improvement. Better results.\nStart Stop Continue\nINCREASE STUDENT ENGAGEMENT.\nFOCUS ON IMPROVEMENT.\nFROM DAY ONE.\nLMS LTI Integrations:\nIntegrate Bluepulse with your LMS via LTI in hours or utilize a web based implementation. Your institution’s \nLMS is Bluepulse’s access point on mobile devieces, tablets, or desktops.\nCHAT LIVE WITH ONE OF OUR EXPERTS\nwww.bluepulsehub.com\nQUESTIONS ABOUT BLUEPULSE? CALL US\n+1 (877) 938-2111 (North America)      \n+1 (514) 938 2111 (International)\nHOW BLUEPULSE \nWORKS:\nALL PARTIES CAN IMPROVE \nFROM CONFIDENTIAL \nSTUDENT FEEDBACK. \nHOW CAN I GET BLUEPULSE:\nYou can get Bluepulse in a few easy steps. \nVisit www.bluepulsehub.com and sign up \nfor a software walkthrough. Bluepulse is \nalso supported on any mobile device and \ncan be set up in hours for your institution.\nInstructors create and publish up to seven \ninitiatives such as, “did you understand today’s \nlecture concepts?”, or, “was today’s pacing too \nfast to take notes?”. This allows instructors to \ngain feedback on areas that are important to \nteaching and learning improvement.\nAt any time students can rate initiatives on a \nfive-point scale and submit one qualitative \nsuggestion or rating on faculty created \ninitiatives, per course, per day. \nCommunications are confidential and directly \nsent to instructors.\nInstructors review student suggestions and \nratings. Instructor graphs show which \ninitiatives have the highest level of \nengagement and when. Suggestions can be \nfiltered to isolate the most important or \ncommon feedback.\nInstructors can respond to a suggestion \ndirectly and start a one-on-one, anonymous \nconversation with the student. This offers a \nproactive way to help instructors work with \nat-risk students during the course and drive \nstudents to other retention solutions on \ncampus.\nInstructors can ask questions to the class at \nany time via Learning Polls. Then instructors \nmay respond to all students or exclusively to \nthose whom answered a certain way. For \nexample, instructors may only want to respond \nto the group of students who claimed, “I am \nnot ready for the mid-term exam.”\n1.\n2.\n3.\n4.\n5.\nINTRODUCING\nLEARNING EXPERIENCE MANAGEMENT (LEM) \nFOR HIGHER EDUCATION \nHow to keep up with the pace of change and \nmeet the expectations of all stakeholders As you know, today’s colleges and universities face a changing landscape with \nan ever-evolving set of challenges:\n• Advances in technology create many new options for learning.\n• Competition for students is on the rise; for example, enrollments in \nonline-only for-profit colleges have fallen since 2009 in the face of increased \ncompetition. 1\n• Higher education budgets are on the decline; for example, since 2008 the \naverage U.S. state has cut per-student spending by 28%. 2\n• Governments are pushing for higher standards; for example, Obama \nexplicitly mentioned accreditation reform in his 2013 State of the Union \nreport. 3\n• Some of the new technologies used by most students today include mobile \ndevices, the cloud, social media, and all the resources of the web for finding \ninformation, on demand. Massive Open Online Courses (MOOCs) are on a \n“high-speed trajectory” attracting millions of participants.4\nAll these technologies give students more choices than ever before, and \nthreaten to reshape the entire paradigm of higher education.\nWith so many assumptions of the past changing so quickly, colleges and \nuniversities must rethink their approaches, so they can continue to attract and \nretain students, and accomplish their mission.\nMany of the tools and systems used in academia were never designed to meet \nthe challenges of today. For example, most existing evaluation and feedback \nsystems are geared to assessing instructor performance alone. These \nevaluation systems do not support a process in which improvements by either \nfaculty or students are compared to an initial benchmark.\nWhat’s more, these feedback systems are designed to be backward-looking, \ngathering course evaluations only once at the end of term. Sadly, many faculty \nand students have lost their belief in these tools:\n•  Faculty members fear that end-of-term course evaluations are little more \nthan a “popularity contest” that determines their future raises and \npromotions.\n•  Students seldom see their institutions take any action on their feedback, \nsince improvements to a course are applied only in the following term. This \ncan lead to lower response rates and less engagement among students.\nThe bottom line is that the systems in place to measure progress in many \ninstitutions of higher education are inadequate for today’s challenges.\nAs all educators know, effective teaching is far more than a simple transaction \nbetween a vendor and a customer. In fact, higher education is a relatively \ncomplex and intensive process that occurs over a long term, measured in \nyears.\nThe higher-education market space involves a complex interplay of many \nstakeholders, including:\n•  Applicants, students, and alumni\n•  Faculty, department chairs, deans, and provosts\n•  Facilities management and support staff\n•  CIOs and IT teams, with security policies to govern access\n•  Corporate and private donors\n•  Local, state and national government policy-makers\n•  Future employers\nYet existing feedback systems only gather evaluations from students. These \nsystems fail to tap all the other rich sources that could shed light on the \nquestion of how to improve the process of higher education.\nIt’s clear, as one education blogger put it, that “engagement happens both \ninside and outside of a classroom.” 5 This is proven by the complex ecosystem \nof organizations in place to provide the many goods and services that support \nthe mission of higher education. These include:\n•  Facilities such as labs, libraries and sport centers\n•  Learning material providers, journal and textbook publishers\n•  IT infrastructure platforms such as CRM, ERP, LMS and SIS\n•  Central databases, security and equipment vendors\n•  Accreditation assessment solutions\nAll these organizations help shape the learning environment and play a role in \ndetermining the student’s experience.\nYet existing feedback systems cannot integrate data from the many players in \nthis ecosystem. This further limits the effective reach of these systems.\nAmong the many useful functions this integration could provide:\n•  Pre-populating certain fields in advance to streamline evaluation and survey \nforms, and boost response rates.\n•  Performing sophisticated analysis based on student, instructor, and course \ndata already in the institution’s databases.\n•  Comparing results over time across the hierarchical faculty structure or \nbetween vendors to ensure continuous improvement.\nImprovement at heart.\nwww.explorance.com\n©2015 eXplorance Inc.\nBE\nN\nCH\nM\nAR\nK\nASSESS ANALYZE\nIMPROVEMONITOR\nAs you know, today’s colleges and universities face a changing landscape with \nan ever-evolving set of challenges:\n• Advances in technology create many new options for learning.\n• Competition for students is on the rise; for example, enrollments in \nonline-only for-profit colleges have fallen since 2009 in the face of increased \ncompetition. 1\n• Higher education budgets are on the decline; for example, since 2008 the \naverage U.S. state has cut per-student spending by 28%. 2\n• Governments are pushing for higher standards; for example, Obama \nexplicitly mentioned accreditation reform in his 2013 State of the Union \nreport. 3\n• Some of the new technologies used by most students today include mobile \ndevices, the cloud, social media, and all the resources of the web for finding \ninformation, on demand. Massive Open Online Courses (MOOCs) are on a \n“high-speed trajectory” attracting millions of participants.4\nAll these technologies give students more choices than ever before, and \nthreaten to reshape the entire paradigm of higher education.\nWith so many assumptions of the past changing so quickly, colleges and \nuniversities must rethink their approaches, so they can continue to attract and \nretain students, and accomplish their mission.\nIntroducing LEM for Higher Education\nMany of the tools and systems used in academia were never designed to meet \nthe challenges of today. For example, most existing evaluation and feedback \nsystems are geared to assessing instructor performance alone. These \nevaluation systems do not support a process in which improvements by either \nfaculty or students are compared to an initial benchmark.\nWhat’s more, these feedback systems are designed to be backward-looking, \ngathering course evaluations only once at the end of term. Sadly, many faculty \nand students have lost their belief in these tools:\n•  Faculty members fear that end-of-term course evaluations are little more \nthan a “popularity contest” that determines their future raises and \npromotions.\n•  Students seldom see their institutions take any action on their feedback, \nsince improvements to a course are applied only in the following term. This \ncan lead to lower response rates and less engagement among students.\nThe bottom line is that the systems in place to measure progress in many \ninstitutions of higher education are inadequate for today’s challenges.\nAs all educators know, effective teaching is far more than a simple transaction \nbetween a vendor and a customer. In fact, higher education is a relatively \ncomplex and intensive process that occurs over a long term, measured in \nyears.\nThe higher-education market space involves a complex interplay of many \nstakeholders, including:\n•  Applicants, students, and alumni\n•  Faculty, department chairs, deans, and provosts\n•  Facilities management and support staff\n•  CIOs and IT teams, with security policies to govern access\n•  Corporate and private donors\n•  Local, state and national government policy-makers\n•  Future employers\nYet existing feedback systems only gather evaluations from students. These \nsystems fail to tap all the other rich sources that could shed light on the \nquestion of how to improve the process of higher education.\nIt’s clear, as one education blogger put it, that “engagement happens both \ninside and outside of a classroom.” 5 This is proven by the complex ecosystem \nof organizations in place to provide the many goods and services that support \nthe mission of higher education. These include:\n•  Facilities such as labs, libraries and sport centers\n•  Learning material providers, journal and textbook publishers\n•  IT infrastructure platforms such as CRM, ERP, LMS and SIS\n•  Central databases, security and equipment vendors\n•  Accreditation assessment solutions\nAll these organizations help shape the learning environment and play a role in \ndetermining the student’s experience.\nYet existing feedback systems cannot integrate data from the many players in \nthis ecosystem. This further limits the effective reach of these systems.\nAmong the many useful functions this integration could provide:\n•  Pre-populating certain fields in advance to streamline evaluation and survey \nforms, and boost response rates.\n•  Performing sophisticated analysis based on student, instructor, and course \ndata already in the institution’s databases.\n•  Comparing results over time across the hierarchical faculty structure or \nbetween vendors to ensure continuous improvement.\nExecutive summary 3\nThe mission of higher education 4\nHigher education faces many challenges 4\nBut yesterday’s feedback systems can’t keep up 5\nTeaching involves many stakeholders 5\nPlus a complex ecosystem of providers 6\nMultiple measures are needed, not just evaluations 7\nThe way forward: LEM 8\nWhat is LEM? 8\nHow does LEM work? 10\nLEM in action: two real-world scenarios 11\nHow do you measure the benefits of LEM? 12\nLEM in the marketplace 13\nAbout eXplorance 14\nCONTENTS\n© 2015 by eXplorance, Inc. All rights reserved.\nThis whitepaper poses some fundamental questions about the higher \neducation space:\n•  What is the real mission of higher education?\n•  What challenges hamper reaching that mission?\n•  How can an institution meet these many challenges?\nDelving into these issues raises further questions that can challenge many \ndeep-seated views, both inside and outside academia.\nFor example, to measure the effectiveness of teaching and learning, is it \nenough to rely only on course evaluations by students?\nIs the instructor the only factor in successful learning or are there other \nfactors to consider?\nWhat is the real goal of gathering feedback from the classroom?\nIs it to get a snapshot of the performance of each instructor—to use as the \nprimary basis for their promotions and raises—or is it to promote continuous \nimprovement of the entire institution?\nCan better feedback be gathered, and a more complete analysis delivered, by \nintegrating data collected from other stakeholders and ecosystem players?\nThis whitepaper considers all these questions, and offers unique answers to \nhigher educators seeking to help their institutions remain competitive and \nachieve their true mission.\nAs you know, today’s colleges and universities face a changing landscape with \nan ever-evolving set of challenges:\n• Advances in technology create many new options for learning.\n• Competition for students is on the rise; for example, enrollments in \nonline-only for-profit colleges have fallen since 2009 in the face of increased \ncompetition. 1\n• Higher education budgets are on the decline; for example, since 2008 the \naverage U.S. state has cut per-student spending by 28%. 2\n• Governments are pushing for higher standards; for example, Obama \nexplicitly mentioned accreditation reform in his 2013 State of the Union \nreport. 3\n• Some of the new technologies used by most students today include mobile \ndevices, the cloud, social media, and all the resources of the web for finding \ninformation, on demand. Massive Open Online Courses (MOOCs) are on a \n“high-speed trajectory” attracting millions of participants.4\nAll these technologies give students more choices than ever before, and \nthreaten to reshape the entire paradigm of higher education.\nWith so many assumptions of the past changing so quickly, colleges and \nuniversities must rethink their approaches, so they can continue to attract and \nretain students, and accomplish their mission.\nIntroducing LEM for Higher Education\nMany of the tools and systems used in academia were never designed to meet \nthe challenges of today. For example, most existing evaluation and feedback \nsystems are geared to assessing instructor performance alone. These \nevaluation systems do not support a process in which improvements by either \nfaculty or students are compared to an initial benchmark.\nWhat’s more, these feedback systems are designed to be backward-looking, \ngathering course evaluations only once at the end of term. Sadly, many faculty \nand students have lost their belief in these tools:\n•  Faculty members fear that end-of-term course evaluations are little more \nthan a “popularity contest” that determines their future raises and \npromotions.\n•  Students seldom see their institutions take any action on their feedback, \nsince improvements to a course are applied only in the following term. This \ncan lead to lower response rates and less engagement among students.\nThe bottom line is that the systems in place to measure progress in many \ninstitutions of higher education are inadequate for today’s challenges.\nAs all educators know, effective teaching is far more than a simple transaction \nbetween a vendor and a customer. In fact, higher education is a relatively \ncomplex and intensive process that occurs over a long term, measured in \nyears.\nThe higher-education market space involves a complex interplay of many \nstakeholders, including:\n•  Applicants, students, and alumni\n•  Faculty, department chairs, deans, and provosts\n•  Facilities management and support staff\n•  CIOs and IT teams, with security policies to govern access\n•  Corporate and private donors\n•  Local, state and national government policy-makers\n•  Future employers\nYet existing feedback systems only gather evaluations from students. These \nsystems fail to tap all the other rich sources that could shed light on the \nquestion of how to improve the process of higher education.\nIt’s clear, as one education blogger put it, that “engagement happens both \ninside and outside of a classroom.” 5 This is proven by the complex ecosystem \nof organizations in place to provide the many goods and services that support \nthe mission of higher education. These include:\n•  Facilities such as labs, libraries and sport centers\n•  Learning material providers, journal and textbook publishers\n•  IT infrastructure platforms such as CRM, ERP, LMS and SIS\n•  Central databases, security and equipment vendors\n•  Accreditation assessment solutions\nAll these organizations help shape the learning environment and play a role in \ndetermining the student’s experience.\nYet existing feedback systems cannot integrate data from the many players in \nthis ecosystem. This further limits the effective reach of these systems.\nAmong the many useful functions this integration could provide:\n•  Pre-populating certain fields in advance to streamline evaluation and survey \nforms, and boost response rates.\n•  Performing sophisticated analysis based on student, instructor, and course \ndata already in the institution’s databases.\n•  Comparing results over time across the hierarchical faculty structure or \nbetween vendors to ensure continuous improvement.\nInstitutions of higher education have always played an important role in \nshaping society. Governments and employers rely on higher education to \nprovide an effective learning environment for students.\nEveryone wants students to graduate with the necessary knowledge, skills and \ncompetencies to enter the workforce, meet the needs of employers, create \nvaluable innovations, and have a positive impact on society.\nThis is the mission of higher education institutions. And the outcomes of this \nmission shape the workforce, markets, and national economies for years to \ncome.\nEXECUTIVE \nSUMMARY\n3\nThis whitepaper poses some fundamental questions about the higher \neducation space:\n•  What is the real mission of higher education?\n•  What challenges hamper reaching that mission?\n•  How can an institution meet these many challenges?\nDelving into these issues raises further questions that can challenge many \ndeep-seated views, both inside and outside academia.\nFor example, to measure the effectiveness of teaching and learning, is it \nenough to rely only on course evaluations by students?\nIs the instructor the only factor in successful learning or are there other \nfactors to consider?\nWhat is the real goal of gathering feedback from the classroom?\nIs it to get a snapshot of the performance of each instructor—to use as the \nprimary basis for their promotions and raises—or is it to promote continuous \nimprovement of the entire institution?\nCan better feedback be gathered, and a more complete analysis delivered, by \nintegrating data collected from other stakeholders and ecosystem players?\nThis whitepaper considers all these questions, and offers unique answers to \nhigher educators seeking to help their institutions remain competitive and \nachieve their true mission.\nAs you know, today’s colleges and universities face a changing landscape with \nan ever-evolving set of challenges:\n• Advances in technology create many new options for learning.\n• Competition for students is on the rise; for example, enrollments in \nonline-only for-profit colleges have fallen since 2009 in the face of increased \ncompetition. 1\n• Higher education budgets are on the decline; for example, since 2008 the \naverage U.S. state has cut per-student spending by 28%. 2\n• Governments are pushing for higher standards; for example, Obama \nexplicitly mentioned accreditation reform in his 2013 State of the Union \nreport. 3\n• Some of the new technologies used by most students today include mobile \ndevices, the cloud, social media, and all the resources of the web for finding \ninformation, on demand. Massive Open Online Courses (MOOCs) are on a \n“high-speed trajectory” attracting millions of participants.4\nAll these technologies give students more choices than ever before, and \nthreaten to reshape the entire paradigm of higher education.\nWith so many assumptions of the past changing so quickly, colleges and \nuniversities must rethink their approaches, so they can continue to attract and \nretain students, and accomplish their mission.\nIntroducing LEM for Higher Education\nMany of the tools and systems used in academia were never designed to meet \nthe challenges of today. For example, most existing evaluation and feedback \nsystems are geared to assessing instructor performance alone. These \nevaluation systems do not support a process in which improvements by either \nfaculty or students are compared to an initial benchmark.\nWhat’s more, these feedback systems are designed to be backward-looking, \ngathering course evaluations only once at the end of term. Sadly, many faculty \nand students have lost their belief in these tools:\n•  Faculty members fear that end-of-term course evaluations are little more \nthan a “popularity contest” that determines their future raises and \npromotions.\n•  Students seldom see their institutions take any action on their feedback, \nsince improvements to a course are applied only in the following term. This \ncan lead to lower response rates and less engagement among students.\nThe bottom line is that the systems in place to measure progress in many \ninstitutions of higher education are inadequate for today’s challenges.\nAs all educators know, effective teaching is far more than a simple transaction \nbetween a vendor and a customer. In fact, higher education is a relatively \ncomplex and intensive process that occurs over a long term, measured in \nyears.\nThe higher-education market space involves a complex interplay of many \nstakeholders, including:\n•  Applicants, students, and alumni\n•  Faculty, department chairs, deans, and provosts\n•  Facilities management and support staff\n•  CIOs and IT teams, with security policies to govern access\n•  Corporate and private donors\n•  Local, state and national government policy-makers\n•  Future employers\nYet existing feedback systems only gather evaluations from students. These \nsystems fail to tap all the other rich sources that could shed light on the \nquestion of how to improve the process of higher education.\nIt’s clear, as one education blogger put it, that “engagement happens both \ninside and outside of a classroom.” 5 This is proven by the complex ecosystem \nof organizations in place to provide the many goods and services that support \nthe mission of higher education. These include:\n•  Facilities such as labs, libraries and sport centers\n•  Learning material providers, journal and textbook publishers\n•  IT infrastructure platforms such as CRM, ERP, LMS and SIS\n•  Central databases, security and equipment vendors\n•  Accreditation assessment solutions\nAll these organizations help shape the learning environment and play a role in \ndetermining the student’s experience.\nYet existing feedback systems cannot integrate data from the many players in \nthis ecosystem. This further limits the effective reach of these systems.\nAmong the many useful functions this integration could provide:\n•  Pre-populating certain fields in advance to streamline evaluation and survey \nforms, and boost response rates.\n•  Performing sophisticated analysis based on student, instructor, and course \ndata already in the institution’s databases.\n•  Comparing results over time across the hierarchical faculty structure or \nbetween vendors to ensure continuous improvement.\n1Goldie Blumenstyk, Nonpro�t \nColleges Compete on For-Pro�t’s Turf, \n�e Chronicle of Higher \nEducation, 21 June 2013, page A3\n2Jordan Weissmann, A Truly \nDevastating Graph on State Higher \nEducation Spending, �e Atlantic, \n20 March 2013\n3Barack Obama, �e President’s Plan \nFor A Strong Middle Class & A \nStrong America, 12 February 2013, \npage 5\n4NMC Horizon Report: 2013 Higher \nEducation Edition, �e New Media \nConsortium, 2013, page 12\nInstitutions of higher education have always played an important role in \nshaping society. Governments and employers rely on higher education to \nprovide an effective learning environment for students.\nEveryone wants students to graduate with the necessary knowledge, skills and \ncompetencies to enter the workforce, meet the needs of employers, create \nvaluable innovations, and have a positive impact on society.\nThis is the mission of higher education institutions. And the outcomes of this \nmission shape the workforce, markets, and national economies for years to \ncome.\nTHE MISSION \nOF HIGHER \nEDUCATION\n4\nHIGHER \nEDUCATION \nFACES MANY \nCHALLENGES\nBUT \nYESTERDAY’S \nFEEDBACK \nSYSTEMS \nCAN’T KEEP UP\nAs you know, today’s colleges and universities face a changing landscape with \nan ever-evolving set of challenges:\n• Advances in technology create many new options for learning.\n• Competition for students is on the rise; for example, enrollments in \nonline-only for-profit colleges have fallen since 2009 in the face of increased \ncompetition. 1\n• Higher education budgets are on the decline; for example, since 2008 the \naverage U.S. state has cut per-student spending by 28%. 2\n• Governments are pushing for higher standards; for example, Obama \nexplicitly mentioned accreditation reform in his 2013 State of the Union \nreport. 3\n• Some of the new technologies used by most students today include mobile \ndevices, the cloud, social media, and all the resources of the web for finding \ninformation, on demand. Massive Open Online Courses (MOOCs) are on a \n“high-speed trajectory” attracting millions of participants.4\nAll these technologies give students more choices than ever before, and \nthreaten to reshape the entire paradigm of higher education.\nWith so many assumptions of the past changing so quickly, colleges and \nuniversities must rethink their approaches, so they can continue to attract and \nretain students, and accomplish their mission.\nMany of the tools and systems used in academia were never designed to meet \nthe challenges of today. For example, most existing evaluation and feedback \nsystems are geared to assessing instructor performance alone. These \nevaluation systems do not support a process in which improvements by either \nfaculty or students are compared to an initial benchmark.\nWhat’s more, these feedback systems are designed to be backward-looking, \ngathering course evaluations only once at the end of term. Sadly, many faculty \nand students have lost their belief in these tools:\n•  Faculty members fear that end-of-term course evaluations are little more \nthan a “popularity contest” that determines their future raises and \npromotions.\n•  Students seldom see their institutions take any action on their feedback, \nsince improvements to a course are applied only in the following term. This \ncan lead to lower response rates and less engagement among students.\nThe bottom line is that the systems in place to measure progress in many \ninstitutions of higher education are inadequate for today’s challenges.\nAs all educators know, effective teaching is far more than a simple transaction \nbetween a vendor and a customer. In fact, higher education is a relatively \ncomplex and intensive process that occurs over a long term, measured in \nyears.\nThe higher-education market space involves a complex interplay of many \nstakeholders, including:\n•  Applicants, students, and alumni\n•  Faculty, department chairs, deans, and provosts\n•  Facilities management and support staff\n•  CIOs and IT teams, with security policies to govern access\n•  Corporate and private donors\n•  Local, state and national government policy-makers\n•  Future employers\nYet existing feedback systems only gather evaluations from students. These \nsystems fail to tap all the other rich sources that could shed light on the \nquestion of how to improve the process of higher education.\nIt’s clear, as one education blogger put it, that “engagement happens both \ninside and outside of a classroom.” 5 This is proven by the complex ecosystem \nof organizations in place to provide the many goods and services that support \nthe mission of higher education. These include:\n•  Facilities such as labs, libraries and sport centers\n•  Learning material providers, journal and textbook publishers\n•  IT infrastructure platforms such as CRM, ERP, LMS and SIS\n•  Central databases, security and equipment vendors\n•  Accreditation assessment solutions\nAll these organizations help shape the learning environment and play a role in \ndetermining the student’s experience.\nYet existing feedback systems cannot integrate data from the many players in \nthis ecosystem. This further limits the effective reach of these systems.\nAmong the many useful functions this integration could provide:\n•  Pre-populating certain fields in advance to streamline evaluation and survey \nforms, and boost response rates.\n•  Performing sophisticated analysis based on student, instructor, and course \ndata already in the institution’s databases.\n•  Comparing results over time across the hierarchical faculty structure or \nbetween vendors to ensure continuous improvement.\nFortunately, some promising beacons are lighting the way forward. According \nto the latest research, effective teaching can be measured... although it’s not \nalways done.\nThis view is based on the three-year Measures of Effective Teaching study \nsponsored by the Bill & Melinda Gates Foundation. This involved 3,000 volun-\nteer teachers from different areas of the U.S., with impartial observers study-\ning the experience shared between teachers and students.\nIn a recent op-ed piece in the Washington Post, Bill Gates summed up the \nstudy’s key findings. “What the country needs are thoughtfully developed \nteacher evaluation systems that include multiple measures of performance,” \nhe wrote. Among these measures, he lists student surveys, classroom obser-\nvations by experienced colleagues, and results against standardized tests or \nbenchmarks.6\nIn other words, the best feedback and evaluation metrics for colleges and \nuniversities are based on a rich set of inputs from multiple sources.\nStudent course evaluations are only one measure of the learning environ-\nment. For a more complete metric, evaluations must be combined with a mea-\nsure of learning progress, plus independent peer assessments such as \n360-degree reviews.\nGathering all three inputs and weighing these factors is essential to gain an \nobjective view on how to improve the entire teaching and learning experience.\nTo remain competitive and accomplish their mission, colleges and universities \nneed a new type of system to give them a well-rounded picture of the higher \neducation space.\nThey need a system that can reach and engage all stakeholders, gather and \nanalyze inputs through numerous channels, and deliver real-time, accurate \ninformation to stakeholders and decision-makers.\nThey need a system that can combine factual feedback on the learning experi-\nence with forward-looking predictive analytics.\nThis kind of system can help colleges and universities foster a continuous \ncycle of improvement, and effectively meet the expectations of students, \nemployers, governments and all other stakeholders.\nTo refer to this type of next-generation feedback and evaluation system, \neXplorance, Inc. has coined the term “Learning Experience Management” or \nLEM.\nAs we’ve seen, accomplishing the mission of higher education involves multi-\nple stakeholders and a complex ecosystem of organizations providing related \ngoods and services.\nLearning Experience Management (LEM) is a multifaceted practice designed \nto support this mission.\nLEM takes place as a recurring cycle that ensures continuous improvement \nacross all the dimensions of a professional development process.\nAn effective LEM system must include a comprehensive set of enterprise-class \nautomated evaluations, tests, feedback surveys and workflow. These tools \nenable colleges and universities to benchmark, evaluate, analyze, improve and \nmonitor every aspect of the learning experience.\nAs shown in Figure 1, LEM deals with two out of three phases of the educa-\ntion process: before and after the central process where knowledge, skills, \nand competencies are transmitted to the student. This core process remains \nthe domain of the faculty.\nFor the pre-learning phase, the LEM system supports an in-depth assess-\nment of the current needs, knowledge, skills, and competencies of each \nstudent and faculty member. This assessment is used to create an initial \nin-depth set of benchmarks.\nFor the post-learning phase, LEM supports a rich set of course evaluations, \nand an effective way to measure both faculty and student improvement \nagainst the original benchmarks.\nThe key functions of LEM can be broken down even further. As shown in \nFigure 2, an effective LEM system involves a continuous cycle through five key \nfunctions:\nBenchmark: LEM sets the path to improvement by creating a set of bench-\nmarks. These are based on a weighted selection of initial student training \nrequirements, government accreditation, and employer needs.\nAssess: Feedback is gathered through online course evaluations, 360-degree \npeer reviews, and stakeholder surveys. These can take place numerous times \nduring the teaching term.\nAnalyze: The results are automatically analyzed, translated into suggested \nimprovements, and reported in real-time.\nImprove: The findings can trigger automated actions, such as a survey or a \n360-degree review to probe deeper into any issue. These findings can also \nspark deliberation by appropriate decision-makers.\nMonitor: These improvements are continuously monitored against the initial \nbenchmarks to ensure that the learning experience is providing a high “return \non expectations.”\nConsider this common scenario: Partway through the term, an instructor \nwonders if his teaching methods are meeting his students expectations.\nThe LEM system gives him the ability to conduct interim evaluations at any \ntime. These evaluations monitor his students’ feedback and sentiment, giving \nhim factual real-time information he can use to make timely interim improve-\nments, long before the end of the course.\nIn this example, both students and instructors directly benefit from engaging \nin this feedback process.\nWhen results are tied to an improvement cycle rather than strictly to teacher \nor student performance, higher education institutes have discovered that \nstakeholders are more willing to engage. The institution can thus achieve \nhigher response rates sustained over time.\nA second likely scenario: A student registering for university must pick \nbetween two different courses running at the same time. She’s curious about \nthe experience of other students who chose either option.\nWhen she logs into the student portal, the LEM system enables her to access \nthe feedback processed from previous terms. Far more than a “popularity” \nrating for each instructor, the system provides detailed information on each \ncourse from the viewpoint of different stakeholders, including alumni and \npotential employers. She can also see factual data about the improvement \nrates of each course.\nAll this helps her make an informed decision, and sets her expectations \naccordingly. When a freshman glimpses the benefits of the LEM system right \nat the outset of her university experience, that encourages her to engage with \nthe feedback evaluation process from that moment on.\nIntroducing LEM for Higher Education 5\nTEACHING \nINVOLVES \nMANY STAKE-\nHOLDERS...\nAs you know, today’s colleges and universities face a changing landscape with \nan ever-evolving set of challenges:\n• Advances in technology create many new options for learning.\n• Competition for students is on the rise; for example, enrollments in \nonline-only for-profit colleges have fallen since 2009 in the face of increased \ncompetition. 1\n• Higher education budgets are on the decline; for example, since 2008 the \naverage U.S. state has cut per-student spending by 28%. 2\n• Governments are pushing for higher standards; for example, Obama \nexplicitly mentioned accreditation reform in his 2013 State of the Union \nreport. 3\n• Some of the new technologies used by most students today include mobile \ndevices, the cloud, social media, and all the resources of the web for finding \ninformation, on demand. Massive Open Online Courses (MOOCs) are on a \n“high-speed trajectory” attracting millions of participants.4\nAll these technologies give students more choices than ever before, and \nthreaten to reshape the entire paradigm of higher education.\nWith so many assumptions of the past changing so quickly, colleges and \nuniversities must rethink their approaches, so they can continue to attract and \nretain students, and accomplish their mission.\nMany of the tools and systems used in academia were never designed to meet \nthe challenges of today. For example, most existing evaluation and feedback \nsystems are geared to assessing instructor performance alone. These \nevaluation systems do not support a process in which improvements by either \nfaculty or students are compared to an initial benchmark.\nWhat’s more, these feedback systems are designed to be backward-looking, \ngathering course evaluations only once at the end of term. Sadly, many faculty \nand students have lost their belief in these tools:\n•  Faculty members fear that end-of-term course evaluations are little more \nthan a “popularity contest” that determines their future raises and \npromotions.\n•  Students seldom see their institutions take any action on their feedback, \nsince improvements to a course are applied only in the following term. This \ncan lead to lower response rates and less engagement among students.\nThe bottom line is that the systems in place to measure progress in many \ninstitutions of higher education are inadequate for today’s challenges.\nAs all educators know, effective teaching is far more than a simple transaction \nbetween a vendor and a customer. In fact, higher education is a relatively \ncomplex and intensive process that occurs over a long term, measured in \nyears.\nThe higher-education market space involves a complex interplay of many \nstakeholders, including:\n•  Applicants, students, and alumni\n•  Faculty, department chairs, deans, and provosts\n•  Facilities management and support staff\n•  CIOs and IT teams, with security policies to govern access\n•  Corporate and private donors\n•  Local, state and national government policy-makers\n•  Future employers\nYet existing feedback systems only gather evaluations from students. These \nsystems fail to tap all the other rich sources that could shed light on the \nquestion of how to improve the process of higher education.\nIt’s clear, as one education blogger put it, that “engagement happens both \ninside and outside of a classroom.” 5 This is proven by the complex ecosystem \nof organizations in place to provide the many goods and services that support \nthe mission of higher education. These include:\n•  Facilities such as labs, libraries and sport centers\n•  Learning material providers, journal and textbook publishers\n•  IT infrastructure platforms such as CRM, ERP, LMS and SIS\n•  Central databases, security and equipment vendors\n•  Accreditation assessment solutions\nAll these organizations help shape the learning environment and play a role in \ndetermining the student’s experience.\nYet existing feedback systems cannot integrate data from the many players in \nthis ecosystem. This further limits the effective reach of these systems.\nAmong the many useful functions this integration could provide:\n•  Pre-populating certain fields in advance to streamline evaluation and survey \nforms, and boost response rates.\n•  Performing sophisticated analysis based on student, instructor, and course \ndata already in the institution’s databases.\n•  Comparing results over time across the hierarchical faculty structure or \nbetween vendors to ensure continuous improvement.\nFortunately, some promising beacons are lighting the way forward. According \nto the latest research, effective teaching can be measured... although it’s not \nalways done.\nThis view is based on the three-year Measures of Effective Teaching study \nsponsored by the Bill & Melinda Gates Foundation. This involved 3,000 volun-\nteer teachers from different areas of the U.S., with impartial observers study-\ning the experience shared between teachers and students.\nIn a recent op-ed piece in the Washington Post, Bill Gates summed up the \nstudy’s key findings. “What the country needs are thoughtfully developed \nteacher evaluation systems that include multiple measures of performance,” \nhe wrote. Among these measures, he lists student surveys, classroom obser-\nvations by experienced colleagues, and results against standardized tests or \nbenchmarks.6\nIn other words, the best feedback and evaluation metrics for colleges and \nuniversities are based on a rich set of inputs from multiple sources.\nStudent course evaluations are only one measure of the learning environ-\nment. For a more complete metric, evaluations must be combined with a mea-\nsure of learning progress, plus independent peer assessments such as \n360-degree reviews.\nGathering all three inputs and weighing these factors is essential to gain an \nobjective view on how to improve the entire teaching and learning experience.\nTo remain competitive and accomplish their mission, colleges and universities \nneed a new type of system to give them a well-rounded picture of the higher \neducation space.\nThey need a system that can reach and engage all stakeholders, gather and \nanalyze inputs through numerous channels, and deliver real-time, accurate \ninformation to stakeholders and decision-makers.\nThey need a system that can combine factual feedback on the learning experi-\nence with forward-looking predictive analytics.\nThis kind of system can help colleges and universities foster a continuous \ncycle of improvement, and effectively meet the expectations of students, \nemployers, governments and all other stakeholders.\nTo refer to this type of next-generation feedback and evaluation system, \neXplorance, Inc. has coined the term “Learning Experience Management” or \nLEM.\nAs we’ve seen, accomplishing the mission of higher education involves multi-\nple stakeholders and a complex ecosystem of organizations providing related \ngoods and services.\nLearning Experience Management (LEM) is a multifaceted practice designed \nto support this mission.\nLEM takes place as a recurring cycle that ensures continuous improvement \nacross all the dimensions of a professional development process.\nAn effective LEM system must include a comprehensive set of enterprise-class \nautomated evaluations, tests, feedback surveys and workflow. These tools \nenable colleges and universities to benchmark, evaluate, analyze, improve and \nmonitor every aspect of the learning experience.\nAs shown in Figure 1, LEM deals with two out of three phases of the educa-\ntion process: before and after the central process where knowledge, skills, \nand competencies are transmitted to the student. This core process remains \nthe domain of the faculty.\nFor the pre-learning phase, the LEM system supports an in-depth assess-\nment of the current needs, knowledge, skills, and competencies of each \nstudent and faculty member. This assessment is used to create an initial \nin-depth set of benchmarks.\nFor the post-learning phase, LEM supports a rich set of course evaluations, \nand an effective way to measure both faculty and student improvement \nagainst the original benchmarks.\nThe key functions of LEM can be broken down even further. As shown in \nFigure 2, an effective LEM system involves a continuous cycle through five key \nfunctions:\nBenchmark: LEM sets the path to improvement by creating a set of bench-\nmarks. These are based on a weighted selection of initial student training \nrequirements, government accreditation, and employer needs.\nAssess: Feedback is gathered through online course evaluations, 360-degree \npeer reviews, and stakeholder surveys. These can take place numerous times \nduring the teaching term.\nAnalyze: The results are automatically analyzed, translated into suggested \nimprovements, and reported in real-time.\nImprove: The findings can trigger automated actions, such as a survey or a \n360-degree review to probe deeper into any issue. These findings can also \nspark deliberation by appropriate decision-makers.\nMonitor: These improvements are continuously monitored against the initial \nbenchmarks to ensure that the learning experience is providing a high “return \non expectations.”\nConsider this common scenario: Partway through the term, an instructor \nwonders if his teaching methods are meeting his students expectations.\nThe LEM system gives him the ability to conduct interim evaluations at any \ntime. These evaluations monitor his students’ feedback and sentiment, giving \nhim factual real-time information he can use to make timely interim improve-\nments, long before the end of the course.\nIn this example, both students and instructors directly benefit from engaging \nin this feedback process.\nWhen results are tied to an improvement cycle rather than strictly to teacher \nor student performance, higher education institutes have discovered that \nstakeholders are more willing to engage. The institution can thus achieve \nhigher response rates sustained over time.\nA second likely scenario: A student registering for university must pick \nbetween two different courses running at the same time. She’s curious about \nthe experience of other students who chose either option.\nWhen she logs into the student portal, the LEM system enables her to access \nthe feedback processed from previous terms. Far more than a “popularity” \nrating for each instructor, the system provides detailed information on each \ncourse from the viewpoint of different stakeholders, including alumni and \npotential employers. She can also see factual data about the improvement \nrates of each course.\nAll this helps her make an informed decision, and sets her expectations \naccordingly. When a freshman glimpses the benefits of the LEM system right \nat the outset of her university experience, that encourages her to engage with \nthe feedback evaluation process from that moment on.\n5Robert Talbert, Education as a \ncomplex adaptive system? �e \nChronicle of Higher Education, \n27 September 20\nIntroducing LEM for Higher Education 6\n... PLUS A \nCOMPLEX \nECOSYSTEM \nOF PROVIDERS\nAs you know, today’s colleges and universities face a changing landscape with \nan ever-evolving set of challenges:\n• Advances in technology create many new options for learning.\n• Competition for students is on the rise; for example, enrollments in \nonline-only for-profit colleges have fallen since 2009 in the face of increased \ncompetition. 1\n• Higher education budgets are on the decline; for example, since 2008 the \naverage U.S. state has cut per-student spending by 28%. 2\n• Governments are pushing for higher standards; for example, Obama \nexplicitly mentioned accreditation reform in his 2013 State of the Union \nreport. 3\n• Some of the new technologies used by most students today include mobile \ndevices, the cloud, social media, and all the resources of the web for finding \ninformation, on demand. Massive Open Online Courses (MOOCs) are on a \n“high-speed trajectory” attracting millions of participants.4\nAll these technologies give students more choices than ever before, and \nthreaten to reshape the entire paradigm of higher education.\nWith so many assumptions of the past changing so quickly, colleges and \nuniversities must rethink their approaches, so they can continue to attract and \nretain students, and accomplish their mission.\nMany of the tools and systems used in academia were never designed to meet \nthe challenges of today. For example, most existing evaluation and feedback \nsystems are geared to assessing instructor performance alone. These \nevaluation systems do not support a process in which improvements by either \nfaculty or students are compared to an initial benchmark.\nWhat’s more, these feedback systems are designed to be backward-looking, \ngathering course evaluations only once at the end of term. Sadly, many faculty \nand students have lost their belief in these tools:\n•  Faculty members fear that end-of-term course evaluations are little more \nthan a “popularity contest” that determines their future raises and \npromotions.\n•  Students seldom see their institutions take any action on their feedback, \nsince improvements to a course are applied only in the following term. This \ncan lead to lower response rates and less engagement among students.\nThe bottom line is that the systems in place to measure progress in many \ninstitutions of higher education are inadequate for today’s challenges.\nAs all educators know, effective teaching is far more than a simple transaction \nbetween a vendor and a customer. In fact, higher education is a relatively \ncomplex and intensive process that occurs over a long term, measured in \nyears.\nThe higher-education market space involves a complex interplay of many \nstakeholders, including:\n•  Applicants, students, and alumni\n•  Faculty, department chairs, deans, and provosts\n•  Facilities management and support staff\n•  CIOs and IT teams, with security policies to govern access\n•  Corporate and private donors\n•  Local, state and national government policy-makers\n•  Future employers\nYet existing feedback systems only gather evaluations from students. These \nsystems fail to tap all the other rich sources that could shed light on the \nquestion of how to improve the process of higher education.\nIt’s clear, as one education blogger put it, that “engagement happens both \ninside and outside of a classroom.” 5 This is proven by the complex ecosystem \nof organizations in place to provide the many goods and services that support \nthe mission of higher education. These include:\n•  Facilities such as labs, libraries and sport centers\n•  Learning material providers, journal and textbook publishers\n•  IT infrastructure platforms such as CRM, ERP, LMS and SIS\n•  Central databases, security and equipment vendors\n•  Accreditation assessment solutions\nAll these organizations help shape the learning environment and play a role in \ndetermining the student’s experience.\nYet existing feedback systems cannot integrate data from the many players in \nthis ecosystem. This further limits the effective reach of these systems.\nAmong the many useful functions this integration could provide:\n•  Pre-populating certain fields in advance to streamline evaluation and survey \nforms, and boost response rates.\n•  Performing sophisticated analysis based on student, instructor, and course \ndata already in the institution’s databases.\n•  Comparing results over time across the hierarchical faculty structure or \nbetween vendors to ensure continuous improvement.\nFortunately, some promising beacons are lighting the way forward. According \nto the latest research, effective teaching can be measured... although it’s not \nalways done.\nThis view is based on the three-year Measures of Effective Teaching study \nsponsored by the Bill & Melinda Gates Foundation. This involved 3,000 volun-\nteer teachers from different areas of the U.S., with impartial observers study-\ning the experience shared between teachers and students.\nIn a recent op-ed piece in the Washington Post, Bill Gates summed up the \nstudy’s key findings. “What the country needs are thoughtfully developed \nteacher evaluation systems that include multiple measures of performance,” \nhe wrote. Among these measures, he lists student surveys, classroom obser-\nvations by experienced colleagues, and results against standardized tests or \nbenchmarks.6\nIn other words, the best feedback and evaluation metrics for colleges and \nuniversities are based on a rich set of inputs from multiple sources.\nStudent course evaluations are only one measure of the learning environ-\nment. For a more complete metric, evaluations must be combined with a mea-\nsure of learning progress, plus independent peer assessments such as \n360-degree reviews.\nGathering all three inputs and weighing these factors is essential to gain an \nobjective view on how to improve the entire teaching and learning experience.\nTo remain competitive and accomplish their mission, colleges and universities \nneed a new type of system to give them a well-rounded picture of the higher \neducation space.\nThey need a system that can reach and engage all stakeholders, gather and \nanalyze inputs through numerous channels, and deliver real-time, accurate \ninformation to stakeholders and decision-makers.\nThey need a system that can combine factual feedback on the learning experi-\nence with forward-looking predictive analytics.\nThis kind of system can help colleges and universities foster a continuous \ncycle of improvement, and effectively meet the expectations of students, \nemployers, governments and all other stakeholders.\nTo refer to this type of next-generation feedback and evaluation system, \neXplorance, Inc. has coined the term “Learning Experience Management” or \nLEM.\nAs we’ve seen, accomplishing the mission of higher education involves multi-\nple stakeholders and a complex ecosystem of organizations providing related \ngoods and services.\nLearning Experience Management (LEM) is a multifaceted practice designed \nto support this mission.\nLEM takes place as a recurring cycle that ensures continuous improvement \nacross all the dimensions of a professional development process.\nAn effective LEM system must include a comprehensive set of enterprise-class \nautomated evaluations, tests, feedback surveys and workflow. These tools \nenable colleges and universities to benchmark, evaluate, analyze, improve and \nmonitor every aspect of the learning experience.\nAs shown in Figure 1, LEM deals with two out of three phases of the educa-\ntion process: before and after the central process where knowledge, skills, \nand competencies are transmitted to the student. This core process remains \nthe domain of the faculty.\nFor the pre-learning phase, the LEM system supports an in-depth assess-\nment of the current needs, knowledge, skills, and competencies of each \nstudent and faculty member. This assessment is used to create an initial \nin-depth set of benchmarks.\nFor the post-learning phase, LEM supports a rich set of course evaluations, \nand an effective way to measure both faculty and student improvement \nagainst the original benchmarks.\nThe key functions of LEM can be broken down even further. As shown in \nFigure 2, an effective LEM system involves a continuous cycle through five key \nfunctions:\nBenchmark: LEM sets the path to improvement by creating a set of bench-\nmarks. These are based on a weighted selection of initial student training \nrequirements, government accreditation, and employer needs.\nAssess: Feedback is gathered through online course evaluations, 360-degree \npeer reviews, and stakeholder surveys. These can take place numerous times \nduring the teaching term.\nAnalyze: The results are automatically analyzed, translated into suggested \nimprovements, and reported in real-time.\nImprove: The findings can trigger automated actions, such as a survey or a \n360-degree review to probe deeper into any issue. These findings can also \nspark deliberation by appropriate decision-makers.\nMonitor: These improvements are continuously monitored against the initial \nbenchmarks to ensure that the learning experience is providing a high “return \non expectations.”\nConsider this common scenario: Partway through the term, an instructor \nwonders if his teaching methods are meeting his students expectations.\nThe LEM system gives him the ability to conduct interim evaluations at any \ntime. These evaluations monitor his students’ feedback and sentiment, giving \nhim factual real-time information he can use to make timely interim improve-\nments, long before the end of the course.\nIn this example, both students and instructors directly benefit from engaging \nin this feedback process.\nWhen results are tied to an improvement cycle rather than strictly to teacher \nor student performance, higher education institutes have discovered that \nstakeholders are more willing to engage. The institution can thus achieve \nhigher response rates sustained over time.\nA second likely scenario: A student registering for university must pick \nbetween two different courses running at the same time. She’s curious about \nthe experience of other students who chose either option.\nWhen she logs into the student portal, the LEM system enables her to access \nthe feedback processed from previous terms. Far more than a “popularity” \nrating for each instructor, the system provides detailed information on each \ncourse from the viewpoint of different stakeholders, including alumni and \npotential employers. She can also see factual data about the improvement \nrates of each course.\nAll this helps her make an informed decision, and sets her expectations \naccordingly. When a freshman glimpses the benefits of the LEM system right \nat the outset of her university experience, that encourages her to engage with \nthe feedback evaluation process from that moment on.\n6Bill Gates,  A fairer way to evaluate \nteachers, Washington Post, 3 April \n2013\nMULTIPLE \nMEASURES \nARE NEEDED, \nNOT JUST \nEVALUATIONS\nIntroducing LEM for Higher Education 7\nAs you know, today’s colleges and universities face a changing landscape with \nan ever-evolving set of challenges:\n• Advances in technology create many new options for learning.\n• Competition for students is on the rise; for example, enrollments in \nonline-only for-profit colleges have fallen since 2009 in the face of increased \ncompetition. 1\n• Higher education budgets are on the decline; for example, since 2008 the \naverage U.S. state has cut per-student spending by 28%. 2\n• Governments are pushing for higher standards; for example, Obama \nexplicitly mentioned accreditation reform in his 2013 State of the Union \nreport. 3\n• Some of the new technologies used by most students today include mobile \ndevices, the cloud, social media, and all the resources of the web for finding \ninformation, on demand. Massive Open Online Courses (MOOCs) are on a \n“high-speed trajectory” attracting millions of participants.4\nAll these technologies give students more choices than ever before, and \nthreaten to reshape the entire paradigm of higher education.\nWith so many assumptions of the past changing so quickly, colleges and \nuniversities must rethink their approaches, so they can continue to attract and \nretain students, and accomplish their mission.\nMany of the tools and systems used in academia were never designed to meet \nthe challenges of today. For example, most existing evaluation and feedback \nsystems are geared to assessing instructor performance alone. These \nevaluation systems do not support a process in which improvements by either \nfaculty or students are compared to an initial benchmark.\nWhat’s more, these feedback systems are designed to be backward-looking, \ngathering course evaluations only once at the end of term. Sadly, many faculty \nand students have lost their belief in these tools:\n•  Faculty members fear that end-of-term course evaluations are little more \nthan a “popularity contest” that determines their future raises and \npromotions.\n•  Students seldom see their institutions take any action on their feedback, \nsince improvements to a course are applied only in the following term. This \ncan lead to lower response rates and less engagement among students.\nThe bottom line is that the systems in place to measure progress in many \ninstitutions of higher education are inadequate for today’s challenges.\nAs all educators know, effective teaching is far more than a simple transaction \nbetween a vendor and a customer. In fact, higher education is a relatively \ncomplex and intensive process that occurs over a long term, measured in \nyears.\nThe higher-education market space involves a complex interplay of many \nstakeholders, including:\n•  Applicants, students, and alumni\n•  Faculty, department chairs, deans, and provosts\n•  Facilities management and support staff\n•  CIOs and IT teams, with security policies to govern access\n•  Corporate and private donors\n•  Local, state and national government policy-makers\n•  Future employers\nYet existing feedback systems only gather evaluations from students. These \nsystems fail to tap all the other rich sources that could shed light on the \nquestion of how to improve the process of higher education.\nIt’s clear, as one education blogger put it, that “engagement happens both \ninside and outside of a classroom.” 5 This is proven by the complex ecosystem \nof organizations in place to provide the many goods and services that support \nthe mission of higher education. These include:\n•  Facilities such as labs, libraries and sport centers\n•  Learning material providers, journal and textbook publishers\n•  IT infrastructure platforms such as CRM, ERP, LMS and SIS\n•  Central databases, security and equipment vendors\n•  Accreditation assessment solutions\nAll these organizations help shape the learning environment and play a role in \ndetermining the student’s experience.\nYet existing feedback systems cannot integrate data from the many players in \nthis ecosystem. This further limits the effective reach of these systems.\nAmong the many useful functions this integration could provide:\n•  Pre-populating certain fields in advance to streamline evaluation and survey \nforms, and boost response rates.\n•  Performing sophisticated analysis based on student, instructor, and course \ndata already in the institution’s databases.\n•  Comparing results over time across the hierarchical faculty structure or \nbetween vendors to ensure continuous improvement.\nFortunately, some promising beacons are lighting the way forward. According \nto the latest research, effective teaching can be measured... although it’s not \nalways done.\nThis view is based on the three-year Measures of Effective Teaching study \nsponsored by the Bill & Melinda Gates Foundation. This involved 3,000 volun-\nteer teachers from different areas of the U.S., with impartial observers study-\ning the experience shared between teachers and students.\nIn a recent op-ed piece in the Washington Post, Bill Gates summed up the \nstudy’s key findings. “What the country needs are thoughtfully developed \nteacher evaluation systems that include multiple measures of performance,” \nhe wrote. Among these measures, he lists student surveys, classroom obser-\nvations by experienced colleagues, and results against standardized tests or \nbenchmarks.6\nIn other words, the best feedback and evaluation metrics for colleges and \nuniversities are based on a rich set of inputs from multiple sources.\nStudent course evaluations are only one measure of the learning environ-\nment. For a more complete metric, evaluations must be combined with a mea-\nsure of learning progress, plus independent peer assessments such as \n360-degree reviews.\nGathering all three inputs and weighing these factors is essential to gain an \nobjective view on how to improve the entire teaching and learning experience.\nTo remain competitive and accomplish their mission, colleges and universities \nneed a new type of system to give them a well-rounded picture of the higher \neducation space.\nThey need a system that can reach and engage all stakeholders, gather and \nanalyze inputs through numerous channels, and deliver real-time, accurate \ninformation to stakeholders and decision-makers.\nThey need a system that can combine factual feedback on the learning experi-\nence with forward-looking predictive analytics.\nThis kind of system can help colleges and universities foster a continuous \ncycle of improvement, and effectively meet the expectations of students, \nemployers, governments and all other stakeholders.\nTo refer to this type of next-generation feedback and evaluation system, \neXplorance, Inc. has coined the term “Learning Experience Management” or \nLEM.\nAs we’ve seen, accomplishing the mission of higher education involves multi-\nple stakeholders and a complex ecosystem of organizations providing related \ngoods and services.\nLearning Experience Management (LEM) is a multifaceted practice designed \nto support this mission.\nLEM takes place as a recurring cycle that ensures continuous improvement \nacross all the dimensions of a professional development process.\nAn effective LEM system must include a comprehensive set of enterprise-class \nautomated evaluations, tests, feedback surveys and workflow. These tools \nenable colleges and universities to benchmark, evaluate, analyze, improve and \nmonitor every aspect of the learning experience.\nAs shown in Figure 1, LEM deals with two out of three phases of the educa-\ntion process: before and after the central process where knowledge, skills, \nand competencies are transmitted to the student. This core process remains \nthe domain of the faculty.\nFor the pre-learning phase, the LEM system supports an in-depth assess-\nment of the current needs, knowledge, skills, and competencies of each \nstudent and faculty member. This assessment is used to create an initial \nin-depth set of benchmarks.\nFor the post-learning phase, LEM supports a rich set of course evaluations, \nand an effective way to measure both faculty and student improvement \nagainst the original benchmarks.\nThe key functions of LEM can be broken down even further. As shown in \nFigure 2, an effective LEM system involves a continuous cycle through five key \nfunctions:\nBenchmark: LEM sets the path to improvement by creating a set of bench-\nmarks. These are based on a weighted selection of initial student training \nrequirements, government accreditation, and employer needs.\nAssess: Feedback is gathered through online course evaluations, 360-degree \npeer reviews, and stakeholder surveys. These can take place numerous times \nduring the teaching term.\nAnalyze: The results are automatically analyzed, translated into suggested \nimprovements, and reported in real-time.\nImprove: The findings can trigger automated actions, such as a survey or a \n360-degree review to probe deeper into any issue. These findings can also \nspark deliberation by appropriate decision-makers.\nMonitor: These improvements are continuously monitored against the initial \nbenchmarks to ensure that the learning experience is providing a high “return \non expectations.”\nConsider this common scenario: Partway through the term, an instructor \nwonders if his teaching methods are meeting his students expectations.\nThe LEM system gives him the ability to conduct interim evaluations at any \ntime. These evaluations monitor his students’ feedback and sentiment, giving \nhim factual real-time information he can use to make timely interim improve-\nments, long before the end of the course.\nIn this example, both students and instructors directly benefit from engaging \nin this feedback process.\nWhen results are tied to an improvement cycle rather than strictly to teacher \nor student performance, higher education institutes have discovered that \nstakeholders are more willing to engage. The institution can thus achieve \nhigher response rates sustained over time.\nA second likely scenario: A student registering for university must pick \nbetween two different courses running at the same time. She’s curious about \nthe experience of other students who chose either option.\nWhen she logs into the student portal, the LEM system enables her to access \nthe feedback processed from previous terms. Far more than a “popularity” \nrating for each instructor, the system provides detailed information on each \ncourse from the viewpoint of different stakeholders, including alumni and \npotential employers. She can also see factual data about the improvement \nrates of each course.\nAll this helps her make an informed decision, and sets her expectations \naccordingly. When a freshman glimpses the benefits of the LEM system right \nat the outset of her university experience, that encourages her to engage with \nthe feedback evaluation process from that moment on.\nIntroducing LEM for Higher Education 8\nTHE WAY \nFORWARD: \nLEM\nWHAT IS \nLEM?\nFortunately, some promising beacons are lighting the way forward. According \nto the latest research, effective teaching can be measured... although it’s not \nalways done.\nThis view is based on the three-year Measures of Effective Teaching study \nsponsored by the Bill & Melinda Gates Foundation. This involved 3,000 volun-\nteer teachers from different areas of the U.S., with impartial observers study-\ning the experience shared between teachers and students.\nIn a recent op-ed piece in the Washington Post, Bill Gates summed up the \nstudy’s key findings. “What the country needs are thoughtfully developed \nteacher evaluation systems that include multiple measures of performance,” \nhe wrote. Among these measures, he lists student surveys, classroom obser-\nvations by experienced colleagues, and results against standardized tests or \nbenchmarks.6\nIn other words, the best feedback and evaluation metrics for colleges and \nuniversities are based on a rich set of inputs from multiple sources.\nStudent course evaluations are only one measure of the learning environ-\nment. For a more complete metric, evaluations must be combined with a mea-\nsure of learning progress, plus independent peer assessments such as \n360-degree reviews.\nGathering all three inputs and weighing these factors is essential to gain an \nobjective view on how to improve the entire teaching and learning experience.\nTo remain competitive and accomplish their mission, colleges and universities \nneed a new type of system to give them a well-rounded picture of the higher \neducation space.\nThey need a system that can reach and engage all stakeholders, gather and \nanalyze inputs through numerous channels, and deliver real-time, accurate \ninformation to stakeholders and decision-makers.\nThey need a system that can combine factual feedback on the learning experi-\nence with forward-looking predictive analytics.\nThis kind of system can help colleges and universities foster a continuous \ncycle of improvement, and effectively meet the expectations of students, \nemployers, governments and all other stakeholders.\nTo refer to this type of next-generation feedback and evaluation system, \neXplorance, Inc. has coined the term “Learning Experience Management” or \nLEM.\nAs we’ve seen, accomplishing the mission of higher education involves multi-\nple stakeholders and a complex ecosystem of organizations providing related \ngoods and services.\nLearning Experience Management (LEM) is a multifaceted practice designed \nto support this mission.\nLEM takes place as a recurring cycle that ensures continuous improvement \nacross all the dimensions of a professional development process.\nAn effective LEM system must include a comprehensive set of enterprise-class \nautomated evaluations, tests, feedback surveys and workflow. These tools \nenable colleges and universities to benchmark, evaluate, analyze, improve and \nmonitor every aspect of the learning experience.\nAs shown in Figure 1, LEM deals with two out of three phases of the educa-\ntion process: before and after the central process where knowledge, skills, \nand competencies are transmitted to the student. This core process remains \nthe domain of the faculty.\nFor the pre-learning phase, the LEM system supports an in-depth assess-\nment of the current needs, knowledge, skills, and competencies of each \nstudent and faculty member. This assessment is used to create an initial \nin-depth set of benchmarks.\nFor the post-learning phase, LEM supports a rich set of course evaluations, \nand an effective way to measure both faculty and student improvement \nagainst the original benchmarks.\nThe key functions of LEM can be broken down even further. As shown in \nFigure 2, an effective LEM system involves a continuous cycle through five key \nfunctions:\nBenchmark: LEM sets the path to improvement by creating a set of bench-\nmarks. These are based on a weighted selection of initial student training \nrequirements, government accreditation, and employer needs.\nAssess: Feedback is gathered through online course evaluations, 360-degree \npeer reviews, and stakeholder surveys. These can take place numerous times \nduring the teaching term.\nAnalyze: The results are automatically analyzed, translated into suggested \nimprovements, and reported in real-time.\nImprove: The findings can trigger automated actions, such as a survey or a \n360-degree review to probe deeper into any issue. These findings can also \nspark deliberation by appropriate decision-makers.\nMonitor: These improvements are continuously monitored against the initial \nbenchmarks to ensure that the learning experience is providing a high “return \non expectations.”\nConsider this common scenario: Partway through the term, an instructor \nwonders if his teaching methods are meeting his students expectations.\nThe LEM system gives him the ability to conduct interim evaluations at any \ntime. These evaluations monitor his students’ feedback and sentiment, giving \nhim factual real-time information he can use to make timely interim improve-\nments, long before the end of the course.\nIn this example, both students and instructors directly benefit from engaging \nin this feedback process.\nWhen results are tied to an improvement cycle rather than strictly to teacher \nor student performance, higher education institutes have discovered that \nstakeholders are more willing to engage. The institution can thus achieve \nhigher response rates sustained over time.\nA second likely scenario: A student registering for university must pick \nbetween two different courses running at the same time. She’s curious about \nthe experience of other students who chose either option.\nWhen she logs into the student portal, the LEM system enables her to access \nthe feedback processed from previous terms. Far more than a “popularity” \nrating for each instructor, the system provides detailed information on each \ncourse from the viewpoint of different stakeholders, including alumni and \npotential employers. She can also see factual data about the improvement \nrates of each course.\nAll this helps her make an informed decision, and sets her expectations \naccordingly. When a freshman glimpses the benefits of the LEM system right \nat the outset of her university experience, that encourages her to engage with \nthe feedback evaluation process from that moment on.\nBased on many scenarios like these, the effectiveness of an LEM system can \nbe measured in terms of “return on expectations” or ROE. ROE can be defined \nas a holistic measure of all the benefits realized from any training program or \ninitiative, both qualitative and quantitative.\nIn other words, ROE conveys “what success looks like” to all the stakeholders \ninvolved. “ROE is a positive measure that pulls an organization together in the \nquest to define and achieve the target,” explain Jim and Wendy Kirkpatrick \nfrom Kirkpatrick Partners.7 Their firm promotes the well-known Kirkpatrick \nmodel for evaluating training, first published in the 1950s and updated in \n2009.\nThe Kirkpatricks also call ROE “a collaborative agreement that unites an orga-\nnization in working towards a common goal.”\nCertainly ROE is a more flexible metric than return on investment (ROI), but it \ncan include all the measures that typically make up ROI, plus others that ROI \ncannot encompass.\nAnother advantage: ROE is highly customizable. It can be defined uniquely by \neach different college and university, and then calculated according to what-\never formula they devise.\nFigure 3 shows the most likely ways for a college or university to measure \nROE, both short-term and long-term.\nTen years ago, one software developer determined to help higher educators \ndeal with their challenges by finding a way to continuously improve their \noperations. The result is Blue® by eXplorance.\nBlue is an enterprise-class LEM solution with a successful track record of 10 \nyears. Blue is installed at 200 colleges and universities, where it’s used to \nevaluate over 1 million courses per year. Every year, Blue replaces about 50 \nmillion paper evaluation forms and 25 million pages of reports, saving almost \n1,000 trees.\neXplorance strongly believes that LEM can help higher education institutions \nattract and retain students, and better achieve their mission. A next-generation \nsystem based on continuous improvement, not individual performance, that \nmerges predictive course corrections with preventive feedback actions to \nengage all stakeholders in a sustained way, will deliver a high ROE (return on \nexpectations).\nThe bottom line is that LEM yields increased value for all stakeholders in the \nhigher education space. To learn more about how LEM can help your college or \nuniversity attract and retain students, engage stakeholders, and achieve its \nmission, please view the Introduction to LEM video.\nIntroducing LEM for Higher Education 9\nFIGURE 1 \nPre-Learning\nPost-Learning\nPRE-LEARNING POST-LEARNING\nBenchmark Assessments\nCourse\nNeeds Fulfillment\nKnowledge\nSkills\nCompetencies\nEvaluations\nNeeds\nKnowledge\nSkills\nCompetencies\nLEARNING\nAPPLICATIONS\nCONTENT INFRASTRUCTURE\nEQUIPMENT\nSECURITY\nFACILITIES\nSYSTEMS\nECOSYSTEM\nSTAKEHOLDERS\nALUMNI\nAPPLICANTS\nCIO\nEMPLOYERS\nFACULTY\nGOVERNMENTS\nRESEARCHERS\nSTUDENTS\nSUPPORTING STAFF\nCONTENT PROVIDERS\nDEANS/PROVOST\nDEPARTMENT CHAIRS\nFortunately, some promising beacons are lighting the way forward. According \nto the latest research, effective teaching can be measured... although it’s not \nalways done.\nThis view is based on the three-year Measures of Effective Teaching study \nsponsored by the Bill & Melinda Gates Foundation. This involved 3,000 volun-\nteer teachers from different areas of the U.S., with impartial observers study-\ning the experience shared between teachers and students.\nIn a recent op-ed piece in the Washington Post, Bill Gates summed up the \nstudy’s key findings. “What the country needs are thoughtfully developed \nteacher evaluation systems that include multiple measures of performance,” \nhe wrote. Among these measures, he lists student surveys, classroom obser-\nvations by experienced colleagues, and results against standardized tests or \nbenchmarks.6\nIn other words, the best feedback and evaluation metrics for colleges and \nuniversities are based on a rich set of inputs from multiple sources.\nStudent course evaluations are only one measure of the learning environ-\nment. For a more complete metric, evaluations must be combined with a mea-\nsure of learning progress, plus independent peer assessments such as \n360-degree reviews.\nGathering all three inputs and weighing these factors is essential to gain an \nobjective view on how to improve the entire teaching and learning experience.\nTo remain competitive and accomplish their mission, colleges and universities \nneed a new type of system to give them a well-rounded picture of the higher \neducation space.\nThey need a system that can reach and engage all stakeholders, gather and \nanalyze inputs through numerous channels, and deliver real-time, accurate \ninformation to stakeholders and decision-makers.\nThey need a system that can combine factual feedback on the learning experi-\nence with forward-looking predictive analytics.\nThis kind of system can help colleges and universities foster a continuous \ncycle of improvement, and effectively meet the expectations of students, \nemployers, governments and all other stakeholders.\nTo refer to this type of next-generation feedback and evaluation system, \neXplorance, Inc. has coined the term “Learning Experience Management” or \nLEM.\nAs we’ve seen, accomplishing the mission of higher education involves multi-\nple stakeholders and a complex ecosystem of organizations providing related \ngoods and services.\nLearning Experience Management (LEM) is a multifaceted practice designed \nto support this mission.\nLEM takes place as a recurring cycle that ensures continuous improvement \nacross all the dimensions of a professional development process.\nAn effective LEM system must include a comprehensive set of enterprise-class \nautomated evaluations, tests, feedback surveys and workflow. These tools \nenable colleges and universities to benchmark, evaluate, analyze, improve and \nmonitor every aspect of the learning experience.\nAs shown in Figure 1, LEM deals with two out of three phases of the educa-\ntion process: before and after the central process where knowledge, skills, \nand competencies are transmitted to the student. This core process remains \nthe domain of the faculty.\nFor the pre-learning phase, the LEM system supports an in-depth assess-\nment of the current needs, knowledge, skills, and competencies of each \nstudent and faculty member. This assessment is used to create an initial \nin-depth set of benchmarks.\nFor the post-learning phase, LEM supports a rich set of course evaluations, \nand an effective way to measure both faculty and student improvement \nagainst the original benchmarks.\nThe key functions of LEM can be broken down even further. As shown in \nFigure 2, an effective LEM system involves a continuous cycle through five key \nfunctions:\nBenchmark: LEM sets the path to improvement by creating a set of bench-\nmarks. These are based on a weighted selection of initial student training \nrequirements, government accreditation, and employer needs.\nAssess: Feedback is gathered through online course evaluations, 360-degree \npeer reviews, and stakeholder surveys. These can take place numerous times \nduring the teaching term.\nAnalyze: The results are automatically analyzed, translated into suggested \nimprovements, and reported in real-time.\nImprove: The findings can trigger automated actions, such as a survey or a \n360-degree review to probe deeper into any issue. These findings can also \nspark deliberation by appropriate decision-makers.\nMonitor: These improvements are continuously monitored against the initial \nbenchmarks to ensure that the learning experience is providing a high “return \non expectations.”\nConsider this common scenario: Partway through the term, an instructor \nwonders if his teaching methods are meeting his students expectations.\nThe LEM system gives him the ability to conduct interim evaluations at any \ntime. These evaluations monitor his students’ feedback and sentiment, giving \nhim factual real-time information he can use to make timely interim improve-\nments, long before the end of the course.\nIn this example, both students and instructors directly benefit from engaging \nin this feedback process.\nWhen results are tied to an improvement cycle rather than strictly to teacher \nor student performance, higher education institutes have discovered that \nstakeholders are more willing to engage. The institution can thus achieve \nhigher response rates sustained over time.\nA second likely scenario: A student registering for university must pick \nbetween two different courses running at the same time. She’s curious about \nthe experience of other students who chose either option.\nWhen she logs into the student portal, the LEM system enables her to access \nthe feedback processed from previous terms. Far more than a “popularity” \nrating for each instructor, the system provides detailed information on each \ncourse from the viewpoint of different stakeholders, including alumni and \npotential employers. She can also see factual data about the improvement \nrates of each course.\nAll this helps her make an informed decision, and sets her expectations \naccordingly. When a freshman glimpses the benefits of the LEM system right \nat the outset of her university experience, that encourages her to engage with \nthe feedback evaluation process from that moment on.\nBased on many scenarios like these, the effectiveness of an LEM system can \nbe measured in terms of “return on expectations” or ROE. ROE can be defined \nas a holistic measure of all the benefits realized from any training program or \ninitiative, both qualitative and quantitative.\nIn other words, ROE conveys “what success looks like” to all the stakeholders \ninvolved. “ROE is a positive measure that pulls an organization together in the \nquest to define and achieve the target,” explain Jim and Wendy Kirkpatrick \nfrom Kirkpatrick Partners.7 Their firm promotes the well-known Kirkpatrick \nmodel for evaluating training, first published in the 1950s and updated in \n2009.\nThe Kirkpatricks also call ROE “a collaborative agreement that unites an orga-\nnization in working towards a common goal.”\nCertainly ROE is a more flexible metric than return on investment (ROI), but it \ncan include all the measures that typically make up ROI, plus others that ROI \ncannot encompass.\nAnother advantage: ROE is highly customizable. It can be defined uniquely by \neach different college and university, and then calculated according to what-\never formula they devise.\nFigure 3 shows the most likely ways for a college or university to measure \nROE, both short-term and long-term.\nTen years ago, one software developer determined to help higher educators \ndeal with their challenges by finding a way to continuously improve their \noperations. The result is Blue® by eXplorance.\nBlue is an enterprise-class LEM solution with a successful track record of 10 \nyears. Blue is installed at 200 colleges and universities, where it’s used to \nevaluate over 1 million courses per year. Every year, Blue replaces about 50 \nmillion paper evaluation forms and 25 million pages of reports, saving almost \n1,000 trees.\neXplorance strongly believes that LEM can help higher education institutions \nattract and retain students, and better achieve their mission. A next-generation \nsystem based on continuous improvement, not individual performance, that \nmerges predictive course corrections with preventive feedback actions to \nengage all stakeholders in a sustained way, will deliver a high ROE (return on \nexpectations).\nThe bottom line is that LEM yields increased value for all stakeholders in the \nhigher education space. To learn more about how LEM can help your college or \nuniversity attract and retain students, engage stakeholders, and achieve its \nmission, please view the Introduction to LEM video.\nIntroducing LEM for Higher Education\nHOW DOES \nLEM WORK?\n10\nFIGURE 2 \nBE\nN\nCH\nM\nAR\nK\nASSESS ANALYZE\nIMPROVEMONITOR\nFortunately, some promising beacons are lighting the way forward. According \nto the latest research, effective teaching can be measured... although it’s not \nalways done.\nThis view is based on the three-year Measures of Effective Teaching study \nsponsored by the Bill & Melinda Gates Foundation. This involved 3,000 volun-\nteer teachers from different areas of the U.S., with impartial observers study-\ning the experience shared between teachers and students.\nIn a recent op-ed piece in the Washington Post, Bill Gates summed up the \nstudy’s key findings. “What the country needs are thoughtfully developed \nteacher evaluation systems that include multiple measures of performance,” \nhe wrote. Among these measures, he lists student surveys, classroom obser-\nvations by experienced colleagues, and results against standardized tests or \nbenchmarks.6\nIn other words, the best feedback and evaluation metrics for colleges and \nuniversities are based on a rich set of inputs from multiple sources.\nStudent course evaluations are only one measure of the learning environ-\nment. For a more complete metric, evaluations must be combined with a mea-\nsure of learning progress, plus independent peer assessments such as \n360-degree reviews.\nGathering all three inputs and weighing these factors is essential to gain an \nobjective view on how to improve the entire teaching and learning experience.\nTo remain competitive and accomplish their mission, colleges and universities \nneed a new type of system to give them a well-rounded picture of the higher \neducation space.\nThey need a system that can reach and engage all stakeholders, gather and \nanalyze inputs through numerous channels, and deliver real-time, accurate \ninformation to stakeholders and decision-makers.\nThey need a system that can combine factual feedback on the learning experi-\nence with forward-looking predictive analytics.\nThis kind of system can help colleges and universities foster a continuous \ncycle of improvement, and effectively meet the expectations of students, \nemployers, governments and all other stakeholders.\nTo refer to this type of next-generation feedback and evaluation system, \neXplorance, Inc. has coined the term “Learning Experience Management” or \nLEM.\nAs we’ve seen, accomplishing the mission of higher education involves multi-\nple stakeholders and a complex ecosystem of organizations providing related \ngoods and services.\nLearning Experience Management (LEM) is a multifaceted practice designed \nto support this mission.\nLEM takes place as a recurring cycle that ensures continuous improvement \nacross all the dimensions of a professional development process.\nAn effective LEM system must include a comprehensive set of enterprise-class \nautomated evaluations, tests, feedback surveys and workflow. These tools \nenable colleges and universities to benchmark, evaluate, analyze, improve and \nmonitor every aspect of the learning experience.\nAs shown in Figure 1, LEM deals with two out of three phases of the educa-\ntion process: before and after the central process where knowledge, skills, \nand competencies are transmitted to the student. This core process remains \nthe domain of the faculty.\nFor the pre-learning phase, the LEM system supports an in-depth assess-\nment of the current needs, knowledge, skills, and competencies of each \nstudent and faculty member. This assessment is used to create an initial \nin-depth set of benchmarks.\nFor the post-learning phase, LEM supports a rich set of course evaluations, \nand an effective way to measure both faculty and student improvement \nagainst the original benchmarks.\nThe key functions of LEM can be broken down even further. As shown in \nFigure 2, an effective LEM system involves a continuous cycle through five key \nfunctions:\nBenchmark: LEM sets the path to improvement by creating a set of bench-\nmarks. These are based on a weighted selection of initial student training \nrequirements, government accreditation, and employer needs.\nAssess: Feedback is gathered through online course evaluations, 360-degree \npeer reviews, and stakeholder surveys. These can take place numerous times \nduring the teaching term.\nAnalyze: The results are automatically analyzed, translated into suggested \nimprovements, and reported in real-time.\nImprove: The findings can trigger automated actions, such as a survey or a \n360-degree review to probe deeper into any issue. These findings can also \nspark deliberation by appropriate decision-makers.\nMonitor: These improvements are continuously monitored against the initial \nbenchmarks to ensure that the learning experience is providing a high “return \non expectations.”\nConsider this common scenario: Partway through the term, an instructor \nwonders if his teaching methods are meeting his students expectations.\nThe LEM system gives him the ability to conduct interim evaluations at any \ntime. These evaluations monitor his students’ feedback and sentiment, giving \nhim factual real-time information he can use to make timely interim improve-\nments, long before the end of the course.\nIn this example, both students and instructors directly benefit from engaging \nin this feedback process.\nWhen results are tied to an improvement cycle rather than strictly to teacher \nor student performance, higher education institutes have discovered that \nstakeholders are more willing to engage. The institution can thus achieve \nhigher response rates sustained over time.\nA second likely scenario: A student registering for university must pick \nbetween two different courses running at the same time. She’s curious about \nthe experience of other students who chose either option.\nWhen she logs into the student portal, the LEM system enables her to access \nthe feedback processed from previous terms. Far more than a “popularity” \nrating for each instructor, the system provides detailed information on each \ncourse from the viewpoint of different stakeholders, including alumni and \npotential employers. She can also see factual data about the improvement \nrates of each course.\nAll this helps her make an informed decision, and sets her expectations \naccordingly. When a freshman glimpses the benefits of the LEM system right \nat the outset of her university experience, that encourages her to engage with \nthe feedback evaluation process from that moment on.\nBased on many scenarios like these, the effectiveness of an LEM system can \nbe measured in terms of “return on expectations” or ROE. ROE can be defined \nas a holistic measure of all the benefits realized from any training program or \ninitiative, both qualitative and quantitative.\nIn other words, ROE conveys “what success looks like” to all the stakeholders \ninvolved. “ROE is a positive measure that pulls an organization together in the \nquest to define and achieve the target,” explain Jim and Wendy Kirkpatrick \nfrom Kirkpatrick Partners.7 Their firm promotes the well-known Kirkpatrick \nmodel for evaluating training, first published in the 1950s and updated in \n2009.\nThe Kirkpatricks also call ROE “a collaborative agreement that unites an orga-\nnization in working towards a common goal.”\nCertainly ROE is a more flexible metric than return on investment (ROI), but it \ncan include all the measures that typically make up ROI, plus others that ROI \ncannot encompass.\nAnother advantage: ROE is highly customizable. It can be defined uniquely by \neach different college and university, and then calculated according to what-\never formula they devise.\nFigure 3 shows the most likely ways for a college or university to measure \nROE, both short-term and long-term.\nTen years ago, one software developer determined to help higher educators \ndeal with their challenges by finding a way to continuously improve their \noperations. The result is Blue® by eXplorance.\nBlue is an enterprise-class LEM solution with a successful track record of 10 \nyears. Blue is installed at 200 colleges and universities, where it’s used to \nevaluate over 1 million courses per year. Every year, Blue replaces about 50 \nmillion paper evaluation forms and 25 million pages of reports, saving almost \n1,000 trees.\neXplorance strongly believes that LEM can help higher education institutions \nattract and retain students, and better achieve their mission. A next-generation \nsystem based on continuous improvement, not individual performance, that \nmerges predictive course corrections with preventive feedback actions to \nengage all stakeholders in a sustained way, will deliver a high ROE (return on \nexpectations).\nThe bottom line is that LEM yields increased value for all stakeholders in the \nhigher education space. To learn more about how LEM can help your college or \nuniversity attract and retain students, engage stakeholders, and achieve its \nmission, please view the Introduction to LEM video.\nLEM \nIN ACTION: \nTWO \nREAL-WORLD \nSCENARIOS\nIntroducing LEM for Higher Education 11\nFortunately, some promising beacons are lighting the way forward. According \nto the latest research, effective teaching can be measured... although it’s not \nalways done.\nThis view is based on the three-year Measures of Effective Teaching study \nsponsored by the Bill & Melinda Gates Foundation. This involved 3,000 volun-\nteer teachers from different areas of the U.S., with impartial observers study-\ning the experience shared between teachers and students.\nIn a recent op-ed piece in the Washington Post, Bill Gates summed up the \nstudy’s key findings. “What the country needs are thoughtfully developed \nteacher evaluation systems that include multiple measures of performance,” \nhe wrote. Among these measures, he lists student surveys, classroom obser-\nvations by experienced colleagues, and results against standardized tests or \nbenchmarks.6\nIn other words, the best feedback and evaluation metrics for colleges and \nuniversities are based on a rich set of inputs from multiple sources.\nStudent course evaluations are only one measure of the learning environ-\nment. For a more complete metric, evaluations must be combined with a mea-\nsure of learning progress, plus independent peer assessments such as \n360-degree reviews.\nGathering all three inputs and weighing these factors is essential to gain an \nobjective view on how to improve the entire teaching and learning experience.\nTo remain competitive and accomplish their mission, colleges and universities \nneed a new type of system to give them a well-rounded picture of the higher \neducation space.\nThey need a system that can reach and engage all stakeholders, gather and \nanalyze inputs through numerous channels, and deliver real-time, accurate \ninformation to stakeholders and decision-makers.\nThey need a system that can combine factual feedback on the learning experi-\nence with forward-looking predictive analytics.\nThis kind of system can help colleges and universities foster a continuous \ncycle of improvement, and effectively meet the expectations of students, \nemployers, governments and all other stakeholders.\nTo refer to this type of next-generation feedback and evaluation system, \neXplorance, Inc. has coined the term “Learning Experience Management” or \nLEM.\nAs we’ve seen, accomplishing the mission of higher education involves multi-\nple stakeholders and a complex ecosystem of organizations providing related \ngoods and services.\nLearning Experience Management (LEM) is a multifaceted practice designed \nto support this mission.\nLEM takes place as a recurring cycle that ensures continuous improvement \nacross all the dimensions of a professional development process.\nAn effective LEM system must include a comprehensive set of enterprise-class \nautomated evaluations, tests, feedback surveys and workflow. These tools \nenable colleges and universities to benchmark, evaluate, analyze, improve and \nmonitor every aspect of the learning experience.\nAs shown in Figure 1, LEM deals with two out of three phases of the educa-\ntion process: before and after the central process where knowledge, skills, \nand competencies are transmitted to the student. This core process remains \nthe domain of the faculty.\nFor the pre-learning phase, the LEM system supports an in-depth assess-\nment of the current needs, knowledge, skills, and competencies of each \nstudent and faculty member. This assessment is used to create an initial \nin-depth set of benchmarks.\nFor the post-learning phase, LEM supports a rich set of course evaluations, \nand an effective way to measure both faculty and student improvement \nagainst the original benchmarks.\nThe key functions of LEM can be broken down even further. As shown in \nFigure 2, an effective LEM system involves a continuous cycle through five key \nfunctions:\nBenchmark: LEM sets the path to improvement by creating a set of bench-\nmarks. These are based on a weighted selection of initial student training \nrequirements, government accreditation, and employer needs.\nAssess: Feedback is gathered through online course evaluations, 360-degree \npeer reviews, and stakeholder surveys. These can take place numerous times \nduring the teaching term.\nAnalyze: The results are automatically analyzed, translated into suggested \nimprovements, and reported in real-time.\nImprove: The findings can trigger automated actions, such as a survey or a \n360-degree review to probe deeper into any issue. These findings can also \nspark deliberation by appropriate decision-makers.\nMonitor: These improvements are continuously monitored against the initial \nbenchmarks to ensure that the learning experience is providing a high “return \non expectations.”\nConsider this common scenario: Partway through the term, an instructor \nwonders if his teaching methods are meeting his students expectations.\nThe LEM system gives him the ability to conduct interim evaluations at any \ntime. These evaluations monitor his students’ feedback and sentiment, giving \nhim factual real-time information he can use to make timely interim improve-\nments, long before the end of the course.\nIn this example, both students and instructors directly benefit from engaging \nin this feedback process.\nWhen results are tied to an improvement cycle rather than strictly to teacher \nor student performance, higher education institutes have discovered that \nstakeholders are more willing to engage. The institution can thus achieve \nhigher response rates sustained over time.\nA second likely scenario: A student registering for university must pick \nbetween two different courses running at the same time. She’s curious about \nthe experience of other students who chose either option.\nWhen she logs into the student portal, the LEM system enables her to access \nthe feedback processed from previous terms. Far more than a “popularity” \nrating for each instructor, the system provides detailed information on each \ncourse from the viewpoint of different stakeholders, including alumni and \npotential employers. She can also see factual data about the improvement \nrates of each course.\nAll this helps her make an informed decision, and sets her expectations \naccordingly. When a freshman glimpses the benefits of the LEM system right \nat the outset of her university experience, that encourages her to engage with \nthe feedback evaluation process from that moment on.\nBased on many scenarios like these, the effectiveness of an LEM system can \nbe measured in terms of “return on expectations” or ROE. ROE can be defined \nas a holistic measure of all the benefits realized from any training program or \ninitiative, both qualitative and quantitative.\nIn other words, ROE conveys “what success looks like” to all the stakeholders \ninvolved. “ROE is a positive measure that pulls an organization together in the \nquest to define and achieve the target,” explain Jim and Wendy Kirkpatrick \nfrom Kirkpatrick Partners.7 Their firm promotes the well-known Kirkpatrick \nmodel for evaluating training, first published in the 1950s and updated in \n2009.\nThe Kirkpatricks also call ROE “a collaborative agreement that unites an orga-\nnization in working towards a common goal.”\nCertainly ROE is a more flexible metric than return on investment (ROI), but it \ncan include all the measures that typically make up ROI, plus others that ROI \ncannot encompass.\nAnother advantage: ROE is highly customizable. It can be defined uniquely by \neach different college and university, and then calculated according to what-\never formula they devise.\nFigure 3 shows the most likely ways for a college or university to measure \nROE, both short-term and long-term.\nTen years ago, one software developer determined to help higher educators \ndeal with their challenges by finding a way to continuously improve their \noperations. The result is Blue® by eXplorance.\nBlue is an enterprise-class LEM solution with a successful track record of 10 \nyears. Blue is installed at 200 colleges and universities, where it’s used to \nevaluate over 1 million courses per year. Every year, Blue replaces about 50 \nmillion paper evaluation forms and 25 million pages of reports, saving almost \n1,000 trees.\neXplorance strongly believes that LEM can help higher education institutions \nattract and retain students, and better achieve their mission. A next-generation \nsystem based on continuous improvement, not individual performance, that \nmerges predictive course corrections with preventive feedback actions to \nengage all stakeholders in a sustained way, will deliver a high ROE (return on \nexpectations).\nThe bottom line is that LEM yields increased value for all stakeholders in the \nhigher education space. To learn more about how LEM can help your college or \nuniversity attract and retain students, engage stakeholders, and achieve its \nmission, please view the Introduction to LEM video.\n7Jim and Wendy Kirkpatrick, Return \non Expectations: �e ultimate \ndemonstration of training value, \nTrainingZone.co.uk/Siftmedia, 25 \nAugust 2009\nSHORT-TERM LONG-TERM\nStudent retention Student registrations\nStudent progress, compared to \ninitial benchmarks\nInstitutional reputation among all \nstakeholders, especially alumni, \ndonors, and future employers\nSatisfaction level, for all \nstakeholders\nIncreased budgets\nWorkforce readiness ratio\nHOW DO YOU \nMEASURE \nTHE BENEFITS \nOF LEM?\nIntroducing LEM for Higher Education 12\nFIGURE 3\nBased on many scenarios like these, the effectiveness of an LEM system can \nbe measured in terms of “return on expectations” or ROE. ROE can be defined \nas a holistic measure of all the benefits realized from any training program or \ninitiative, both qualitative and quantitative.\nIn other words, ROE conveys “what success looks like” to all the stakeholders \ninvolved. “ROE is a positive measure that pulls an organization together in the \nquest to define and achieve the target,” explain Jim and Wendy Kirkpatrick \nfrom Kirkpatrick Partners.7 Their firm promotes the well-known Kirkpatrick \nmodel for evaluating training, first published in the 1950s and updated in \n2009.\nThe Kirkpatricks also call ROE “a collaborative agreement that unites an orga-\nnization in working towards a common goal.”\nCertainly ROE is a more flexible metric than return on investment (ROI), but it \ncan include all the measures that typically make up ROI, plus others that ROI \ncannot encompass.\nAnother advantage: ROE is highly customizable. It can be defined uniquely by \neach different college and university, and then calculated according to what-\never formula they devise.\nFigure 3 shows the most likely ways for a college or university to measure \nROE, both short-term and long-term.\nTen years ago, one software developer determined to help higher educators \ndeal with their challenges by finding a way to continuously improve their \noperations. The result is Blue® by eXplorance.\nBlue is an enterprise-class LEM solution with a successful track record of 10 \nyears. Blue is installed at 200 colleges and universities, where it’s used to \nevaluate over 1 million courses per year. Every year, Blue replaces about 50 \nmillion paper evaluation forms and 25 million pages of reports, saving almost \n1,000 trees.\neXplorance strongly believes that LEM can help higher education institutions \nattract and retain students, and better achieve their mission. A next-generation \nsystem based on continuous improvement, not individual performance, that \nmerges predictive course corrections with preventive feedback actions to \nengage all stakeholders in a sustained way, will deliver a high ROE (return on \nexpectations).\nThe bottom line is that LEM yields increased value for all stakeholders in the \nhigher education space. To learn more about how LEM can help your college or \nuniversity attract and retain students, engage stakeholders, and achieve its \nmission, please view the Introduction to LEM video.\nhttps://youtu.be/pf5PPj7J5Gs\nHOW DOES \nLEM WORK?\nIntroducing LEM for Higher Education 13\nBased on many scenarios like these, the effectiveness of an LEM system can \nbe measured in terms of “return on expectations” or ROE. ROE can be defined \nas a holistic measure of all the benefits realized from any training program or \ninitiative, both qualitative and quantitative.\nIn other words, ROE conveys “what success looks like” to all the stakeholders \ninvolved. “ROE is a positive measure that pulls an organization together in the \nquest to define and achieve the target,” explain Jim and Wendy Kirkpatrick \nfrom Kirkpatrick Partners.7 Their firm promotes the well-known Kirkpatrick \nmodel for evaluating training, first published in the 1950s and updated in \n2009.\nThe Kirkpatricks also call ROE “a collaborative agreement that unites an orga-\nnization in working towards a common goal.”\nCertainly ROE is a more flexible metric than return on investment (ROI), but it \ncan include all the measures that typically make up ROI, plus others that ROI \ncannot encompass.\nAnother advantage: ROE is highly customizable. It can be defined uniquely by \neach different college and university, and then calculated according to what-\never formula they devise.\nFigure 3 shows the most likely ways for a college or university to measure \nROE, both short-term and long-term.\nTen years ago, one software developer determined to help higher educators \ndeal with their challenges by finding a way to continuously improve their \noperations. The result is Blue® by eXplorance.\nBlue is an enterprise-class LEM solution with a successful track record of 10 \nyears. Blue is installed at 200 colleges and universities, where it’s used to \nevaluate over 1 million courses per year. Every year, Blue replaces about 50 \nmillion paper evaluation forms and 25 million pages of reports, saving almost \n1,000 trees.\neXplorance strongly believes that LEM can help higher education institutions \nattract and retain students, and better achieve their mission. A next-generation \nsystem based on continuous improvement, not individual performance, that \nmerges predictive course corrections with preventive feedback actions to \nengage all stakeholders in a sustained way, will deliver a high ROE (return on \nexpectations).\nThe bottom line is that LEM yields increased value for all stakeholders in the \nhigher education space. To learn more about how LEM can help your college or \nuniversity attract and retain students, engage stakeholders, and achieve its \nmission, please view the Introduction to LEM video.\nIntroducing LEM for Higher Education 14\nABOUT \nEXPLORANCE\nAt eXplorance, we believe that improvement is at the heart of progress. By \nproviding tools that assess knowledge, competencies, and skills, we assist \norganizations in developing a culture of improvement. Blue helps build that \nculture by powering a cycle of continuous improvement resulting in strategic \ninsights for future innovation. \nBlue is a complete Learning Experience Management (LEM) system that \nincludes applications for course and instructor evaluations, broad-based \nstakeholder surveys, psychometric and knowledge tests, 360 degree \nfeedback, and more. Putting ‘being better’ at the forefront, Blue provides \nbenchmarks, stakeholder assessments, sophisticated reporting, adapted \ninsights and continuous monitoring.\nFounded in 2003, eXplorance is a privately held corporation based in \nMontreal, Canada. Some of eXplorance’s clients include RMIT University, \nUniversity of Louisville, PPS International Limited, University of Toronto, \nBabson College, Fidelity Marketing, UAE University, loanDepot, University of \nGroningen and NASA.\nFor more information, visit www.explorance.com\nToll-free: 877.938.2111 (North America)\nPhone: +1.514.938.2111\nFax: +1.514.635.6264\ninfo@explorance.com\nFollow us...\nwww.facebook.com/eXplorance         www.twitter.com/eXplorance         www.linkedin.com/company/eXplorance\nBased on many scenarios like these, the effectiveness of an LEM system can \nbe measured in terms of “return on expectations” or ROE. ROE can be defined \nas a holistic measure of all the benefits realized from any training program or \ninitiative, both qualitative and quantitative.\nIn other words, ROE conveys “what success looks like” to all the stakeholders \ninvolved. “ROE is a positive measure that pulls an organization together in the \nquest to define and achieve the target,” explain Jim and Wendy Kirkpatrick \nfrom Kirkpatrick Partners.7 Their firm promotes the well-known Kirkpatrick \nmodel for evaluating training, first published in the 1950s and updated in \n2009.\nThe Kirkpatricks also call ROE “a collaborative agreement that unites an orga-\nnization in working towards a common goal.”\nCertainly ROE is a more flexible metric than return on investment (ROI), but it \ncan include all the measures that typically make up ROI, plus others that ROI \ncannot encompass.\nAnother advantage: ROE is highly customizable. It can be defined uniquely by \neach different college and university, and then calculated according to what-\never formula they devise.\nFigure 3 shows the most likely ways for a college or university to measure \nROE, both short-term and long-term.\nTen years ago, one software developer determined to help higher educators \ndeal with their challenges by finding a way to continuously improve their \noperations. The result is Blue® by eXplorance.\nBlue is an enterprise-class LEM solution with a successful track record of 10 \nyears. Blue is installed at 200 colleges and universities, where it’s used to \nevaluate over 1 million courses per year. Every year, Blue replaces about 50 \nmillion paper evaluation forms and 25 million pages of reports, saving almost \n1,000 trees.\neXplorance strongly believes that LEM can help higher education institutions \nattract and retain students, and better achieve their mission. A next-generation \nsystem based on continuous improvement, not individual performance, that \nmerges predictive course corrections with preventive feedback actions to \nengage all stakeholders in a sustained way, will deliver a high ROE (return on \nexpectations).\nThe bottom line is that LEM yields increased value for all stakeholders in the \nhigher education space. To learn more about how LEM can help your college or \nuniversity attract and retain students, engage stakeholders, and achieve its \nmission, please view the Introduction to LEM video.\nImprovement at heart.\nwww.explorance.com\n© 2015 by eXplorance Inc. All rights reserved.\nREVISED Item No. 6 \nGFC COMMITTEE ON THE LEARNING ENVIRONMENT \nFor the Meeting of March 2, 20016 \nOUTLINE OF ISSUE \nAgenda Title: Mandated USRI Questions for Project Based and Online Courses \nMotion:  N/A  \nItem   \nAction Requested Approval Recommendation  Discussion/Advice Information \nProposed by N/A \nPresenter Mani Vaidyanathan and Toni Samek, GFC Committee on the Learning \nEnvironment \nSubject Mandated USRI Questions for project based and online courses  \nDetails \nResponsibility N/A \nThe Purpose of the Proposal is \n(please be specific) \nTo provide additional information on GFC mandated USRI questions for \nproject based and 100% online courses \nThe Impact of the Proposal is N/A \nReplaces/Revises (eg, policies, \nresolutions) \nN/A \nTimeline/Implementation Date N/A \nEstimated Cost N/A \nSources of Funding N/A \nNotes  \nAlignment/Compliance \nAlignment with Guiding \nDocuments \nDare to Discover, Dare to Deliver, Institutional values \nCompliance with Legislation, \nPolicy and/or Procedure \nRelevant to the Proposal \n(please quote legislation and \ninclude identifying section \nnumbers) \n1. GFC Committee on the Learning Environment (3. Mandate of the \nCommittee) \n“The Committee on the Learning Environment is a standing committee of \nthe General Faculties Council that promotes an optimal learning \nenvironment in alignment with guiding documents of the University of \nAlberta. (EXEC 04 DEC 2006) \nThe Committee on the Learning Environment is responsible for making \nrecommendations concerning policy matters and action matters with \nrespect of the following: \n[…] \nd) To develop policies that promote ongoing assessment of teaching, \nlearning, and learning services through all Faculties and units. \ne) To nurture the development of innovative and creative learning \nservices and teaching practices. \nf) To encourage the sharing and discussion of evidence about effective \nteaching, learning, and learning services. \ng) To promote critical reflection on the impact of broad societal changes \nin teaching, learning, and the learning environment. \nh) To promote projects with relevant internal and external bodies that \noffer unique teaching and learning opportunities that would benefit the \nuniversity community. \ni) To consider any matter deemed by the GFC Committee on the \nLearning Environment to be within the purview of its general \nREVISED Item No. 6 \nGFC COMMITTEE ON THE LEARNING ENVIRONMENT \nFor the Meeting of March 2, 20016 \nresponsibility.” \nRouting (Include meeting dates) \nParticipation: \n(parties who have seen the \nproposal and in what capacity) \n• Those who have been \ninformed \n• Those who have been \nconsulted \n• Those who are actively \nparticipating \nGFC CLE October 7, 2015 Meeting: Discussion on Topics for 2015-2016 \nCommittee Workplan \nGFC CLE November 4, 2015 Meeting: Draft Template \nGFC CLE January 20, 2016 Meeting: Challenges for CLE – Topics for \nDiscussion \nApproval Route (Governance) \n(including meeting dates) \nN/A \nFinal Approver N/A \nAttachments (each to be numbered 1 - <>) \n1. Attachment 1 (page 1) USRI for Project-Based Courses \n2. Attachment 2 (page 1 – 3) Background: Need for New GFC Mandated USRIs for 100% Online Teaching \nPrepared by: Meg Brolley, Coordinator, GFC Committee on the Learning Environment, \nmeg.brolley@ualberta.ca \nDraft for GFC-CLE discussion [Mar. 2016] \nUSRI for Project-Based Courses \nThe questions below relate to a project-based course and are not the same as those used \nin a lecture-based course. The objective of a project-based course is to teach independent \nlearning in an open-ended environment and the role of the course coordinator is to act as \na facilitator and a mentor. \nIn each of the 10 cases below, the current USRI question is indicated in regular typeface, followed \nby a suggested replacement that is bulleted and italicized underneath. \nStudent engagement with the course: \n1.      The goals and objectives of the course were clear.        \n The goals and objectives of this project-based course were clear. \n2.      In-class time was used effectively.  \n The course resources were helpful. \n3.      I am motivated to learn more about these subject areas. \n I am motivated to engage in more project-based work. \n4.      I increased my knowledge of the subject areas in this course.   \n My experience in this project-based course will increase my chances for success with \nsimilar work in the future. \n5.      Overall, the quality of the course content was excellent. \n Overall, this was a useful project experience. \nStudent experience with the instructor/coordinator: \n6.      The instructor spoke clearly. \n The coordinator clearly communicated the expectations for a successful project and for \nthe reports and/or presentations. \n7.      The instructor was well prepared.  \n The coordinator facilitated access to the necessary mentors, expertise, and resources \nfor my project. \n8.      The instructor treated the students with respect. \n The coordinator was courteous and professional. \n9.      The instructor provided constructive feedback throughout this course. \n The coordinator provided constructive feedback and strategies for success throughout \nthe project.  \n10.  Overall, this instructor was excellent. \n Overall, this coordinator was helpful in supporting my project.  \n 1 \nBACKGROUND \nNeed for New GFC Mandated USRIs for 100% Online Teaching \nPart 1 (4 AUGUST 2015): \nKathleen Brough (Senior Administrative Officer, Office of the Provost and Vice-\nPresident (Academic)) to Toni Samek (Chair, School of Library & Information Studies): \nI've been asked by IST to be in touch about some instances in SLIS in which it \nappears that not all of the GFC-mandated USRI questions have been included on \nquestionnaires. During a periodic review of the block IDs used to populate Universal \nStudent Ratings of Instruction (USRIs) and Instructor-Designed Questionnaires \n(IDQs), a very small number of block IDs at the University have been found to lack \nsome of the GFC-mandated questions (GFC policy 111.3). These deficiencies may \nhave existed for some time, so you may not have been aware of them. In order to \nmodify the USRI to comply with GFC policy, you can send an email to the TSQS group \nwithin Information Services & Technology (IST) at tsqsweb@ualberta.ca requesting \nthat they add the missing question(s) to the block ID used by your academic unit. \nPart 2:  (4 AUGUST 2015): \nToni to Kathleen: \nJennifer Branch (as lead at the time on our online teachings) and I were in \ncommunications with Scott Delinger almost a couple of years ago now to get a set of \nquestions for online SLIS courses approved. We kept some GFC questions, dropped \nsome questions that were odd for the online scenario, and added others (new ones) \nmore suited to the online context.  I was under the impression at the time that our \nrevised set was approved.  \nPART 3: (14 AUGUST 2015): \nKathleen to Toni: \nSorry for the delay in getting back to you. Scott and I have discussed and I think \nyou've identified a really interesting fault in our GFC-mandated questions, that \nbeing that when they were originally approved, a fully online program obviously \nwasn't in the University's consciousness.  I think you're fine to carry on status quo. I \nwill forward your email to the Chair of CLE, as soon as we know who that person is, \nto see if there is value in facilitating a conversation at that committee about how our \nGFC-mandated questions might be adapted for online programming.  \nmailto:tsqsweb@ualberta.ca\n 2 \nCurrently In Use \nFor On Campus Graduate Courses at the  \nSchool of Library and Information Studies \nQuestion        \nThe goals and objectives of the course were \nclear.           \nIn-class time was used effectively.           \nI am motivated to learn more about these subject \nareas.           \nI increased my knowledge of the subject areas in \nthis course.           \nOverall, the quality of the course content was \nexcellent.           \nThe instructor spoke clearly.           \nThe instructor was well prepared.           \nThe instructor treated the students with respect.           \nThe instructor provided constructive feedback \nthroughout this course.           \nThe instructor endeavored to create and \nmaintain a climate of mutual respect.           \nOverall, this instructor was excellent.           \n 3 \nCurrently in Use for \nOnline Graduate Courses at the  \nSchool of Library and Information Studies \nQuestion               \nThe online course was effectively designed \nand easily navigable.                      \nThe goals and objectives of the course \nwere clear.                     \nThe instructor's use of diverse learning \nmaterials and assignments contributed to \nmy education.  \nI am motivated to learn more about these \nsubject areas.                     \nI increased my knowledge of the subject \nareas in this course.                     \nThe instructor was accessible.                      \nThe instructor was responsive.                      \nThe instructor helped students by \nfacilitating learning.                      \nThe instructor treated the students with \nrespect.                     \nThe instructor endeavored to create and \nmaintain a climate of mutual respect.                     \nThe instructor provided constructive \nfeedback throughout this course.                     \nOverall, the course content and the \nlearning opportunities provided were \nexcellent.  \nOverall, this instructor was excellent.                     \nItem No. 7 \nGFC COMMITTEE ON THE LEARNING ENVIRONMENT \nFor the Meeting of March 2, 2016 \n OUTLINE OF ISSUE \nAgenda Title: Proposed Terms of Reference for GFC Committee on the Learning Environment (CLE) \nSubcommittee to Explore Teaching Tenure Stream at University of Alberta \nMotion:  THAT the GFC Committee on the Learning Environment (CLE) approve, with delegated authority \nfrom General Faculties Council, the proposed terms of reference CLE Subcommittee to Explore Teaching \nTenure Stream at University of Alberta, as set forth in Attachment 1. \nItem   \nAction Requested Approval Recommendation  Discussion/Advice Information \nProposed by Sarah Forgie, Chair, GFC Committee on the Learning Environment and \nFahim Rahman, Vice-President (Academic), Students’ Union \nPresenter Navneet Khinda, President, Students’ Union (delegate, Fahim Rahman, \nVice-President (Academic), Students’ Union) \nSubject Proposed Terms of Reference for GFC CLE Subcommittee to Explore \nTeaching Tenure Stream at University of Alberta \nDetails \nResponsibility Provost and Vice-President (Academic) \nThe Purpose of the Proposal is \n(please be specific) \nTo approve the terms of reference to establish a CLE Subcommittee to \nexplore the opportunities and challenges for creating a teaching tenure \nstream at the University of Alberta.  \nThe Impact of the Proposal is The CLE sub-committee will examine the opportunities and barriers to \ncreating a teaching tenure stream at University of Alberta and will \nprepare a report summarizing its discussions, review of existing \nevidence and its likely consequences (excluding financial implications) \nfor the teaching and learning environment at the University of Alberta. \nReplaces/Revises (eg, policies, \nresolutions) \nN/A \nTimeline/Implementation Date N/A \nEstimated Cost N/A \nSources of Funding N/A \nNotes  \nAlignment/Compliance \nAlignment with Guiding \nDocuments \nDare to Discover Values:  \nExcellence: Excellence in teaching that promotes learning; outstanding \nresearch and creative activity that fuel discovery and advance \nknowledge; and enlightened service that builds citizenship. \nStudent Experience: The centrality of our students and our \nresponsibility to provide an intellectually superior educational \nenvironment. \nDiversity and Creativity: A diverse, yet inclusive, dynamic collegial \ncommunity that welcomes change and seizes opportunity with passion \nand creativity. \nRecommendation 2-11 of the Report of the Renaissance Committee of \nUniversity of Alberta (2013) articulated: “Within the tenure track \nconstituencies, create a career progression structure for teaching-\nfocused staff that accommodates variances within the Faculty \nItem No. 7 \nGFC COMMITTEE ON THE LEARNING ENVIRONMENT \nFor the Meeting of March 2, 2016 \n Agreement to allow for emphasis on teaching, and that encourages and \nallows for promotion by means analogous to the current structure for \ntenure-track faculty”. \nCompliance with Legislation, \nPolicy and/or Procedure \nRelevant to the Proposal \n(please quote legislation and \ninclude identifying section \nnumbers) \nGFC Committee on the Learning Environment Terms of Reference \n(3. Mandate of the Committee) \n“The Committee on the Learning Environment is responsible for making \nrecommendations concerning policy matters and action matters with \nrespect to the following: […] \nb) To review and, as necessary, recommend to the GFC Academic \nPlanning Committee or the GFC Executive Committee policies on \nteaching, learning, teaching evaluation, and recognition for teaching that \npromote the University’s Academic Plan. […] \ne) To nurture the development of innovative and creative learning \nservices and teaching practices. \nf) To encourage the sharing and discussion of evidence about effective \nteaching, learning, and learning services. \ng) To promote critical reflection on the impact of broad societal changes \nin teaching, learning, and the learning environment. \nh) To promote projects with relevant internal and external bodies that \noffer unique teaching and learning opportunities that would benefit the \nuniversity community. \ni) To consider any matter deemed by the GFC Committee on the \nLearning Environment to be within the purview of its general \nresponsibility.” \nRouting (Include meeting dates) \nParticipation: \n(parties who have seen the \nproposal and in what capacity) \n• Those who have been \ninformed \n• Those who have been \nconsulted \n• Those who are actively \nparticipating \nGFC CLE October 7, 2015 Meeting: Discussion on Topics for 2015-2016 \nCommittee Workplan \nGFC CLE November 4, 2015 Meeting: Draft Template \nGFC CLE January 20, 2016 Meeting: Challenges for CLE – Topics for \nDiscussion \nApproval Route (Governance) \n(including meeting dates) \nGFC Committee on the Learning Environment (March 2, 2016) – for \napproval \nFinal Approver GFC Committee on the Learning Environment \nAttachments (each to be numbered 1 - <>) \n1.  Attachment 1 (page(s) 1 - 3) – GFC Committee on the Learning Environment Subcommittee on Exploring \nTeaching Tenure Stream at University of Alberta Terms of Reference for Approval \nPrepared by: <Fahim Rahman, Vice-President (Academic), University of Alberta Students’ \nUnion, fahim.rahman@su.ualberta.ca and Surma Das, University Governance and Advocacy Advisor, \nStudents’ Union, Surma.das@su.ualberta.ca> \nmailto:fahim.rahman@su.ualberta.ca\nmailto:Surma.das@su.ualberta.ca\n1 \nGFC Committee on the Learning Environment (CLE) \nSubcommittee on the Exploring Teaching Tenure Stream at University of Alberta (TTS) \nTERMS OF REFERENCE \n1. Background \nExploring Teaching Tenure Stream at University of Alberta \nIn response to growing enrollment and shrinking per-student funding, universities are forced to be more \ncreative in how they allocate resources. A common response across North America has been the rapid \nexpansion of contract teaching positions, as opposed to the traditional research-teaching-service model \nof tenured positions. Individuals in these contract positions generally lack the job security, \ncompensation and benefits of their tenured or tenure-track counterparts. In 2014-15, there were 922 \ncontract academics at our institution; as the number of contract instructors continues to grow, failure to \naddress this issue creates a liability for the institution.  \nSome North American universities, including the University of Toronto, UBC, Waterloo and the \nPennsylvania State University system have recognized that contract staff represent a tremendous asset \nto the academy and have implemented programs alike tenure to assure these individuals job security, \nfair compensation and the ability to conduct research – usually on discipline-specific pedagogy. \nDepartments tend to employ these individuals to teach junior courses, reserving more advanced classes \nfor “traditional” academics.   \nThe disproportionate presence of contract faculty in introductory classes raises important questions \nabout the relationship between their precarious status and student learning outcomes. With respect to \nstudent learning, there are two distinct issues: the innate ability of contract staff to teach at the same \nlevel as their research-focused colleagues, and the institutional support lent to contract faculty to \nensure they are able to engage with and support their students. The majority of available data on \nstudent learning outcomes under the two classes of instructors suggests that there is no statistically \nsignificant difference in learning outcomes, and in some cases contract instructors may affect \nimprovement in students’ performance in later classes in the same discipline.  Hence, creating \npermanent, secure positions for these instructors would not be detrimental, and may actually have \nbenefits for students. Additionally, the creation of these new, secure appointments would allow \ninstructors to dedicate more time to students and become more deeply invested in the university. \nStudies suggest that where shortcomings have been identified with contract instructors, they tend to be \nattributable to structural factors (lack of office space, insufficient time to prepare for courses, rushed \nevaluative measures) rather than instructor inability.  Taken together, the creation of teaching-tenure \npositions is likely to have a positive impact on student engagement and student learning outcomes.  \nWhile the mechanics of a teaching-tenure system remain unclear, and obtaining broad institutional buy-\nin will be critical to any initiative, the issue warrants further deliberation and study. The University of \nAlberta must demonstrate leadership on this issue to help ensure that the stock of teaching-focused \nfaculty remains stable and that students are able to continue to access high-quality education. \n2 \nThe Students' Union VPA proposes that CLE establishes a sub-committee to operate from March - \nOctober 2016 that will explore the opportunities and challenges of establishing a teaching tenure stream \nat the University of Alberta. \n2. Committee Mandate \nThe mandate of the CLE Subcommittee is to explore the opportunities and challenges for creating a \nteaching tenure stream at University of Alberta with the goal to enhance quality instruction and learning \nenvironment for undergraduate students. To fulfill this mandate the committee will consider \nundertaking the following activities: \ni. Consider the ways creation of teaching tenure stream (potentially accompanied by \ncontinuing appointments and job stability, greater professional development opportunities, \nincreased scholarship of teaching and learning, increased support and resources from home \ndepartment and faculty) will potentially affect the learning environment and quality of \ninstruction available to undergraduate students at University of Alberta. \nii. Review teaching tenure stream practices and arrangements at other Canadian peer \ninstitutions and research available literature on the issue in Canadian post-secondary \nlandscape (and if need be, at equivalent American public post-secondary context). \niii. Collect comprehensive statistics on total number of undergraduate courses and sections \ntaught by instructors who are not appointed as tenure track /tenured/ full time academic \nstaff/non-industry experts, by department / programs and faculties at University of Alberta. \niv. Consult key stakeholders on consequences of creating teaching tenure stream at University \nof Alberta on teaching and learning environment for undergraduate students and the \nopportunities and barriers to establishing a teaching tenure stream at University of Alberta. \nThis can include but is not limited to members of Dean’s Council, Chair’s Council or \nUndergraduate Chair’s Council, Students’ Union, GSA, Academic Staff Association of \nUniversity of Alberta (including representatives of Contract Academic Staff Association and \nSessional and Other Temporary Staff, members of AASUA Teaching and Learning \nCommittee) and former members (co-chairs) of Renaissance Committee. \nv. Survey and solicit aggregated feedback from members of university community on their \nviews on teaching tenure stream, with a caveat that it is only in exploratory stages.   \n3. Committee Composition \n• One representative of the Graduate Students’ Association \n• One representative of the Students’ Union \n• One representative of the Provost’s office \n• One representative of Department Chairs \n• One representative of Academic Staff \n3 \n• One representative of the Association of Academic Staff University of Alberta (external to \nCLE) \n• The Director (or delegate) of the Centre for Teaching and Learning  \n4. Committee Meetings and Timeline \n• The subcommittee will meet bi-weekly between March 2016 and October 2016. \n• A draft report for discussion will be presented at the October 2016 CLE meeting and be \nsubmitted to November 2016 GFC for discussion only. \n• Based on the discussion in November 2016 GFC, the final report will be submitted to the \nDecember 2016 CLE meeting, and if approved go to the January 2017 GFC meeting. \n5. Committee Support \nThe Office of Vice-President (Academic), Students’ Union; Office of Vice-Provost (Learning Initiatives) \nwill provide administrative support. \n6. Reference and Resource Documents: \n GFC Policy Manual section 111 on Teaching and Learning \n http://www.gfcpolicymanual.ualberta.ca/111TeachingandLearningandT each.aspx \nhttp://www.gfcpolicymanual.ualberta.ca/en/111TeachingandLearningandT%20each.aspx\nItem No. 8 \nGFC COMMITTEE ON THE LEARNING ENVIRONMENT \nFor the Meeting of March 2, 2016 \n OUTLINE OF ISSUE \nAgenda Title: Proposal for a new Scheduling Initiative for Augustana Faculty  \nMotion:  N/A  \nItem   \nAction Requested Approval Recommendation  Discussion/Advice Information \nProposed by Dr. Allen Berger, Dean, Augustana Faculty \nPresenter Dr. Karsten Mündel, Associate Dean, Academic, Augustana Faculty \nSubject New Scheduling Initiative for Augustana Faculty \nDetails \nResponsibility Provost and Vice-President (Academic) \nThe Purpose of the Proposal is \n(please be specific) \nAs a residential, undergraduate, liberal arts and science faculty within \nthe University of Alberta, the Augustana Campus places a special value \non community-based education, international and outdoor educational \nexperiences, undergraduate research and connections to rural and \naboriginal communities. In this context, the proposed new framework \nserves a dual-purpose vision: 1) to provide a rhythm for each academic \nyear that advances experiential learning opportunities for students, \nconnections between these opportunities and more traditional classroom \nwork, and pedagogical innovation by faculty; 2) to create a clearer niche \nfor Augustana and further differentiate the undergraduate student \nexperience at Augustana from alternatives on North Campus or at other \nAlberta universities. \nThe Impact of the Proposal is Apart from the above, the proposed Augustana Scheduling Initiative \ncould potentially address:  \n-student workload issues: particularly important for student mental \nhealth challenges that are increasingly recognized as critical;  \n-faculty workload issues: particularly the need to accommodate \nresearch expectations in a predominantly teaching Faculty;  \n-greater flexibility in degree completion times: especially with the \nopportunity to complete a *3 course in September or January;  \n-development of a first-year seminar: understood across North \nAmerica to be a “high-impact practice”, this mandatory “First Year \nExperience” course (proposed as AUIDS 101) will be a small seminar-\nstyle course for new students beginning studies at Augustana Faculty in \nthe September or January 3-weeks course block;  \n-provide opportunities for first and second-year students to \n‘sample’ courses: the 3-week block means students commit less time \nto an interest that may or may not result in a change of major or minor, \nand give a ‘short-term’ opportunity to explore other subject areas;  \n-ability to accommodate students’ varying learning styles: this \ncomes with the flexibility to present different learning methods within a 3 \nor 11 week course, as well as potentially over two or more of these \ncomponents in the academic schedule;  \nReplaces/Revises (eg, policies, \nresolutions) \nUniversity Calendar 52.2, 52.3, 52.4, 55.4. \nTimeline/Implementation Date September 2017 \nEstimated Cost N/A \nSources of Funding Existing resources.  There are no additional costs associated with the \nmove to the Block and Sessions calendar. A full load for students will \nItem No. 8 \nGFC COMMITTEE ON THE LEARNING ENVIRONMENT \nFor the Meeting of March 2, 2016 \n continue to be 15 credits in the standard University of Alberta Fall term \nand 15 credits in the Winter term. \nNotes On May 4, 2015, Augustana Faculty Council passed the following \nmotion: \n“THAT the Augustana Faculty implement, effective 2017-18, a new \nacademic schedule with the Fall and Winter semesters each consisting \nof a 3-week term followed by an 11-week term and adopt a new \ntimetable for the 11-week terms…and investigate the feasibility of an \nadditional 3-week block term in the spring.” \nTo avoid confusion with the standard University of Alberta Term \nstructure, current language designates the 3-week period as a ‘Block’ \nand the 11-week period as a ‘Session’ (see Attachments). \nAlignment/Compliance \nAlignment with Guiding \nDocuments \nAligns with Dare to Deliver; Dare to Discover values:  \n-enrich the student experience; foster a collegial learning culture; \npromote interdisciplinary collaboration, enhancing opportunities to \ndevelop undergraduate inquiry and research skills; create learning \nopportunities for students and creative collaborations to address global \nchallenges and initiatives; provide an intellectually superior educational \nenvironment for students; diverse, yet inclusive, dynamic collegial \ncommunity that welcomes change. \nAligns with Comprehensive Institutional Plan strategies, such as: \n-provide foundational support structures for students to create positive \nstudent experiences and engagement; ensure a high level of teaching \nquality; support programs and initiatives to help increase retention and \ncompletion rates; provide enhanced experiential learning opportunities; \ncontinue to create international opportunities for students; provide \nfoundational support structures for students in order to create a nurturing \nenvironment that allows for positive student experience and \nengagement; continue development of innovative programming to meet \nthe needs of students and the community; increase interdisciplinary, \ncollaborative program and initiative development in order to offer \nstudents innovative and relevant educational opportunities. \nCompliance with Legislation, \nPolicy and/or Procedure \nRelevant to the Proposal \n(please quote legislation and \ninclude identifying section \nnumbers) \n1. Post-Secondary Learning Act (PSLA): GFC is responsible, \ngenerally, for the academic affairs of the University and specifically, for \nthe Academic Schedule of the University (Sections 26(1), 26(1)(d)(e)(g) \nand (j) (Powers of General Faculties Council)).  \n2. GFC Executive Committee Terms of Reference (3. Mandate of the \nCommittee:  \n“4. Academic Schedule  \na. Delegation  \nPost-Secondary Learning Act (PSLA) Section 26(l)(j) follows:  \n26(1) Subject to the authority of the board, a general faculties council \nis responsible for the academic affairs of the university and, without \nrestricting the generality of the foregoing, has the authority to…  \n(j) determine the date for the beginning and end of lectures in the \nuniversity and also the beginning and end of each university term…. \nItem No. 8 \nGFC COMMITTEE ON THE LEARNING ENVIRONMENT \nFor the Meeting of March 2, 2016 \n b. Academic Schedule Changes \nThe GFC Executive Committee has delegated authority from General \nFaculties Council to approve the Academic Schedule. Any changes to \nthe Academic Schedule proposed after the Schedule has been \napproved must be submitted to the Executive Committee. That \ncommittee will determine which changes are sufficiently substantial \nand require, therefore, GFC approval and which ones are routine in \nnature and could be dealt with by the Executive Committee.” \n3. UAPPOL Academic Schedule Policy states: \n“[…] \n2. ACADEMIC SCHEDULE DELEGATION OF AUTHORITY \nThe authority to determine the Academic Schedule is the responsibility of \nthe GFC Executive Committee, as delegated to that body by General \nFaculties Council. \nThe Registrar recommends on the Academic Schedule to the GFC \nExecutive Committee.” \n4. UAPPOL Academic Schedule Procedure states: “Each spring, the \nExams and Timetabling Division in the Office of the Registrar will begin \ndrafting the Academic Schedule for the following year[…]. \nTwo drafts will be sent out to a distribution list that includes the \nPresident, Vice-Presidents and senior administrators, Deans, Assistant \nand Associate Deans, Directors and other stakeholders for feedback and \nsuggested changes. \nThe final draft of the Academic Schedule will be sent to the GFC \nExecutive Committee no later than mid-October for approval. \nAfter the Academic Schedule has been approved, it will be published in \nthe University Calendar.” \n5. GFC Committee on the Learning Environment Terms of \nReference (3. Mandate of the Committee) \n“The Committee on the Learning Environment is responsible for making \nrecommendations concerning policy matters and action matters with \nrespect to the following: […] \ne) To nurture the development of innovative and creative learning \nservices and teaching practices. \nf) To encourage the sharing and discussion of evidence about effective \nteaching, learning, and learning services. \ng) To promote critical reflection on the impact of broad societal changes \nin teaching, learning, and the learning environment. \nh) To promote projects with relevant internal and external bodies that \noffer unique teaching and learning opportunities that would benefit the \nuniversity community. \ni) To consider any matter deemed by the GFC Committee on the \nLearning Environment to be within the purview of its general \nresponsibility. \n6. GFC Academic Standards Committee Subcommittee on \nItem No. 8 \nGFC COMMITTEE ON THE LEARNING ENVIRONMENT \nFor the Meeting of March 2, 2016 \n Standards Terms of Reference (3. Mandate of the Committee) \n“To review and make recommendations to the GFC Academic Standards \nCommittee (ASC) with respect to a number of issues which affect all \nstudents at the University of Alberta. These include, but are not limited \nto: a. examination policy \nb. academic definitions \nc. academic standing regulations \nd. admission/transfer requirement” \n7. GFC Academic Standards Committee Terms of Reference  (3. \nMandate of the Committee) \n“The ASC is responsible for making recommendations and/or for \nproviding advice to GFC, its Executive Committee, and/or the GFC \nAcademic Planning Committee (APC) on the matters set out below, \nwhich include such areas as admission and transfer, including admission \nand transfer to Faculties, admission of Open Studies students, academic \nstanding policies and general university admission policies, and all \ninstitutional marking and grading policies and/or procedures.” […] \nRouting (Include meeting dates) \nParticipation: \n(parties who have seen the \nproposal and in what capacity) \n• Those who have been \ninformed \n• Those who have been \nconsulted \n• Those who are actively \nparticipating \nAugustana Fine Arts and Humanities, Science, and Social Sciences \nDepartment meetings – extensive consultation January-April 2015 (all \ndepartments include student representatives). \nAugustana Faculty Council – regular discussion in monthly meetings \nprior to formal approval in May 2015. \nProvost’s office – consultations and discussion \nDean’s Council – discussion, January 19 2016 \nSU President & VP-Academic – discussion, January 2016. \nPhyllis Clark’s Senior Executive Team – discussion, January 2016 \nAASUA – discussion, January 12, 2016 \nGFC Committee on the Learning Environment – discussion March 2, \n2016 \nGFC Academic Standards Committee-Subcommittee on Standards – \ndiscussion March 3, 2016 \nGFC Academic Standards Committee – discussion March 17, 2016 \nGFC Executive Committee – discussion April 11, 2016 \nApproval Route (Governance) \n(including meeting dates) \nN/A \nFinal Approver N/A \nAttachments (each to be numbered 1 - 3) \n1.  Attachment 1: Augustana Faculty 3-11 Calendar Information Document (pages 1 - 10) \n2.  Attachment 2: Proposed Augustana 3-11 Calendar Revisions (pages 1 - 4) \n 3.  Attachment 3: Draft table of standard U of A 2017-18 Academic Schedule compared to proposed      \nAugustana Block and Session Academic Schedule.  \nPrepared by: Jonathan Hawkins, Assistant Registrar, Augustana Campus, jonathan.hawkins@ualberta.ca \nmailto:jonathan.hawkins@ualberta.ca\n 1 \n AUGUSTANA FACULTY    3-11 CALENDAR  \n                     INFORMATION DOCUMENT \nTable of Contents \nI.  Short information summary regarding '3-11'.......2 \nII.  Background....................................................................4 \nIII. Faculty Consultation.....................................................6 \nIV.  FAQ.....................................................................................8 \n 2 \nI.  SHORT INFORMATON SUMMARY REGARDING '3-11' \nWhat Is It? \nOn May 4, 2015, the Augustana Faculty Council, after two years of study and with an overall \nmajority of 89%, passed the following motion: \nTHAT the Augustana Faculty implement, effective 2017-18, a new academic schedule with \nthe Fall and Winter semesters each consisting of a 3-week term followed by an 11-week \nterm and adopt a new timetable for the 11-week terms as outlined in Schedule A, and \ninvestigate the feasibility of an additional 3-week block term in the spring. \nVision \nAs a residential, undergraduate, liberal arts and science faculty within the University of \nAlberta, the Augustana Campus places a special value on community-based education, \ninternational and outdoor educational experiences, undergraduate research and \nconnections to rural and aboriginal communities. In this context, the 3-11 framework \nserves a dual-purpose vision: 1) to provide a rhythm for each academic year that advances \nexperiential learning opportunities for students, connections between these opportunities \nand more traditional classroom work, and pedagogical innovation by faculty; 2) to create a \nclearer niche for Augustana and further differentiate the undergraduate student experience \nat Augustana from alternatives on North Campus or at other Alberta universities. \nBackground \nSeveral undergraduate universities (e.g., Quest University in Canada; Colorado College and \nCornell College in the U.S.) have organized the entire undergraduate experience on a block \ncalendar in which students take one course at a time and faculty only teach one course at a \ntime. Other universities have traditionally placed courses into 10-11 week quarters instead \nof 13-15 week semesters. Based on personal experiences that Augustana faculty members \nhave had with both systems and the visit of a delegation to Quest University, we have \ndecided on a hybrid approach that we believe offers significant advantages and flexibility. \nAdditional Benefits \nThe new academic calendar and timetable also offer opportunities to address: student \nworkload issues (particularly important for student mental health challenges that are \nincreasingly recognized as critical); faculty workload issues (particularly the need to \naccommodate research expectations in a predominantly teaching Faculty); the need for \nmore flexibility in degree completion times; the possibility of developing a first-year \nseminar, understood across North America to be a “high-impact practice;” the need to \nprovide opportunities for first and second-year students to ‘sample’ courses (i.e., to \ncommit less time to an interest that may or may not result in a change of major); the \nchallenge of how to accommodate students’ varying learning styles; and Augustana’s \nrelated goals of enrolment and revenue growth (the latter not only determined by the \nnumber of degree-seeking students but also by the number of community members who \nmay be interested in taking, and paying for, 3-week courses).  \n 3 \nOrganization of Implementation \nAugustana recognizes that implementation of these changes will require the support of \npartners within the central University of Alberta administration, including key personnel in \nthe Registrar’s Office and the Office of the Provost. Preliminary conversations with \nRegistrar Lisa Collins have helped identify the likely players. In addition, Augustana is \norganizing a 3-11 Task Force that will include representatives from all academic \ndepartments, student services and the Augustana Students’ Association. Leadership will be \nprovided by Vice Dean Anne-Marie Link and Associate Dean Academic Karsten Mündel. \nOther faculty and staff will be brought in as necessary to help work out specific details \nrelated to implementation. Significant work will also be done within our three Department \nCouncils. \nTimeline \nThe motion passed by the Augustana Faculty Council envisions two years for preparation, \nwith roll-out for the 2017/18 Academic Year. Most of the logistical, policy, and procedural \nwork of implementation must be completed by July 2016 for calendar and recruitment \nmaterials to accurately reflect the new Augustana realities. An important first task of \nimplementation, therefore, is collectively to work backwards from that date to establish the \ndeadlines for the various subtasks outlined below. \nKey Tasks \nThe work of implementation at this point falls into three overlapping categories. The \nfollowing list is presented as a starting point for our work with Central partners, \nrecognizing that other tasks will be added as a result of initial planning discussions.  \nNew Timetable \nAdoption of the 3-11 academic schedule requires us to adopt a new timetable for both the \n3-week and 11-week terms. The timetable for the 3-week terms will be relatively easy to \nimplement, as traditional courses will be scheduled for approximately 3 hours per day with \nmorning, afternoon and evening timeslots. The 11-week schedule, found in Appendix A \nfrom the original motion and appended here, ensures that we have the same number of \ninstructional minutes in an 11-week term as in the current 13-week term. \nNew Academic Schedule \n● setting up Campus Solutions to deal with the semester/term structure at Augustana \n● changes to relevant academic procedures and regulations in relation to the schedule \nand timetable changes (the group will need to create early on a full list of these \nprocedures and regulations) \nOther Issues \n● tuition carry-forward for students who are unable to complete a 3-week term for \nlegitimate (health) reasons \nAugustana Tasks \nWe recognize that a series of Augustana-specific tasks need to take place in advance of the \n3-11 start date. These include: work on relevant promotional and recruitment materials; \ninvestments in faculty development; curriculum revisions; development of a First Year \nExperience seminar course for the first three-week block as a pilot project.  \n 4 \nII.  BACKGROUND \nA Learning Experience Research Committee (LERC) was convened after the Augustana \nFaculty Council meeting of October 2013 to research and consider alternative learning \nexperience opportunities that might be implemented at Augustana Campus and to produce \na specific proposal for an alternative learning experience that reflects the values and \nculture of learning at Augustana. The point of producing a specific proposal was to facilitate \na substantive discussion in the Faculty.  Following this substantive discussion and \nconsultation [SEE BELOW], the proposal, which was to become known as '3-11' was \nsubsequently passed with an 89% majority at the Augustana Faculty Council meeting in \nMay 2015.   \nRationale for Proposal  \nA. The proposal was guided by the values and culture of learning articulated in The \nAugustana Faculty Academic Performance Measures (December 2012) and by the evaluation \nand recommendations of the Academic Unit Review of the Augustana Faculty (2011) since  \n(1) both reports have been accepted by the Augustana Faculty and University of Alberta  \n(2) the self-description of Augustana in The Augustana Faculty Academic Performance \nMeasures was a supplement to the Academic Measures for Budgeting Process 2013-14 \ndistributed by the Office of the Provost and as such is used to determine budget allocations \nto Augustana  \nB. This proposal aimed to strengthen the three characteristics that are unique to Augustana \n(according to The Augustana Faculty Academic Performance Measures):  \n(1) International Experiences  \n(2) Community-Based Learning  \n(3) Rural Connectedness  \nIn all three areas, the intention is to increase both the number of participating students and \nthe number of courses in each area.  \nC. The proposal also aimed to implement specific recommendations from the Academic Unit \nReview:  \n(1) to “push ahead confidently in making programming even more distinctive than is \nalready the case” by “strengthening and extending the core curriculum”;  \n(2) expand opportunities for “undergraduate research and creative work”;  \n(3) focus on “the liberal education provided to students regardless of major,” particularly \nwith regards to international experiences, community-based learning, and rural \nconnectedness.  \nD. The proposed learning experiences are high-impact practices that have all been tried \nand successfully implemented at one or more COPLAC institutions. This evidence suggests \nthat these practices could also work at Augustana if tailored to our specific situation. \nMoreover, the  \nspecific learning experiences in the proposal are constructed to meet current student needs \n 5 \n(such as greater flexibility). \nThe \"3-11\" calendar was the major component of the resulting proposal, along with a First \nYear Experience. \nThe objective of 3-11 is to provide students and faculty with more flexibility as well as to \nfacilitate unique experiential learning opportunities. Augustana could institute a 3 week \nblock at the beginning of the Fall and/or Winter term followed by an 11 week session.  These \nblocks and sessions are accommodated within the existing Fall and Winter terms of the \nUniversity of Alberta and do not change the number of contact hours, number of \ncourses taken by students over each term (normally 5) or number of courses taught by \nfaculty (normally 3).  \n 6 \nIII.  FACULTY CONSULTATION RE:  3-11 CALENDAR \nThe change to the 3-11 Calendar system formed the major part of the LERC proposal.   \nThe LERC committee consisted of representatives from all three academic departments and \nfrom the Augustana Students Association.  In the 2014-15 academic year it organized \ndiscussions regarding 3-11 at departmental meetings, at Faculty Council meetings and a \nseries of formal consultations with faculty and staff.  The formal consultation dates are listed \nhere: \n6 January           noon - 1:30         \n13 January         noon - 1:30          \n20 January         noon - 1:30 \n27 January         noon-1:30  \n2 February         12:30 - 2              \n2 March             12:30 - 2              \n10 March           noon - 1:30          \n24 March           noon-1:30            \n13 April              noon - 1:30  \nThere were between ten and twenty participants at the consultations outside Faculty \nCouncil meetings and departmental meetings. \nThe Faculty Council met in May 2015 to review, discuss and consider the material brought \nforth by the LERC committee and the results of its consultations.  The following motion was \nsubsequently put before the Faculty Council: \nTHAT the Augustana Faculty implement, effective 2017-18, a new \nacademic schedule with the Fall and Winter semesters each \nconsisting of a 3-week term followed by an 11-week term and \nadopt a new timetable for the 11-week terms as outlined in \nSchedule A, and investigate the feasibility of an additional 3-week \nblock term in the spring.  \nThe procedure for voting was that of  a 'Super Majority', a decision-making procedure that \nhad been voted on and carried at the December 1, 2014 meeting of the Faculty Council. This \nrequired that the motion for implementation of 3-11 needed to attain both a simple majority \nin each academic department followed by a two-thirds majority of YES votes at Faculty \nCouncil in which all members were to vote (faculty members, APOs, student representatives). \nThe majorities were achieved in all departments and an 89% YES vote was achieved at the \nFaculty Council meeting of May 2015. \n 7 \nDuring that meeting, an Implementation Committee was constituted,  which consists of \nrepresentatives from all academic departments, from the ASA, and from Residence \nLife/Student Services. \nConsultation continues as a major focus of the Implementation Committee. \n 8 \nIV.  FAQ \nStudent FAQ \n1) Why is Augustana doing this? \nAfter more than 2 years of consultation with students, faculty and staff, about \nways to improve the Augustana Advantage, we decided to implement a new \nacademic calendar and a First Year Experience. The new calendar will introduce \ngreater flexibility and foster the development of new experiential, travel and \nlearning opportunities. The First Year Experience will give students a seminar \nexperience in their first year to introduce them to learning in a Liberal Arts \ncontext. \n2) How does the new Augustana Academic Calendar work? \nThe Fall Term will consist of a 3-week block in which students would take 1 \ncourse followed by an 11-week session in which students would take 4 courses. \nThe Winter Term would also have a 3-week block and an 11-week session. There \nwill be an increasing effort to also offer courses in a Spring 3-week block. \n3) What is the implementation timeline? \nThe new academic calendar and First Year Experience will come into effect for the \n2017-18 academic year. The whole Augustana Campus will adopt the new \ncalendar. Students starting in the 2017-18 academic year will take the First Year \nSeminar class. \n4) Will I still be able to graduate in 4 years? \nAbsolutely! Students will still be able to take 5 courses in the Fall and Winter \nTerms and therefore be able to graduate in 4 years. As we increase our course \nofferings in the Spring and Summer Terms, students will also be able to pick up \nadditional courses to introduce greater flexibility into their schedules. \n5) What is the Augustana First Year Experience? \nThe Augustana First Year Experience is specifically designed to help students to \nmake the transition to university life and learning in a Liberal Arts context. There \nare two key components: a) the new student orientation and b) the Augustana \nFirst Year Seminar (FYS). The FYS will explore a specific topic in a small \nseminar-style setting. Students will be exposed to small-group discussion and will \nexplore a topic from a variety of academic disciplines and viewpoints. The new \nstudent orientation will work with the non-academic aspects of the transition to \nuniversity life. \n 9 \n6) What do I need to do to maintain full-time status in the new Augustana \nAcademic Calendar? \nFull-time status will continue to be a minimum of 9 credits per Term. Students have the \nflexibility to choose where in the Term to take their courses (for example, they could take \n3 credits in the 3-week block and 6 credits in the 11-week session). As is currently the case, \nspecific scholarships and sponsorships may require a greater number of credits to maintain \neligibility. In any case, the number of credits will be calculated at the Term level (and not \nthe block level). \n7) What kinds of courses will be offered in the fall and winter blocks? \nThere will be a variety of courses offered in all blocks. The courses offered in the 3-week \nblocks will take advantage of the different time frame and the fact that students and \nprofessors are not involved in any other courses at the same time. \n8) Can I take September or January off? \nOne of the advantages of the new Academic Calendar is the choice it provides for \nscheduling. So, yes, you may be able to build an academic schedule that does not have any \nclasses in September or January for some of the Terms of your academic career at \nAugustana. However, depending on your major and other components of your academic \nprogram, it may be more challenging to complete your degree in 4 years if you take a \nSeptember or January block off. \n9) Can I transfer my courses from Augustana to other universities? \nNone of the changes we are making to the academic schedule will impact the \ntransferability of these courses to other institutions. As at present, not all courses will \nalways transfer to a given program in a given receiving institution. Students are always \nadvised to check with a receiving institution about transferability. \n10) Are there any impacts on costs? \nNo. The costs for courses will continue to be calculated in the same manner as they are now. \nAugustana will continue to follow the same fee assessment schedule as it currently does. \nResidence fees will continue to be assessed on a Term basis (and not block). \n11) Will my transcript look the same as it does now? \nYes. The transcripts will continue to look the same as they do now, listing courses by term \ntaken. \nDo you have other questions? Please contact Sarah Ross in the Dean’s Office  \nross3@ualberta.ca and she will find you an answer (and include it here in the FAQ). \nmailto:ross3@ualberta.ca\n 10 \nStaff FAQ \n1. How does the new Augustana Academic Calendar work? \nThe Fall Term will consist of a 3-week block in which students would take 1 course and an \n11-week session in which students would take 4 courses. The Winter Term would \nalso have a 3-week block and 11-week session. There will be an increasing effort to offer \ncourses in a Spring 3-week block. \n1. What is the implementation timeline? \nThe new academic calendar are First Year Experience will come into effect for the \n2017-18 academic year. The whole Augustana Campus will adopt the new calendar. \nStudents starting in the 2017-18 academic year will take the First Year Seminar class. \n2. How do I raise issues related to the impact of the new Academic Calendar on my \nwork? The first person to ask is your direct manager. Additionally, Anne-Marie \nand Karsten are scheduling meetings with every unit on campus during the Fall \nTerm. Those meetings will be a further chance to ask questions about the impact \nof these changes on your work rhythms. \n3. How does full-time status work in the new Augustana Academic Calendar? \nFull-time status will continue to be 9 credits per Term. Students have the flexibility to \nchoose where in the Term to take their courses (for example, they could take one course in \nthe 3-week block and 2 courses in the 11-week session). As is currently the case, specific \nscholarships and sponsorships may require a greater number of credits to maintain \neligibility. In any case, the number of credits will be calculated at the Term level (and not \nthe block or session level). \nDo you have other questions? Please contact Sarah Ross in the Dean’s Office  \nross3@ualberta.ca and she will find you an answer (and include it here in the FAQ).  \nmailto:ross3@ualberta.ca\nProposed Augustana 3-11 Calendar Revisions \nCurrent Proposed \n52.1 Classification of Degree Programs \n Academic disciplines at the Augustana Faculty \nare organized into three departments for administrative \npurposes: Fine Arts and Humanities, Science, and \nSocial Sciences. The following programs are available \nwithin these departments: \nProgram Chart follows \n{…no changes required in this section…} \nNew 52.2 The Augustana Academic Schedule: Blocks \nand Sessions \nThe Augustana “Blocks and Sessions” academic \nschedule provides a unique rhythm for each academic \nyear that advances experiential learning opportunities \nfor students, creates connections between these \nopportunities and more traditional classroom work, \noffers greater flexibility for students in managing \ncourse workloads and degree completion times, and \nprovides greater accommodation to a variety of student \nlearning styles. \nAugustana Faculty features an academic schedule in \nwhich each of the traditional Fall and Winter Terms \nconsist of a 3-week Block followed by an 11-week \nSession, with an additional 3-week Block at the start of \nthe standard University Spring Term.  This schedule \ncreates a potential annual student academic enrollment \ncycle of 3-11-3-11-3. Students typically register in a \nsingle *3 course in a particular Block and a \ncombination of courses totalling *12 in a particular \nSession. \n52.2      The Augustana Core \n{…no further changes in this section…} \n52.3     The Augustana Core \n{…no further changes in this section…} \n52.3 General Program Information \n The following terms, definitions, and \nabbreviations are used throughout the Augustana \nFaculty section of the Calendar. \n(1)  Unit of Course Weight: A unit of course weight \nindicates the instructional credit assigned to a course \nand is designated by the symbol after the course \nnumber and name. Units of course weight form a part \nof the degree requirements and are also used to \ncalculate a student’s Grade Point Average (GPA). \n(2)  Junior-level Courses: Courses numbered 100-199. \n(3)  Senior-level Courses: Courses numbered 200-499. \n(4)  Term: The instructional periods are from \nSeptember to December (Fall Term), January to April \n(Winter Term), May/June (Spring Term), and \nJuly/August (Summer Term). \n52.4 General Program Information \n The following terms, definitions, and \nabbreviations are used throughout the Augustana \nFaculty section of the Calendar. \n(1)  Unit of Course Weight: A unit of course weight \nindicates the instructional credit assigned to a course \nand is designated by the * symbol after the course \nnumber and name. Units of course weight form a part \nof the degree requirements and are also used to \ncalculate a student’s Grade Point Average (GPA). \n(2)  Junior-level Courses: Courses numbered 100-199. \n(3)  Senior-level Courses: Courses numbered 200-599. \n(4)  Term: The standard University of \nAlberta instructional periods are from September to \nDecember (Fall Term), January to April (Winter Term), \nMay/June (Spring Term), and July/August (Summer \nTerm).  Augustana Faculty further divides these periods \nas follows: \na.   Blocks: Augustana designates three specific \n(5)  Single-term Course: A term course is a course with \na course weight of 3 that normally extends over one \nUniversity term. Certain courses are offered over a \nsingle term with weights of *1, *1.5, and *2. \n(6)  Two-term Course: A two-term course is a course \nwith a course weight of 6 that normally extends \nover two consecutive University terms. Certain \ncourses are offered over Fall/Winter with weights of \n*2, *3, and *4. \n(7)  Year Status: Each student who has been admitted \nto a degree program at Augustana is classified \naccording to year status as follows: \na. *0-23 earned: first-year standing. First-year \nstudents are normally not eligible to take courses \nnumbered 200 or higher. \nb. *24-53 earned: second-year standing. \nc. *54-83 earned: third-year standing. \nd. *84 or more earned: fourth-year standing. \n(8)  Course load:  \na. The normal full course load is *30 for the \nacademic year; \nb. Course overload: A student must receive special \npermission from his or her Academic Adviser \nto carry more than *17 in any one term. \n(9)  Minimum Passing Grade: The minimum passing \ngrade in University of Alberta undergraduate courses is \na D. The minimum final grade for transfer of courses \nfrom other postsecondary institutions is C-. \n(10)  Overlapping Options:  \na. A course that fulfills more than one \nrequirement on a major or in a major/minor \ncombination; \nb. A course that fulfills a requirement in both the \ncore and within a specific program. \n(11)  Non-Overlapping Options:  \na. A course that is not allowed to count towards \nmore than one requirement within a major; \nb. No course may be counted towards more than \ninstructional periods during the academic year, \nconsisting of approximate 3 week Blocks, normally \nin September, January, and May. \nb.   Sessions: Augustana designates two specific \ninstructional periods during the academic year, \nconsisting of approximate 11 week Sessions \nextending from late-September to December, and \nfrom late-January to April. \n(5)  Credit Course: A course that carries credit toward a \ndegree or diploma. A standard credit course has a \ncourse weight of *3 and normally extends over a single \ninstructional period, namely a University Term, an \nAugustana Block, or an Augustana Session. Certain \ncourses may present an alternative course weight. \n(6)  Two-term Course: A two-term course is a course \nwith a course weight of *6 that normally extends \nover two or more instructional periods, such as \nUniversity Fall/Winter Terms, or multiple Augustana \nBlocks/Sessions. Certain courses may present an \nalternative course weight. \n(7)  Year Status: Each student who has been admitted \nto a degree program at Augustana is classified \naccording to year status as follows: \na. *0-23 earned: first-year standing. First-year \nstudents are normally not eligible to take courses \nnumbered 200 or higher. \nb. *24-53 earned: second-year standing. \nc. *54-83 earned: third-year standing. \nd. *84 or more earned: fourth-year standing. \n(8)  Course load:  \na. The normal full course load is *30 for the \nacademic year; \nb. Course overload: A student will not normally \nbe allowed to attempt more than one *3 course in \nany given Augustana Block, or carry more than *13 \nin any given Augustana Session.  A student must \nreceive special permission from his or her Academic \nAdviser to exceed these course load limits. \n(9)  Minimum Passing Grade: The minimum passing \ngrade in University of Alberta undergraduate courses is \na D. The minimum final grade for transfer of courses \nfrom other postsecondary institutions is C-. \n(10)  Overlapping Options:  \na. A course that fulfills more than one \nrequirement for a major or in a major/minor \ncombination, or in some form of \nmajor/minor/certificate combination; \nb. A course that fulfills a requirement in both the \ncore and within a specific program. \n(11)  Non-Overlapping Options:  \na. A course that is not allowed to count towards \nmore than one requirement within a major; \nb. No course may be counted towards more than \none core requirement. \n(12)  Supporting Course: A course from outside a \nparticular major which generally complements the \nstudy of that major; it is a requirement for the \ncompletion of the major, but is not used in calculating \nthe major GPA. \n(13)  Option: The term “option” where it appears in \nprograms means a course chosen by the student from \nofferings by the Augustana Faculty if the necessary \nprerequisites have been met, and which is not a specific \nprogram requirement. \n(14)  Arts Courses/Options: Courses offered by the \nAugustana Faculty which are classified as “Arts” \ncourses (see §56.2) for which the student is eligible and \nwhich meet degree requirements. \n(15)  Music Courses/Options: Courses offered by the \nAugustana Faculty which are classified as “AUMUS” \ncourses (see §231) for which the student is eligible and \nwhich meet degree requirements. \n(16)  Science Courses/Options: Courses offered by the \nAugustana Faculty which are classified as “Science” \ncourses (see §56.2) for which the student is eligible and \nwhich meet degree requirements. \n(17)  Specialized Professional Courses: Courses offered \nby the Augustana Faculty which are classified as neither \n“Arts” nor “Science” courses (see §56.2) for which the \nstudent is eligible and which meet degree requirements. \none core requirement. \n(12)  Supporting Course: A course from outside a \nparticular major which generally complements the \nstudy of that major; it is a requirement for the \ncompletion of the major, but is not used in calculating \nthe major GPA. \n(13)  Option: The term “option” where it appears in \nprograms means a course chosen by the student from \nofferings by the Augustana Faculty if the necessary \nprerequisites have been met, and which is not a specific \nprogram requirement. \n(14)  Arts Courses/Options: Courses offered by the \nAugustana Faculty which are classified as “Arts” \ncourses (see §56.2) for which the student is eligible and \nwhich meet degree requirements. \n(15)  Music Courses/Options: Courses offered by the \nAugustana Faculty which are classified as “AUMUS” \ncourses (see §231) for which the student is eligible and \nwhich meet degree requirements. \n(16)  Science Courses/Options: Courses offered by the \nAugustana Faculty which are classified as “Science” \ncourses (see §56.2) for which the student is eligible and \nwhich meet degree requirements. \n(17)  Specialized Professional Courses: Courses offered \nby the Augustana Faculty which are classified as neither \n“Arts” nor “Science” courses (see §56.2) for which the \nstudent is eligible and which meet degree requirements. \n{…no further changes required in subsequent \nAugustana sections by 3-11 implementation, other \nthan potential section re-numbering, until…} \n{…no further changes until…} \n55.4 Attendance, Evaluations and Grading \n Since presence at lectures, participation in \nclassroom discussions and projects, and the completion \nof assignments are important components of most \ncourses, students will serve their interests best by \nregular attendance. Those who choose not to attend \nmust assume whatever risks are involved. Students \nshould pay close attention to any further requirements \non attendance and class participation indicated on \ncourse outlines (see §23.4). As well, students should \nrefer to §23.3 for specific regulations regarding exams. \n Every student’s performance will be evaluated \nat least two times per term in each course. The \nevaluations may take the form of tests, essays, and/or \nother assignments. The results of at least one \nevaluation in each course will be available to students \nno later than the eighth week of the term. For further \ninformation on evaluations, grading, and exams, see \n§§23.4 and 23.5. \n No examination valued at more than 20% of \nthe final grade (10% in two term Fall/Winter courses) \nshall be scheduled during the last ten instructional days \nof the Fall or Winter term. \n55.4 Attendance, Evaluations and Grading \n Since presence at lectures, participation in \nclassroom discussions and projects, and the completion \nof assignments are important components of most \ncourses, students will serve their interests best by \nregular attendance. Those who choose not to attend \nmust assume whatever risks are involved. Students \nshould pay close attention to any further requirements \non attendance and class participation indicated on \ncourse outlines (see §23.4). As well, students should \nrefer to §23.3 for specific regulations regarding exams. \n Every student’s performance will be evaluated \nat least two times in each course. The evaluations may \ntake the form of tests, essays, and/or other \nassignments. The results of at least one evaluation in \neach course will be available to students no later \nthan eight weeks into a standard Fall or Winter Term, \nseven weeks into an 11-week Augustana Session, or 8 \ninstructional days into a 3-week Augustana Block \ncourse. For further information on evaluations, \ngrading, and exams, see §§23.4 and 23.5. \n No examination valued at more than 20% of \nthe final grade shall be scheduled during the last ten \n No student shall be required to write three final \nexams in one day (i.e., in the morning, afternoon, and \nevening exam periods). Should a student have three \nexams scheduled in one day, the student should contact \nthe Office of the Registrar at Augustana as soon as \npossible for assistance in rescheduling one exam to \nanother time within that final examination period. \ninstructional days of a standard Fall or Winter \nTerm course, the last eight instructional days of an 11-\nweek Augustana Session course, or the last 3 \ninstructional days of a 3-week Augustana Block course \n(the exception being a final exam in a 3-week Block \ncourse, which typically will occur on the last day of the \ncourse). \n No student shall be required to write three final \nexams in one day (i.e., in the morning, afternoon, and \nevening exam periods). Should a student have three \nexams scheduled in one day, the student should contact \nthe Office of the Registrar at Augustana as soon as \npossible for assistance in rescheduling one exam to \nanother time within that final examination period. \nComparative Sample Illustrating How the Proposed Augustana Block & Session Schedule \nWould Look in Relation to the ‘Standard’ University of Alberta Academic Schedule \nThe following table attempts to show approximate dates for the 2017-2018 academic year, which is the intended implementation period \nfor the revised Augustana academic framework.  The left column indicates the major dates/events in the standard University of Alberta \nacademic schedule, while the column on the right indicates the potential schedule for Augustana Faculty.  Dates that apply to both \nschedules are not highlighted, while notable differences are noted in yellow, with potential Augustana dates bolded.  All dates are \nunofficial and subject to change – this provides a general overview and comparison of how these schedules might appear for 2017-18. \nSample University of Alberta Academic Schedule  Sample Proposed Augustana Block/Session Schedule \n2017  2017  \nJuly  July  \n1 One hundred and Eleventh University year \nbegins. \n1 One hundred and Eleventh University year begins. \n1 Canada Day. University buildings closed. 1 Canada Day. University buildings closed. \n3 Canada Day Holiday. University buildings \nclosed. \n3 Canada Day Holiday. University buildings closed. \n4 Summer Term courses begin. 4 Summer Term courses begin. \n4-7 Auditor registrations for Summer Term \ncourses will be accepted only on these days. \n4-7 Auditor registrations for Summer Term courses will \nbe accepted only on these days. \n7 n  Last day for students enrolled in the \nUniversity of Alberta Health Insurance \nProgram (UAHIP) to opt out of this insurance \ncoverage by providing proof of enrolment in \nthe Alberta Health Care Insurance Plan to the \nInternational Centre. \n7 n  Last day for students enrolled in the University of \nAlberta Health Insurance Program (UAHIP) to opt \nout of this insurance coverage by providing proof \nof enrolment in the Alberta Health Care Insurance \nPlan to the International Centre. \n7 n  Summer Term Registration Deadline (for \nsix-week and first half three-week courses): \nLast day to add or drop these courses. (Bear \nTracks web registration available to midnight.) \nStudents wishing to add or drop three-week \ncourses offered during the second half of the \nterm should seek assistance at department \noffices. \n7 n  Summer Term Registration Deadline (for six-\nweek and first half three-week courses): Last day \nto add or drop these courses. (Bear Tracks web \nregistration available to midnight.) Students \nwishing to add or drop three-week courses offered \nduring the second half of the term should seek \nassistance at department offices. \n7 n  Payment Deadline: Last day for payment of \nSummer Term fees. Students who have not \npaid their fees in full, or made satisfactory \nalternate arrangements, will be assessed late \npayment penalty charges. \n7 n  Payment Deadline: Last day for payment of \nSummer Term fees. Students who have not paid \ntheir fees in full, or made satisfactory alternate \narrangements, will be assessed late payment \npenalty charges. \n11 n  Summer Term Refund Deadline (for three-\nweek courses): Students withdrawing from \ncourses taught in the first three weeks of \nSummer Term will be assessed full fees after \nthis date. \n11 n  Summer Term Refund Deadline (for three-week \ncourses): Students withdrawing from courses \ntaught in the first three weeks of Summer Term will \nbe assessed full fees after this date. \n18 n  Summer Term Refund Deadline (for six-\nweek courses): Students withdrawing after \nthis date will be assessed full fees. \n18 n  Summer Term Refund Deadline (for six-week \ncourses): Students withdrawing after this date will \nbe assessed full fees. \n19 n  Last day for withdrawal from courses taught \nin the first half of Summer Term. \n19 n  Last day for withdrawal from courses taught in \nthe first half of Summer Term. \n24 Last day of classes for courses taught in the \nfirst half of Summer Term. \n24 Last day of classes for courses taught in the first \nhalf of Summer Term. \n25 Classes begin for courses taught in the \nsecond half of Summer Term. \n25 Classes begin for courses taught in the second \nhalf of Summer Term. \n28 n  Second half Summer Term Registration \nDeadline (for three week courses): Last day to \nadd or drop courses taught in the second half \nof Summer Term. Students should seek \nassistance at department offices. \n28 n  Second half Summer Term Registration Deadline \n(for three week courses): Last day to add or drop \ncourses taught in the second half of Summer \nTerm. Students should seek assistance at \ndepartment offices. \nAugust  August  \n2 n  Summer Term Refund Deadline (for three-\nweek courses): Students withdrawing from \ncourses taught in the last three weeks of \nSummer Term will be assessed full fees after \nthis date. \n2 n  Summer Term Refund Deadline (for three-week \ncourses): Students withdrawing from courses \ntaught in the last three weeks of Summer Term will \nbe assessed full fees after this date. \n3 n  Last day for withdrawal from six-week \ncourses in Summer Term. \n3 n  Last day for withdrawal from six-week courses in \nSummer Term. \n7 Heritage Day. University buildings closed. 7 Heritage Day. University buildings closed. \n8 n  Last day for withdrawal from courses taught \nin the second half of Summer Term. \n8 n  Last day for withdrawal from courses taught in \nthe second half of Summer Term. \n11-14 Final examinations for Summer Term \ncourses, exceptions may apply. \n11-14 Final examinations for Summer Term courses, \nexceptions may apply. \n15 Registration opens for Open Studies students \nin courses designated for delayed registration.  \n15 Registration opens for Open Studies students in \ncourses designated for delayed registration.  \n  31-1 Orientation for new Undergraduate Students in \nAugustana Faculty. \nSeptember  September  \n1 Orientation for new Undergraduate Students.   \n1 n  Last day for Undergraduate students to \napply through Bear Tracks for permission to \ngraduate at Fall Convocation. \n1 n  Last day for Undergraduate students to apply \nthrough Bear Tracks for permission to graduate at \nFall Convocation. \n4 Labour Day. University buildings closed.  4 Labour Day. University buildings closed.  \n5 Fall Term and Fall/Winter Term classes begin, \nexcept for students in Faculty of Law, Faculty \nof Medicine and Dentistry, Faculty of \nPharmacy, and Faculty of Rehabilitation \nMedicine. \n5 Fall Term and Fall/Winter Term classes begin, \nexcept for students in Faculty of Law, Faculty of \nMedicine and Dentistry, Faculty of Pharmacy, and \nFaculty of Rehabilitation Medicine. \n  5 Fall 3-week Block courses begin in Augustana \nFaculty. \n  8 n  Fall 3-week Block Registration Deadline in \nAugustana Faculty. Students withdrawing after this \ndate through September 13 will be assessed 50% \nfees for withdrawn courses. \n  11-12 Registrations by Undergraduate students to audit \nor to change from ‘credit’ to ‘audit’ in Fall 3-week \nBlock courses in Augustana Faculty will be \naccepted only during this period. \n  13 n  Fall 3-week Block Refund Deadline in Augustana \nFaculty: Students withdrawing after this date will \nbe assessed full fees.   \n18 n  Fall Registration Deadline (Bear Tracks web \nregistration system available to midnight): \nLast day to add or drop Fall Term and \nFall/Winter Term courses. Students \nwithdrawing after this date through October 5 \nwill be assessed 50% fees for withdrawn \ncourses. Exceptions may apply students must \nconsult with their Faculty office. \n18 n  Fall Registration Deadline (Bear Tracks web \nregistration system available to midnight): Last day \nto add or drop Fall Term and Fall/Winter Term \ncourses. Students withdrawing after this date \nthrough October 5 will be assessed 50% fees for \nwithdrawn courses. Exceptions may apply \nstudents must consult with their Faculty office. \n18 n  SU Health and Dental Plan Change of \nCoverage Deadline. Students wishing to opt-\nout of this service or change their coverage \nmust do so through www.ihaveaplan.ca.  \n18 n  SU Health and Dental Plan Change of Coverage \nDeadline. Students wishing to opt-out of this \nservice or change their coverage must do so \nthrough www.ihaveaplan.ca.  \n  19 n  Last day for withdrawal from Fall 3-week Block \ncourses in Augustana Faculty. \n19-25 Registrations by Undergraduate students to \naudit or to change from ‘credit’ to ‘audit’ in Fall \nTerm and Fall/Winter Term courses will be \naccepted only during this period. \n19-25 Registrations by Undergraduate students to audit \nor to change from ‘credit’ to ‘audit’ in Fall Term and \nFall/Winter Term courses will be accepted only \nduring this period. \n  21 Last day of classes for Fall 3-week Block courses \nin Augustana Faculty \n21-24 Alumni weekend. 21-24 Alumni weekend. \n  25 Fall 11-week Session courses begin in Augustana \nFaculty. \n28 n  Fall Term Refund Deadline (for six-week \ncourses): Students withdrawing from courses \noffered in the first six weeks of Fall Term will \nbe assessed full fees after this date. \n28 n  Last day for students enrolled in the \nUniversity of Alberta Health Insurance \nProgram (UAHIP) to opt out of this insurance \ncoverage by providing proof of enrolment in \nthe Alberta Health Care Insurance Plan to the \nInternational Centre. \n28 n  Last day for students enrolled in the University of \nAlberta Health Insurance Program (UAHIP) to opt \nout of this insurance coverage by providing proof \nof enrolment in the Alberta Health Care Insurance \nPlan to the International Centre. \n29 n  Payment Deadline: Last day for payment of 29 n  Payment Deadline: Last day for payment of Fall \nFall Term fees. Students who have not paid \ntheir fees in full, or made satisfactory alternate \narrangements, will be assessed late penalty \ncharges. To avoid instalment charges, all \nFall/Winter fees must be paid by the Fall Term \nFee Deadline. \nTerm fees. Students who have not paid their fees \nin full, or made satisfactory alternate \narrangements, will be assessed late penalty \ncharges. To avoid instalment charges, all \nFall/Winter fees must be paid by the Fall Term Fee \nDeadline. \nOctober  October  \n  4 n  Fall 11-week Session Registration Deadline in \nAugustana Faculty. Students withdrawing after this \ndate through October 16 will be assessed 50% \nfees for withdrawn courses. \n5 n  Fall Term Refund Deadline: Students \nwithdrawing after this date will be assessed \nfull fees.  Exceptions may apply students \nmust consult with their Faculty office. \n5 n  Fall Term Refund Deadline: Students \nwithdrawing after this date will be assessed full \nfees.  Exceptions may apply students must consult \nwith their Faculty office. \n  5-11 Registrations by Undergraduate students to audit \nor to change from ‘credit’ to ‘audit’ in Fall 11-week \nSession courses in Augustana Faculty will be \naccepted only during this period. \n  6 n  Last day to drop from six-week courses offered in \nthe first half of Augustana Fall Session. \n12 n  Last day for withdrawal from six-week \ncourses offered in the first half of the Fall \nTerm. \n9 Thanksgiving Day. University buildings \nclosed. \n9 Thanksgiving Day. University buildings closed. \n  16 n  Fall 11-week Session Refund Deadline in \nAugustana Faculty: Students withdrawing after this \ndate will be assessed full fees.   \n  16 n  Augustana Fall Session Refund Deadline (for six-\nweek courses): After this date students \nwithdrawing from courses offered in the first six \nweeks of the Augustana Fall Session will be \nassessed full fees. \n17 Last day of classes for six-week courses \noffered in the first half of Fall Term. \n19 Classes begin for six-week courses offered in \nthe second half of the Fall Term. \n21 University of Alberta Open House. 21 University of Alberta Open House. \n  23 n  Last day for withdrawal from six-week courses \noffered in the first half of Augustana Fall Session. \n30 n  Last day to drop six-week courses offered in \nthe second half of the Fall Term. \n  30 Last day of classes for six-week courses offered in \nthe Augustana Fall Session. \nNovember  November  \n  2 Classes begin for six-week courses offered in the \nsecond half of the Augustana Fall Session. \n11 Remembrance Day. University buildings \nclosed. \n11 Remembrance Day. University buildings closed. \n13-17 Fall Term Reading week. Classes withdrawn \nfor a full week, except for students in \nAugustana Faculty, Faculty of Law; Faculty of \nMedicine and Dentistry; Faculty of \nRehabilitation Medicine; Faculty of Nursing \nundergraduate programs; and students in \nCooperative Education, Experiential Learning \nPlacement and Work Placement terms. \n13-17 Fall Term Reading week. Classes withdrawn for a \nfull week, except for students in Augustana \nFaculty, Faculty of Law; Faculty of Medicine and \nDentistry; Faculty of Rehabilitation Medicine; \nFaculty of Nursing undergraduate programs; and \nstudents in Cooperative Education, Experiential \nLearning Placement and Work Placement terms. \n  13-15 Augustana Faculty Fall Term break. \n  16 n  Last day to drop from six-week courses offered in \nthe second half of Augustana Fall Session. \n21-22 Fall Convocation, Part I, Parts II and III 21-22 Fall Convocation, Part I, Parts II and III \n20 n  Fall Term Refund Deadline (for six-week \ncourses): After this date students withdrawing \nfrom courses offered in the last six weeks of \nFall Term will be assessed full fees. \n  23 n  Fall Term Refund Deadline (for six-week \ncourses): After this date students withdrawing from \ncourses offered in the last six weeks of Augustana \nFall Session will be assessed full fees. \nDecember  December  \n1 n  Last day for withdrawal from six-week \ncourses offered in the second half of Fall \nTerm. \n1 n  Last day for withdrawal from Fall Term \ncourses. Exceptions may apply students must \nconsult with their Faculty office. \n1 n  Last day for withdrawal from Fall Term courses. \nExceptions may apply students must consult with \ntheir Faculty office. \n  5 n  Last day for withdrawal from Fall 11-week \nSession courses in Augustana Faculty. \n  6 n  Last day for withdrawal from six-week courses \noffered in the second half of Augustana Fall \nSession. \n8 Last day of Fall Term classes. Exceptions \nmay apply, students must consult with their \nFaculty office. \n8 Last day of Fall Term classes. Exceptions may \napply, students must consult with their Faculty \noffice. \n  11 Last day of Fall Term classes for Augustana \nFaculty. \n11-22 Fall Term examinations (including \nconsolidated examinations) Exceptions may \napply, students must consult with their Faculty \noffice. Examinations other than consolidated \nexaminations are held within the period \nDecember 13-22 (inclusive). University-\norganized extracurricular activities will \nnormally not be allowed during this period.  \n11-22 Fall Term examinations (including consolidated \nexaminations) Exceptions may apply, students \nmust consult with their Faculty office. \nExaminations other than consolidated \nexaminations are held within the period December \n13-22 (inclusive). University-organized \nextracurricular activities will normally not be \nallowed during this period.  \n  14-22 Fall Term examinations for Augustana Faculty. \nUniversity-organized extracurricular activities will \nnormally not be allowed during this period. \n25-31 Christmas holiday period. University buildings \nclosed. \n25-31 Christmas holiday period. University buildings \nclosed. \n2018  2018  \nJanuary  January  \n1 New Year’s Day. University buildings closed. 1 New Year’s Day. University buildings closed. \n  3 Winter 3-week Block courses begin in Augustana \nFaculty. \n  8 n  Winter 3-week Block Registration Deadline in \nAugustana Faculty. Students withdrawing after this \ndate through January 11 will be assessed 50% \nfees for withdrawn courses. \n8 Winter Term classes begin. Exceptions may \napply, students must consult with their Faculty \noffice. \n8 Winter Term classes begin. Exceptions may apply, \nstudents must consult with their Faculty office. \n  9-10 Registrations by Undergraduate students to audit \nor to change from ‘credit’ to ‘audit’ in Winter 3-\nweek Block courses in Augustana Faculty will be \naccepted only during this period. \n  11 n  Winter 3-week Block Refund Deadline in \nAugustana Faculty: Students withdrawing after this \ndate will be assessed full fees.   \n  17 n  Last day for withdrawal from Winter 3-week Block \ncourses in Augustana Faculty. \n19 n  Last day to withdraw from Fall/Winter two-\nterm courses. \n19 n  Last day to withdraw from Fall/Winter two-term \ncourses. \n19 n  Winter Term Registration Deadline: Last day \nto add or drop Winter Term courses. (Bear \nTracks system available to midnight.) \nStudents withdrawing after this date through \nFebruary 7 will be assessed 50% fees for \nwithdrawn courses. Exceptions may apply \nstudents must consult with their Faculty office.  \n19 n  Winter Term Registration Deadline: Last day to \nadd or drop Winter Term courses. (Bear Tracks \nsystem available to midnight.) Students \nwithdrawing after this date through February 7 will \nbe assessed 50% fees for withdrawn courses. \nExceptions may apply students must consult with \ntheir Faculty office.  \n  19 Last day of classes for Winter 3-week Block \ncourses in Augustana Faculty \n19-25 Registrations by Undergraduate students to \naudit or to change from ‘credit’ to ‘audit’ in \n19-25 Registrations by Undergraduate students to audit \nor to change from ‘credit’ to ‘audit’ in Winter Term \nWinter Term courses will be accepted only \nduring this period.  \ncourses will be accepted only during this period.  \n  24 Winter 11-week Session courses begin in \nAugustana Faculty. \n26 n  Winter Term Refund Deadline (for six-week \ncourses): After this date students withdrawing \nfrom courses offered in the first six weeks of \nWinter Term will be assessed full fees. \n26 n  Last day for students enrolled in the \nUniversity of Alberta Health Insurance \nProgram (UAHIP) to opt out of this insurance \ncoverage by providing proof of enrolment in \nthe Alberta Health Care Insurance Plan to the \nInternational Centre. \n26 n  Last day for students enrolled in the University of \nAlberta Health Insurance Program (UAHIP) to opt \nout of this insurance coverage by providing proof \nof enrolment in the Alberta Health Care Insurance \nPlan to the International Centre. \n31 n  Payment Deadline: Last day for payment of \nWinter Term fees. Students who have not \npaid their fees in full, or made satisfactory \nalternate arrangements, will be assessed late \npayment penalty charges. \n31 n  Payment Deadline: Last day for payment of \nWinter Term fees. Students who have not paid \ntheir fees in full, or made satisfactory alternate \narrangements, will be assessed late payment \npenalty charges. \nFebruary  February  \n1 n  Last day for Undergraduate students to \napply through Bear Tracks for permission to \ngraduate at Spring Convocation. \n1 n  Last day for Undergraduate students to apply \nthrough Bear Tracks for permission to graduate at \nSpring Convocation. \n  2 n  Winter 11-week Session Registration Deadline in \nAugustana Faculty. Students withdrawing after this \ndate through February 16 will be assessed 50% \nfees for withdrawn courses. \n  5-8 Registrations by Undergraduate students to audit \nor to change from ‘credit’ to ‘audit’ in Fall 11-week \nSession courses in Augustana Faculty will be \naccepted only during this period. \n  6 n  Last day to drop from six-week courses offered in \nthe first half of Augustana Winter Session. \n7 n  Winter Term Refund Deadline: Students \nwithdrawing from courses after this date will \nbe assessed full fees. Exceptions may apply, \nstudents must consult with their Faculty office.  \n7 n  Winter Term Refund Deadline: Students \nwithdrawing from courses after this date will be \nassessed full fees. Exceptions may apply, students \nmust consult with their Faculty office.  \n8 n  Last day for withdrawal from six-week \ncourses offered in the first half of Winter \nTerm. \n  13 n  Augustana Winter Session Refund Deadline (for \nsix-week courses): After this date students \nwithdrawing from courses offered in the first six \nweeks of the Augustana Winter Session will be \nassessed full fees. \n15 Registration system opens for Spring/Summer \n2018. \n15 Registration system opens for Spring/Summer \n2018. \n16 Last day of classes for six-week courses \noffered in the first half of Winter Term. \n  16 n  Winter 11-week Session Refund Deadline in \nAugustana Faculty: Students withdrawing after this \ndate will be assessed full fees.   \n19 Statutory Provincial holiday. University \nbuildings closed. \n19 Statutory Provincial holiday. University buildings \nclosed. \n20-23 Winter Term Reading Week. Classes \nwithdrawn for a full week, except for students \nin NURS 495, SC INF 495, PHARM 425, \nExperiential Learning placement, third and \nfourth years of the MD program, and students \nin the clinical component of the Radiation \nTherapy program. Exceptions may apply, \nstudents must consult with their Faculty office. \n20-23 Winter Term Reading Week. Classes withdrawn \nfor a full week, except for students in Augustana \nFaculty, NURS 495, SC INF 495, PHARM 425, \nExperiential Learning placement, third and fourth \nyears of the MD program, and students in the \nclinical component of the Radiation Therapy \nprogram. Exceptions may apply, students must \nconsult with their Faculty office. \n  20 n  Last day for withdrawal from six-week courses \noffered in the first half of Augustana Winter \nSession. \n  28 Last day of classes for six-week courses offered in \nthe first half of Augustana Winter Session. \nMarch  March  \n5 Classes begin for six-week courses offered in \nthe second half of the Winter Term. \n  5 Classes begin for six-week courses offered in the \nsecond half of the Augustana Winter Session. \n  7-9 Augustana Faculty Winter Term break. \n16 n  Last day to drop from six-week courses \noffered in the second half of Winter Term. \n  21 n  Last day to drop from six-week courses offered in \nthe second half of Augustana Winter Session. \n23 n  Winter Term Refund Deadline (for six-week \ncourses): After this date students withdrawing \nfrom courses offered in the last six weeks of \nWinter Term will be assessed full fees. \n  28 n  Augustana Winter Session Refund Deadline (for \nsix-week courses): After this date students \nwithdrawing from courses offered in the last six \nweeks of the Augustana Winter Session will be \nassessed full fees. \n30 Good Friday. University buildings closed. 30 Good Friday. University buildings closed. \nApril  April  \n2 Easter Monday. University buildings closed. 2 Easter Monday. University buildings closed. \n6 n  Last day for withdrawal from six-week \ncourses offered in the second half of Winter \nTerm. \n6 n  Last day for withdrawal from Winter Term \ncourses. Exceptions may apply students must \nconsult with their Faculty office. \n6 n  Last day for withdrawal from Winter Term \ncourses. Exceptions may apply students must \nconsult with their Faculty office. \n  9 n  Last day for withdrawal from Winter 11-week \nSession courses in Augustana Faculty. \n  11 n  Last day for withdrawal from six-week courses \noffered in the second half of Augustana Winter \nSession. \n13 Last day of Winter Term classes.  Exceptions \nmay apply students must consult with their \nFaculty office. \n13 Last day of Winter Term classes.  Exceptions may \napply students must consult with their Faculty \noffice. \n  16 Last day of Winter Term classes for Augustana \nFaculty. \n16-27 Winter Term examinations (including \nconsolidated examinations). Exceptions may \napply students must consult with their Faculty \noffice. Examinations other than consolidated \nexaminations are held within the period April \n18-27 (inclusive). University-organized \nextracurricular activities will normally not be \nallowed during this period. \n16-27 Winter Term examinations (including consolidated \nexaminations). Exceptions may apply students \nmust consult with their Faculty office. \nExaminations other than consolidated \nexaminations are held within the period April 18-27 \n(inclusive). University-organized extracurricular \nactivities will normally not be allowed during this \nperiod. \n  20-28 Winter Term examinations for Augustana Faculty. \nUniversity-organized extracurricular activities will \nnormally not be allowed during this period. \nMay  May  \n  2 Spring 3-week Block courses begin in Augustana \nFaculty. \n7 Spring Term classes begin. 7 Spring Term classes begin. \n  8 n  Spring 3-week Block Registration Deadline in \nAugustana Faculty. Students withdrawing after this \ndate through May 10 will be assessed 50% fees \nfor withdrawn courses. \n7-10 Auditor registrations for Spring Term courses \nwill be accepted only on these days.  \n7-10 Auditor registrations for Spring Term courses will \nbe accepted only on these days.  \n  8-9 Registrations by Undergraduate students to audit \nor to change from ‘credit’ to ‘audit’ in Spring 3-\nweek Block courses in Augustana Faculty will be \naccepted only during this period. \n9 Charter Day. 9 Charter Day. \n10 n  Payment Deadline: Last day for payment of \nSpring Term fees. Students who have not \npaid their fees in full, or made satisfactory \n10 n  Payment Deadline: Last day for payment of \nSpring Term fees. Students who have not paid \ntheir fees in full, or made satisfactory alternate \nalternate arrangements, will be assessed late \npayment penalty charges.  \narrangements, will be assessed late payment \npenalty charges.  \n10 n  Last day for students enrolled in the \nUniversity of Alberta Health Insurance \nProgram (UAHIP) to opt out of this insurance \ncoverage by providing proof of enrolment in \nthe Alberta Health Care Insurance Plan to the \nInternational Centre. \n10 n  Last day for students enrolled in the University of \nAlberta Health Insurance Program (UAHIP) to opt \nout of this insurance coverage by providing proof \nof enrolment in the Alberta Health Care Insurance \nPlan to the International Centre. \n10 n  Spring Term Registration Deadline (for six-\nweek courses): Last day to add or drop \ncourses. (Bear Tracks web registration will be \navailable until midnight). Students wishing to \nadd or drop three-week courses offered \nduring the second half of the Spring Term \nshould seek assistance at department offices. \n10 n  Spring Term Registration Deadline (for six-week \ncourses): Last day to add or drop courses. (Bear \nTracks web registration will be available until \nmidnight). Students wishing to add or drop three-\nweek courses offered during the second half of the \nSpring Term should seek assistance at department \noffices. \n  10 n  Spring 3-week Block Refund Deadline in \nAugustana Faculty: Students withdrawing after this \ndate will be assessed full fees.   \n14 n  Spring Term Refund Deadline (for three-\nweek courses): Students withdrawing from \ncourses taught in the first three weeks of \nSpring Term will be assessed full fees after \nthis date. \n14 n  Spring Term Refund Deadline (for three-week \ncourses): Students withdrawing from courses \ntaught in the first three weeks of Spring Term will \nbe assessed full fees after this date. \n  16 n  Last day for withdrawal from Spring 3-week Block \ncourses in Augustana Faculty. \n  18 Last day of classes for Spring 3-week Block \ncourses in Augustana Faculty \n21 Victoria Day. University buildings closed. 21 Victoria Day. University buildings closed. \n22 n  Spring Term Refund Deadline (for six-week \ncourses): Students withdrawing after this date \nwill be assessed full fees. \n22 n  Spring Term Refund Deadline (for six-week \ncourses): Students withdrawing after this date will \nbe assessed full fees. \n22 n  Last day for withdrawal from courses taught \nin the first three weeks of Spring Term. \n22 n  Last day for withdrawal from courses taught in \nthe first three weeks of Spring Term. \n25 n  Last day for classes taught in the first three \nweeks of Spring Term. \n25 n  Last day for classes taught in the first three \nweeks of Spring Term. \n28 Classes begin for courses taught in the last \nthree weeks of Spring Term. \n28 Classes begin for courses taught in the last three \nweeks of Spring Term. \n31 n  Second half Spring Term Registration \nDeadline (for three-week courses): Last day \nto add or drop courses taught in the last three \nweeks of Spring Term. Students should seek \nassistance at department offices. \n31 n  Second half Spring Term Registration Deadline \n(for three-week courses): Last day to add or drop \ncourses taught in the last three weeks of Spring \nTerm. Students should seek assistance at \ndepartment offices. \nJune  June  \n3 Augustana Faculty convocation. 3 Augustana Faculty convocation. \n4 n  Spring Term Refund Deadline (for three-\nweek courses): Students withdrawing from \ncourses taught in the last three weeks of \nSpring Term will be assessed full fees after \nthis date. \n4 n  Spring Term Refund Deadline (for three-week \ncourses): Students withdrawing from courses \ntaught in the last three weeks of Spring Term will \nbe assessed full fees after this date. \n5-8 Spring Convocation, Parts I to VI. 5-8 Spring Convocation, Parts I to VI. \n6 n  Last day for withdrawal from six-week \ncourses in Spring Term. \n6 n  Last day for withdrawal from six-week courses in \nSpring Term. \n8 n  Last day for withdrawal from courses taught \nin the last three weeks of Spring Term. \n8 n  Last day for withdrawal from courses taught in \nthe last three weeks of Spring Term. \n11-14 Spring Convocation, Parts VII to XI. 11-14 Spring Convocation, Parts VII to XI. \n14-15 Final examinations for Spring Term courses. \nNo classes held, exceptions may apply. \n14-15 Final examinations for Spring Term courses. No \nclasses held, exceptions may apply. \n30 One Hundred and Eleventh University year \nends. \n30 One Hundred and Eleventh University year ends. \n\tItem-1-Agenda-CLE-MR2\n\tItem-5-Formative-Feedback\n\t5a-OI-Formative-Feedback\n\t5b-Bluepulse\n\t5c-LEM for HE\n\tItem-6-mandated-USRI-questions-revised\n\t6a-OI-mandated-questions-USRI-online-project-based-courses\n\t6b-project_USRI_for_GFC_CLE_discussion (1)\n\t6c-Mandated-questions-USRI-online-courses\n\tItem-7-ToR-subctte-teaching-tenure\n\t7a-teaching-tenure-ToR-OI\n\t7b-ToR-CLE-subcommittee-teaching-tenure\n\tItem-8-Augustana-3-11\n\t8a-OUTLINE-OF-ISSUE Augustana 3-11 Academic Schedule Feb 2016\n\t8b-3-11AugustanaFacultyConsultation (1)\n\t8c-3-11 Proposed changes - updated for Governance Feb 17\n\t8d-2017-2018 sample academic schedules\n",
    "collection title": "CLE"
}