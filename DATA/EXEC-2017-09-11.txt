{
    "Committee": "EXEC",
    "Date": "2017-09-11",
    "Title": "EXEC General Faculties Council - 2017-09-11",
    "Location": "Council Chamber, 2-100 University Hall",
    "Time": "2:00 PM - 4:00 PM",
    "Attendees": [
        "David Turpin, Chair",
        "Sylvia Brown",
        "Lisa Collins",
        "Lesley Cormack",
        "Steven Dew",
        "Delane Howie",
        "Firouz Khodayari",
        "Al Meldrum",
        "Shane Scott",
        "Eleni Stroulia",
        "Jonathan White",
        "Bill Foster",
        "Brent Swallow",
        "Meg Brolley, Coordinator",
        "Marion Haggarty-France",
        "Andrea Patrick, Scribe"
    ],
    "Items": [
        {
            "Item No.": "4",
            "Agenda Title": "Committee Kick-Off and Orientation 2017-2018 ",
            "Motion": "N/A",
            "Action Requested": "N/A",
            "Date": "2017-09-11",
            "Committee": "EXEC",
            "Proposed By": "University Governance ",
            "Presenter": "Marion Haggarty France, University Secretary Meg Brolley, GFC Secretary ",
            "Description": " Purpose of the Proposal: To provide committee members with an overview of the principles under which GFC operates and how these inform the work and functioning of the committee. To orient members to the committee’s mandate, terms of reference, procedures and to committee member roles and responsibilities. Discussion: Ms Haggarty-France and Ms Brolley provided members with a high level overview of the university’s governance structure. Members were provided with an orientation to GFC’s approved principles of delegated authority and committee composition, and the significance of these documents to the structure and functioning of the GFC Executive Committee. In addition, the roles and responsibilities or members and procedural rules were reviewed. Finally, the mandate and responsibilities of the GFC Executive Committee were discussed and the recommendation of the ad hoc committee to revise the terms of reference of the committee was introduced. During the discussion, a member commented that revisions to simplify the Outline of Issue would be welcomed.",
            "Participation": [
                "GFC Executive Committee "
            ],
            "Approval Route": [
                "N/A"
            ],
            "Final Approver": "N/A"
        },
        {
            "Item No.": "5A",
            "Agenda Title": "Goals from the Students’ Union 2017-2018",
            "Motion": "N/A",
            "Action Requested": "N/A",
            "Date": "2017-09-11",
            "Committee": "EXEC",
            "Proposed By": "Marina Banister, President, Students’ Union ",
            "Presenter": "Marina Banister, President, Students’ Union ",
            "Description": "Purpose of the Proposal: To provide members with the strategic goals of the Students’ Union (SU) and Graduate Students’ Association (GSA) for 2017-2018. Discussion: Following the presentation of the Students’ Union (SU) goals for 2017-2018, Ms Banister addressed questions about the renovation of the Myer Horowitz Theatre and how goals were established this year. The Chair requested that further tuition advocacy efforts include support for base funding and tuition freeze backfill for the university. Mr Soltannia provided members with a presentation highlighting the GSA goals for 2017-2018 and a question arose regarding homeless graduate students at the university. A member enquired about the use of the Consumer Price Index (CPI) in tuition calculations and a response was provided.  ",
            "Participation": [
                "GFC Executive Committee – September 11, 2017 ",
                "General Faculties Council – September 25, 2017 ",
                "Board Learning and Development Committee – September 29, 2017 "
            ],
            "Approval Route": [
                "N/A"
            ],
            "Final Approver": "N/A"
        },
        {
            "Item No.": "5B",
            "Agenda Title": "Graduate Students’ Association (GSA) Board Strategic Work Plan 2017-2018 ",
            "Motion": "N/A",
            "Action Requested": "N/A",
            "Date": "2017-09-11",
            "Committee": "EXEC",
            "Proposed By": "Babak Soltannia, President, Graduate Students’ Association (GSA) ",
            "Presenter": "Babak Soltannia, President, Graduate Students’ Association (GSA) ",
            "Description": " Purpose of the Proposal: To provide members with the strategic goals of the Students’ Union (SU) and Graduate Students’ Association (GSA) for 2017-2018. Discussion: Following the presentation of the Students’ Union (SU) goals for 2017-2018, Ms Banister addressed questions about the renovation of the Myer Horowitz Theatre and how goals were established this year. The Chair requested that further tuition advocacy efforts include support for base funding and tuition freeze backfill for the university. Mr Soltannia provided members with a presentation highlighting the GSA goals for 2017-2018 and a question arose regarding homeless graduate students at the university. A member enquired about the use of the Consumer Price Index (CPI) in tuition calculations and a response was provided.  ",
            "Participation": [
                "GFC Executive Committee – September 11, 2017 ",
                "General Faculties Council – September 25, 2017 ",
                "Board Learning and Development Committee – September 29, 2017 ",
                "GSA Board (May 24, 2017, May 31, 2017, and June 21, 2017) ",
                "GSA Council (June 19, 2017, and July 17, 2017) "
            ],
            "Approval Route": [
                "N/A"
            ],
            "Final Approver": "N/A"
        },
        {
            "Item No.": "7",
            "Agenda Title": "Proposed Changes to the University of Alberta Convocation Admission ",
            "Motion": "THAT the GFC Executive Committee recommend to General Faculties Council the proposed changes to the Convocation Admission, as set forth in Attachment 1, and as proposed by the University of Alberta Senate, to take effect upon final approval. ",
            "Action Requested": "Recommendation",
            "Date": "2017-09-11",
            "Committee": "EXEC",
            "Proposed By": "Douglas Stollery, Chancellor ",
            "Presenter": "Douglas Stollery, Chancellor ",
            "Description": "Purpose of the Proposal: To discuss and approve proposed changes to the University of Alberta Convocation Admission. Discussion: Mr Roy Brenneis noted that, since this item was discussed at GFC in the spring as an item of early consultation, the Chancellor had met with the Chaplains’ Association in regards to the proposed changes who provided a range of feedback including the lack of spirituality in the language of the proposed Convocation Admission. Mr Roy Brenneis added that the proposal has received widespread positive support throughout community consultations.",
            "Participation": [
                "The Office of the President ",
                "The University of Alberta Senate ",
                "Standing Committee on Convocation ",
                "GFC Executive Committee ",
                "General Faculties Council ",
                "GFC Executive Committee ",
                "General Faculties Council "
            ],
            "Approval Route": [
                "GFC Executive Committee (September 2017 for recommendation to GFC)",
                "General Faculties Council (September 2017 for final approval)"
            ],
            "Final Approver": "General Faculties Council"
        },
        {
            "Item No.": "8",
            "Agenda Title": "Report of the GFC Committee on Learning Environment on Teaching and Learning and Teaching Evaluation and the Use of the Universal Student Ratings of Instruction (USRI) as an Evaluation Tool ",
            "Motion": "THAT the GFC Executive Committee recommend that General Faculties Council approve the CLE Report on Teaching and Learning and Teaching Evaluation and the Use of the Universal Student Ratings of Instruction (USRI) as an Evaluation Tool, as attached. ",
            "Action Requested": "Recommendation",
            "Date": "2017-09-11",
            "Committee": "EXEC",
            "Proposed By": "Sarah Forgie, Chair, Committee  on the Learning Environment ",
            "Presenter": "Sarah Forgie, Chair, Committee  on the Learning Environment and Principal Investigator Norma Nocente, Co-Investigator L Francisco Vargas M, Research Coordinator Rebecca Best-Bertwistle, Research Assistant ",
            "Description": "Purpose of the Proposal: The GFC Committee on the Learning Environment (CLE) was requested by GFC to report on research into the use of student rating mechanisms of instruction in university courses. This report fulfills this request. Discussion: Dr Forgie provided members with a summary of the report including details about the process and methodology of researching and compiling the data presented. Members engaged in a discussion surrounding the implications of the wording of the motion, including whether the committee was approving the recommendations, or endorsing the report. The wording of the motion was amended to reflect that the committee was recommending that GFC receive the report and endorse the recommendations contained within it. In response to a question about the timeline of implementation, it was clarified that the project would require significant time and additional steps before completion. A member suggested that the recommendations be clearly referred to within the documents. ",
            "Participation": [
                "Provost and Vice-President (Academic) ",
                "Vice-Provost Council ",
                "Deans’ Council ",
                "Chairs’ Council ",
                "GFC Executive Committee ",
                "General Faculties Council ",
                "GFC Committee on the Learning Environment ",
                "GFC Executive Committee ",
                "GFC Committee on the Learning Environment ",
                "Sarah Forgie, Vice-Provost (Learning Initiatives) and Principal Investigator ",
                "Norma Nocente, Co-Investigator ",
                "L Francisco Vargas M, Research Coordinator ",
                "Rebecca Best-Bertwistle, Research Assistant ",
                "GFC Executive Committee ",
                "General Faculties Council "
            ],
            "Approval Route": [
                "GFC Committee on the Learning Environment – April 2017",
                "GFC Executive Committee – September 11, 2017",
                "General Faculties Council – September 25, 2017"
            ],
            "Final Approver": " General Faculties Council"
        },
        {
            "Item No.": "9",
            "Agenda Title": "Faculty of Graduate Studies and Research: Proposed revisions to existing Supervision and Examinations policy. ",
            "Motion": "THAT the GFC Executive Committee recommend that General Faculties Council approve the proposed revisions to existing Supervision and Examinations policy, as recommended by the GFC Academic Standards Committee, as submitted by the Faculty of Graduate Studies and Research and as set forth in Attachment 1, to take effect July 1, 2018. ",
            "Action Requested": "Recommendation",
            "Date": "2017-09-11",
            "Committee": "EXEC",
            "Proposed By": "Heather Zwicker, Dean, Faculty of Graduate Studies and Research ",
            "Presenter": "Deborah Burshtyn, Vice-Dean, Faculty of Graduate Studies and Research ",
            "Description": " Purpose of the Proposal: The proposed revisions are intended to clarify the policies, elaborate on procedures, and improve policies. The impact will be to have greater clarity for students, faculty and staff in the administration and conduct and outcomes of examinations in thesis-based programs. Discussion: Dr Burshtyn explained the proposal contains two changes in relation to who can chair candidacy and doctoral examinations, and conflict resolutions between students and supervisors. Members expressed support for the changes and identified minor editorial changes within the proposal. A member enquired about the implications around leaves of absence other than sabbatical leaves.",
            "Participation": [
                "Dean and Associate Deans, FGSR ",
                "FGSR Program Services staff ",
                "Graduate Program Administrators Council (GPAC) ",
                "Faculty Graduate Councils (or equivalents) ",
                "FGSR Council ",
                "Graduate Students Association (GSA)—represented on the PRC (below), also conducted wider consultation with graduate students ",
                "FGSR Policy Review Committee (PRC) ",
                "Brent Epperson, Graduate Ombudsperson (as a member of PRC) ",
                "Graduate Students Association (GSA)—(represented on PRC and FGSR Council) ",
                "Vice Dean, FGSR "
            ],
            "Approval Route": [
                "FGSR Council, May 17, 2017, approved",
                "ASC-Subcommittee on Standards - June 1, 2017 (for discussion)",
                "GFC Academic Standards Committee - June 15, 2017",
                "GFC Executive Committee - September 11, 2017",
                "General Faculties Council - September 25, 2017"
            ],
            "Final Approver": " General Faculties Council"
        },
        {
            "Item No.": "10",
            "Agenda Title": "Proposed Faculty Name Change: Faculty of Kinesiology, Sport, and Recreation (from Faculty of Physical Education and Recreation (FPER)) ",
            "Motion": "THAT General Faculties Council approve the proposed name change for the Faculty of Physical Education and Recreation to the ‘Faculty of Kinesiology, Sport, and Recreation’, as submitted by the Dean of the Faculty, to take effect upon final approval. ",
            "Action Requested": "Approval",
            "Date": "2017-09-11",
            "Committee": "EXEC",
            "Proposed By": "Kerry Mummery, Dean, Faculty of Physical Education & Recreation ",
            "Presenter": "Kerry Mummery, Dean, Faculty of Physical Education & Recreation ",
            "Description": " N/A",
            "Participation": [
                "Canadian Council of University Physical Education and Kinesiology Administrators (CCUPEKA) ",
                "Presidential Visiting Committee (PVC) ",
                "International Partner Universities ",
                "Faculty staff, students, and alumni ",
                "Physical Education and Recreation Council of Students (PERCS) ",
                "Physical Education and Recreation and Recreation Graduate Students Society (PERGGS) ",
                "Physical Education and Recreation Alumni Associate (PERRA) ",
                "Community stakeholders ",
                "Faculty of Physical Education and Recreation Academic Planning Committee ",
                "Faculty of Physical Education and Recreation Faculty Management Group (APC) ",
                "Faculty of Physical Education and Recreation Faculty Council Executive Committee (FEXC) ",
                "Faculty of Physical Education and Recreation Faculty Council "
            ],
            "Approval Route": [
                "Faculty of Physical Education and Recreation Council",
                "GFC Academic Planning Committee – September 13, 2017",
                "GFC Executive Committee (for information) – September 11, 2017",
                "General Faculties Council – September 25, 2017"
            ],
            "Final Approver": "General Faculties Council"
        },
        {
            "Item No.": "11",
            "Agenda Title": "Increase to Required English Language Proficiency (ELP) Scores for Undergraduate Admissions ",
            "Motion": "THAT General Faculties Council approve: - the minimum overall TOEFL score be increased 4 points to 90, with no change to the required score of 21 on each band. - the minimum band score for the IELTS Academic be increased from 5.0 to 5.5, with no change to the required minimum overall score of 6.5 as recommended by the GFC Academic Planning Committee, as set forth in Attachment 4, to take effect fall 2018. ",
            "Action Requested": "N/A",
            "Date": "2017-09-11",
            "Committee": "EXEC",
            "Proposed By": "Lisa Collins, Vice Provost and University Registrar ",
            "Presenter": "Lisa Collins, Vice Provost and University Registrar Melissa Padfield, Deputy Registrar ",
            "Description": "N/A",
            "Participation": [
                "University of Alberta International (John Soltice, Cen Huang) (May-June 2016) ",
                "Faculty of Extension, English Language School (Donald Mason, Greg Sowak, Mimi Hui, Michael Viola, Martin Guardado) Monday, July 11th, 2016 ",
                "Academic Standards Committee June 2016 ",
                "Faculty of Arts Executive Committee ",
                "Faculty of Arts Chairs’ Council ",
                "International and undergraduate advisors in the Faculty of Arts ",
                "Stuart Landon ",
                "Advisory Committee on Enrolment Management (May, June 2016) ",
                "ELP Working Group Members ",
                "Brenda Leskiw (Science) ",
                "Jim Bohun (ALES) ",
                "Melissa Casey (RO) ",
                "Nat Kav (Vice Provost’s office) ",
                "Elizabeth Taylor (Rehabilitation Medicine) ",
                "Sam Stowe (RO) December 2015 meeting only ",
                "Rebecca Nagel (Arts) ",
                "Yidi Liu (SU) May 2016 meeting only ",
                "Marina Banister (SU) May 2016 meeting only ",
                "Fahim Rahman (SU) December 2015 meeting only ",
                "Suzanne French (Provost’s office) "
            ],
            "Approval Route": [
                "ASC Subcommittee on Standards  – May 4, 2017",
                "GFC Academic Standards Committee – May 18, 2017",
                "GFC Academic Planning Committee – September 13, 2017",
                "GFC Executive Committee (for information) – September 11, 2017",
                "General Faculties Council – September 25, 2017"
            ],
            "Final Approver": " General Faculties Council"
        },
        {
            "Item No.": "12",
            "Agenda Title": "Budget Model Principles ",
            "Motion": "THAT General Faculties Council recommend  that the Board of Governors approve the budget model principles, as recommended by the GFC Academic Planning Committee, and as set forth in Attachment 1, to take effect upon final approval. ",
            "Action Requested": "Recommendation",
            "Date": "2017-09-11",
            "Committee": "EXEC",
            "Proposed By": "Provost and Vice-President (Academic), Vice-President (Finance and Administration) ",
            "Presenter": "Steven Dew, Provost and Vice-President (Academic) ",
            "Description": " N/A",
            "Participation": [
                "Deans ",
                "Vice-Provosts ",
                "Associate Vice-Presidents ",
                "President’s Executive Committee ",
                "Budget Model Technical Working Group "
            ],
            "Approval Route": [
                "GFC Academic Planning Committee – June 14, 2017",
                "GFC Executive Committee (for information) – September 11, 2017",
                "General Faculties Council – September 25, 2017",
                "Board Finance and Properties Committee – September 26, 2017",
                "Board of Governors – October 20, 2017"
            ],
            "Final Approver": " Board of Governors"
        },
        {
            "Item No.": "13",
            "Agenda Title": "Draft Agenda for the September 25, 2017 Meeting of General Faculties Council (GFC) ",
            "Motion": "THAT the GFC Executive Committee approve, under delegated authority from General Faculties Council, the Agenda for the September 25, 2017 meeting of General Faculties Council (GFC), as set forth in Attachment 1. ",
            "Action Requested": "Approval",
            "Date": "2017-09-11",
            "Committee": "EXEC",
            "Proposed By": "David Turpin, President and Chair, GFC Executive Committee ",
            "Presenter": "David Turpin, President and Chair, GFC Executive Committee ",
            "Description": "Purpose of the Proposal: To approve the agenda of GFC for the meeting of September 25, 2017. Discussion: Members suggested an editorial amendment to the agenda, and a member suggested that a short briefing document be provided in support of the update on the budget.",
            "Participation": [
                "David Turpin, President and Vice-Chancellor and Chair, GFC Executive Committee; Office of the President; Office of the Provost and Vice-President (Academic); University Governance; GFC Executive Committee "
            ],
            "Approval Route": [
                "GFC Executive Committee – September 11, 2017"
            ],
            "Final Approver": " GFC Executive Committee"
        }
    ],
    "url": "/static/EXEC/2017-09-11/Past-Meeting-Material.pdf",
    "content": "This agenda and its corresponding attachments are transitory records. University Governance is the official copy holder for files of the Board of \nGovernors, GFC, and their standing committees. Members are instructed to destroy this material following the meeting. \nEXECUTIVE COMMITTEE \nOPEN SESSION AGENDA \nGreen. Gold. Governance. \nMonday, September 11, 2017 \nCouncil Chamber, 2-100 University Hall \n2:00 PM - 4:00 PM \nOPENING SESSION                               \n1. Approval of the Agenda David Turpin \n2. Approval of the Open Session Minutes of June 12, 2017 David Turpin \n3. Comments from the Chair David Turpin \n4. Committee Kick-Off and Orientation 2017-2018 Marion Haggarty-France \nMeg Brolley \nDISCUSSION ITEMS  \n5. 5A. Goals from the Students Union (SU) 2017-2018  \n5B. Graduate Students' Association (GSA) Strategic Work Plan 2017-\n2018 \nMarina Banister  \nBabak Soltannia \n6. University of Alberta Senate Strategic Plan 2017-2021 Douglas Stollery \nACTION ITEMS  \n7. Proposed Changes to the University of Alberta Convocation Admission \nMotion: To Recommend General Faculties Council Approval \nDouglas Stollery \n8. Report of the GFC Committee on the Learning Environment (CLE) on \nTeaching and Learning Evaluation and the Use of the Universal \nStudent Ratings of Instruction (USRI) as an Evaluation Tool \nMotion: To Recommend General Faculties Council Approval \nSarah Forgie  \nNorma Nocente \n9. Faculty of Graduate Studies and Research: Proposed Revisions to \nexisting Supervision and Examinations policy \nMotion: To Recommend General Faculties Council Approval \nDeborah Burshtyn \nITEMS FROM GFC ACADEMIC PLANNING COMMITTEE FOR GFC \nAGENDA (for information only) \n10. Proposed Faculty Name Change: Faculty of Kinesiology, Sport, and \nRecreation (from Faculty of Physical Education and Recreation \n(FPER)) \nKerry Mummery \n11. Proposed Increase to Required English Language Proficiency (ELP) \nScores for Undergraduate Admission \nLisa Collins \nMelissa Padfield \nhttp://www.senate.ualberta.ca/en/%7E/media/senate/About/Docs/2017-2021_Senate_Strategic_Plan-V5-Spreads_drb.pdf\nGFC Executive Committee 09/11/2017 \nPage 2 \n12. Budget Model Principles  \nACTION ITEMS  \n13. Draft Agenda for the Next Meeting of General Faculties Council \nMotion: To Approve with Delegated Authority \nDavid Turpin \nDISCUSSION ITEMS  \n14. Question Period David Turpin \nINFORMATION REPORTS  \n15. Items Approved by the GFC Executive Committee by email ballots  \n- Changes to School of Public Health Dean Selection Committee \ncomposition (email of June 26, 2017) \n16. Information Items Forwarded to GFC Executive Committee between \nMeetings - no items to date \nCLOSING SESSION  \n17. Next Meeting of the GFC Executive Committee: October 15, 2107  \n18. Next Meeting of General Faculties Council: September 25, 2017  \nPresenter(s):                               \nDavid Turpin President and Vice-Chancellor \nMarion Haggarty-France University Secretary \nMeg Brolley Secretary to GFC and Manager of GFC Services \nMarina Banister President, Students’ Union \nBabak Soltannia President, Graduate Students’ Association \nDouglas Stollery Chancellor \nSarah Forgie Chair of GFC Committee on the Learning Environment, and Vice-Provost (Learning Initiatives) \nNorma Nocente Associate Professor, University of Alberta \nDeborah Burshtyn Vice-Dean, Faculty of Graduate Studies and Research \nLisa Collins Vice-Provost and University Registrar \nSteven Dew Provost and Vice-President (Academic) \nDocumentation was before members unless otherwise noted. \nMeeting REGRETS to: Andrea Patrick,  \nPrepared by: Meg Brolley, Coordinator, GFC Executive Committee \nUniversity Governance www.governance.ualberta.ca \nhttp://www.uofaweb.ualberta.ca/governance/\nItem No. 4 \nGFC EXECUTIVE COMMITTEE \nFor the Meeting of September 11, 2017 \nOUTLINE OF ISSUE \n Discussion Item  \nAgenda Title: Committee Kick-Off and Orientation 2017-2018 \nItem   \nProposed by University Governance \nPresenters Marion Haggarty France, University Secretary \nMeg Brolley, GFC Secretary \nDetails \nResponsibility General Faculties Council \nThe Purpose of the item is \n(please be specific) \nTo provide committee members with an overview of the principles under \nwhich GFC operates and how these inform the work and functioning of \nthe committee. \nTo orient members to the committee’s mandate, terms of reference, \nprocedures and to committee member roles and responsibilities. \nTimeline/Implementation Date N/A \nSupplementary Notes and \ncontext \nEngagement and Routing (Include meeting dates) \nParticipation: \n(parties who have seen the \nproposal and in what capacity) Those who are actively participating: \n• GFC Executive Committee \nAlignment/Compliance \nAlignment with Guiding \nDocuments \nFor the Public Good \nObjective 21 \nEncourage continuous improvement in administrative, governance, \nplanning and stewardship systems, procedures, and policies that \nenable students, faculty, staff, and the institutions as a whole to \nachieve shared strategic goals. \nReport of the ad hoc Committee on Academic Governance \nIncluding Delegated Authority (April 21, 2017) \nOrientation and Education \n“Orientation sessions should provide both high level governance \ninformation and detailed information on the responsibilities of members, \nvoting protocol, seating, how meetings are structured, question period \nprocedures, how members can report back to their constituencies, and \nhow to get items on the agenda. It is important to recognize that \ncommittee orientation must be designed in light of the fact that those at-\nlarge members who do not sit on GFC may require additional attention. \nThe ad hoc committee recommends that orientation and orientation \nItem No. 4 \nGFC EXECUTIVE COMMITTEE \nFor the Meeting of September 11, 2017 \nmaterials should be provided in a number of modes and formats, \nincluding stand-alone orientation workshops, briefings at meetings, and \nthrough widely available written and online materials. A GFC member \nhandbook or guidebook would be an ideal reference tool. In light of the \nunique character of collegial academic governance, GFC members \nshould be encouraged to use orientation sessions to meet and get to \nknow their fellow members and create networks which can provide \ninformal support and community building opportunities. The following \nrecommendations focus on improving orientation to prepare GFC and \ncommittee members to be informed and active participants in academic \ngovernance. \nRecommendation: THAT a variety of orientation sessions be offered \nincluding a general orientation to governance (Governance 101), \nfollowed by orientations more specific to GFC and GFC standing \ncommittees, and follow up sessions through the year \nRecommendation: THAT the responsibilities of members be clearly \noutlined in a core GFC document” \nCompliance with Legislation, \nPolicy and/or Procedure \nRelevant to the Proposal \n(please quote legislation and \ninclude identifying section \nnumbers) \n1. Post-Secondary Learning Act (PSLA) \n“Powers of general faculties council” \n26(1)Subject to the authority of the board, a general faculties council is \nresponsible for the academic affairs of the university” \nAttachments: \n1. GFC Principles for Delegation of Authority \n2. GFC Principles for Standing Committee Composition \n3. GFC Roles and Responsibilities of Members \n4. GFC Meeting Procedural Rules \n5. Current Committee Terms of Reference \nPrepared by: University Governance \n1 of 2 \nGENERAL FACULTIES COUNCIL \nPrinciples of Delegation \nPrinciples for General Faculties Council Delegation of Authority \nIntroduction \nGovernance is understood as the process through which an organization defines and achieves \nits mandate, which includes making decisions with regard to the structures, policies, and \npractices of decision-making; the exercise of authority; and the mechanisms of accountability.  \nGeneral Faculties Council (GFC) has employed a structure that relies upon the delegation of its \nprovincially-mandated authorities to its standing committees, individuals on campus and other \ncampus bodies.  Delegation is essential to ensure timely and efficient decision-making in \nsmaller forums with access to appropriate resource people, while allowing GFC to focus on \nsubstantive and strategic issues of broad relevance to the university community.  The following \noffers guidance to this delegation structure and helps maintain accountability, transparency, and \ncollegiality in the academic governance system at the University of Alberta. \nRetained Authority \nGeneral Faculties Council shall pursue major policy and strategic issues that include: \n● significant strategic and policy issues related to the academic affairs of the university;\n● any matter involving the alteration of the mandate, terms of reference, membership, or\nstructure of a GFC standing committee; and\n● those matters that a standing committee, body, or officer holding delegated authority\nfrom GFC considers to be of major strategic significance or long-term impact on the\nuniversity.\nPrinciples \n1. Delegations of authority must be reasonable in scope and appropriate to the character and\ncapacity of the body (e.g. council or committee) or officer receiving the delegated authority. \n2. An officer or body acting with delegated authority is accountable to the body which\ndelegated the authority and must report to that body in a timely and sufficiently detailed\nfashion on actions taken under the delegated authority.\n3. An officer or body is responsible to be alert to situations where, for example, there is\nuncertainty as to whether an item falls within the intended delegation or the significance of\nan issue and the division of opinion on the issue suggest it is prudent to refer the issue or\ndecision to the delegating body for consideration. When there is uncertainty as to whether\nan item falls within the intended delegated authority, or if there is clear division of opinion,\nthe officer or body with delegated authority will refer the item to the body that delegated the\nauthority along with a recommendation.\n4. Delegations should be recorded in written form and curated in a transparent manner.\n2 of 2 \nGENERAL FACULTIES COUNCIL \nPrinciples of Delegation \n 5. A body delegating authority may impose restrictions on that authority -- including restrictions \non the authority to sub-delegate -- so long as the restrictions allow sufficient authority for the \ndelegation to be meaningful. \n6. All delegations of authority should be reviewed at regular intervals (ideally once every three \nyears) to ensure they remain appropriate. \n7. Withdrawal of delegated authority should be considered judiciously based on the best \ninterest of the institution and cannot be done retroactively. \n8. An officer or body is not compelled to exercise delegations. The fact that a delegation is held \ndoes not oblige the officer or body to exercise the delegation if, in the opinion of the \ndelegate, some special or unusual circumstances are involved which make it sensible that \nthe issue should receive consideration at a more senior level. \nApproved by General Faculties Council: April 21, 2017 \n1 of 1 \nGENERAL FACULTIES COUNCIL \nPrinciples of Committee Composition \nPrinciples for General Faculties Council Standing Committee Composition \nIntroduction \nGovernance at the University of Alberta relies upon a structure wherein the General Faculties \nCouncil has delegated many of its provincially-mandated authorities to its standing committees.  \nAs such, the composition of those standing committees is crucial to ensuring that decisions are \nmade in an informed manner that takes into account the breadth of issues, perspectives and \nopinions on campus.  The following principles provide a framework to create committee \ncompositions which are reflective of the membership of GFC and appropriate to the role and \nmandate of those committees.  \nPrinciples \n1. Wherever possible, the majority of elected members of each standing committee should be\ndrawn from the membership of GFC to provide tangible links between GFC and its standing\ncommittees and increase engagement of the greater GFC community.\n2. Wherever possible, the number of elected members of a standing committee should exceed\nthe number of ex-officio members.\n3. The voting status of ex-officio members of standing committees should be consistent with\ntheir voting status on GFC and should extend to their delegates.\n4. Ex-officio members should be included in the membership of a standing committee only\nwhen their portfolio is directly relevant to the mandate and role of the standing committee.\n5. Wherever possible, the Vice-Chair of a standing committee should be elected by the\ncommittee from its elected academic staff members and ideally be a member of GFC.\n6. Standing Committees should be populated with a commitment to diversity and broad\nrepresentation from across the university.\n7. When cross-appointment of members on standing committees is appropriate, this should be\noutlined in the terms of reference of each committee and such members shall have voting\nstatus on both committees.\nApproved by General Faculties Council: April 21, 2017 \n1 of 2 \nGENERAL FACULTIES COUNCIL \nRoles and Responsibilities of Members \nRoles and Responsibilities of Members \nIntroduction \nGeneral Faculties Council (GFC) is the principal academic decision-making body of the \nuniversity. It is established in the Post-Secondary Learning Act (PSLA) and given authority, \nsubject to the Board of Governors, over the academic affairs of the university. \nFor GFC to be successful in fulfilling its terms of reference and meeting its responsibilities to the \nuniversity it depends on the active engagement of its members. GFC has delegated much of its \nauthority for routine matters to standing committees allowing GFC to engage in high level \nstrategic and stewardship policy issues. GFC members have the opportunity to serve on the \nstanding committees that approve matters with the delegated authority from GFC.  \nGFC operates under the principle of collegial academic governance including: \n• A commitment to inclusive and participatory governance decision-making\n• A desire to facilitate meaningful individual-level engagement in governance processes\n• A commitment to openness, transparency, and respectful communication\n• A commitment to responsiveness, respect, and reciprocity between governing bodies\nand between governing bodies and university administration\nRoles and Responsibilities of Members \n1. Understand GFC\n1.1 Members should understand that not all matters under GFC jurisdiction will come\nbefore that body for approval. Some decisions are made at the standing committee \nlevel as GFC has delegated authority to approve and report on actions taken on certain \nmatters.   \n1.2 The university operates in a bicameral governance system. Members should \nunderstand the distinction between the role and responsibilities of GFC and the Board \nof Governors. \n2. Meeting Attendance\n2.1 Members have a responsibility to attend GFC meetings.\na. If a student misses two consecutive meetings, or more than three meetings in one\nacademic year, the Students’ Union or the Graduate Students’ Association may\nrequest that the Chair declare the position vacant.\nb. If a Faculty representative or a non-student member misses two consecutive\nmeetings or more than three meetings in one academic year without a reason\nsatisfactory to the members of the GFC Executive Committee, the Executive\nCommittee shall declare the position vacant.\n2.2 Members have a responsibility to serve on GFC committees as appropriate and attend \ncommittee meetings. \na. If an elected member is absent from three consecutive meetings or is frequently\nabsent without a reason satisfactory to the remaining members of the committee, the \nChair shall declare the position vacant. \n2 of 2 \nGENERAL FACULTIES COUNCIL \nRoles and Responsibilities of Members \n2.3 Members should advise the GFC Secretary or committee coordinator if they are unable \nto attend a meeting. \n3.  Participate in GFC Business \n3.1 Members should prepare for meetings by reviewing agenda materials in advance that, \nfor open sessions, are publicly available at governance.ualberta.ca \n 3.2 Members should engage in candid and respectful discussion of matters which are \nbrought before GFC and its various bodies  \n3.3 When voting on motions: \na. Members must act in good faith with the view to the best interests of the university as \na whole. While members may be informed by matters raised by various \nconstituencies, it is the duty of a member to ensure that all constituencies are fairly \nconsidered in the process of decision making.  \nb. When notified of an e-vote, members should vote in a timely manner in order to \nensure that quorum requirements are met.  \n4.  Manage Conflict of Interest and Act Ethically \n4.1 Comply with the university’s policies and procedures regarding both ethical conduct and \nconflict of interest.  Members must declare conflicts when they arise.  \n4.2 Maintain confidentiality of all information included in closed session meetings.  \n5.  Ask Questions \n5.1 Information requests may be made of the University Governance office, should \nmembers require more information than is provided with the meeting agenda. \n5.2 If a member wishes to raise a question at GFC within the jurisdiction of the body, a \nquestion may be submitted in writing to the GFC Secretary up to six working days \nbefore the next GFC meeting to receive a written response. \n5.3 Every GFC meeting has Question Period as a standing item wherein members may \nraise a question during the time set aside for this item. Procedures for Question Period \nare available at governance.ualberta.ca \n5.4 If a member has a question with regard to an item on the agenda, it may be raised \nduring consideration of that item at the GFC meeting. \n5.5 If a member wishes to add an item to the agenda for debate, the member should \ncontact the Chair or GFC Secretary for assistance. \n6.  Communicate Information to Constituents \n6.1 Members should communicate with their Faculty or constituency regarding agenda \nitems coming before GFC.  \n6.2 Members should communicate with their Faculty or constituency on matters which were \ndiscussed/approved at GFC in Open Session. \nApproved at General Faculties Council:  April 21, 2017 \nhttp://www.governance.ualberta.ca/\nhttps://policiesonline.ualberta.ca/PoliciesProcedures/Policies/Ethical-Conduct-and-Safe-Disclosure-Policy.pdf\nhttps://policiesonline.ualberta.ca/PoliciesProcedures/Policies/Conflict-Policy--Conflict-of-Interest-and-Commitment-and-Institutional-Conflict.pdf\nhttp://www.governance.ualberta.ca/GeneralFacultiesCouncil/%7E/media/Governance/Documents/GO05/GEN/Linked%20Documents%20on%20GFC%20Home%20Page/Question-Period-Excerpt-from-the-2006-GFC-PM.pdf\nhttp://www.governance.ualberta.ca/GeneralFacultiesCouncil/%7E/media/Governance/Documents/GO05/GEN/Linked%20Documents%20on%20GFC%20Home%20Page/Question-Period-Excerpt-from-the-2006-GFC-PM.pdf\n1 of 6 \nGENERAL FACULTIES COUNCIL \nMeeting Procedural Rules  \nMeeting Procedural Rules \n Introduction \nGeneral Faculties Council (GFC) has on many occasions confirmed its commitment to having a \nset of rules that assist rather than impede the conduct of business. GFC rules are not meant to \nunduly restrict debate or limit opportunities for participation. Their purpose is to facilitate \ninclusive and respectful dialogue, while ensuring efficient decision-making. It is the responsibility \nof the Chair, with the support of GFC, to employ the rules governing general meetings in a \nmanner consistent with these principles. Substantive motions should be handled with \nconsiderable formality, but whenever possible the Chair should deal with matters of procedure \nby general agreement. \nThe following rules and procedures are based on a number of fundamental principles that \nencourage participation and engagement of members. These principles include: \n• A commitment to inclusive and participatory decision-making. \n• A commitment to openness, transparency and respectful communication. \n1.  Procedural Rules  \n1.1  GFC and its standing committees are governed by the procedural rules set out below. \nFor matters not covered by these rules, or by the Post Secondary Learning Act (PSLA) \nreference shall be made to the current edition of Robert's Rules of Order. If this does \nnot provide clear direction regarding a point in question, then the Chair shall decide \nhow to proceed. However, such rulings by the Chair may be overruled via a motion \nsupported by a vote of the majority of those present.  \n1.2  The chairs of GFC and its standing committees will be responsible for guiding \nmeetings of GFC and its standing committees, enforcing rules, and deciding questions \npertaining to those rules. Any decisions of the chair are subject to challenge (see \n10.3). \n1.3 The Chair will not participate actively in debate regarding a motion before GFC without \npassing the role of the Chair to the Vice-Chair for the duration of the debate and the \nsubsequent vote.  \n2. Meetings \n 2.1 GFC and its standing committees shall meet regularly during the academic year, the \nschedule of which will be published on the governance website at least one month \nbefore the beginning of each academic year. GFC meetings will not be scheduled \nduring the period set aside for final examinations or Reading Week, however \ncommittee meetings may occur during this time. \n 2.2 Cancellation - GFC Executive Committee may cancel a meeting of GFC if it \ndetermines that the number and nature of the agenda items make it reasonable to \ndefer consideration, and provided that notice of such cancellation is given to members \nat least one week prior to the date of the meeting. The Chair of a GFC standing \ncommittee may cancel a meeting if the agenda items make it reasonable to defer \n2 of 6 \nGENERAL FACULTIES COUNCIL \nMeeting Procedural Rules   \nconsideration, and provided that notice of such cancellation is given to members as \nearly as possible.  \n 2.3  From time to time, the Chair of GFC may call special meetings of GFC, provided that \nnotice of such meetings is given to members at least one month in advance.  \n 2.4 GFC meetings shall normally be scheduled and planned to end two hours after being \ncalled to order. \n 2.5 Debate on new items of business will not be entertained after GFC has been sitting for \nthree hours.  \n 2.6 No audio or video recording of meetings shall be permitted unless by express authority \nof the Chair. \n3. Open Sessions \n 3.1 Meetings of GFC and its standing committees are normally held in open session, with \nthe exception of those dealing with nominations and adjudication which are always \nheld in closed session. \n 3.2 Subject to the limitations of space and orderly conduct as determined by the chair, \nmembers of the university community and the general public may attend open \nmeetings as observers. Observers may only speak if expressly invited to do so by the \nChair.  \n4. Closed Sessions \n 4.1 From time to time, GFC or its committees may hold meetings or portions of meetings \nas closed meetings; at that point, proceedings will be confidential and all non-\nmembers, except those specifically invited, will be asked to withdraw. \n5.  Questions  \n5.1  If more information than is provided as part of the meeting agenda is required, \ninformation requests may be made of the University Governance office. \n5.2  Questions on an issue within GFC’s jurisdiction may be submitted in writing to the GFC \nSecretary up to six working days before the next GFC meeting to receive a written \nresponse. \n5.3  Every GFC meeting has Question Period as a standing item wherein members may \nraise a question during the time set aside for this item (see 6.5). Procedures for \nQuestion Period are available at governance.ualberta.ca \n5.4  Questions with regard to a specific item on an agenda may be raised during \nconsideration of that item at the GFC meeting. \n6.  Agendas \n 6.1  The agenda of each GFC meeting will be proposed by the GFC Executive Committee \nand approved by GFC. The GFC Executive Committee will ensure that items put \nbefore GFC are complete and ready for discussion and published in advance of the \nmeeting.  \nhttp://www.governance.ualberta.ca/GeneralFacultiesCouncil/%7E/media/Governance/Documents/GO05/GEN/Linked%20Documents%20on%20GFC%20Home%20Page/Question-Period-Excerpt-from-the-2006-GFC-PM.pdf\n3 of 6 \nGENERAL FACULTIES COUNCIL \nMeeting Procedural Rules   \n 6.2 If GFC members want to have an issue debated, they are asked to submit the issue to \nthe GFC Executive Committee. Whenever possible, members wishing to add items to \nthe agenda should contact the Chair or GFC Secretary two weeks in advance of the \nGFC Executive Committee meeting to allow time for the item to be added to the \nagenda. \n 6.3 Should a member wish to add an item to the agenda at a meeting of GFC, a two-thirds \nvote of those present is required; the Chair will then determine where the item appears \non the agenda. In cases where the Chair or GFC Secretary has been informed in \nadvance of a planned request to add a new item, but after the agenda has been \npublished, the proposal shall be circulated to members through the normal means. \n 6.4 When the Agenda is being approved, the Chair will entertain a request to change the \norder of items, for specified reasons.  \n 6.5 Each agenda of GFC and its standing committees will include Question Period of one \nhalf hour in length that may be extended with the approval of members.  \na. Question period is comprised of both written questions and, time permitting, \nquestions from the floor.   \nb. The Chair will rule on whether a question from the floor can be answered \nexpeditiously; if not, it will be referred to the appropriate officer for response at the \nnext meeting.  \n 6.6 Reports from standing committees are included on the GFC agenda for information \nonly. Questions may be asked for clarification, but no debate may take place on such \nitems. \n 6.7 Reports for Information may be moved to the discussion part of the agenda if a \nmember gives two days notice to the GFC Secretary to ensure that an appropriate \nperson is present to answer questions that may arise during discussion.  \n 6.8   Agendas and materials for open session meetings are posted at \ngovernance.ualberta.ca \n7. Quorum  \n 7.1 General Faculties Council -  The quorum for a GFC meeting is one-third of the total \nmembership, except in the months of May through August when the quorum shall be \none-quarter of the total membership.  \n 7.2 GFC Standing Committees – The quorum for standing committee meetings is one-half \nof the voting members or, in the case where this is an even number, one-half plus 1 \nmember.  \n 7.3 Vacancies on committees are not included when establishing quorum. \n 7.4 Maintaining quorum - A duly-called meeting which starts with a quorum present shall \nbe deemed to have a continuing quorum, notwithstanding the departure of voting \nmembers, unless the quorum is challenged by a voting member. In the event of a \nchallenge, the remaining members may choose to adjourn or continue the meeting. In \nhttp://www.governance.ualberta.ca/en/GeneralFacultiesCouncil.aspx\n4 of 6 \nGENERAL FACULTIES COUNCIL \nMeeting Procedural Rules   \nthe event of a decision to continue a meeting without quorum, the minutes shall record \nthis fact and any decisions taken must be ratified at the next meeting.  \n8. Motions \n 8.1 Normally, all motions concerning substantive matters shall be published in the agenda \nmaterials. \n 8.2 All motions must be moved and seconded by members of GFC.  Motions to appoint \nnew members may only be moved and seconded by statutory members of GFC. \n 8.3 Motions pass with a majority vote, except for the following: (1) motions to add an item \nto the agenda require a two-thirds majority of those present; (2) motions to rescind a \nmotion require a two-thirds majority of total members. \n 8.4 To make a motion, a member must be recognized by the Chair. (In the interest of \nclarity and to expedite business, it is advisable to provide a written motion to the GFC \nSecretary). The person making a motion will be invited by the Chair to speak first in \nany ensuing debate. \n 8.5 Amendments to Motions - A member may make a motion to amend the wording – \nand within certain limits the meaning – of a pending motion before the pending motion \nitself is voted upon. The amendment must be germane and cannot be used to \nintroduce a new subject. An amendment is debatable. \n 8.6 Motion to Adjourn - A motion to adjourn is a motion to close the meeting. It must be \nseconded, is not debatable or amendable, and typically requires a simple majority \nvote. During the months of March and April, motions to adjourn require a two-thirds \nmajority if substantive items of business remain on the agenda.  \n 8.7 During the course of a GFC meeting, members may make a Notice of Motion for \ndebate at the next GFC meeting. In such cases GFC Executive will be responsible for \nplacement of the motion on the next GFC agenda. \n9. Motions for Specific Purposes \n 9.1 Motion to Table – Enables the pending question to be laid aside until some future \ntime. The motion cannot be debated. The mover may make a statement regarding \nwhat information they believe would be required to remove the item from the table, and \nthe proposer of the item may make a brief comment on the impact of tabling the \nmotion.  \n 9.2 Motion to Take From the Table – Brings the motion back before GFC and cannot be \ndebated. \n. \n 9.3 Motion to Reconsider an item which was voted upon at the current or the last \nmeeting. If passed, proceedings are restored to the point immediately prior to the vote \nto which it applies. \n 9.4 Motion to Rescind a Motion is only used when a Motion to Reconsider is out of time. \nMotions to Rescind require support of two-thirds of the total membership if no Notice of \nMotion was given, but only a simple majority if Notice was given.  \n5 of 6 \nGENERAL FACULTIES COUNCIL \nMeeting Procedural Rules   \n10. Debate \n 10.1  Normally, a member may not speak for a second time until the Chair is satisfied that all \nmembers wishing to speak for their first time have done so. \n 10.2  A member who has the floor may not normally be interrupted. However, the Chair may \ninterrupt a speaker if the speaker is out of order by using unacceptable language, is \nabusive of other members, or is not speaking to the motion. If the Chair does not do \nso, a member may raise this as a point of order.  \n 10.3  Point of Order - It is the right of any member who notices a breach of the rules of \nCouncil to insist on their enforcement. If the Chair fails to notice such a breach, any \nmember may make the appropriate Point of Order, calling on the Chair for a ruling. A \nPoint of Order does not require a seconder, it is not debatable or amendable, and \ncannot be reconsidered.  \n 10.4  Calling the Question - Upon hearing a member call the question, the Chair will ask \nmembers if they are ready to vote on the motion being discussed. If there appears to \nbe opposition to closing the debate, the Chair may ask for a motion to close debate. If \nseconded, members will then vote on this motion and proceed accordingly.  \n11. Debates without Motions \n11.1  When discussion of an issue and the formal rules pertaining to making motions, \ndebate, and voting seem to be a hindrance to thoughtful discussion, the GFC agenda \ncan allow for a less structured discussion guided by the Chair and the consensus of \nthe members in attendance.  \n12. Attendance  \n 12.1 Delegates – members who serve on GFC or its standing committees by virtue of their \noffice may send a delegate; such delegates shall act with all the rights of membership.  \nThere shall be no alternates for other members. \n 12.2 GFC attendance - If a student misses two consecutive meetings or more than three \nmeetings, the Students’ Union or the Graduate Students’ Association may request that \nthe Chair declare the position vacant. If a faculty representative or a non-student \nappointed member misses two consecutive meetings or more than three meetings in \none academic year without a reason satisfactory to the members of the GFC Executive \nCommittee, the Executive Committee may declare the position vacant.  \n 12.3 Standing committee attendance - If an elected member is absent from three \nconsecutive meetings or is frequently absent without a reason satisfactory to the \nremaining members of the Committee, the Chair shall declare the position vacant.  \n13. Voting  \n 13.1 All members of GFC are charged with the responsibility of examining issues before \nCouncil and voting as they judge fit on such issues. No member of GFC, regardless of \nhow that person gains membership on Council, is an instructed delegate. \n 13.2 Motions shall normally be adopted on a simple majority of members present except to \nadd items to the agenda which requires a two-thirds majority of those present, or for a \nMotion to Rescind which requires a two-thirds majority vote of total membership. \n6 of 6 \nGENERAL FACULTIES COUNCIL \nMeeting Procedural Rules   \n 13.3  An abstention is not considered to be a vote cast.  \n 13.4 The Chair votes only in the instance of a tie. When there is a tie vote, the motion is lost \nif the Chair abstains.  \n 13.5 All members may participate in discussions; only voting members may move, second \nand vote on motions.  \n 13.6 Electronic Votes by Committees – In cases where extensive deliberation is not \nessential to determining a course of action and it is necessary for a business item to \nbe decided before the next scheduled meeting, the Chair and Secretary of a GFC \nstanding committee may hold an electronic vote. The motion will be duly moved and \nseconded and all normal procedures will be followed in conducting the e-mail ballot. \nHowever, upon receiving the item of business and ballot, any committee member may \nrequest that the matter be debated at the next meeting or at a special meeting and the \nvote delayed until after that debate, with the Chair determining the appropriate course \nof action.  \n 13.7 Electronic Votes by GFC – In cases where GFC is the electing body to populate \ncertain selection committees and other bodies, the election process may use e-vote \nmechanisms. \n 13.8 Electronic Approval of Committee Reports by GFC – Reports from the Nominating and \nReplenishment Committees may be distributed electronically to GFC members and are \nconsidered approved by the deadlines indicated on the report subject to receipt of \nadditional nominations.   \n14. Records of Proceedings \n 14.1 Official Record – The official record of meetings of GFC shall be the minutes taken by \nthe Secretary and approved by GFC. \n 14.2 Minutes – The minutes shall reflect the decisions made and reasons for the decision.  \n15. Amendment of these Rules and Procedures \nRules and procedures governing meetings of General Faculties Council may be amended \nby a majority vote of those present and voting at a duly constituted meeting of GFC, \nprovided that notice of the proposed amendment has been given and that a quorum is \npresent at the time the vote is taken.  Rules are reviewed every three years. \n16. Links \nGFC terms of reference \nQuestion period procedures \nApproved by General Faculties Council: April 21, 2017 \n1 \nGFC Executive Committee Terms of Reference \n1. Authority \nThe Post-Secondary Learning Act (PSLA) gives General Faculties Council (GFC) responsibility, subject \nto the authority of the Board of Governors, over \"academic affairs\" (section 26(1)). GFC has established \nan Executive Committee. The items referred to in subsections (d) (e) (g) and (j) of Section 26(l) of the \nAct are delegated to the Executive Committee. (GFC 08 SEP 1966) \nThe complete wording of the section(s) of the PSLA, as referred to above, should be checked in any \ninstance where formal jurisdiction needs to be determined. \n2. Composition of the Committee  \nEx Officio  \n-Chair - The President \n- Provost and Vice-President (Academic) \n- Vice-Provost and University Registrar \n- Graduate Students' Association Vice-President (Academic)  \n- Students' Union Vice-President (Academic) \nElected  (to be elected from and by GFC) \n- 8 members from Categories A1.1 and A1.6 and their counterparts in A1.5 and A1.7*, providing that \nthere shall be no more than one representative from any Faculty except that both the Faculty of Arts \nand the Faculty of Science may have two representatives providing they come from different \nDepartments. \n- 1 undergraduate student  \n* See UAPPOL Recruitment Policy (Appendix A) Definition and Categories of Academic Staff. \n3. Mandate of the Committee \nTo act as the executive body of General Faculties Council and, in general, carry out the functions \ndelegated to it by General Faculties Council. (GFC 08 SEP 1966) (GFC 12 FEB 1996)  \n1. Urgent Matters  \nThe power to deal with any matters that cannot be deferred is delegated to the Executive \nCommittee which shall determine which matters are to be considered urgent. (GFC 09 AUG \n1966) \n2. Routine Matters  \nMatters which are routine in carrying out the policies approved by General Faculties Council are \ndelegated to the Executive Committee. (GFC 08 SEP 1966) \n3. Academic Awards \nResponsibility, as it concerns all students other than graduate students registered in the Faculty \nof Graduate Studies and Research, for making rules and regulations respecting academic \nawards shall be delegated by General Faculties Council to the Executive Committee. (GFC 02 \nDEC 1966) \n4. Academic Schedule \na. Delegation \nPost-Secondary Learning Act (PSLA) Section 26(l)(j) follows: \n26(1) Subject to the authority of the board, a general faculties council is responsible for \nthe academic affairs of the university and, without restricting the generality of the \nforegoing, has the authority to… \n2 \n(j) determine the date for the beginning and end of lectures in the university and also the \nbeginning and end of each university term…. \nb. Academic Schedule Changes \nThe GFC Executive Committee has delegated authority from General Faculties Council \nto approve the Academic Schedule.  Any changes to the Academic Schedule proposed \nafter the Schedule has been approved must be submitted to the Executive Committee.  \nThat committee will determine which changes are sufficiently substantial and require, \ntherefore, GFC approval and which ones are routine in nature and could be dealt with by \nthe Executive Committee. (GFC 20 SEP 1982) \n5. Agendas of General Faculties Council  \nGFC has delegated to the Executive Committee the authority to decide which items are placed \non a GFC Agenda, and the order in which those agenda items appear on each GFC agenda.   \nWhen ordering items, the GFC Executive Committee will be mindful of any matters that are of \nparticular concern to students during March and April so that the student leaders who bring \nthose items forward are able to address these items at GFC before their terms end.  (EXEC 06 \nNOV 2006) \nWhen recommendations are forwarded to General Faculties Council from APC, the role of the \nExecutive shall be to decide the order in which items should be considered by GFC.  The \nExecutive Committee is responsible for providing general advice to the Chair about proposals \nbeing forwarded from APC to GFC. \nWith respect to recommendations from other bodies and other GFC committees, however, the \nrole of the Executive Committee shall be to examine and debate the substance of reports or \nrecommendations and to decide if an item is ready to be forwarded to the full governing body.  \nThe Executive Committee may decide to refer a proposal back to the originating body, to refer \nthe proposal to another body or individual for study or review, or to take other action in order to \nready a proposal for consideration by General Faculties Council.  When the GFC Executive \nCommittee forwards a proposal to GFC, it shall make a recommendation that GFC endorse; \nendorse with suggested amendments; not endorse; or forward the proposal with no comment. \n(GFC 30 JUN 1992) \n6. Calendar  \nSection 26(1) of the PSLA empowers GFC to  \n(g) provide for the preparation and publication of the university calendar. \n(Technical matters relating to the printing and publication of the Calendar are delegated to the \nRegistrar (GFC May 31, 1976).   \n7. Examinations  \nSection 26(1) of the PSLA empowers GFC to \n(d) determine the timetables for examinations, and for lectures and other instruction in \neach Faculty. \n3 \n(e) consider and make decisions on the reports of faculty councils as to the appointment \nof examiners and the conduct and results of examinations in the faculties. \na. Subject to challenge by General Faculties Council, the Executive Committee has accorded to \nFaculty Councils the authority to deal with special arrangements regarding final examinations. \n(EXEC 15 FEB 1967) \nb. The Executive Committee approves requests from Faculties which wish to schedule common \nexaminations (See Section 52.8 of the GFC Policy Manual). (GFC 27 OCT 1980)  \n8. Faculty Councils  \na. Appointments to Faculty Councils \nThe Executive Committee of General Faculties Council shall be authorized to make \nappointments to Faculty Councils on their recommendations. (GFC 25 NOV 1968) \nWith respect to appointments of external members to Faculty Councils, approval of the positions \nby the Executive Committee, on behalf of GFC, shall suffice. (GFC 28 JUN 1976) \nb. Control Functions re: Faculty Councils \nThe responsibility of exercising supervision of the control functions referred to in Sections 29 \nand 30 of the PSLA shall be delegated to the Executive Committee which shall make \nrecommendations to General Faculties Council when appropriate. (GFC 02 DEC 1966) \nPost-Secondary Learning Act Section 29(1) \nA faculty council may \n(a) determine the programs of study for which the faculty is established, \n(b) appoint the examiners for examinations in the faculty, conduct the examinations and \ndetermine the results of them, \n(c) provide for the admission of students to the faculty, \n(d) determine the conditions under which a student must withdraw from or may continue \nthe student's program of studies in the faculty, and \n(e)authorize the granting of degrees, \nsubject to any conditions or restrictions that are imposed by the general faculties council. \nc. Quorum \nSubject to the approval of the GFC Executive Committee, each Faculty shall establish its own \nFaculty Council quorum provision(s), on the understanding that nothing in those provisions shall \ntake away from those persons eligible to attend their right to do so.  In the summer (ie, the \nmonths of May through August), the members of the Faculty Council who are available shall \nhave power to deal with matters that arise. (EXEC 09 SEP 2002) \n9. Student Records:  Requests for Access for Research Purposes  \nThe Policy on Student Records: Contents, Access, Use and Protection of the GFC Policy \nManual was approved by the Board of Governors on January 26, 2007 for inclusion in the \nUniversity of Alberta Policies and Procedures On-Line (UAPPOL). \n4 \n10. Access to Information Held by GFC Standing Committees  \nWhere a GFC Standing Committee does not accede to a request for access to specified \nmaterial in its hands, there shall be a right of appeal to the Executive Committee of GFC. A \nformal request may also be made for specified material through the University of Alberta's \nInformation and Privacy Office. (EXEC 30 AUG 1999)  \nA committee may, if it chooses, seek the advice of the Executive Committee on requests for \nrelease of information or refer requests for decision to the Executive Committee. (GFC 31 MAR \n1981) \n11. Student Residence Codes \nNew student residence codes shall be submitted to the GFC Campus Law Review Committee \nwhich will make a recommendation to the GFC Executive Committee. The GFC Executive has \nthe delegated authority from General Faculties Council to approve new residence codes. \nAny changes to existing student residence codes shall be submitted to the GFC Campus Law \nReview Committee. Any major changes to existing student residence codes shall be forwarded \nwith the recommendation of the CLRC to the GFC Executive for final approval.  \nAny student residence with a code or similar set of regulations is required to report annually on \nthe operation of that code to General Faculties Council through its Campus Law Review \nCommittee and its Executive Committee. (GFC 22 SEP 1997)  \n12. Membership on the GFC University Appeal Board (UAB), GFC Academic Appeals \nCommittee (AAC) and GFC Practice Review Board (PRB)  \nGFC delegates to the Executive Committee the authority to take whatever special measures are \nnecessary to ensure timely and fully-constituted hearings by the University Appeal Board (UAB), \nAcademic Appeals Committee (AAC) and Practice Review Board (PRB).  These measures may \ninclude, but are not limited to, the extension of terms of office and the appointment of additional \nmembers for a temporary period. (EXEC 10 MAY 1999)  (GFC 21 JUNE 1999) \n13. Course Challenges and Service Courses  \na. In cases where a challenge cannot be resolved … the Secretary to General Faculties Council \nshall … have the challenge placed before the Executive Committee of GFC for final resolution. \nIn those cases where the Executive Committee is of the opinion that a policy issue is involved, it \nwill place the issue before General Faculties Council. \nThe Executive Committee shall decide whether a course challenge is frivolous and an appeal \nfrom such a decision shall lie to General Faculties Council. \nb. If agreement is reached between a servicing and a serviced Faculty on a proposed \nwithdrawal of a service course, then approval need not be sought from General Faculties \nCouncil nor from the Executive Committee. \nIf agreement cannot be reached between the servicing and serviced Faculty on a proposed \nwithdrawal of a service course, the matter should be referred to the GFC Executive Committee.  \n5 \nIf the Executive Committee is unable to resolve the problem, the matter should be referred to \nGeneral Faculties Council. \n14. Course Numbering and Naming System  \na. Recommendations to renumber courses at the same level shall be proposed by the \nappropriate Faculty Council, circulated according to the procedures described in Section 37.1, \nand, in the absence of unresolved challenges, submitted to GFC Executive for ratification.  \nCourse renumbering to a different number level will normally be accomplished by deleting the \ncurrent course and introducing a new course at the new level. (GFC 17 JUN 1996) \nb. New course subject names and their abbreviations shall be proposed by the Faculty Council, \ncirculated according to the procedure described in Section 37.1, and, in the absence of \nunresolved challenges, submitted to GFC Executive for ratification. (GFC 17 JUN 1996) \nAlso see Section 37. \nFor appeals against decisions on program challenges, see Courses, Section 37.1.E. \n15. Terms of Office for GFC Members \nThe GFC Executive is authorized to specify, after consultation with the Faculty concerned, the \nterm of office of each elected member whose term has not been specified. (GFC 08 SEP 1966) \n16. Institutional Marking and Grading Policies and/or Procedures \nTo consider advice or recommendation from the GFC ASC on institutional marking and grading \npolicies and/or procedures. (GFC 31 MAY 2005) \n17. Institutional Term Work Policies and/or Procedures \nTo consider advice or recommendation from the GFC ASC on institutional term work policies \nand/or procedures. (GFC 31 MAY 2005) \n4. Committee Procedures \nAttendance  \nIt is expected that members will attend all meetings of the Executive Committee. If a member knows in \nadvance that an absence of two or more consecutive meetings is unavoidable, the Chair should be \nconsulted. (GFC 09 FEB 1981)  \nVoting \na. When Acting as an Executive Committee \nWhen dealing with matters specifically delegated to it by General Faculties Council, the Executive \nCommittee shall conform to the Voting procedures set out in the General Terms of Reference – \nStanding Committees of General Faculties Council (GFC).  \nb. When Acting for General Faculties Council \n6 \nWhen dealing with other matters on behalf of General Faculties Council, the Executive Committee shall \nbe authorized to take action providing the number of votes in favor of such action is greater than 50% of \nthe total number of members.  (On the basis of the present membership of fourteen (1992), eight votes \nin favor of a proposal would be sufficient.)  The Chair will have the right to cast a vote or abstain as the \nChair sees fit. (EXEC 20 SEP 1971) \n5. Additional Reporting Requirements \nExecutive Committee minutes shall be filed with GFC for information. (EXEC 06 NOV 2006)  \nR:\\GO04 General Faculties Council - General\\PRO\\TER\\EXE\\Executive-Committee-Amended.doc \nApproved November 26, 2007 (GFC) \nItem No. 5A \nGFC EXECUTIVE COMMITTEE \nFor the Meeting of September 11, 2017 \nOUTLINE OF ISSUE \nAdvice, Discussion, Information \nItem Agenda Title: Goals from the Students’ Union 2017-2018 \nItem  \nProposed by Marina Banister, President, Students’ Union \nPresenter Marina Banister, President, Students’ Union \nDetails \nResponsibility Graduate Students’ Association (GSA) \nThe Purpose of the item is \n(please be specific) \nTo brief the Board Learning and Development Committee, the GFC \nExecutive Committee, and General Faculties Council (GFC) on the SU \nExecutive Goals for 2017-2018. \nTimeline/Implementation Date Ongoing \nSupplementary Notes and \ncontext \nEngagement and Routing (Include meeting dates) \nParticipation: \n(parties who have seen the \nproposal and in what capacity) \n<For further information see \nthe link posted on the \nGovernance Toolkit section \nStudent Participation Protocol> \nThose who have been informed: \n GFC Executive Committee – September 11, 2017\n General Faculties Council – September 25, 2017\n Board Learning and Development Committee – September 29,\n2017 \nThose who have been consulted: \n \nThose who are actively participating: \n \nAlignment/Compliance \nAlignment with Guiding \nDocuments \nFor the Public Good \nGOAL: EXPERIENCE diverse and rewarding learning opportunities that \ninspire us, nurture our talents, expand our knowledge and skills, and \nenable our success. \nObjective 8: Create and facilitate co-curricular and extracurricular \nlearning experiences for undergraduate and graduate students that \nenable their self-discovery and give them the skills to use their talents, \ncreativity, and curiosity to contribute as future citizens and leaders.  \nStrategy iii: Support the roles of the Graduate Students’ Association and \nStudents’ Union, along with other student groups, in the promotion of \nextracurricular programs that create a sense of community and support \nthe learning environment. \nCompliance with Legislation, \nPolicy and/or Procedure \nRelevant to the Proposal \n1. Post-Secondary Learning Act (PSLA): The PSLA gives the Board\nof Governors the authority to “develop, manage and operate, alone\nor in co-operation with any person or organization, programs,\nhttp://www.governance.ualberta.ca/GovernanceToolkit/Toolkit.aspx\nhttp://www.governance.ualberta.ca/GovernanceToolkit/Toolkit.aspx\nItem No. 5A \nGFC EXECUTIVE COMMITTEE \nFor the Meeting of September 11, 2017 \n(please quote legislation and \ninclude identifying section \nnumbers) \nservices and facilities for the educational or cultural advancement of \nthe people of Alberta” (Section 60(1)). Subject to the authority of the \nBoard of Governors, the General Faculties Council has responsibility \nover “academic affairs” (Section 26(1)) and “student affairs” (Section \n31(1)). \n2. PSLA Section 93(3): “The students association of a public post-\nsecondary institution shall provide for the administration of student \naffairs at the public post-secondary institution, including the \ndevelopment and management of student committees, the \ndevelopment and enforcement of rules relating to student affairs and \nthe promotion of the general welfare of the students consistent with \nthe purposes of the public post-secondary institution.” \n3. Board Learning and Discovery Committee (BLDC) Terms of \nReference (3. Mandate of the Committee): “Except as provided in \nparagraph 4 hereof and in the Board’s General Committee Terms of \nReference, the Committee shall, in accordance with the Committee’s \nresponsibilities monitor, evaluate, advise and make decisions on \nbehalf of  the Board with respect to matters concerning the teaching \nand research affairs of the University, including proposals coming from \nthe administration and from General Faculties Council (the “GFC”), \nand shall consider future educational expectations and challenges to \nbe faced by the University. The Committee shall also include any \nother matter delegated to the Committee by the Board. \nWithout limiting the generality of the foregoing the Committee shall:  \n[…] \na. review and approve initiatives related to the overall academic mission \nand related plans and policies of the University; […].” \n4. GFC Executive Committee Terms of Reference (3. Mandate of the \nCommittee): \n“5. Agendas of General Faculties Council \nGFC has delegated to the Executive Committee the authority to \ndecide which items are placed on a GFC Agenda, and the order in \nwhich those agenda items appear on each GFC agenda.” \nAttachments (each to be numbered 1 - <>) \n1. Students’ Union 2017/2018 Executive Goals (3 pages)  \nPrepared by: University Governance \nMarina Banister \npresident \n1. A Welcoming University for Students \nStudents who are welcomed and accepted \nare better able to thrive in their studies and \nextracurricular activities. \n• Strengthen student rights \n• Support diverse student identities\n• Improve accessibility to resources, services,   \n and supports \n2. Support Student Culture \n Students who feel at home, both in their \ncampus culture and in their city, are better \nequipped to foster community with their \npeers. \n• Support student representatives\n• Enhance the student group experience \n• Collaborate to make Edmonton a better place  \n to learn and thrive \n3. Bringing Students back to Campus\n If students stay on campus they are better \nable to connect with their peers and \n meet new friends, all in a supportive and \nsustainable environment. \n• Promote a vibrant campus \n• Improve campus spaces\n• Make a better Students’ Union Building  \n4. A Predictable and Affordable Future \n Students should be able to focus on their \neducation and extracurriculars while at  \nUniversity. Reducing financial stress on \nstudents will improve their university experi-\nence, ensure they are able to complete their \ndegree, and set them up for success after \ngraduation. \n• Advocate for affordable Post-Secondary   \n Education \n• Regulate Post-Secondary Education costs \n• Advocate for affordable non-academic costs\n2017/2018 Executive Goals \nShane Scott\nvp academic\nReed Larsen\nvp external \nRobyn Paches \nvp operations \n& finance \nIlya Ushakov\nvp student life \nThe Students’ Union Executive team is committed to representing, serving, and \nengaging students during our terms. This includes holding regular office hours, \nattending a variety of campus events, reaching out to students for feedback, and \nalways being available to talk to students about their needs. \nThis document outlines the 2017/2018 goals set out by the SU Executive. \nThe Students’ Union Executive team is committed to representing, serving, and \nengaging students during our terms. This includes holding regular office hours, \nattending a variety of campus events, reaching out to students for feedback, and \nalways being available to talk to students about their needs. \nThis document outlines the 2017/2018 goals set out by the SU Executive. \n1. A Welcoming University for Students\n Students who are welcomed and accepted \nare better able to thrive in their studies and \nextracurricular activities.\nStrengthen student rights \n• Draft a Charter of Student Rights \n• Advocate for student tenant rights, on  \n and off campus\n• Increased rights and access to work for  \n international students \nSupport diverse student identities \n• Raise awareness of diversity in the classroom\n• Finish large internal research projects\n• Increase collection of demographics by  \n the University \n• Collaborate with indigenous students to work  \n towards reconciliation\n Improve accessibility to resources, services, \nand supports \n• Establish student access to syllabi and im  \n prove scholarship accessibility \n• Increase accessibility to mental health \n resources, including completing the mental   \n health website and increasing supports to   \n marginalized students \n• Strengthen the network between SU,   \n University, and local services, including   \n supporting community mental health and   \n sexual violence prevention initiatives\n• Reanalyze Access Fund fee model \n2. Support Student Culture \n Students who feel at home, both their \ncampus culture and in their city, are  \nbetter equipped to foster community  \nwith their peers. \nSupport student representatives\n• Strengthen relationships with faculty  \n associations and residents associations \n• Promote inclusivity in student governance \n• Promote transparency with Residence  \n Services \n• Expand training for student leaders for  \n mental health and sexual violence  \n prevention\nEnhance the student group experience \n• Achieve student group autonomy \n• Increase accessibility to information about  \n  Student groups, including exploring  \n  alternatives to BearsDen \n• Offer full suite of operational supports  \n to  student groups. \nCollaborate to make Edmonton a better \nplace to learn and thrive \n• Work with the City of Edmonton to  \n establish community orientation \n• Increase education about housing  \n options in Edmonton\n• Develop employment strategies for  \n recent graduates \n2017/2018 Executive Goals \n3. Bringing Students back to Campus \nIf students stay on campus they are better \nable to connect with their peers and meet \nnew friends, all in a supportive and sustain-\nable environment.  \nPromote a vibrant campus \n• Promote campus recreation and athletics  \n at U of A\n• Establish a student event calendar \nImprove campus spaces\n• Housing and residence development \n• Champion deferred maintenance \nMake a better Students’ Union Building (SUB)  \n• Create a student video creation space in SUB \n• Solidify the SUB student event centre plan \n• Create a comprehensive plan for the Myer   \n Horowitz Theatre renovations and fundraising  \n campaign \n4. A Predictable and Affordable Future \n  Students should be able to focus on their \neducation and extracurriculars while at Uni-\nversity. Reducing financial stress on students \nwill improve their university experience, en-\nsure they are able to complete their degree, \nand set them up for success post graduation. \nAdvocate for affordable Post-Secondary  \nEducation \n• Reduce base tuition costs in line with the   \n efforts of provincial and federal advocacy.\nAdvocate for affordable non-academic costs\n• Advocate for an affordable meal plan \n• Advocate for affordable housing on campus \n• Advocate for subsidized work programs and  \n graduate retention strategies  \nRegulate Post Secondary Education costs \n• Advocate for provincial regulation for all new  \n Mandatory Non-Instructional Fees (MNIFs) \n• Pursue stability and predictability in Interna-  \n tional Student Tuition \nThe University of Alberta Students’ Union (SU) is the official body that represents all  \nundergraduates, and advocates on their behalf at the university and all levels of  \ngovernment. The SU is a proactive organization that is run by students for students:  \nwe operate a variety of businesses designed to appeal to students, and provide  \naccess to a wide range of student-centric services. We also operate - and own - the  \nStudents’ Union Building, and manage a budget of more than $14 million, with  \nmore than 200 staff. \nMarina Banister \npresident \nShane Scott\nvp academic\nReed Larsen\nvp external \nRobyn Paches \nvp operations \n& finance \nIlya Ushakov\nvp student life \nItem No. 5B \nGFC EXECUTIVE COMMITTEE \nFor the Meeting of September 11, 2017 \nOUTLINE OF ISSUE \nAdvice, Discussion, Information Item  \nAgenda Title: Graduate Students’ Association (GSA) Board Strategic Work Plan 2017-2018 \nItem   \nProposed by Babak Soltannia, President, Graduate Students’ Association (GSA) \nPresenter Babak Soltannia, President, Graduate Students’ Association (GSA) \nDetails \nResponsibility Graduate Students’ Association (GSA) \nThe Purpose of the item is \n(please be specific) \nTo brief the Board Learning and Development Committee, the GFC \nExecutive Committee, and General Faculties Council (GFC) on the key \npriorities for 2017-2018 identified by the GSA in its Board Strategic Work \nPlan (SWP). \nThis item provides the opportunity for communication and discussion \nbetween the GSA and, respectively, the Board of Governors and GFC \nregarding the GSA’s strategic planning process and goals for 2017-2018. \nTimeline/Implementation Date Ongoing \nSupplementary Notes and \ncontext \nThe GSA will continue to meet with members of university administration \nand other stakeholders to pursue these goals. Updates on the GSA \nBoard’s progress on the SWP goals will be reported to GSA Council.  \nEngagement and Routing (Include meeting dates) \nParticipation: \n(parties who have seen the \nproposal and in what capacity) \n<For further information see \nthe link posted on \nthe Governance Toolkit section \nStudent Participation Protocol> \nThose who have been informed: \n• GFC Executive Committee – September 11, 2017 \n• General Faculties Council – September 25, 2017 \n• Board Learning and Development Committee – September 29, \n2017 \nThose who have been consulted: \n• GSA Board (May 24, 2017, May 31, 2017, and June 21, 2017) \n• GSA Council (June 19, 2017, and July 17, 2017) \nThose who are actively participating: \n•  \nAlignment/Compliance \nAlignment with Guiding \nDocuments \nFor the Public Good \nGOAL: EXPERIENCE diverse and rewarding learning opportunities that \ninspire us, nurture our talents, expand our knowledge and skills, and \nenable our success. \nObjective 8: Create and facilitate co-curricular and extracurricular \nlearning experiences for undergraduate and graduate students that \nenable their self-discovery and give them the skills to use their talents, \ncreativity, and curiosity to contribute as future citizens and leaders.  \nStrategy iii: Support the roles of the Graduate Students’ Association and \nStudents’ Union, along with other student groups, in the promotion of \nhttp://www.governance.ualberta.ca/GovernanceToolkit/Toolkit.aspx\nhttp://www.governance.ualberta.ca/GovernanceToolkit/Toolkit.aspx\nItem No. 5B \nGFC EXECUTIVE COMMITTEE \nFor the Meeting of September 11, 2017 \nextracurricular programs that create a sense of community and support \nthe learning environment. \nCompliance with Legislation, \nPolicy and/or Procedure \nRelevant to the Proposal \n(please quote legislation and \ninclude identifying section \nnumbers) \n1. Post-Secondary Learning Act (PSLA): The PSLA gives the Board \nof Governors the authority to “develop, manage and operate, alone \nor in co-operation with any person or organization, programs, \nservices and facilities for the educational or cultural advancement of \nthe people of Alberta” (Section 60(1)). Subject to the authority of the \nBoard of Governors, the General Faculties Council has responsibility \nover “academic affairs” (Section 26(1)) and “student affairs” (Section \n31(1)). \n2. PSLA Section 94(3): “The graduate students association of a \nuniversity shall provide for the administration of graduate student \naffairs at the university, including the development and management \nof graduate student committees, the development and enforcement \nof rules relating to the graduate student affairs and the promotion of \nthe general welfare of the graduate students consistent with the \npurposes of the university.” \n3. Board Learning and Discovery Committee (BLDC) Terms of \nReference (3. Mandate of the Committee): “Except as provided in \nparagraph 4 hereof and in the Board’s General Committee Terms of \nReference, the Committee shall, in accordance with the Committee’s \nresponsibilities monitor, evaluate, advise and make decisions on \nbehalf of  the Board with respect to matters concerning the teaching \nand research affairs of the University, including proposals coming from \nthe administration and from General Faculties Council (the “GFC”), \nand shall consider future educational expectations and challenges to \nbe faced by the University. The Committee shall also include any \nother matter delegated to the Committee by the Board. \nWithout limiting the generality of the foregoing the Committee shall:  \n[…] \na. review and approve initiatives related to the overall academic mission \nand related plans and policies of the University; […].” \n4. GFC Executive Committee Terms of Reference (3. Mandate of the \nCommittee): \n“5. Agendas of General Faculties Council \nGFC has delegated to the Executive Committee the authority to \ndecide which items are placed on a GFC Agenda, and the order in \nwhich those agenda items appear on each GFC agenda.” \nAttachments (each to be numbered 1 - <>) \n1. Letter from Graduate Students’ Association President Babak Soltannia providing highlights of the 2017-2018 \nGSA Board Strategic Work Plan (2 pages)  \nPrepared by: Babak Soltannia, President, Graduate Students’ Association, gsa.president@ualberta.ca, (780) \n492-2175 \nmailto:gsa.president@ualberta.ca\nAugust 28, 2017 \nDear Members of the GFC EXEC, GFC, and BLDC, \nEach spring and summer the Graduate Students’ Association (GSA) executive team produces a rolling Board Strategic \nWork Plan (SWP). The GSA Board’s SWP serves to identify key priorities and initiatives, direct the GSA’s efforts for the \ncoming year, and identify areas where we can work with others in the University community.  \nThe GSA Directly-Elected officers participated in a workshop on May 18 to develop the 2017-2018 SWP, using the \n2016-2017 GSA Board SWP as a starting point. The draft 2017-2018 SWP was reviewed and discussed by the GSA \nBoard on May 24 and May 31. During these conversations, the elected team identified several key team goals, as well \nas other pivotal initiatives associated with their individual portfolios. These goals were shared with GSA Council on \nJune 19, 2017, and following the GSA Councillor group discussions, the GSA Board reviewed and incorporated the \nfeedback and ideas received into the SWP. Finally, the GSA Board presented the final SWP to GSA Council on July 17, \n2017. The elected team is committed to working on all the initiatives outlined in our SWP, but will use the team and \nindividual portfolio goals, as listed below, to guide our conversations and work with key stakeholders in the University \ncommunity.  \nTeam Goals: \n• The GSA will advocate for the University to launch a review of the current state of graduate student funding \non campus and to consider the creation of transparent and sustainable funding packages for all thesis-based \ngraduate students that support a reasonable standard of living and which take into consideration ‘time to \ncompletion’ requirements, the cost of living in Edmonton, and current tuition costs.  \n• Promote the need for clear and concise contract terms in offer letters issued by the University, and urge that \nthese letters be made available to graduate students well in advance of deadlines for offers of admission. \n• Advocate for the continuation of a tuition model that ties graduate student tuition increases to the Alberta \nConsumer Price Index (CPI), oppose across-the-board increases, and advocate that provincial regulations \nconcerning tuition increases be applied to international graduate students. Should some formulary aside \nfrom tethering increases to Alberta CPI be considered (such as the Academic Price Index), ensure that proper \nconsultation is undertaken and that any such proposals will benefit graduate students. \n• Support the need for sustainable, affordable, and well-maintained graduate student housing on campus and \nother options, to both prevent homelessness and enhance the graduate student experience. \n• Advocate for appropriate training and accountability measures that retain a focus on addressing power \nimbalances in supervisory relationships and cultivate a culture in which graduate students are acknowledged \nas junior colleagues.  \nIndividual Portfolio Goals: \n• Ensure active participation in the Mandatory Non-Instructional Fees (MNIFs) Oversight Committee. \n(President) \n• Maintain engagement with the Alberta Graduate Provincial Advocacy Council (ab-GPAC) to ensure the \npriorities of U of A graduate students are heard by both ab-GPAC and the provincial government. (President \nand Vice-President External) \n• Support professional development and internship opportunities for graduate students. (Vice-President \nAcademic) \n• Engage with Residence Associations and other stakeholders concerning the collection of Residence \nAssociation fees. (Vice-President External) \n• Assist graduate students living in residences to ensure safe conditions and the provision of excellent services, \nwhich will include securing GSA representation on the newly formed Residence Oversight Committee. (Vice-\nPresident Student Services and Vice-President External) \n• Negotiate for increased compensation for graduate assistantships in the Collective Agreement and educate \nthe campus community on the provisions of the Collective Agreement. (Vice-President Labour)  \n• Ensure the GSA’s compliance with Bill 7 and consult with/educate graduate students on the implications of \nthis legislation. (Vice-President Labour) \n• Support the Campus Food Bank in its mission to ensure the delivery of adequate food for students and their \nfamilies. (Vice-President Student Services) \nAlong with the GSA Vice-Presidents, I am looking forward to a productive and engaging year working closely with the \nUniversity’s administration team, and other stakeholders, as we pursue these goals on behalf of our graduate student \nconstituents. I encourage you all to read the full 2017-2018 GSA SWP on the GSA’s website \n(www.gsa.ualberta.ca/SWP), and look forward to discussing it in more detail over the coming months. \nSincerely, \nBabak Soltannia \n2017-2018 GSA President \nItem No. 7 \nGFC EXECUTIVE COMMITTEE \nFor the Meeting of September 11, 2017 \nOUTLINE OF ISSUE \nAction Item \nAgenda Title: Proposed Changes to the University of Alberta Convocation Admission \nMotion:  THAT the GFC Executive Committee recommend to General Faculties Council the proposed \nchanges to the Convocation Admission, as set forth in Attachment 1, and as proposed by the University of \nAlberta Senate, to take effect upon final approval. \nItem   \nAction Requested Approval Recommendation   \nProposed by Douglas Stollery, Chancellor \nPresenter Douglas Stollery, Chancellor \nDetails \nResponsibility General Faculties Council \nThe Purpose of the Proposal is \n(please be specific) \nApprove proposed changes to the University of Alberta Convocation \nAdmission. \nThe Impact of the Proposal is Proposed changes are intended to reflect broadened inclusivity by \nupdating language within the Convocation Admission.   \nReplaces/Revises (eg, policies, \nresolutions) \nProposed changes would revise the current Convocation Admission. \nTimeline/Implementation Date Upon final approval. \nEstimated Cost and funding \nsource \nN/A \nNext Steps (ie.: \nCommunications Plan, \nImplementation plans) \nChanges will become effective following approval by General Faculties \nCouncil. \nSupplementary Notes and \ncontext \nN/A \nEngagement and Routing (Include meeting dates) \nParticipation: \n(parties who have seen the \nproposal and in what capacity) \n<For further information see \nthe link posted on \nthe Governance Toolkit section \nStudent Participation Protocol> \nThose who have been informed: \nThose who have been consulted: \n• The Office of the President \n• The University of Alberta Senate \n• Standing Committee on Convocation \n• GFC Executive Committee  \n• General Faculties Council \nThose who are actively participating: \n• GFC Executive Committee \n• General Faculties Council \nApproval Route (Governance) \n(including meeting dates) \nGFC Executive Committee (September 2017 for recommendation to \nGFC) \nGeneral Faculties Council (September 2017 for final approval) \nhttp://www.governance.ualberta.ca/GovernanceToolkit/Toolkit.aspx\nhttp://www.governance.ualberta.ca/GovernanceToolkit/Toolkit.aspx\nItem No. 7 \nGFC EXECUTIVE COMMITTEE \nFor the Meeting of September 11, 2017 \nFinal Approver General Faculties Council \nAlignment/Compliance \nAlignment with Guiding \nDocuments \nFor the Public Good  \nValues  \nWe value diversity, inclusivity, and equity across and among our people, \ncampuses, and disciplines. \nWe value the history and traditions of our university, celebrating with \npride our people, achievements, and contributions to society. \nGOAL:  BUILD \nOBJECTIVE 5:  Build and strengthen trust, connection, and a sense \nof belonging among all members of the university community through a \nfocus on shared values. \nStrategy 1  \nSupport and enhance activities, initiatives, and traditions that bond \nalumni, students, staff, faculty, and professors emeriti to the university. \nStrategy 2  \nCelebrate and support diversity and inclusivity.  \nCompliance with Legislation, \nPolicy and/or Procedure \nRelevant to the Proposal \n(please quote legislation and \ninclude identifying section \nnumbers) \n1. Post-Secondary Learning Act (PSLA): The PSLA gives GFC \nresponsibility, subject to the authority of the Board of Governors, “to \nprovide for the granting and conferring of degrees other than honorary \ndegrees” (26(1)(f))  \n2. PSLA: The PSLA gives the Chancellor authority to “represent the \nuniversity at ceremonial occasions, preside over all degree-conferring \nceremonies of the university and confer the degrees” (9(1)(a)) \n3. PSLA: The PSLA gives the Senate authority to “inquire into any \nmatter that might benefit the university and enhance its position in the \ncommunity” (13(1)) \n4. GFC Executive Committee Terms of Reference  \n“5. Agendas of General Faculties Council \nGFC has delegated to the Executive Committee the authority to decide \nwhich items are placed on a GFC Agenda, and the order in which those \nagenda items appear on each GFC agenda.”  \nAttachments: \nPrepared by: <> \nADMISSION – University of Alberta  \n(proposed for Fall Convocation November 2017) \nBy virtue of the authority vested in me  \nby the Legislature of this Province  \nand with the consent of this University,  \nI admit you to the degrees to which you are entitled, and \ninvest you with all the powers, rights, and privileges \npertaining to such degrees.   \nI charge you to use them for the uplifting of the whole people;  \nto inspire the human spirit;  \nto serve your community for the public good; \nand to pursue more steadfastly whatsoever things are true. \nPlease be seated. \nReferences: \nThe Admission (Chancellor) \n(effective January 2009) \nBy virtue of the authority vested in me  \nby the Legislature of this Province  \nand with the consent of this University,  \nI admit you to the degrees to which you are entitled, and \ninvest you with all the powers, rights, and privileges \npertaining to such degrees.   \nI charge you to use them for the uplifting of the whole people;  \nto inspire the human spirit;  \nfor all who believe, to serve your God;  \nand to pursue more steadfastly whatsoever things are true. \nPlease be seated. \nTHE ADMISSION before 1999 \nBy virtue of the authority vested in me by the legislature \nof this Province, and with the consent of this University, \nI admit you to the degrees to which you are entitled, \nand invest you with all the powers, rights, and privileges \npertaining to such degrees.   \nI charge you to use them for the glory of God and the \nhonour of your country.   \nPlease be seated. \nItem No. 8 \nGFC EXECUTIVE COMMITTEE \nFor the Meeting of September 11, 2017 \nOUTLINE OF ISSUE \nAction Item \nAgenda Title: Report of the GFC Committee on Learning Environment on Teaching and Learning and \nTeaching Evaluation and the Use of the Universal Student Ratings of Instruction (USRI) as an \nEvaluation Tool \nMotion: THAT the GFC Executive Committee recommend that General Faculties Council approve the CLE \nReport on Teaching and Learning and Teaching Evaluation and the Use of the Universal Student Ratings of \nInstruction (USRI) as an Evaluation Tool, as attached.  \nItem   \nAction Requested Approval Recommendation   Discussion \nProposed by Sarah Forgie, Chair, Committee  on the Learning Environment \nPresenter Sarah Forgie, Chair, Committee  on the Learning Environment and \nPrincipal Investigator \nNorma Nocente, Co-Investigator \nL Francisco Vargas M, Research Coordinator \nRebecca Best-Bertwistle, Research Assistant \nDetails \nResponsibility Provost and Vice-President (Academic) \nThe Purpose of the Proposal is \n(please be specific) \nThe GFC Committee on the Learning Environment (CLE) was requested \nby GFC to report on research into the use of student rating mechanisms \nof instruction in university courses. This report fulfills this request. \nThe Impact of the Proposal is  \nReplaces/Revises (eg, policies, \nresolutions) \nN/A \nTimeline/Implementation Date N/A \nEstimated Cost and funding \nsource \nNext Steps (ie.: \nCommunications Plan, \nImplementation plans) \nFinal report will be forwarded to General Faculties Council for \ndiscussion. \nRecommendations arising from the report will inform the work of the \nCommittee on the Learning Environment over the next year. \nSupplementary Notes and \ncontext \nOn May 30, 2016, General Faculties Council passed the following \nmotion: \nTHAT the General Faculties Council, on the recommendation of the GFC \nExecutive Committee, request that the GFC Committee on the Learning \nEnvironment report by 30 April 2017, on research into the use of student \nrating mechanisms of instruction in university courses. This will be \ninformed by a critical review of the University of Alberta’s existing \nUniversal Student Ratings of Instruction (USRIs) and their use for \nassessment and evaluation of teaching as well as a broad review of \npossible methods of multifaceted assessment and evaluation of \nteaching. The ultimate objective will be to satisfy the Institutional \nStrategic Plan: For the Public Good strategy to: Provide robust supports, \ntools, and training to develop and assess teaching quality, using \nqualitative and quantitative criteria that are fair, equitable, and \nItem No. 8 \nGFC EXECUTIVE COMMITTEE \nFor the Meeting of September 11, 2017 \nmeaningful across disciplines. \nEngagement and Routing (Include meeting dates) \nParticipation: \n(parties who have seen the \nproposal and in what capacity) \n<For further information see \nthe link posted on the \nGovernance Toolkit section \nStudent Participation Protocol> \nThose who have been informed: \n Provost and Vice-President (Academic) \n Vice-Provost Council \n Deans’ Council \n Chairs’ Council \n GFC Executive Committee \n General Faculties Council \nThose who have been consulted: \n GFC Committee on the Learning Environment \n GFC Executive Committee \nThose who are actively participating: \n GFC Committee on the Learning Environment \n Sarah Forgie, Vice-Provost (Learning Initiatives) and Principal \nInvestigator \n Norma Nocente, Co-Investigator \n L Francisco Vargas M, Research Coordinator \n Rebecca Best-Bertwistle, Research Assistant \n GFC Executive Committee \n General Faculties Council \nApproval Route (Governance) \n(including meeting dates) \nGFC Committee on the Learning Environment – April 2017 \nGFC Executive Committee – September 11, 2017 \nGeneral Faculties Council – September 25, 2017 \nFinal Approver General Faculties Council  \nAlignment/Compliance \nAlignment with Guiding \nDocuments \nFor the Public Good \nGOAL: EXCEL as individuals, and together, sustain a culture that \nfosters and champions distinction and distinctiveness in teaching, \nlearning, research, and service. \nOBJECTIVE 14: Inspire, model, and support excellence in teaching and \nlearning.  \nStrategy iii: Provide robust supports, tools, and training to develop and \nassess teaching quality, using qualitative and quantitative criteria that \nare fair, equitable, and meaningful across disciplines. \nCompliance with Legislation, \nPolicy and/or Procedure \nRelevant to the Proposal \n(please quote legislation and \ninclude identifying section \nnumbers) \n1. Post-Secondary Learning Act (PSLA): The PSLA gives GFC \nresponsibility, subject to the authority of the Board of Governors, over \nacademic affairs (Section 26(1)).  \n2. General Faculties Council Terms of Reference (3. Mandate of the \nCommittee) \n“The issues which remain with GFC or which would be referred by a \nStanding Committee of GFC would generally be in the nature of the \nfollowing: \n High level strategic and stewardship policy issues or matters of \nhttp://www.governance.ualberta.ca/GovernanceToolkit/Toolkit.aspx\nhttp://www.governance.ualberta.ca/GovernanceToolkit/Toolkit.aspx\nItem No. 8 \nGFC EXECUTIVE COMMITTEE \nFor the Meeting of September 11, 2017 \nsignificant risk to the University”  \n3. GFC Executive Committee Terms of Reference (3. Mandate of the \nCommittee) \n“5. Agendas of General Faculty Council \nGFC has delegated to the Executive Committee the authority to decide \nwhich items are placed on a GFC Agenda, and the order in which those \nagenda items appear on each GFC agenda.  \nWhen ordering items, the GFC Executive Committee will be mindful of \nany matters that are of particular concern to students during March and \nApril so that the student leaders who bring those items forward are able \nto address these items at GFC before their terms end. (EXEC 06 NOV \n2006)  \n[…]  \nWith respect to recommendations from other bodies and other GFC \ncommittees, however, the role of the Executive Committee shall be to \nexamine and debate the substance of reports or recommendations and \nto decide if an item is ready to be forwarded to the full governing body.  \nThe Executive Committee may decide to refer a proposal back to the \noriginating body, to refer the proposal to another body or individual for \nstudy or review, or to take other action in order to ready a proposal for \nconsideration by General Faculties Council. When the GFC Executive \nCommittee forwards a proposal to GFC, it shall make a recommendation \nthat GFC endorse; endorse with suggested amendments; not endorse; \nor forward the proposal with no comment.” \n4. GFC Committee on the Learning Environment (CLE) Terms of \nReference (3.Mandate of the Committee):  \n“The Committee on the Learning Environment is a standing committee \nof the General Faculties Council that promotes an optimal learning \nenvironment in alignment with guiding documents of the University of \nAlberta.  \nThe Committee on the Learning Environment is responsible for making \nrecommendations concerning policy matters and action matters with \nrespect to the following:  \n[…] \nb) To review and, as necessary, recommend to the GFC Academic \nPlanning Committee and GFC Executive Committee as relates to the \ndevelopment and implementation of policies on teaching, learning, \nteaching evaluation, and recognition for teaching that promote the \nUniversity Academic Plan. \nc) To develop policies that promote ongoing assessment of teaching and \nlearning through all Faculties and units. \nd) To nurture the development of innovative and creative teaching \npractices. \ne) To encourage the sharing and discussion of evidence about effective \nteaching and learning. \nf) To encourage the sharing and discussion of evidence about effective \nteaching, learning, and the services. \ng) To promote projects with relevant internal and external bodies that \noffer unique teaching and learning opportunities that would benefit the \nItem No. 8 \nGFC EXECUTIVE COMMITTEE \nFor the Meeting of September 11, 2017 \nuniversity community. \nh) To consider any matter deemed by the GFC Committee on the \nLearning Environment to be within the purview of its general \nresponsibility. \n5. GFC policy 111 Teaching and Learning and Teaching Evaluation \n“111.2 Teaching Evaluation  \n1. Evaluation of teaching at the University of Alberta serves two \npurposes: \na. Summative – Evaluation provides a review and overview of an \ninstructor’s teaching that is an essential element in promotion and tenure \ndecisions. In its summative form, teaching evaluation forms a basis for \nrewarding excellence, as well as the basis for withholding reward. \nb. Formative – Evaluation provides helpful feedback to teachers by \nidentifying teaching strengths and weaknesses and, in so doing, giving \nguidance for the improvement or refinement of teaching skills. \n2. Evaluation of teaching must be multifaceted. Multifaceted evaluation \nshall include the Universal Student Ratings of Instruction set out in \nSection 111.3 and other methods of assessing teaching designed within \nindividual Faculties to respond to the particular conditions of that \nFaculty. Such assessments shall include one or more of the following: \ninput from administrators, peers, self, undergraduate and graduate \nstudents, and alumni. \n3. Recognizing that the evaluation of teaching at the University shall be \nmultifaceted, Faculty Evaluation Committee (FEC) decisions concerning \ntenure, promotion or unsatisfactory teaching performance must be \nbased on more than one indicator of the adequacy of teaching. \n4. Assessment of teaching involving input from administrators, peers, \nself, alumni, or undergraduate and graduate students in addition to the \nUniversal Student Ratings of Instruction should occur annually prior to \ntenure. For continuing faculty (ie, Categories A1.1, A1.5 and A1.6), such \nassessment will occur at least triennially.  \n5. The University shall continue to support University Teaching Services \nin its education programming which is focused on the development and \nimprovement of teaching and learning and its efforts to enhance \nresearch in university teaching. \n111.3 Universal Student Ratings of Instruction \nIn recognition of the University's commitment to teaching, the General \nFaculties Council endorses a system of Universal Student Ratings of \nInstruction. This system, however, is only one part of the multi-faceted \napproach described in Section 111.2. \nThe Universal Student Ratings of Instruction are administered \nelectronically via a system known as the eUSRI system.   \nThe Universal Student Ratings of Instruction are designed to provide a \nminimal university-wide base of information on student ratings to the \nparties listed in this Section. With this purpose in mind, the General \nItem No. 8 \nGFC EXECUTIVE COMMITTEE \nFor the Meeting of September 11, 2017 \nFaculties Council adopts the following policies: \nA. All Faculties will ensure that evaluation of all instructors and courses \nwill take place each time a course is offered. The term ‘instructors’ is \nmeant to include tenured professors, tenure-track professors, sessional \ninstructors, clinical instructors, field supervisors and graduate teaching \nassistants with responsibilities for courses. \n[…] \nD. The anonymity of student responses to the Universal Student Ratings \nof Instruction is of fundamental importance in maintaining student \nconfidentiality and encouraging the free expression of views. Under \nnormal circumstances, the anonymity of students will be protected. \nUniversal Student Ratings of Instruction offer an avenue of feedback, \nincluding feedback critical of instructors. \n[…] \nG. The numerical summaries for the ten Universal Student Ratings of \nInstruction questions will be reported to the instructor, the Chair, Director \nor Dean and students. \n[…] \nI. All results given out to students, Chairs, Directors and Deans will have \nthe following cautionary preface: \nStudent questionnaires form an important part of evaluating teaching \neffectiveness but cannot be taken alone as a complete assessment of \nan instructor or course. Factors other than an instructor’s teaching ability \nmay influence ratings. These factors include class size, class level, \nFaculty, time in class, required versus optional course, grade \nexpectations, student GPA, gender, race, ethnicity, age of both students \nand instructors. \n[…] \nJ. Nothing in this section will prevent instructors from seeking other \nmeans of feedback from students during the term.” \nThe full GFC Policy 111 Teaching and Learning and Teaching \nEvaluation is available at: \nhttp://www.gfcpolicymanual.ualberta.ca/111TeachingandLearningandTe\nach.aspx \n5. University of Alberta Faculty Agreement July 2006 (incorporating \nJune 2007 and July 2008 amendments) \n“13.06 The standards for evaluation of teaching performance shall be \nbroadly based, including course content, course design and \nperformance in the classroom. Such evaluation may take into account \ninformation such as statistical summaries of responses to student \nquestionnaires, comprehensive reviews of student commentary; reviews \nby peers, reviews by administrative officials and reviews of teaching \ndossiers and other materials provided by the staff member.” \nAttachments (each to be numbered 1 - <>) \n1. Attachment 1 – Recommendations from GFC Committee on Learning Environment (2 pages) \n2. Attachment 2 -  Summary Report of the Evaluation of Teaching at the University of Alberta (96 pages) \nPrepared by: Sarah Forgie, Chair of CLE with the assistance of University Governance \nhttp://www.gfcpolicymanual.ualberta.ca/111TeachingandLearningandTeach.aspx\nhttp://www.gfcpolicymanual.ualberta.ca/111TeachingandLearningandTeach.aspx\nGFC COMMITTEE ON THE LEARNING ENVIRONMENT \n Recommendations from the GFC Committee on the Learning Environment on Teaching Evaluation and \nthe Use of the Universal Student ratings of Instruction (USRI) as an Evaluation Tool \nWith General Faculties Council approval, the Committee on the Learning Environment would like to continue \nour work examining teacher assessment and evaluation.  We believe that “Robust supports, tools, and training \nto assess teaching quality, using qualitative and quantitative criteria that are fair, equitable, and meaningful \nacross disciplines” is an attainable goal towards fulfilling Objective 13 in For the Public Good:  “To inspire, \nmodel, and support excellence in teaching and learning.”    \nWe plan to use the following recommendations in our work plan:  \n1) Re-examine the overall goals of teaching assessment and evaluation at the U of A ensuring that these \ngoals:  \na. Provide the instructor with feedback to improve their teaching (formative assessment) \nb. Provide administrators with evidence of effective teaching for merit, promotion and tenure decisions \n(summative evaluation). \n2) Consult with the Faculties and the literature in order to define qualities and measures of effective teaching \nand ensure that there is a clear link between these qualities and measures. \n3) Examine GFC Policy 111. “Teaching and Learning and Teaching Evaluation” and transition this policy to \nUAPPOL.  In the process, we will: \na. Examine how decisions regarding promotion and tenure can be based on multiple indicators of effective \nteaching, including course based evaluations and more broadly on other teaching related duties.   \nb. Support consistent interpretation of multiple indicators of effective teaching across the University. \nc. Separate instructor feedback for improvement of teaching (formative assessment) and administrative \nevidence of effective teaching for merit, promotion and tenure decisions (summative evaluation) in both \npolicy and practice. \nd. Develop guidelines for the timing, depth and frequency of summative evaluations. \n4) Create a suite of assessment and evaluation tools and supports (for both faculty and administrators) with \ndefinitions, examples and specific strategies.  In developing these resources we will: \na. Investigate methods for instructors to use feedback to improve their teaching and recommend \nopportunities for teaching development, support and training.   \nb. Investigate methods and tools to support administrators in using a variety of assessment and \nevaluation strategies and recommend opportunities for training. \n5) Ensure student input is included in teaching evaluation. In our re-examination of the current methods in \nwhich student ratings are collected, we will consider:  \na. Using student input for both feedback to improve teaching and for feedback in promotion and tenure \ndecisions (formative assessment and summative evaluation), but separating these two purposes in \nboth policy and practice. \nb. Examining when student evaluations should not be used by FEC for merit, promotion or tenure \ndecisions. \nc. Shifting the emphasis of some of the student rating questions from teacher to student, looking at \nparticipation and learning in addition to instruction. \nd. Increasing the flexibility of the student rating instrument to apply to multiple teaching contexts (including \nvarious class sizes and levels) and unique needs within Faculties. \ne. Creating options within the student rating tool that allow the instructor to contextualize their course.  \nf. Examining qualitative student comments and methods to optimize their use in teaching evaluation.  \ng. Continued investigations into bias and student ratings. \nh. Standardizing methods to optimize response rates and quality of comments with the electronic student \nratings.  \nGFC COMMITTEE ON THE LEARNING ENVIRONMENT \n i. Providing all students (including those with accommodation requirements or those who have withdrawn \nfrom a course) with a fair opportunity to provide feedback. \nSummary Report of the Evaluation of Teaching at the \nUniversity of Alberta \nPrepared by: \nSarah Forgie, Vice-Provost (Learning Initiatives) and CLE Chair \nNorma Nocente, Associate Director, CTL \nL. Francisco Vargas M., Senior Research Coordinator, CTL  \nAnita Parker, Research Assistant, CTL \nCarol Brown, Educational Developer, CTL \nRebecca Best-Bertwistle, Research Assistant, CTL \nApril 2017 \nTable of Contents \n1. Introduction 1 \n2. Method 2 \n2.1. Student Ratings of Instruction 2 \n2.2. Evaluation of Teaching at University of Alberta 3 \n2.3. Multifaceted Evaluation 3 \n3. Findings 3 \n3.1. Student Ratings of Instruction 3 \nInformation from University of Alberta reports and documents 3 \nReview of the literature 4 \nInformation from other universities 6 \n3.2. Evaluation of Teaching at University of Alberta 6 \nInformation from interviews with department chairs 6 \n3.3. Multifaceted Evaluation 7 \nApproaches to multifaceted evaluation 8 \n4. Conclusion 9 \n5. References 10 \n6. Appendices 12 \n1 \n1. Introduction \nThe University of Alberta is committed to excellence in teaching. Its institutional strategic             \nplan, ​For the Public Good, pledges to “inspire, model, and support excellence in teaching and               \nlearning” (University of Alberta, 2016, p. 21). Evaluation of teaching plays an important role in               \nupholding this commitment by shaping the quality of instruction being offered to students.             \nUniversal Student Ratings of Instruction (USRI) questionnaires can provide ​formative          \nevaluation​, revealing areas of strength or shortcomings related to aspects of teaching, such as              \nplanning, organization, communication, and assessment. \nTeaching evaluations also affect the careers of instructors at the University of Alberta,             \nsince USRI results are used as ​summative evaluation for faculty annual review, as well as               \ntenure and promotion. This dual purpose of USRIs (summative and formative) is often             \ncontentious, ​because of their perceived weight with Faculty Evaluation Committees (FEC).           \nConsequently, in May 2016 the Committee on the Learning Environment (CLE) was tasked by              \nthe General Faculties Council (GFC) to report on research into tools for evaluation of teaching               \nby students in university courses. This was to include a critical review of the USRI, as well as an                   \noverview of possible multifaceted evaluation methods, ultimately intending to satisfy the           \nUniversity’s institutional strategic plan to “provide robust supports, tools, and training to develop             \nand assess teaching quality, using qualitative and quantitative criteria that are fair, equitable,             \nand meaningful across disciplines” (University of Alberta, 2016, p. 21). \nCLE approached their investigation with three questions:  \n1. What does the research have to say about student ratings of instruction?  \n2. How are the USRIs and other tools used in the evaluation of teaching at the               \nUniversity of Alberta?  \n3. What are some approaches for multifaceted evaluation of teaching?  \nThe purpose of this report is to address these questions and provide CLE and GFC with                \ninformation to guide future decisions on the USRI instrument and multifaceted evaluation of             \nteaching at the University of Alberta. \n2. Method \nData for this report were obtained from multiple sources. We reviewed 81 articles             \nrelating to the three questions above, beginning with literature referenced in the ​2009 CLE              \nreport Evaluation of Teaching at the U of A (Kanuka et al. 2009), which led us to more recent                   \narticles (see ​Appendix A​). We researched evaluation processes by other universities, reviewed            \nUniversity of Alberta reports and documents, and conducted interviews with University of Alberta             \ndepartment chairs (see a full report of interviews with department chairs in ​Appendix B​).  \n2.1. Student Ratings of Instruction \nInvestigation of question 1, what research has to say about student ratings of instruction,              \nincluded a review of reports and documents, which provided background information about the             \nhistory and current status of teaching evaluation at University of Alberta. These included: \n● Report from the sub-committee on evaluation of alternate-delivery courses (Erkut &           \nKreber, 2002); \n2 \nhttps://docs.google.com/document/d/1sYc7CRUexl1NlOl7JGizsYzc97Zfy439A9xbQlx8kKw/edit\nhttps://drive.google.com/open?id=0B5B3IdGb_-gwbTJmUjFvaGhTbkk\n● Evaluation of teaching at the U of A ​(Kanuka, Marentette, Braga, Campbell, Harvey,             \nHolte, Nychka, Precht, Read, Skappak, & Varnhagen, 2009); \n● AASUA position statement on URSIs ​(Association of Academic Staff University of           \nAlberta [AASUA], 2012); \n● Report of the GFC Committee on the Learning Environment subcommittee on the status             \nof the USRIs ​(​Andrews, Chelen, Connor, Kostiuk, Kwong See, & Milner, 2013​); \n● Report of the Renaissance Committee (Cheeseman, MacLaren, Carey, Glanfield, Liu,          \nMcFarlane, Cahill, Garneau, Supernant, & Szeman, 2013); and \n● GFC policy manual.​ (General Faculties Council, n.d.). \nFor this report, Test Scoring & Questionnaire Services (TSQS) at University of Alberta             \nconducted descriptive analyses that generated gender-specific USRI scores using data from the            \nacademic years 2011/12 to 2015/16. TSQS also participated in an unstructured interview about             \nthe validity, reliability, and use of USRIs at the University of Alberta. \n2.2. Evaluation of Teaching at University of Alberta \nInvestigation of question 2, how USRIs and other tools are used at University of Alberta,               \nincluded short, semi-structured interviews with department chairs (or their equivalents in           \nnon-departmental faculties). These interviews were 35-40 minutes, audio recorded, and used an            \ninterview protocol pre-approved by CLE with questions about their experiences evaluating           \nteaching (see ​Appendix C​). Interview participants were also given two sample USRI case             \nstudies representing real teaching scores and were asked to interpret the scores within the              \ncontext of their department (see ​Appendix D​). They were asked to reflect on both score sets as                 \nif both instructors were teaching different sections of the same course. All potential interview              \nparticipants were emailed directly with information about the study, including a research letter of              \ninvitation, and were encouraged to contact any member of the research team if they had               \nquestions or concerns. Data was collected from January to March 2017.  \n2.3. Multifaceted Evaluation \nInformation sources for question 3, approaches to multifaceted evaluation, included: \n● University of Alberta reports and documents (listed above);  \n● Multifaceted summative evaluation of teaching​, a symposium held in May 2015 at Centre             \nof Teaching and Learning (CTL), University of Alberta; \n● University of Alberta peer review of teaching​ (Gibson, n.d.); and \n● Interviews with department chairs.  \n3. Findings \n3.1. Student Ratings of Instruction \nInformation from University of Alberta reports and documents \nThe 2009 CLE report ​outlined a number of recommendations related to the USRI             \ninstrument and to teaching evaluation more generally, as well as GFC policy (Kanuka et al.,               \n2009). ​This report reviewed literature from up to 2008 and selected 35 articles providing insights               \n3 \nhttps://docs.google.com/document/d/1qNWd1zwfL7qAyGkSK9Duawk2CZa9QxlY8HMrrnOb1kE/edit\nhttps://docs.google.com/document/d/1eflt4J3IB-5685QR_z2TNCFXhwTlT1jMu2Ce5UHx5Wg/edit\non the following themes: validity; bias; whether students can effectively measure quality            \nteaching; the need for effective tools; correlations between grades and ratings; the impact of              \nevaluation on quality teaching; and the evaluation of faculty for tenure and promotion.  \nIn 2012, the 2009 CLE report was revisited, and the resulting 2013 CLE report, ​Report of                \nthe GFC Committee on the Learning Environment subcommittee on the status of the USRIs​, ​put               \nforward four recommendations, including that the purpose of USRIs needs to be clearly             \nidentified, and that GFC policy needs updating. It was also suggested that a “working group be                \nstruck to determine how to promote consistent interpretation and implementation of policy”            \n(Andrews et al., 2013). \nIn 2013, the Renaissance Committee, ratified by the AASUA and the Governors of the              \nUniversity of Alberta, addressed aspects of the       \nterms and conditions of work performed at the        \nUniversity of Alberta. Their report detailed a       \nnumber of concerns and made specific      \nrecommendations related to the evaluation of      \nteaching, including USRIs (​Cheeseman et al.,      \n2013)​. The committee recommended that the      \nUniversity of Alberta ​design a set of questions        \non the USRI that evaluate the effectiveness of        \nteaching​. There is no evidence to indicate that any of the recommendations from the 2009 CLE,                \n2013 CLE, or 2013 Renaissance Committee reports were pursued. See ​Appendix E for a table               \nsummarizing the positions and recommendations related to USRIs in University of Alberta            \npolicy, documents, and reports. \nReview of the literature \nIn our review of articles referenced in the 2009 CLE report, as well as articles published                \nthereafter, we organized literature relating to student ratings of instruction into two categories ​–              \nbiases and validity (see ​Appendix A​). \nBiases. ​We divided the biases category into sub-categories of gender, instructor           \ncharacteristics, the correlation between grades and ratings, nonresponse, and non-instructional          \nfactors. \n● Gender. ​The literature in this category is extensive and conflicted. Numerous articles in             \nthis subcategory report gender differences or no differences in student evaluations of            \nteaching. For example, Boring, Ottoboni, and Stark (2016) concluded that student           \nratings are “biased against female instructors by an amount that is large and statistically              \nsignificant.” On the other hand, Wright and Jenkins-Guarieri (2012) conducted a           \nmeta-analysis of 193 studies and concluded that student evaluations appear to be free             \nfrom gender bias. The University of Alberta TSQS conducted descriptive analyses and            \nthe results showed there is no apparent difference between scores for males (​N ​=              \n18576, ​Mdn ​= 4.53) and females (​N ​= 13679, ​Mdn = 4.57) for statement 211 ​(“overall the                 \ninstructor was excellent”)​. \n● Instructor characteristics. ​Article findings in this sub-category, seven articles total, were           \nthat: instructor personality positively correlates with student evaluations (Clayson, 2013;          \n4 \nhttps://docs.google.com/document/d/11hFvMpGYeT9BWjW7iWcdFrFE0W11oALycSs2MprsaRY/edit\nhttps://docs.google.com/document/d/1sYc7CRUexl1NlOl7JGizsYzc97Zfy439A9xbQlx8kKw/edit\nKim & MacCann, 2016); instructor physical attractiveness positively correlates with          \nstudent evaluations on   \nRateMyProfessor.com (Felton, Mitchell,   \n& Stinson, 2004); instructor age     \nnegatively correlates with student    \nevaluations on RateMyProfessor.com   \n(Stonebraker & Stone, 2015) and     \ninstructor age impacts negatively on perceptions of teachers and anticipated rapport in            \nthe classroom based on photographs (Wilson, Beyer, & Monteiro, 2014); instructor           \nposition (limited term lecturer versus full time faculty) does affect student evaluations            \n(Cho & Otani, 2014); and instructor rank (i.e. achievement of tenure) does not affect              \nstudent evaluations (Cheng, 2015). \n● Correlation between grades and ratings. Most literature, seven articles in this           \nsub-category, reported that students receiving higher grades tended to provide more           \nfavourable evaluations of teaching. Cho, Baek, and Cho (2015) found this to be true in               \ntheir research study and suggested that it might be a psychological “gift” from the              \nstudent to the instructor. However, two articles suggested otherwise, such as an analysis             \nof 50,000 courses by Centra (2003) that debunked the correlation between expected            \ngrades and student evaluations. \n● Nonresponse. ​Nonresponse bias occurs when students choose not to participate in an            \nevaluation of teaching, and the missing data may cause skewed results. Three articles in              \nthis sub-category reported that nonresponse bias does influence student evaluations of           \nteaching. For example, Macfadyen, Dawson, Prest, and Gasevic (2016) uncovered that           \n“respondent pools do not fully represent the distribution of students in courses.” No             \narticles suggested otherwise. \n● Non-instructional. Non-instructional bias occurs when circumstances beyond the control         \nof an instructor ​– ​such as class type,        \ntime, size, and semester ​– ​influence      \nstudent evaluation of teaching. The four      \narticles in this sub-category varied in      \ntheir investigations and conclusions. For     \nexample, Nargundkar and Shrikhande    \n(2014) studied numerous factors and     \nconcluded that the combined impact was      \nstatistically significant; Reardon, Leierer, and Lee (2014) determined that class schedule           \ndoes not affect ratings. \nIt should be noted that GFC Policy 111.3 (I) also recognizes student bias may impact the                \nevaluation of an instructor.  \nValidity. ​Validity refers to the extent that an instrument or procedure measures what it              \nintends to measure, and the extendibility of the results to other situations. Literature within this               \ncategory equally supports opposing viewpoints as to whether or not student evaluations of             \nteaching are valid measures of teaching quality; whether or not students have the knowledge,              \nskills, or motivation to measure teaching quality. For example, Grammatikopoulos, Linardakis,           \n5 \nGregoriadis, and Oikonomidis (2015) found an instrument used in the Greek higher education             \nsystem to be valid, whereas Lama, Arias, Mendoza, and Manahan (2015) stated that students              \nat an Australian university completed surveys without diligence. A meta-analysis by Uttl, White,             \nand Gonzalez (2016) re-analyzed meta-analytic data from Cohen (1981) and concluded that            \nstudent evaluations of teaching did not indicate teaching quality. Marsh and Roche (1997) found              \nthat student evaluations correlated with those of peers and trained evaluators, whereas            \nUijtdehaage and O’Neal (2015) reported that students mindlessly evaluated a fictitious           \ninstructor, even when a photograph was provided. During this project, our research team was              \nnot able to find information on the validity of the USRI instrument at the University of Alberta .  1\nRelated to validity is the impact of student evaluations on teaching quality. In our review               \nof the literature, five articles were divided as to whether or not results from student evaluations                \nhad a positive impact on teaching quality. For example, Makondo and Ndebele (2014) reported              \nthat lecturers perceive student feedback as valuable for building their teaching skills, yet ​Stein,              \nSpiller, Harris, Deaker, and Kennedy (2013) argued that evaluation data ​is not being used              \neffectively for professional development. In a 2011 survey of 564 academic staff at the              \nUniversity of Alberta, 69.2% of respondents agreed that ​qualitative comments on USRIs helped             \nimprove the quality of their teaching; 49.5% stated that the USRI’s ​quantitative scores were not               \nhelpful in this regard (AASUA, 2012).  \nInformation from other universities \nThe general consensus that student input should be sought related to their experience             \nwith course instruction and the learning environment is evident in the practices of institutions              \nother than the University of Alberta​. ​For example, in 2015 Stanford University introduced a new               \nend-of-term course evaluation instrument that included nine required items and additional           \ncustomizable, open- or closed-ended questions (​Stanford University VPTL, n.d.​). \nSome institutions use multiple instruments to seek insight on students’ perceptions of            \nteaching and learning, as well as the broader context of the student experience. ​For example,               \nboth University of Oxford and University of Sydney have recently adopted “The Student             \nBarometer”, which includes the learning experience, living experience, support services, and           \nother areas (​I-graduate, n.d.​). This measure is administered once per year and aims to “track               \nand compare the decision-making, expectations, perceptions and intentions of students from           \napplication to graduation” (University of Sydney, 2016a, para. 2). The University of Oxford also              \nemploys department-specific evaluation mechanisms, as well as the “National Student Survey”           \nfor undergraduate students in the last year of their program (​Ipsos MORI, n.d.​; University of               \nOxford, 2015, p. 7). \nUniversity of Sydney uses a “Student Experience Survey” for undergraduate students in            \ntheir first and final year of their program, as well as a mandatory online “Unit of Study Survey                  \n(USS)” with eight required items (six quantitative, two open response) and up to four              \nfaculty-specific quantitative items and one faculty-specific open response item (​University of           \nSydney, 2016b​). Each faculty can also have up to four USS versions to allow customization of                \n1 ​TSQS measures the reliability of the USRI by comparing medians to the previous academic \nyears. \n6 \nhttps://vptl.stanford.edu/teaching-learning/teaching-practices/evaluation-feedback/stanfords-new-course-evaluations/standard\nhttps://www.i-graduate.org/services/student-barometer/\nhttp://sydney.edu.au/education-portfolio/ei/ses/\nhttp://sydney.edu.au/education-portfolio/ei/ses/\nhttp://www.thestudentsurvey.com/\nthe survey for different contexts (University of Sydney, 2016c). ​Taken together, the examples             \nprovided here highlight that other institutions value student feedback on the teaching and             \nlearning environment and are making efforts to update and improve the instruments they utilize              \nto obtain this feedback. \nIn summary ​for question 1, what research has to say about student ratings of instruction,               \nwe conclude that the topic of survey tools is prevalent the literature, often around the concerns                \nof biases or validity. It is evident that universities globally value student feedback and are               \nworking to implement high-quality instruments. University of Alberta reports and documents           \nhave historically addressed the USRI, making recommendations for the instrument and           \nUniversity policy; however, there is no indication suggestions made in these reports have had              \nany traction. \n3.2. Evaluation of Teaching at University of Alberta \nInformation from interviews with department chairs \nInterview participants from all faculties other than Faculty of Medicine and Dentistry            \n(FOMD) reported using USRIs scores and comments to evaluate teaching; only a portion of              \nFOMD participants reported using this tool. Department chairs revealed that, although they try             \nto consider all the USRI statements, they focus primarily on USRI statement 221 (“overall the               \ninstructor was excellent”), and statement 25 (“overall the quality of the course content was              \nexcellent”) as indicators of effective teaching. \nMost participants stated that they     \napproach the interpretation of USRI results      \nwith a contextual attitude, indicating that      \nUSRIs should be understood in light of       \ninstructor characteristics and   \nnon-instructional elements. \nParticipants identified several issues    \nwith using USRIs exclusively to evaluate      \nteaching, which aligned with our review of the        \nliterature, such as biases with gender,      \ninstructor characteristics, and   \nnon-instructional factors. Most department    \nchairs voiced their need for additional      \nsupports to better evaluate teaching. Although      \nsome recommended possible alternatives to     \nsupplement USRI scores, they still expressed      \nhope that the institution would provide      \nsolutions for their concerns. \nParticipants also raised the issue of using       \nUSRIs for purposes of tenure and promotion.       \nThe 2009 CLE report mentioned this concern,       \nand our review of the literature included seven        \n7 \narticles concerning the use of student surveys for summative purposes, and misinterpretation of             \ntheir results leading to incorrect conclusions.  \nIn summary for question 2, ‘how USRIs and other tools are used at University of Alberta’,                \nwe conclude that ​participants from all faculties other than FOMD consistently use USRIs scores              \nand comments to evaluate teaching. Department chairs focus on one or two statements as a               \nbarometer of effective teaching, and although most approach interpretation of results with a             \ncontextual attitude, they also recognize issues with the USRI that are consistent with our review               \nof the literature, specifically perceived issues of bias, validity, and concerns about potential             \nmisinterpretations of student survey results for the summative purposes of tenure and            \npromotion. \n3.3. Multifaceted Evaluation \nAccording to Lyde, Grieshaber, & Byrns (2016), a ​comprehensive system of teaching            \nevaluation is necessary due to the limitations of student surveys and the complex nature of               \nteaching performance. In our review of articles referenced in the 2009 CLE report, as well as                \nmore recently, ten articles recognized the need for instruments that are of high psychometric              \nquality, and also that evaluations should include multiple sources of information, such as             \nsurveys, peer evaluations, self-evaluations, focus groups, and more.  \nReference to multifaceted evaluation is found in University of Alberta documents and            \nreports discussed earlier. The 2009 CLE report commented that an imprecise definition of             \nteaching excellence in section 111.1 of the GFC policy exacerbates the lack of guidance              \nprovided to individual faculties for multifaceted evaluation (Kanuka et al., 2009, pp. 21-22). The              \n2013 CLE report recommended the creation of a resource to guide faculties with “possibilities              \nand/or examples” of multifaceted evaluation (Andrews et al., 2013).  \nIn May 2015, the Centre for Teaching and Learning (CTL) hosted a symposium entitled              \nMultifaceted Summative Evaluation of Teaching​, wherein some recommendations for best          \npractice were brought forward. Key points included: \n● University of Alberta policy needs to include a clear definition of teaching excellence,             \nincluding a specific set of criteria of effective teaching that can be used for purposes of                \nevaluation; these criteria should be shared with faculty, instructors and students. \n● Both formative and summative evaluation of teaching should be multifaceted, collecting           \nmultiple sources of evidence at multiple times annually.  \n● A multifaceted teaching evaluation plan should be developed to supplement University           \npolicy, including definitions, examples, evaluation procedures, and specific strategies for          \ntraining and support. \nApproaches to multifaceted evaluation \nThe 2013 Renaissance Committee report highlighted the importance of rigorous,          \nmultifaceted evaluation, which was described as information “collected through a variety of            \nmethods and assessed at multiple points in time” (Cheeseman et al., 2013, p. 7, 69). “The array                 \ncan include student ratings of courses, a teaching dossier, peer observations, external reviews             \nof content, reflection of the teacher (self-assessment), administrator reviews of content and            \ncourse observation, review of published work on teaching Scholarship, and evidence supporting            \n8 \nhttps://www.ualberta.ca/centre-for-teaching-and-learning/events/symposium-series/past-symposia/multifaceted-summative-evaluation-teaching\nthe reputation of the teacher in the field(s) of instruction, within and without the University”               \n(Cheeseman et al., p. 70). See ​Appendix F for a table summarizing the positions and               \nrecommendations related to multifaceted evaluation in University of Alberta policy, documents,           \nand reports. \nPeer review of teaching. Gibson (n.d.), author of ​University of Alberta Peer Review of              \nTeaching (an online article provided as a resource for the 2015 CTL symposium), defined peer               \nreview of teaching as “informed collegial assessment of faculty teaching for either fostering             \nimprovement or making personnel decisions” and stated that both formative and summative            \nmethods were required for comprehensive teaching evaluation (para 5). Gibson explained that            \nwhile quantitative student questionnaires provide information about day-to-day classroom         \ninteraction, peer review can broaden this to aspects, such as “course content, academic rigor              \nand appropriateness of objectives and topics;… subject matter expertise; instructional materials           \nand methods; and, assessment and grading” (para 3). Gibson outlined six phases of summative              \npeer review and provided eighteen appendices of practical resources, such as sample            \nobservation tools and reports. \nTeaching dossiers (portfolios). ​A teaching dossier serves “to facilitate the presentation of            \na faculty member’s teaching achievements and major strengths for self-assessment and           \ninterpretation by others\" (Day, Robberecht & Roed, 1996, p. 1). They are a cumulative record of                \none’s teaching activities and often include: “(a) a statement regarding the faculty member’s             \nteaching philosophy, goals, and strategies; (b) a description of teaching (planning, preparing,            \nand teaching courses; assessing student learning; and giving feedback); (c) an evaluation of             \nteaching accomplishments; and (d) suggestions regarding possible changes for future teaching”           \n(Day et al.,1996, p. 1). Teaching dossiers require instructors to gather multiple sources of              \nevidence and define the value of their scholarship in teaching (Cheeseman et al., 2013).              \nRelated to summative evaluation of teaching, the 2013 Renaissance Committee report           \nrecommended that “​a teaching dossier, following CTL standards, should be part of all tenure              \nand promotion packages” (Cheeseman et al., 2013, p. 70). A document from the ​University of               \nSydney​ provides a comprehensive list of data sources instructors may include in a dossier.  \nInterviews with department chairs​. Participants indicated having already implemented         \nsome approaches for multi-faceted evaluation of teaching. In-class peer observation was the            \nmost commonly used additional source of information, followed by annual instructor pedagogical            \nself-reflections. Some departments chairs    \nhave also implemented yearly faculty     \naudits, in which a small portion of their        \nprofessoriate teaching is evaluated in a      \nmore comprehensive way, and using a      \nvariety of supplementary sources of     \ninformation. Participants indicated,   \nhowever, that they mostly obtain these      \nextra resources on a voluntary basis (only       \nwhen professors agree to provide them),      \nand even when they do obtain these resources, not all of them bring this information to FEC.                 \n9 \nhttps://docs.google.com/document/d/1X6E4VtHWARCopnvqFoGIPb9FSZZpH3HugEBSSrXGFRM/edit\nhttps://www.ualberta.ca/centre-for-teaching-and-learning/events/symposium-series/past-symposia/multifaceted-summative-evaluation-teaching/peer-review-of-teaching\nhttp://sydney.edu.au/education-portfolio/ei/programs/teaching_insights/pdf/insight7_evidence.pdf\nhttp://sydney.edu.au/education-portfolio/ei/programs/teaching_insights/pdf/insight7_evidence.pdf\nhttps://www.ualberta.ca/centre-for-teaching-and-learning/events/symposium-series/past-symposia/multifaceted-summative-evaluation-teaching/peer-review-of-teaching\nThey voiced their need for additional institutional supports to better evaluate teaching with a              \nmulti-faceted approach, and they hope the institution will provide a solution. \nIn summary for question 3, approaches to multifaceted evaluation, we conclude that:            \nthere are numerous potential evaluative methods in addition to student surveys; multifaceted            \nevaluation is encouraged by several University reports and documents and literature in general,             \nas well as mandated by University policy; yet this has not yet translated into its consistent or                 \nformal implementation across faculties en masse. \n4. Conclusion \nThe purpose of this report is to support CLE with their investigation into student ratings               \nof instruction, the use of USRIs and other evaluation tools at the University of Alberta, and                \napproaches for multifaceted evaluation of teaching.  \nQuestion 1, w​hat does the research have to say about student ratings of instruction?  \nResearch around student ratings of instruction primarily point to concerns about biases            \nand validity of survey tools and results. The perspective that student feedback is valuable to               \nhelp ensure high-quality teaching environments, yet that survey tools are imperfect and limited             \nfor a comprehensive evaluation of teaching, is shared by universities globally.  \nQuestion 2, how are the USRIs and other tools used in the evaluation of teaching at the                 \nUniversity of Alberta? \nSemi-structured interviews with department chairs revealed that USRIs are the primary           \nsource of teaching evaluation information for all faculties except FOMD. Specifically, most            \ndepartment chairs indicated that they start with only one or two statements but they do their best                 \nto contextualize the numerical results. Some department chairs expressed concerns around           \nbiases, validity, and the potential for misinterpretation of USRI results for summative purposes             \nof promotion and tenure decisions. \nQuestion 3, what are some approaches for multifaceted evaluation of teaching?  \nMultifaceted evaluation is supported by the literature and is also mandated by GFC             \npolicy. However, impeding its University-wide adoption and consistency is a lack of support and              \ntime for those responsible for conducting such robust, comprehensive evaluations of teaching.            \nMoving forward, systematic and purposeful evaluation of teaching can only materialize if there             \nare realistic and tangible expectations, and supports (documents, workshops, etc.). \n5. References \nThese are the references used in the preparation of this report, not including our review of the \nliterature. For the latter, see ​Appendix G​. \nAndrews, N., Chelen, D., Connor, B., Kostiuk, L., Kwong See, S., & Milner, R. (2013, June 5). \nReport of the GFC Committee on the Learning Environment subcommittee on the status \nof the USRIs. ​Retrieved from \n10 \nhttps://docs.google.com/document/d/1WJosw7X5j6mZ5dGFBQY4BCow4HILSK0q7zku0Bm36wI/edit\nhttp://www.governance.ualberta.ca/en/GeneralFacultiesCouncil/CommitteeontheLearnin\ngEnvironm/~/media/Governance/Documents/GO05/LEA/13-14/Reports/Item-5-USRI-Su\nbcommittee-Final-Report-June-2013-FINAL.pdf \nAssociation of Academic Staff University of Alberta (AASUA). (2012). ​AASUA position statement \non URSIs.​ Retrieved from \nhttp://www.aasua.ca/wp-content/uploads/2014/03/AASUA_Position_Statement_on_USR\nIs.pdf \nCentre for Teaching and Learning. (2015). ​Multifaceted summative evaluation of teaching \nsymposium​. Retrieved from \nhttps://www.ualberta.ca/centre-for-teaching-and-learning/events/symposium-series/past-\nsymposia/multifaceted-summative-evaluation-teaching \nCheeseman, C., MacLaren, I., Carey, J., Glanfield, F., Liu, L., McFarlane, L., Cahill, J. C., \nGarneau, T., Supernant, K., & Szeman, I. (2013, December 9). ​Report of the \nRenaissance Committee.​ Retrieved from ​http://www.renaissance.ualberta.ca/ \nDay, R., Robberecht, P., & Roed, B. (1996).​ ​Teaching dossier: A guide.​ Retrieved from:  \nhttps://d1pbog36rugm0t.cloudfront.net/-/media/ualberta/centre-for-teaching-and-learning/\ninstructional-resources/teaching-dossier/teachingdossierguide-1.pdf \nErkut, E. & Kreber, C. (2002). ​Report from the sub-committee on evaluation of  \nalternate-delivery courses: Continuing discussion. ​General Faculties Council Teaching \nand Learning Committee. Retrieved from \nhttps://docs.google.com/document/d/1KpLMK5kN4r6Mp_BSEoYiZ1xOrbdI9shhScBDAc\n2NPdI/edit \nGeneral Faculties Council. (n.d.).​GFC policy manual.​ Retrieved from \nhttp://www.gfcpolicymanual.ualberta.ca/ \nGibson, S. (n.d.). ​University of Alberta peer review of teaching​. Retrieved from \nhttps://www.ualberta.ca/centre-for-teaching-and-learning/events/symposium-series/past-\nsymposia/multifaceted-summative-evaluation-teaching/peer-review-of-teaching \nI-graduate. (n.d.). ​The student barometer. ​Retrieved from \nhttps://www.i-graduate.org/services/student-barometer/ \nIpsos MORI. (n.d.). ​National student survey. ​Retrieved from ​http://www.thestudentsurvey.com/ \nKanuka, H., Marentette, P., Braga, J., Campbell, K., Harvey, S., Holte, R., Nychka, J., Precht, \nD., Read, D., Skappak, C., & Varnhagen, C. (2009, January 9). ​Evaluation of teaching at \nthe U of A: Report of the sub-committee of the Committee on the Learning Environment \n(CLE).​ Retrieved from \nhttps://www.ualberta.ca/-/media/ualberta/centre-for-teaching-and-learning/symposium/ev\naluating-teaching-2009/symposiumevaluating-teaching-at-the-u-of-a-taskforce-report.pdf \nLyde, A. R., Grieshaber, D. C., Byrns, G. (2016). Faculty teaching performance: Perceptions of \na multi-source method for evaluation (MME). ​Journal of the Scholarship of Teaching and \nLearning, 16​(3), 82-94. doi: 10.14434/josotl.v16i3.18145 \nStanford University Vice Provost for Teaching and Learning (VPTL). (n.d.). ​Standard Course  \nEvaluation Questions​. Retrieved from: \nhttps://vptl.stanford.edu/teaching-learning/teaching-practices/evaluation-feedback/stanfo\nrds-new-course-evaluations/standard \n11 \nhttps://www.ualberta.ca/-/media/ualberta/centre-for-teaching-and-learning/symposium/evaluating-teaching-2009/symposiumevaluating-teaching-at-the-u-of-a-taskforce-report.pdf\nhttp://www.aasua.ca/wp-content/uploads/2014/03/AASUA_Position_Statement_on_USRIs.pdf\nhttp://www.governance.ualberta.ca/en/GeneralFacultiesCouncil/CommitteeontheLearningEnvironm/~/media/Governance/Documents/GO05/LEA/13-14/Reports/Item-5-USRI-Subcommittee-Final-Report-June-2013-FINAL.pdf\nhttp://www.governance.ualberta.ca/en/GeneralFacultiesCouncil/CommitteeontheLearningEnvironm/~/media/Governance/Documents/GO05/LEA/13-14/Reports/Item-5-USRI-Subcommittee-Final-Report-June-2013-FINAL.pdf\nhttps://www.ualberta.ca/centre-for-teaching-and-learning/events/symposium-series/past-symposia/multifaceted-summative-evaluation-teaching/peer-review-of-teaching\nhttp://www.thestudentsurvey.com/\nhttps://www.ualberta.ca/-/media/ualberta/centre-for-teaching-and-learning/symposium/evaluating-teaching-2009/symposiumevaluating-teaching-at-the-u-of-a-taskforce-report.pdf\nhttps://www.ualberta.ca/centre-for-teaching-and-learning/events/symposium-series/past-symposia/multifaceted-summative-evaluation-teaching\nhttp://www.gfcpolicymanual.ualberta.ca/\nhttps://vptl.stanford.edu/teaching-learning/teaching-practices/evaluation-feedback/stanfords-new-course-evaluations/standard\nhttp://www.renaissance.ualberta.ca/\nhttp://www.governance.ualberta.ca/en/GeneralFacultiesCouncil/CommitteeontheLearningEnvironm/~/media/Governance/Documents/GO05/LEA/13-14/Reports/Item-5-USRI-Subcommittee-Final-Report-June-2013-FINAL.pdf\nhttps://docs.google.com/document/d/1KpLMK5kN4r6Mp_BSEoYiZ1xOrbdI9shhScBDAc2NPdI/edit\nhttps://docs.google.com/document/d/1KpLMK5kN4r6Mp_BSEoYiZ1xOrbdI9shhScBDAc2NPdI/edit\nhttp://www.aasua.ca/wp-content/uploads/2014/03/AASUA_Position_Statement_on_USRIs.pdf\nhttps://d1pbog36rugm0t.cloudfront.net/-/media/ualberta/centre-for-teaching-and-learning/instructional-resources/teaching-dossier/teachingdossierguide-1.pdf\nhttps://www.ualberta.ca/centre-for-teaching-and-learning/events/symposium-series/past-symposia/multifaceted-summative-evaluation-teaching\nhttps://www.i-graduate.org/services/student-barometer/\nhttps://d1pbog36rugm0t.cloudfront.net/-/media/ualberta/centre-for-teaching-and-learning/instructional-resources/teaching-dossier/teachingdossierguide-1.pdf\nhttps://vptl.stanford.edu/teaching-learning/teaching-practices/evaluation-feedback/stanfords-new-course-evaluations/standard\nhttps://www.ualberta.ca/centre-for-teaching-and-learning/events/symposium-series/past-symposia/multifaceted-summative-evaluation-teaching/peer-review-of-teaching\nUniversity of Alberta.​ (2016). ​For the public good: Institutional strategic plan 2016-2021. \nRetrieved from ​https://www.ualberta.ca/strategic-plan \nUniversity of Sydney. (n.d.). Teaching insight: Possible data sources to draw on when providing \nevidence about your teaching. Retrieved from \nhttp://sydney.edu.au/education-portfolio/ei/programs/teaching_insights/pdf/insight7_evid\nence.pdf \nUniversity of Sydney. (2016a). ​Student Barometer (SB/IB)​. Retrieved from:  \nhttp://sydney.edu.au/education-portfolio/ei/studentbarometer/ \nUniversity of Sydney. (2016b). ​Student Experience Survey (SES)​. Retrieved from:  \nhttp://sydney.edu.au/education-portfolio/ei/ses/ \nUniversity of Sydney. (2016c). ​Unit of Study Survey (USS)​. Retrieved from:  \nhttp://sydney.edu.au/education-portfolio/ei/USS/default.htm \nUniversity of Oxford. (2015). ​Procedures for the Annual Monitoring of Courses. ​Retrieved from: \nhttps://www.admin.ox.ac.uk/edc/qa/pamc/ \n6. Appendices  \n● Appendix A: Table of Reviewed Literature \n● Appendix B: ​Summary of Interviews with Department Chairs \n● Appendix C: Interview Questions \n● Appendix D: Sample USRI Case Studies \n● Appendix E: Summary of Positions and Recommendations Related to USRIs in \nUniversity of Alberta Policy, Documents, and Reports \n● Appendix F: ​Summary of Positions and Recommendations Related to Multifaceted \nEvaluation in University of Alberta Policy, Documents, and Reports \n● Appendix G: References of Reviewed Literature  \n● Appendix H: Abstracts for Reviewed Literature \n● Appendix I: Recommendations Related to Evaluation of Teaching from the 2013 \nRenaissance Committee Report \n12 \nhttps://drive.google.com/open?id=1qNWd1zwfL7qAyGkSK9Duawk2CZa9QxlY8HMrrnOb1kE\nhttp://sydney.edu.au/education-portfolio/ei/ses/\nhttps://drive.google.com/open?id=1zy-uKCxmyykDMGopvkLYVwvn1SN1IVqP56lYGlJbDv0\nhttp://sydney.edu.au/education-portfolio/ei/programs/teaching_insights/pdf/insight7_evidence.pdf\nhttp://sydney.edu.au/education-portfolio/ei/USS/default.htm\nhttps://drive.google.com/open?id=1sYc7CRUexl1NlOl7JGizsYzc97Zfy439A9xbQlx8kKw\nhttps://drive.google.com/open?id=0B5B3IdGb_-gwbTJmUjFvaGhTbkk\nhttp://sydney.edu.au/education-portfolio/ei/programs/teaching_insights/pdf/insight7_evidence.pdf\nhttps://drive.google.com/open?id=11hFvMpGYeT9BWjW7iWcdFrFE0W11oALycSs2MprsaRY\nhttps://drive.google.com/open?id=1eflt4J3IB-5685QR_z2TNCFXhwTlT1jMu2Ce5UHx5Wg\nhttps://drive.google.com/open?id=0B5B3IdGb_-gwbTJmUjFvaGhTbkk\nhttps://www.ualberta.ca/strategic-plan\nhttps://drive.google.com/open?id=12fjibAleuJTHDzU-cUCKuqWSS5HyJA1aAxGq4_NGj-4\nhttps://drive.google.com/open?id=1X6E4VtHWARCopnvqFoGIPb9FSZZpH3HugEBSSrXGFRM\nhttps://drive.google.com/open?id=1X6E4VtHWARCopnvqFoGIPb9FSZZpH3HugEBSSrXGFRM\nhttp://sydney.edu.au/education-portfolio/ei/studentbarometer/\nhttps://drive.google.com/open?id=1WJosw7X5j6mZ5dGFBQY4BCow4HILSK0q7zku0Bm36wI\nhttps://drive.google.com/open?id=11hFvMpGYeT9BWjW7iWcdFrFE0W11oALycSs2MprsaRY\nhttps://drive.google.com/open?id=1zy-uKCxmyykDMGopvkLYVwvn1SN1IVqP56lYGlJbDv0\nhttps://drive.google.com/open?id=1X6E4VtHWARCopnvqFoGIPb9FSZZpH3HugEBSSrXGFRM\nhttps://www.admin.ox.ac.uk/edc/qa/pamc/\nAppendix A: Table of Reviewed Literature \nThis table contains literature referenced in the 2009 CLE report, as well as more recent articles \nrelating to the evaluation of teaching. Due to varied research methodologies, measures, and \nresults, definitive comparisons and conclusions from the literature is not be possible; however, \nthe depth and breadth of the articles can provide a general idea about current academic \nperspectives. Black font indicates literature cited in the 2009 CLE report; ​green font ​indicates \nmore recent articles. Brief summarizing points from each article are provided.  \nClick on the links to move directly to each bookmarked section. For abridged abstracts, see \nAppendix H​. For a complete reference list, see ​Appendix G​. \nBiases  \n● Gender \n● Instructor characteristics \n● Correlation between grades and ratings \n● Nonresponse \n● Non-instructional \n● Other \nValidity  \nImpact on Teaching Quality \nEvaluating Faculty for Tenure and Promotion \nMultifaceted Evaluation  \nhttps://docs.google.com/document/d/1WJosw7X5j6mZ5dGFBQY4BCow4HILSK0q7zku0Bm36wI/edit\nhttps://docs.google.com/document/d/12fjibAleuJTHDzU-cUCKuqWSS5HyJA1aAxGq4_NGj-4/edit\n Biases \nThis category is divided into sub-categories of gender, instructor characteristics, correlation \nbetween grades and ratings, nonresponse, and non-instructional. Also, an “other” category \nincludes articles that focused on multiple biasing factors, biasing factors that do not fit into any \nother category, or biases in general. \n Biases, Gender. ​Most literature, seven articles in this sub-category, reported that an \ninstructor’s gender does influence student evaluations of teaching; however, two articles \nsuggest otherwise. \nGender influences student ratings Gender does not influence student ratings \nBoring, Ottoboni, & Stark (2016): ratings are \nbiased against female instructors by an \namount that is large and statistically \nsignificant \nGehrt, Louie, & Osland (2015): female \nstudents evaluated female lower-ranked \nfaculty most favorably; male students \nevaluations were more favorable for lower \nranked male faculty, but they did not degrade \nhigher ranked female faculty \nHuebner & Magel (2015): variances of the \nclass average responses between male and \nfemale faculty were higher for male faculty \nLaube, Massoni, Sprague, & Ferber (2007): \nthe inconsistency on the question of whether \nstudent evaluations are gendered is itself an \nartifact of the way that quantitative measures \ncan mask underlying gender bias \nMacNell, Driscoll, & Hunt (2015): students \nrate males significantly higher than females \nMiles & House (2015): lower ratings for \nfemale instructors teaching larger required \nclasses \nWilson, Beyer, & Monteiro (2014): lower \nratings for older instructors, but more so for \nfemales than males \nCentra & Gaubatz (2000): only small \nsame-gender preferences found, particularly \nwith females \nSmith, Yoo, Farr, Salmon, & Miller (2007): \nmale and female students rated female \ninstructors more highly; effect was small but \nsignificant due to sample size  \nWright & Jenkins-Guarieri (2012): SETs \nappear to be valid and free from gender bias \n Biases, Instructor characteristics​ ​(appearance, personality, age, and/or rank). Article \nfindings in this sub-category, seven articles total, were that: instructor personality positively \ncorrelates with student evaluations; instructor physical attractiveness positively correlates with \nstudent evaluations; instructor age negatively correlates with student evaluations; instructor \nrank does affect student evaluations; and instructor rank does not affect student evaluations.  \nInstructor characteristics influence \nstudent ratings \nInstructor characteristics do not \ninfluence student ratings \nCho & Otani (2014): students give higher \nratings for limited-term lecturers versus \nfull-time faculty \nClayson (2013): students’ first perceptions of \nan instructor’s personality are significantly \nrelated to ratings at the end of the semester \nFelton, Mitchell, & Stinson (2004): students \ngive attractively-rated professors higher \nquality and easiness scores  \nKim & MacCann (2016): students’ expressed \neducational satisfaction was related to \nperceptions of instructor personality \nStonebraker & Stone (2015): age has a \nnegative impact on student ratings of faculty \nmembers; begins around mid-forties; offset by \nattractiveness \nWilson, Beyer, & Monteiro (2014): lower \nratings for older instructors, but more so for \nfemales than males \nCheng (2015): tenure does not have a \nsignificant impact on student ratings of \nteaching performance \n Biases, Correlation between grades and ratings. ​Most literature, seven articles in this \nsub-category, reported that students receiving higher grades tend to provide more favourable \nevaluations of teaching; however, two articles suggest otherwise. \nThere is a correlation between higher \ngrades and higher ratings \nThere is not a correlation between higher \ngrades and higher ratings \nBacker (2012): some students punish \nacademics for failing grades with low ratings \nBlackhart, Peruche, DeWall, & Joiner (2006): \nhigher ratings given to instructors who give \nhigher grades, and also to graduate teaching \nassistant rank \nBoring, Ottoboni, & Stark (2016): ratings​ are \nmore sensitive to students’ grade \nexpectations than they are to teaching \neffectiveness \nCho, Baek, & Cho (2015): students with better \ngrades than their expected grades provide a \npsychological “gift” to their teachers by giving \nhigher ratings \nGreenwald & Gillmore (1997): the \ngrades-ratings correlation is due to an \nunwanted influence of instructors' grading \nleniency; there are 5 theories of the \ngrades-ratings correlation \nMaurer (2006): cognitive dissonance may be \na theory to explain the grades-ratings \ncorrelation \nMiles & House (2015): higher expected \ngrades may lead to higher ratings \nCentra (2003): expected grades generally do \nnot affect student evaluations \nGump (2007): questions the validity of \nresearch done on the leniency hypothesis \n Biases, Nonresponse.​ ​Nonresponse bias occurs when students choose not to participate in \nevaluation of teaching, and the missing data may cause skewed results. Three articles in this \nsub-category reported that nonresponse bias does influence student evaluations of teaching. \nNo articles suggested otherwise. \nNonresponse bias influences student \nratings \nNonresponse bias does not influence \nstudent ratings \nKuwaiti, AlQuraan, & Subbarayalu (2016): \nratings are affected by class size and \nresponse rate \nMacfadyen, Dawson, Prest, & Gasevic \n(2016): ratings affected by who is completing \nthe surveys \nReisenwitz (2015): ​there are significant \ndifferences between those who complete \nonline student evaluations and those who do \nnot \nNo articles found. \n Biases, Non-Instructional. ​Non-instructional bias occurs when circumstances beyond the \ncontrol of an instructor, such as class type, time, size, and semester, influence student \nevaluation of teaching. The four articles in this sub-category varied in their investigations and \nconclusions. \nNon-instructional factors influence \nstudent ratings \nNon-instructional factors do not influence \nstudent ratings \nKuwaiti, AlQuraan, & Subbarayalu (2016): \nratings are affected by class size and \nresponse rate \nNargundkar & Shrikhande (2014): combined \nimpact of all the noninstructional factors \nstudied is statistically significant \nRoyal & Stockdale (2015): students give \nlower ratings to instructors of quantitative \nmethods subjects \nReardon, Leierer, & Lee (2014): class \nschedule does not affect ratings \n Biases, Other.​ ​This sub-category includes literature that focused on multiple biasing factors, \nbiasing factors that do not fit into any other category, or biases in general.  \nThe factors influence student ratings  \nBlackhart, Peruche, DeWall, & Joiner (2006): \nvarying results for investigation if class size, \nclass level, instructor gender, number of \npublications (faculty instructors), average \ngrade given by the instructor, and instructor \nrank predicted teaching evaluation ratings \nKeeley, English, Irons, & Henslee (2013): \nfound halo and ceiling/floor effects to be \npresent and persistent; (Halo effect occurs \nwhen a positive rating on one aspect of the \nSET influences the other aspects. Ceiling and \nfloor effects are issues when the SET \ninstrument scale is limited.) \nMerritt (2012): covers biases in general, \nincluding race minority \nPounder (2007): identifies and organizes \nfactors influencing SET scores \nZumback & Funke (2014): students’ mood \naffects ratings \n Validity \nLiterature within this category equally supports opposing viewpoints as to whether or not student \nevaluations of teaching are valid measures of teaching quality, whether or not students have the \nknowledge, skills, or motivation to measure teaching quality. \nStudent Evaluations are (Mostly) Valid \nMeasures of Teaching; Students are able \nto measure aspects of teaching quality \nStudent Evaluations are not/may not be \nValid Measures of Teaching; Students \nmay not be able to measure teaching \nquality \nAl-Eidan, Baig, Magzoub, & Omair (2016): \nthe faculty evaluation tool was found to be \nreliable, but validity has to be interpreted with \ncaution because of low response \nBedggood & Donovan (2012): student \nsatisfaction does not equal teaching quality; \nboth student satisfaction and student learning \nare relevant measures \nChen & Hoshower (2003): student motivation \nto participate in SET affects ratings \nCohen (1981): student ratings are a valid \nmeasure of teaching effectiveness; this is the \npaper included in a ​meta-analysis​ by Uttl et \nal. (2016) \nDolmans, Janssen-Noordman, & Wolfhagen \n(2006): students can distinguish excellent and \npoor teaching quality \nGinns, Prosser, & Barrie (2007): the SET tool \nstudied supports quality assurance and \nimprovement processes at the university \nGrammatikopoulos, Linardakis, Gregoriadis, \n& Oikonomidis (2015): provides evidence of a \nvalid SET instrument; evaluating test validity \nis a continuous process, not a one-time event \nKhong (2014): SET is a valid instrument in \nevaluating teaching effectiveness \nBrown, Wood, Ogden, & Maltby (2014): \nstudents’ satisfaction rating is context \ndependent; objective quality and subjective \nsatisfaction are different things and should be \nassessed accordingly \nChonko, Tanner, & Davis (2002): students \nfocus more on qualities that make a course \nappealing, not learning \nd'Apollonia & Abrami (1997): student ratings \nare moderately valid; however, they are \naffected by administrative, instructor, and \ncourse characteristics \nDodeen (2013): validity of SET is \nquestionable \nGrayson (2015): questions student’s ability to \ngive accurate ratings \nGreenwald (1997): student rating measures \nhave validity concerns \nLama, Arias, Mendoza, & Manahan (2015): \nlack of student diligence when rating \ninstructors raises validity concerns \nMartin, Dennehy, & Morgan (2013): validity of \nSET is questioned; student focus groups \nsuggested as an alternative \nMorley (2012): ​student evaluations in this \nstudy were generally unreliable \nValidity,​ continued \nStudent Evaluations are (Mostly) Valid \nMeasures of Teaching; Students are able \nto measure aspects of teaching quality \nStudent Evaluations are not/may not be \nValid Measures of Teaching; Students \nmay not be able to measure teaching \nquality \nMarsh & Roche (1997): evaluations are \nrelatively valid and unaffected by \nhypothesized biases; student ratings \ncorrelate with those of peer evaluators and \ntrained evaluators \nMcKeachie (1997): student ratings are valid \nbut affected by contextual variables such as \ngrading leniency \nNargundkar & Shrikhande (2012): an \ninstrument that was validated 20 years ago is \nstill valid \nSocha (2013): a SET instrument was found to \nhave overall good reliability and validity with \nrelatively few biases \nWright & Jenkins-Guarieri (2012): SETs \nappear to be valid and free from gender bias \nRantanen (2013): reliability of SET is \nquestionable; multiple feedbacks required \nSpooren, Brockx, & Mortelmans (2013): the \nutility and validity of SET is questionable \nUttl, White, & Gonzalez (2016): SETs do not \nindicate teaching quality, ​meta-analysis \nUijtdehaage & O’Neal (2015): many students \nrate instructors mindlessly \nImpact on Teaching Quality \nThe five articles in this category are divided as to whether or not results from student \nevaluations of teaching have a positive impact on teaching quality. \nEvaluation results may have an impact on \nteaching quality \nEvaluation results may not have an impact \non teaching quality \nCurwood, Tomitsch, Thomson, & Hendry \n(2015): provide an example of support for \nacademics’ learning from SETs \nMakondo & Ndebele (2014): SETs are \nbeneficial for improving teaching quality \nAsassfeh, Al-Ebous, Khwaileh, & Al-Zoubi \n(2014): students’ perceptions include lack of \nimpact of evaluations on teaching behaviors \nCampbell & Bozeman (2008): questions the \neffect student evaluations have on teaching \nquality \nStein, Spiller, Harris, Deaker, & Kennedy \n(2013): there are gaps in the way academics \nengage with student evaluation \nEvaluating Faculty for Tenure and Promotion \nLiterature in this category includes seven more recent articles (2012 onward) that express \nconcern about the use of evaluation results for summative purposes, misinterpretation of results \nleading to incorrect conclusions. \nSupport for use of student evaluations for \ntenure and promotion decisions \nConcerns related to the use of  student \nevaluations for tenure and promotion \ndecisions \nFraile & Bosch-Morell (2015): present a \nreliable approach to SET interpretation \nBoysen (2015): faculty and administrators \ncan over-interpret small variations \nBoysen, Raesly, & Casner (2014): ratings are \nmisinterpreted by faculty and administrators \nJackson & Jackson (2015): concerns with use \nof SETs for summative purposes \nJones, Gaffney-Rhys, & Jones (2015): \npresents issues if decision-makers use SET \nresults summatively \nMitry & Smith (2014): conclusions drawn from \nevaluations may be invalid and harmful \nPalmer (2012): presents examples of \nineffective responses to evaluation results \n Multifaceted Evaluation \nThis category amalgamates the concepts of effective tools and multifaceted evaluations into one \ntheme, since effective tools provide the ingredients for multifaceted evaluations. The ten articles \nin this category recognize the need for instruments that are of high psychometric quality, and \nalso that evaluations should include multiple sources of information, such as surveys, peer \nevaluations, self-evaluations, focus groups, and more. \nBerk (2013): covers several issues, including multifactorial evaluations \nCox, Peeters, Stanford, & Seifert (2013): a peer assessment instrument was piloted; formative \npeer assessment seems important \nHughes II & Pate (2013): present a multisource evaluation method \nIqbal (2013): faculty express concerns with peer reviews \nLyde, Grieshaber, & Byrns (2016): a multisource method of evaluating is a useful tool \nMarsh & Roche (1997): multidimensional aspects of teaching should be evaluated; suggest \nnine factors; “homemade” surveys are of questionable quality \nMartin, Dennehy, & Morgan (2013): validity of SET is questioned; student focus groups \nsuggested as an alternative \nRidley & Collins (2015): suggests a comprehensive performance evaluation instrument \nStupans, McGuren, & Babey (2016): present a tool for analyzing free-form comments on \nratings forms \nZimmerman (2008): some tools may encourage students to focus on negative aspects of \nteaching; anonymous feedback means students are not accountable for their comments \nEVALUATION\tOF\tTEACHING\t\nAT\tTHE\tUNIVERSITY\tOF\tALBERTA\t\nA\tSUMMARY\tOF\tDEPARTMENT\tCHAIR\tINTERVIEWS\tACROSS\tCAMPUS\t\nSarah\tForgie\t&\tNorma\tNocente\t Principal\tInvestigators\t\nL.\tFrancisco\tVargas\tM.\t Research\tCoordinator\t\nRebecca\tBest-Bertwistle\t Research\tAssistant\t\n2017\t\n\t 2\t\n“I\tthink\tthese\tmeasures\tare\tuseful,\tas\tlong\t\nas\t they’re\t not\t used\t by\t themselves.\t They\t\nneed\t to\t be\t supplemented\t by\t all\t kinds\t of\t\nother\tthings”\t(Department\tChair).\t\n\t 3\t\nTable\tof\tContents\t\n1.\t Executive\tSummary\t............................................................................................................................................................\t5\t\n2.\t Introduction\t........................................................................................................................................................................\t6\t\n3.\t Methods\t..............................................................................................................................................................................\t6\t\n3.1.\t Participants\t................................................................................................................................................................\t7\t\n3.2.\t Data\tAnalysis\t..............................................................................................................................................................\t7\t\n4.\t Results\t.................................................................................................................................................................................\t9\t\n4.1.\t Use\tof\tUSRI\tto\tEvaluate\tTeaching\t..............................................................................................................................\t9\t\n4.2.\t Use\tof\tAdditional\tTools\t&\tInformation\tto\tEvaluate\tTeaching\t.................................................................................\t11\t\n4.3.\t Perceived\tFEC\tWeighting\tof\tTeaching,\tResearch\t&\tService\t....................................................................................\t13\t\n4.4.\t Need\tfor\tAdditional\tSupports\tto\tBetter\tEvaluate\tTeaching\t....................................................................................\t14\t\n4.5.\t Difference\tBetween\tTeaching\tEvaluation\tfor\tAnnual\tReview\t&\tPromotion\t..........................................................\t16\t\n4.6.\t Characteristics\tof\tEffective\t&\tExcellent\tTeachers\t...................................................................................................\t16\t\n4.7.\t Experiences\tTransitioning\tto\te-USRI\tCompared\tto\tPaper-Based\tUSRI\t...................................................................\t17\t\n5.\t Conclusions\t.......................................................................................................................................................................\t19\t\n6.\t Appendix\t1:\tSemi-Structured\tInterview\tQuestions\t..........................................................................................................\t21\t\n7.\t Appendix\t2:\tSample\tUSRI\tResults\tfor\tDepartment\tChairs\t...............................................................................................\t23\t\n\t 4\t\n\t 5\t\n1. Executive\tSummary\t\nIn\tMay\t2016,\tGeneral\tFaculties\tCouncil\ttasked\tthe\tCommittee\ton\tLearning\tEnvironment\tto\treport\ton\tthe\t“…\tresearch\tinto\t\nthe\tuse\tof\tstudent\trating\tmechanisms\tof\tinstruction\tin\tuniversity\tcourses.\tThis\twill\tbe\tinformed\tby\ta\tcritical\treview\tof\tthe\t\nUniversity\t of\t Alberta’s\t existing\t Universal\t Student\t Ratings\t of\t Instruction\t (USRIs)\t and\t their\t use\t for\t assessment\t and\t\nevaluation\t of\t teaching\t as\t well\t as\t a\t broad\t review\t of\t possible\t methods\t of\t multifaceted\t assessment\t and\t evaluation\t of\t\nteaching.”\t\nMethods\t\n• Qualitative\t research.\tDepartment\t chairs\t (or\t their\t equivalents\t in\t non-departmental\t faculties)\twere\t asked\t to\t\nparticipate\tin\tshort\t30-45\tminute\t(audio-recorded)\tsemi-structured\tinterviews\twith\tquestions\tregarding\ttheir\t\nexperiences\tevaluating\tteaching.\t\n• Data\twas\tcollected\tfrom\tJanuary\tto\tMarch\t2017,\twith\ta\tresponse\trate\tof\t59%.\t\nOur\tcommittee\tsought\tto\taddress\tthe\tGFC\tmotion\tby\tanswering\tthe\tfollowing\tthree\tquestions:\t\n1. What\tdoes\tthe\tresearch\thave\tto\tsay\tabout\tstudent\tratings\tof\tteaching?\t\n• A\t literature\t review\ton\tstudent\t rating\tsystems\tpreviously\tpresented\t in\ta\t2009\tUniversity\tof\tAlberta\t report\t\nwas\tupdated\t(Evaluation\tof\tTeaching\tat\tthe\tU\tof\tA:\tReport\tof\tthe\tSub-Committee\tof\tthe\tCommittee\ton\tthe\t\nLearning\tEnvironment).\t\n2. How\tare\tthe\tUSRIs\tand\tother\ttools\tused\tin\tthe\tevaluation\tof\tteaching\tevaluation\tat\tthe\tUniversity\tof\tAlberta?\t\n• Participants\t from\t all\t faculties\t other\t than\t FOMD\t use\t USRI\t scores\t and\t comments\t (and\t only\t a\t portion\t of\t\nparticipants\tfrom\tFOMD)\tto\tevaluate\tteaching.\t\n• Statement\t221\t (overall\t the\t instructor\twas\texcellent),\t and\t statement\t25\t (overall\t the\tquality\tof\t the\t course\t\ncontent\twas\texcellent)\tare\tthe\tmost\tcommonly\tused\tUSRI\titems\tto\tevaluate\tteaching.\t\n• Most\tparticipants\ttry\tto\tcontextualize\ttheir\tinterpretation\tof\tUSRI\tresults.\t\n3. What\tare\tsome\tapproaches\tfor\tmulti-faceted\tevaluation\tof\tteaching?\t\n• In-class\t peer\t teaching\t observations\t were\t the\t most\t commonly\t used\t additional\t source\t of\t information,\t\nfollowed\tby\tannual\tinstructor\tpedagogical\tself-reflections.\t\n• Most\t participants\t obtain\t these\t resources\t on\t a\t voluntary\t basis,\t only\twhen\t professors\t agree\t to\t give\t them\t\nthese\tsupplementary\tresources.\t\n• Some\t participants\t have\t implemented\t yearly\t faculty\t audits,\t in\t which\t a\t manageable\t portion\t of\t their\t\nprofessorate’s\tteaching\tis\tevaluated\tusing\tadditional\tinformation.\t\n• Even\t when\t participants\t obtain\t these\t resources,\t not\t all\t reported\t to\t bring\t them\t to\t FEC.\t When\t this\t\ninformation\tmakes\tit\tto\tFEC,\tit\tis\tused\tto\tinform\ttheir\tnarrative,\tand\tis\tonly\texplicitly\tbrought\tup\twhen\tthere\t\nis\ta\tconcern\twith\tthe\tnumerical\tscores.\t\n• Despite\t more\t value\t being\t placed\t in\t teaching,\t most\t participants\t still\t described\t a\t strong\t bias\t towards\t\nresearch\tat\ttheir\trespective\tFECs.\t\n• Most\tparticipants\tvoiced\ttheir\tneed\tfor\tadditional\tsupports\tto\tbetter\tevaluate\tteaching.\t\n• Most\t participants\t identified\t some\t issues\t when\t evaluating\t teaching\t exclusively\t with\t USRI,\t and\t some\t\nrecommended\tpossible\talternatives\tto\tsupplement\tthese\tscores,\tbut\tthey\tstill\thope\tthe\tinstitution\twill\t\nprovide\tsolutions\tfor\ttheir\tconcerns.\t\n6\t\n2. Introduction\nThe\t University\t of\t Alberta’s\t Institutional\t Strategic\t Plan,\tFor\t the\t Public\t Good,\t underscores\t its\t strong\t commitment\t to\t\nteaching\t and\t learning.\t The\t University\t community\t values\t the\t intellectual\t and\t engaging\t learning\t environment\t that\t is\t\ncultivated\tby\tour\tinspiring\tteachers.\t\tAccordingly,\tthe\tevaluation\tof\tteaching\tis\tessential\tin\tupholding\tthese\tvalues.\t\nTeaching\tevaluations\tnot\tonly\taffect\tthe\tcareers\tof\tindividuals\tat\tthe\tUniversity\tof\tAlberta,\tthey\talso\tshape\tthe\tquality\tof\t\ninstruction\tbeing\toffered\tto\tstudents.\tUniversal\tStudent\tRatings\tof\tInstruction\t(USRI)\tare\toften\tused\tto\tevaluate\tteaching\t\nquality\t for\t faculty\t annual\t review\t and\t tenure\t and\t promotion\t (summative\t evaluation).\t Also,\t USRIs\t can\t provide\t insight\t\n(formative\t evaluation)\t into\t specific\t areas\t of\t strength\t or\t improvement\t related\t to\t different\t aspects\t of\t teaching\t such\t as\t\nplanning\t and\torganization,\t communication,\t assessment,\t etc.\tHowever,\t the\tdual\t purpose\tof\tUSRIs\t is\t often\t contentious,\t\nparticularly\tbecause\tof\tthe\tperceived\tweight\tthey\tcarry\twith\tFaculty\tEvaluation\tCommittees.\t\nConsequently,\t in\tMay\t 2016,\t General\t Faculties\t Council\t (GFC)\t tasked\t the\t Committee\t on\t Learning\t Environment\t (CLE)\t to\t\nreport\t on\t the\t “…\t research\t into\t the\t use\t of\t student\t rating\tmechanisms\t of\t instruction\t in\t university\t courses.\t This\twill\t be\t\ninformed\tby\ta\tcritical\t review\tof\t the\tUniversity\tof\tAlberta’s\texisting\tUniversal\tStudent\tRatings\tof\t Instruction\t (USRIs)\tand\t\ntheir\t use\t for\t assessment\t and\t evaluation\t of\t teaching\t as\t well\t as\t a\t broad\t review\t of\t possible\t methods\t of\t multifaceted\t\nassessment\tand\tevaluation\tof\t teaching.\tThe\tultimate\tobjective\twill\tbe\t to\t satisfy\t the\t Institutional\tStrategic\tPlan:\tFor\t the\t\nPublic\t Good\t strategy\t to:\t Provide\t robust\t supports,\t tools,\t and\t training\t to\t develop\t and\t assess\t teaching\t quality,\t using\t\nqualitative\tand\tquantitative\tcriteria\tthat\tare\tfair,\tequitable,\tand\tmeaningful\tacross\tdisciplines.”\t\nOur\tcommittee\tsought\tto\taddress\tthe\tGFC\tmotion\tby\tanswering\tthe\tfollowing\tthree\tquestions:\t\n1. What\tdoes\tthe\tresearch\thave\tto\tsay\tabout\tstudent\tratings\tof\tteaching?\n2. How\tare\tthe\tUSRIs\tand\tother\ttools\tused\tin\tthe\tevaluation\tof\tteaching\tevaluation\tat\tthe\tUniversity\tof\tAlberta?\n3. What\tare\tsome\tapproaches\tfor\tmulti-faceted\tevaluation\tof\tteaching?\nFor\tthe\tfirst\tquestion,\twe\tupdated\ta\tliterature\treview\ton\tstudent\trating\tsystems\tpreviously\tpresented\tin\ta\t2009\tUniversity\t\nof\tAlberta\treport\t(Evaluation\tof\tTeaching\tat\tthe\tU\tof\tA:\tReport\tof\tthe\tSub-Committee\tof\tthe\tCommittee\ton\tthe\tLearning\t\nEnvironment).\t To\t partially\t address\t the\t third\t question,\t we\t resurrected\t previous\t work\t completed\t at\t the\t University\t of\t\nAlberta\t on\t the\t multi-faceted\t evaluation\t of\t teaching.\t This\t information\t was\t presented\t to\t CLE\t in\t September\t 2016.\t This\t\nreport\tprimarily\t addresses\t the\t second\tand\t third\tquestion\t through\t information\tcollected\t in\t interviews\twith\tdepartment\t\nchairs\tacross\tcampus.\t\nWhile\tUniversity\tpolicy\tsuggests\tthat\tdepartments\tutilize\ta\tmulti-faceted\tapproach\tto\tevaluating\tteaching,\twe\tdo\tnot\thave\t\na\t clear\t picture\t of\t the\t tools\t used\t other\t than\t the\t mandated\t Universal\t Student\t Rating\t System\t (USRI).\t These\t interviews\t\nhelped\tto\tuncover\thow\tdepartment\tchairs\tutilize\tUSRIs\tto\tmake\tpersonnel\tdecisions\tand\tthe\thelped\tto\tdetermine\twhich\t\nother\ttools\tthey\tused\tto\tevaluate\tthe\tquality\tof\tteaching\tin\ttheir\trespective\tdepartments.\t\t\nThe\t purpose\t of\t this\t study\t is\t to\t describe\t the\t current\t state\t of\t teaching\t evaluation\t at\t the\t University\t of\t Alberta.\t More\t\nspecifically\tit\twill\thelp\tus\tunderstand\tthe\ttools\tused\tto\tevaluate\tteaching\tat\tthe\tUniversity\tof\tAlberta.\t\n3. Methods\nEthics\tapproval\tfor\tthis\tqualitative\tstudy\twas\tsought\tfrom\tthe\tHuman\tResearch\tEthics\tBoard\tat\tthe\tUniversity\tof\tAlberta,\t\nand\tobtained\tDecember\t7,\t2016\t(Pro00069070).\t \tA\tqualitative\tapproach\twith\t interviews\twas\tused\tto\telicit\tthe\tdepth\tof\t\nresponse\tnecessary\tfor\tunderstanding\tthe\tnuances\tand\tvariety\tin\tpossible\tanswers.\t\t\t\nDepartment\tchairs\t(or\ttheir\tequivalents\tin\tnon-departmental\tfaculties)\twere\temailed\tdirectly\twith\tinformation\tabout\tthe\t\nstudy,\tand\twith\tcopy\tof\tthe\tresearch\tletter\tof\tinvitation.\tThey\twere\tasked\tto\tparticipate\tin\ta\tshort\t30-45\tminute\t(audio-\nrecorded)\tsemi-structured\tinterview\t(see\tAppendix\t1).\tThe\tinterview\tprotocol\twas\tpre-approved\tby\tCLE,\tand\tit\tconsisted\t\nof\t questions\t regarding\t the\t chairs’\t experiences\t evaluating\t teaching.\t Participants\twere\t also\t given\t two\t sample\tUSRI\t case\t\nstudies\tbased\ton\treal\tteaching\tscores\t(see\tAppendix\t2)\tand\tasked\tto\tinterpret\tthe\tscores.\tThey\twere\tdirected\tto\treflect\ton\t\nboth\tscores\tas\tif\tboth\tinstructors\twere\tteaching\tdifferent\tsections\tof\tthe\tsame\tcourse\twithin\ttheir\tdepartment.\t\t\nhttp://www.governance.ualberta.ca/GeneralFacultiesCouncil/CommitteeontheLearningEnvironm/~/media/Governance/Documents/GO05/LEA/16-17/USRI-Reference-Material/Executive_Summary-Teaching_Evaluation_at_the_UofA_-_September_2016.pdf\n\t 7\t\nData\twas\tcollected\tfrom\tJanuary\tto\tMarch\t2017.\t\n3.1. Participants\t\nParticipants\twere\t43\tdepartment\tchairs\t(or\ttheir\tequivalents\tin\tnon-departmental\tfaculties)\twhich\tis\ta\t59%\tresponse\trate.\t\nThe\tdistribution\twas\t9.3%\tfrom\tAgricultural,\tLife\tand\tEnvironmental\tSciences\t(ALES),\t4.7%\tfrom\tAlberta\tSchool\tof\tBusiness\t\n(BUS),\t 20.9%\t from\t Arts\t (ART),\t 4.7%\t from\t Augustana\t Campus\t (AUG),\t 7%\t from\t Education\t (EDU),\t 7%\t from\t Engineering\t\n(ENG),\t23.3%\tfrom\tMedicine\tand\tDentistry\t(FOMD),\t4.7%\tfrom\tRehabilitation\tMedicine\t(RM),\t7%\tfrom\tScience\t(SCI),\tand\t\n11.6%\t from\t all\t non-departmental\t faculties\t (ND)\t (see\t Figure\t 1).\t Response\t rate\t reached\t a\tminimum\t of\t 50%\twithin\t the\t\ndifferent\tfaculties\t(see\tFigure\t2).\t\nParticipants\treported\thaving\tan\taverage\tof\t32.07\t(SD\t=\t22.42)\tfaculty\tand\tFSO,\t23.18\t(SD\t=\t27.03)\tsessional\tor\tcontract\t\ninstructors,\t and\t 3.06\t (SD\t =\t 3.82)\t graduate\t students\t teaching\t in\t their\t departments.\t They\t mentioned\t working\t for\t an\t\naverage\tof\t4.34\t(SD\t=\t3.61)\tyears\tas\tdepartment\tchairs\t(or\ttheir\tequivalents\tin\tnon-departmental\tfaculties),\tand\t9.3%\tof\t\nthe\ttotal\tindicated\thaving\tan\tinterim\tappointment.\t\n3.2. Data\tAnalysis\t\nConfidentiality\t and\t anonymity\t were\t guaranteed\t by\t assigning\t pseudonyms\t to\t each\t audio\t file\t before\t it\t was\t sent\t for\t\ntranscription.\t Transcripts\twere\t further\t anonymized\tby\t removing\t any\t information\t that\t identified\t the\tdepartment\t under\t\ndiscussion\t(i.e.,\tmention\tof\tdisciplines,\tcourses,\tspecific\tindividuals,\tand\tothers).\tParticipants\tfrom\tdepartmental\tfaculties\t\nwere\t grouped\t together\t and\t those\t from\t non-departmental\t faculties\t were\t combined\t to\t protect\t their\t identity.\t The\t\ncomplete\t list\t of\t participants,\t as\twell\t as\t assigned\t pseudonyms,\t is\t only\t available\t to\t the\t research\t coordinator.\t Interview\t\ntranscripts\twere\t then\t coded\twith\t the\tqualitative\tdata\t analysis\t software\tNVivo\t11,\t using\t the\tmain\tquestions\t as\t general\t\nguidelines\tthat\tinformed\tthe\tdifferent\tcodes/nodes.\tAn\texternal\tresearch\tassistant\tdetermined\tan\tinter-coder\tpercentage\t\nagreement\tof\t.95\twith\t10%\tof\tthe\ttotal\tnumber\tof\tinterviews\tfor\tthe\tqualitative\tdata,\tand\tof\t.98\twith\t100%\tof\tinterviews\t\nfor\tthe\tquantitative\trepresentation\tof\tthe\tdata.\t\n9.3% \n4.\n7%\n20.9% \n4.\n7%\n7.0% 7.0% 23.3% \n4.\n7%\n7.0% 11.6% \nFigure\t1.\tDistribution\tof\tParticipants\tby\tFaculty\nALES BUS ART AUG EDU ENG FOMD RM SC ND\n100.0% \n50.0% \n60.0% \n66.0% \n60.0% \n60.0% \n50.0% \n66.0% \n50.0% \n62.5% \nALES\nBUS\nART\nAUG\nEDU\nENG\nFOMD\nRM\nSCI\nND\nFigure\t2.\tResponse\tRate\tby\tFaculty\n\t 8\t\n\t 9\t\n4. Results\t\nThis\tsection\toffers\tboth\ta\tquantitative\tand\ta\tqualitative\tsummary\tof\tall\tparticipant\tresponses,\texcept\tsection\t4.1.,\tsection\t\n4.2.,\tand\tsection\t4.7.,\tin\twhich\tresults\tonly\tconsider\tparticipants\twho\treported\tusing\tUSRI.\tInformation\tin\tthese\tsections\t\nexcludes\tparticipants\tfrom\tFOMD\twho\tindicated\tnot\tusing\tUSRI,\tor\twhose\tapplication\twas\tnot\tclear\t(see\tFigure\t3).\t\n4.1. Use\tof\tUSRI\tto\tEvaluate\tTeaching\t\nParticipants\t from\t all\t faculties\t other\t than\t FOMD\t reported\t using\t USRI\t scores\t and\t comments\t as\t part\t of\t their\t teaching\t\nevaluation\tprocess\t(100%).\tDepartment\tchairs\tfrom\tFOMD\teither\tmentioned\tusing\tthe\tUSRI\tscores\t(40%),\tnot\tusing\tthem\t\n(20%),\tor\tdid\tnot\tprovide\ta\tdefinite\tanswer\t(40%)\t(see\tFigure\t3).\t\t\nAdditionally,\t department\t chairs\t from\t FOMD\t either\t indicated\t using\t USRI\t comments\t (30%),\t not\t taking\t them\t into\t\nconsideration\t (30%),\t or\t their\t responses\t were\t unclear\t (40%)\t (see\t Figure\t 4).\t “I\t have\t never\t seen\t it,\t but\t our\t largest\t\nundergraduate\tprogram\thas\ta\tdifferent\tevaluation\tsystem,\twhich\tis\tmainly\tbased\ton\tnarrative\tcomments.\tSo,\tyour\temail,\t\nas\t I\t said,\twas\t the\t first\t time\tthat\t I\theard\t the\t term\tever.”\tThey\twere\toften\tunsure\t if\t their\tdepartment\tused\tUSRI,\tor\thad\t\nnever\theard\tabout\tUSRI,\tor\thad\tnever\tseen\tthe\tscores\t(see\tAppendix\t2).\t\nFROM\tTHIS\tPOINT\tON\tINFORMATION\tONLY\tCONSIDERS\tPARTICIPANTS\tWHO\tREPORTED\tUSING\tUSRI\t\nWhen\t asked\t which\t USRI\t statements\t were\t most\t commonly\t used\t in\t their\t teaching\t evaluation\t process,\t statement\t 221\t\n(overall\t this\t instructor\twas\t excellent)\twas\t identified\t by\t 97.3%\t of\t participants,\t statement\t 25\t (overall\t the\t quality\t of\t the\t\n40.0% 20% 40% \nFigure\t3.\tParticipants\t\tfrom\tFOMD\tthat\tReported\tUsing\tUSRI\tScores\tto\tEvaluate\tTeaching\nYes No Unclear\n30.0% 30.0% 40.0% \nFigure\t4.\tParticipants\tfrom\tFOMD\tthat\tReported\tUsing\tUSRI\tComments\tto\tEvaluate\tTeaching\nYes No Unclear\n21.6% \n16.2% \n24.3% \n18.9% \n67.6% \n2.7% \n16.2% \n35.1% \n10.8% \n97.3% \n21:\tThe\tgoals\tand\tobjectives\tof\tthe\tcourse\twere\tclear\n22:\tIn-class\ttime\twas\tused\teffectively\n23:\tI\tam\tmotivated\tto\tlearn\tmore\tabout\tthese\tsubject\tareas\n24:\tI\tIncreased\tmy\tknowledge\tof\tthe\tsubject\tareas\tin\tthis\tcourse\n25:\tOverall\tthe\tquality\tof\tthe\tcourse\tcontent\twas\texcellent\n674:\tThe\tinstructor\tspoke\tclearly\n51:\tThe\tinstructor\twas\twell\tprepared\n9:\tThe\tinstructor\ttreated\tstudents\twith\trespect\n26:\tThe\tinstructor\tprovided\tconstructive\tfeedback\tthroughout\tthis\t…\n221:\tOverall\tthe\tinstructor\twas\texcellent\nFigure\t5.\tUSRI\tStatements\tMost\tCommonly\tUsed\tto\tEvaluate\tTeaching\n\t 10\t\ncourse\tcontent\twas\texcellent)\twas\tselected\tby\t67.6%,\tand\tstatement\t9\t(the\tinstructor\ttreated\tstudents\twith\trespect)\twas\t\nidentified\t by\t 35.1%\t (see\t Figure\t 5).\t In\t general,\t participants\t revealed\t that\t one\t or\t two\t items\t are\t used\t as\t an\t indicator\t of\t\neffective\tteaching.\tThey\tseem\tto\thave\tbenchmarks\tin\tmind\tas\tthey\treview\tUSRI\tscores:\t\nWe\tconsider\tall\tof\tthem,\tbut\tof\tcourse\twe\tkey\tin\tright\taway\ton\t‘the\tinstructor\twas\texcellent.’\tYou\talways\tlook\tat\tthat\t\none\tfirst.\tAnd\toverall\tthe\tcourse\tcontent\twas\texcellent\tis\tthe\tsecond\tthing\tyou\tlook\tat.\tAnd\tthen,\tif\tthere’s\tproblems\t\nin\t either\t of\t those\t two\t scores\t you\t look\t in\tmore\t detail\t at\t the\t other\t questions.\t There’s\t something\t like\t 300\t faculty\t\nmembers\tin\tthe\tFaculty\tof\tScience\tfor\tFEC,\tso\twe’re\tonly\tfinding\tways\tto\tefficiently\tgo\tthrough\tthese\tthings.\t\nParticipants\talso\treflected\ton\tthe\tUSRI\tcase\tstudies\t(see\tAppendix\t2).\tInstructor\tA\thad\t6\tUSRI\titems\ton\tthe\t25th\tpercentile\t\nor\tbelow,\tand\t1\titem\tbelow\tthe\tTukey\tfence.\tThis\tinstructor\tscored\t4.0\ton\tstatement\t221,\t3.8\ton\tstatement\t25,\tand\t4.0\ton\t\nstatement\t 9.\t Instructor\t B\t had\t7\tUSRI\t items\tbetween\t the\t50th\t and\t25th\t percentile,\t but\t no\t items\twere\tbelow\t the\t Tukey\t\nfence.\tThis\tinstructor\tscored\t4.5\ton\tstatement\t221,\t4.2\ton\tstatement\t25,\tand\t4.8\ton\tstatement\t9.\tAfter\treflecting\ton\tthese\t\nsample\tcase\tstudies,\t8.1%\tof\tparticipants\tgave\tInstructor\tA\t‘unsatisfactory’\treviews,\t13.5%\tthought\tthe\tscores\twere\t‘okay’,\t\nand\t 24.3%\t considered\t the\t scores\t were\t ‘good’\t (see\t Figure\t 6).\t Instructor\t B\t received\t more\t positive\t reviews,\t with\t 8.1%\t\nconsidering\tthe\tscores\twere\t‘okay’,\t27%\tthinking\tthey\twere\t‘good’,\tand\t10.8%\tdeeming\tthem\tas\t‘excellent’\t(see\tFigure\t7).\t\nMoreover,\tbelieving\tthe\tUSRI\tdata\t indicated\ttheir\tteaching\twas\t ‘okay’,\t45.9%\tof\tparticipants\tmentioned\tthat\tcontextual\t\nfactors\t should\t be\t considered\t in\t the\t evaluation\t of\t teaching\t (see\t Figure\t 6\t and\t 7),\t and\t that\t to\t provide\t an\t informed\t\ninterpretation\tof\tthese\tUSRI\tscores,\tthey\trequired\tmore\tinformation\tthan\tthe\tone\tprovided:\t\nTo\tbe\tperfectly\thonest,\tin\tthe\tabstract\tI\tdon’t\tknow\twhat\tI\twould\tsay.\tWithout\tknowing\tthe\tcircumstances,\tif\tone\tof\t\nthose\t instructors\t is\t in\t her\t or\t his\t first\t year\t of\t teaching,\t and\t the\t other\twas\t an\t experienced\t professor,\t I\t think\t that\t\ninterpretation\tis\tdramatically\tdifferent\tthan\tif\tthey’re\tboth\texperienced\tprofessors\tor\tif\tthey’re\tboth\tnew\tprofessors.\tI\t\ncan\tsay,\tif\twe\tlook\tat\tthe\toverall\taverages\tthey’re\tboth\tscoring\tin\tthe\tlower\tpercentile,\tand\tthat\tsort\tof\tdata,\tbut\tto\t\nbe\tperfectly\thonest\tthat\tmeans\tvery\tlittle\tto\tme\tbecause\tI\tthink\tthat\tunderstanding\ta\tperson’s\tposition\tis\tcrucial\tto\t\nbeing\table\tto\tread\tany\tof\tthese\tnumbers.\t\nAdditionally,\t18.9%\twould\tonly\t follow\tup\twith\t Instructor\tA\tto\taddress\t issues\trelated\tto\t their\t teaching\tscores,\tand/or\t to\t\nprovide\t supplementary\t guidance\t to\t help\t them\t improve\t their\t results;\t 24.3%\twould\t follow\t up\t with\t both\t instructors\t to\t\ndiscuss\ttheir\tconcerns;\t8.1%\twould\tnot\tfollow\tup\twith\teither\tinstructor,\tdue\tto\twhat\tthey\tconsider\ta\tlack\tof\tany\tteaching\t\n8.1% 13.5% 24.3% 45.9% \n2.\n7%\n5.4% \nFigure\t6.\tParticipant\tInterpretation\tof\tInstructor\tA's\tUSRI\tScores\nNot\tsatisfactory Okay Good Contextual No\tcomments Not\tasked\n8.1% 27.0% 10.8% 45.9% \n2.\n7%\n5.4% \nFigure\t7.\tParticipant\tInterpretation\tof\tInstructor\tB's\tUSRI\tScores\nOkay Good Excellent Contextual No\tcomments Not\tasked\n18.9% 24.3% 8.1% 45.9% 5.4% \nFigure\t8.\tParticipant\tReported\tCase\tStudies\tFollow-Up\t\nInstructor\tA Both None Contextual Not\tasked\n\t 11\t\nred\tflags;\tand\t45.9%\tstill\tmentioned\tthat\tsince\tUSRI\tneeds\tto\tbe\tinterpreted\tin\ta\tcontextual\tway,\tthey\tneed\tto\tlook\tinto\t\nthe\tcircumstances\tof\tboth\tinstructors\tas\tpart\tof\ttheir\tnormal\tprocess\t(see\tFigure\t8).\t\nParticipants\t also\t had\t access\t to\t two\tpieces\t of\t reference\t data\twhen\t given\t these\t case\t studies.\t The\t Tukey\t fence\twas\t not\t\nreferenced\t by\t 81.1%\t of\t the\t participants,\t even\t though\t Instructor\t A\t had\t one\t score\t below\t the\t Tukey\t fence,\t and\t not\t all\t\nparticipants\t(5.4%)\tseemed\tfamiliar\twith\tits\tapplication\t(see\tFigure\t9).\tThe\tTest\tScoring\t&\tQuestionnaire\tServices\t(TSQS)\t\nOffice\tmentioned\t that\t they\tgenerate\tdiverse\t reports\t for\tdifferent\t faculties\tand\tdepartments,\t and\tbased\ton\t that,\t some\t\nparticipants\tmight\tnot\tbe\tgetting\tthe\tcomplete\tset\tof\tdata\tavailable.\tParticipants\twere\tmore\tfamiliar\twith\tquartiles\tdata,\t\nhowever,\t as\t37.8%\tof\tparticipants\tmade\texplicit\t reference\t to\t them,\t13.5%\tstated\tdepartmental\texpectations\t regarding\t\nUSRI\t scores\twithout\tmaking\t explicit\t reference\t to\t the\t quartiles,\t and\t 43.2%\t did\t not\t provide\t any\t definite\t comment\t (see\t\nFigure\t10).\t\nIn\tgeneral,\tparticipants\tfrom\tall\tfaculties\tother\tthan\tFOMD\tuse\tUSRI\tscores\tand\tcomments\t(and\tonly\ta\tportion\tof\tFOMD\t\nparticipants\t reported\t using\t this\t tool)\t to\t evaluate\t teaching.\t And\t even\t when\t one\t or\t two\t items\t are\t mainly\t used\t as\t an\t\nindicator\tof\teffective\tteaching,\tmost\tparticipants\ttry\tto\tcontextualize\ttheir\tinterpretations\tof\tUSRI\tresults.\t\n4.2. Use\tof\tAdditional\tTools\t&\tInformation\tto\tEvaluate\tTeaching\t\nWhen\tasked\tabout\tthe\tuse\tof\tadditional\ttools\tand\tinformation\tto\tevaluate\tteaching,\t in-class\tpeer\tteaching\tobservations\t\nwere\t the\t most\t commonly\t implemented\t resource\t (70.3%),\t followed\t by\t annual\t instructor\t self-reflections\t about\t their\t\npedagogical\tpractices\t(37.8%),\treview\tof\tclass\tmaterials\t(e.g.,\tsyllabi,\tassignments,\tand\texams)\t(29.7%),\tand\tdepartmental\t\nspecific\ttools\tthat\thave\tbeen\tcreated\tto\taccommodate\tto\tthe\tuniqueness\tof\ttheir\tdepartments\t(21.6%)\t(see\tFigure\t11).\t\n8.1% 81.1% 5.4% 5.4% \nFigure\t9.\tParticipant\tReference\tto\tTukey\tFence\tData\nYes No\tcomments Not\tknow Not\tasked\n37.8% 13.5% 43.2% 5.4% \nFigure\t10.\tParticipant\tReference\tto\tQuartile\tData\nYes Departmental Unclear Not\tasked\n70.3% \n37.8% \n29.7% \n21.6% \nIn-Class\tPeer\tTeaching\tObservations\nAnnual\tInstructor\tSelf-Reflections\nClass\tMaterials\nDepartmental-Specific\tTools\nFigure\t11.\tAdditional\tTools\t&\tInformation\tMost\tCommonly\tUsed\tto\tEvaluate\tTeaching\n\t 12\t\nBut\t the\t implementation\tof\t these\t tools\t varies\tbetween\tdepartments.\t Some\tparticipants\t (35.1%)\tonly\t employ\tadditional\t\nresources\t on\t a\t voluntary\t basis,\t encouraging\t professors\t to\t provide\t further\t information,\t but\t reportedly\t are\t not\t able\t to\t\nengage\teveryone\tin\tthe\tdepartment.\tAnother\tgroup\t(27%)\tuses\tadditional\tinformation\tas\ta\tstandard,\tobtaining\tit\tthrough\t\ndepartmental\t specific\t tools.\t Some\t of\t them\t (8.1%)\t have\t already\t implemented\t yearly\t departmental\t audits\t that\t include\t\nadditional\ttools\tand\tinformation.\tFurthermore,\t18.9%\tonly\tgo\tbeyond\tUSRI\twhen\tthey\tneed\tto\tevaluate\tteaching\tpractices\t\nof\tprofessors\tgoing\tup\tfor\tpromotion/tenure;\t10.8%\tonly\timplement\tadditional\tstrategies\tto\tassess\tsessional\tinstructors\tor\t\nnew\tprofessors;\tand\t8.1%\tacknowledged\tthey\tdid\tnot\tuse\tany\tadditional\ttools\tor\tinformation\t(see\tFigure\t12).\t\nAmong\tthe\tparticipants\twho\tused\tadditional\ttools\tand\tinformation\tin\tany\tway,\t42.8%\tused\tone\tof\tthe\tlisted\tresources\t(see\t\nFigure\t 11),\t 42.8%\t used\t two,\t and\t 14.4%\t used\t three.\t Nevertheless,\t most\t participants\t share\t a\t common\t rationale\t for\t\nincluding\t other\t tools\t recognize\t the\t need\t to\t include\t other\t tools\t are\t very\tmuch\t alike,\t as\t one\t of\t them\tmentioned\twhen\t\nreflecting\ton\trelying\texclusively\ton\tUSRI\tto\tevaluate\tteaching:\t\nI\tdon’t\tthink\tthat’s\tvery\tuseful\tby\titself,\tit’s\tincomplete.\tI’d\tfeel\tuncomfortable\tjudging\tsomebody’s\tfate\tjust\tbased\ton\t\nthat.\t I’m\t not\t saying\t it’s\t wrong\t but\t it’s\t only\t one\t piece.\t It’s\t one\t piece\t of\t understanding,\t and\t we\t take\t teaching\t\nseriously.\tIt’s\tnot\tjust\ta\tbunch\tof\tsimple\tnumbers\tpouring\tat\tus.\tWe\tdon’t\t just\tlook\tat\tyou’re\tabove\tthis\tnumber\tor\t\nbelow\tthis\tnumber,\tand\twe’re\tdone.\tWe’re\tlooking\tat\tyou\tmuch\tmore\tcarefully\tthan\tthat,\tbut\tit’s\ta\tgood\tstart.\t\nParticipants,\tfurthermore,\tmentioned\ttools\tand\tinformation\tthey\thave\tutilized\tin\ttheir\tdepartments\tto\tsupport\tteaching.\t\nFor\t instance,\t40.5%\thave\torganized\tpeer\tsupport\t initiatives\t(e.g.,\tmentoring,\tteaching\ttriads,\tand\tsupport\tgroups\twhere\t\ninstructors\t find\t a\t safe\t space\t to\t talk\t about\t their\t teaching\t practices).\t Another\t 13.5%\t have\t referred\t struggling\t faculty\t to\t\ndepartmental\t specific\t training\t and/or\tworkshops,\t or\t to\t other\t units\t on\t campus\t that\t offer\t pedagogical\t guidance;\t 13.5%\t\nhave\tinstituted\tfaculty\tgatherings\tto\topen\tcasual\tconversations\tabout\tteaching\tpractices\tand\tproblems.\tAdditionally,\t8.1%\t\nhave\tproduced\tdepartmental\tteaching\thandbooks\t(see\tFigure\t13).\t\nALES\nALES\nALES\nBUS\nBUS\nART\nART\nART\nART\nAUG\nAUG\nEDU\nEDU\nEDU\nENG\nENG\nFOMD\nFOMD\nFOMD\nRM\nRM\nSCI\nSCI\nSCI\nND\nND\nND\nND\nVoluntary\tBasis\nDepartment\tStandard\nOnly\tfor\tTenure\tPurposes\nOnly\tfor\tLower\tRank\tProfessors\nNo\tAdditional\tTools\nFigure\t12.\tDistribution\tof\tAdditional\tTools\t&\tInformation\tUse\tby\tFaculty\n40.5% \n13.5% \n13.5% \n8.1% \nPeer\tSupport\nTraining\t&\tWorkshops\nFaculty\tGatherings\nHandbook\nFigure\t13.\tAdditional\tTools\t&\tInformation\tUsed\tto\tSupport\tTeaching\n37.8% \n27.0% \n18.9% \n10.8% \n5.4% \n\t 13\t\nWhen\tit\tcomes\tto\tbringing\tthis\tadditional\ttools\tand\tinformation\tto\tFEC,\t45.9%\tindicated\tthat\tthese\tsources\tplay\ta\trole\tin\t\ntheir\t annual\t teaching\t evaluation,\t by\t informing\t a\t narrative\t and/or\t the\t reasoning\t with\t other\t FEC\t members\t if\t their\t\nrecommendation\tgets\tchallenged;\t21.6%\tacknowledged\tnot\tbringing\tthese\tresources\tto\tFEC,\tand\t32.4%\tdid\tnot\tcomment\t\nor\ttheir\tresponses\twere\tunclear\t(see\tFigure\t14).\tThus,\teven\twhen\tparticipants\tindicated\tusing\tone\tor\ttwo\tadditional\ttools\t\nto\tevaluate\tteaching,\tmost\tacknowledged\tusing\tthem\ton\ta\tvoluntary\tbasis,\t receiving\tthis\t information\tonly\twhen\tfaculty\t\nagrees\tto\tprovide\tthese\tsupplementary\tresources.\t\n4.3. Perceived\tFEC\tWeighting\tof\tTeaching,\tResearch\t&\tService\t\nFROM\tTHIS\tPOINT\tON\tINFORMATION\tCONSIDERS\tALL\tPARTICIPANTS\t\nMost\t participants\t recognized\t that\t there\t is\t a\t strong\t bias\t towards\t research\t (60.5%),\t despite\t their\t FEC’s\t best\t efforts\t to\t\nweight\tthem\tequally\t(14%)\t(see\tFigure\t19):\t\nI\twould\tsay\tthat\tthere’s\tstill\ta\tbias\ttowards\tresearch.\tAlthough\tmy\texperience\twas\tthat\tteaching\twas\ttaken\tseriously,\t\nand\twe\t looked\tat\t those\t things\ta\t lot,\tand\t they\twere\t raised\t in\t terms\tof\t the\tkinds\tof\t things\tpeople\twere\tdoing,\t the\t\namount\tof\tteaching\tthey\twere\tdoing,\ttheir\tscores,\tand\tall\t that\tstuff\twas\ttaken\t into\tconsideration,\t I\twould\tstill\tsay\t\nthat\tthe\tpublications\tand\tother\tresearch\tactivities\tand\toutcomes\twere\tprobably\tweighed\tmore\tseriously.\tSo,\tI’d\tsay\t\nit’d\tbe\tmore\tlike\t50%,\t30%,\t20%\trather\tthan\t40%,\t40%,\t20%.\t\nAn\tadditional\t14%\tmentioned\t that\tFEC\tweights\t the\t importance\tof\t teaching,\t research\tand\tservice\tbased\ton\t the\tspecific\t\ntime\t allocation\t of\t the\t individual\t (mostly\t in\t health-related\t disciplines\t where\t their\t contracts\t have\t different\t time\t\nallocations),\tand\t11.6%\tthought\tthat\ttheir\tFEC\tweights\tteaching\tmore\theavily\tthan\tresearch\t(see\tFigure\t15).\t\n45.9% 21.6% 32.4% \nFigure\t14.\tPercentage\tof\tParticipants\tthat\tBring\tAdditional\tTools\t&\tInformation\tto\tFEC\nYes No Unclear\nALES\nAL\nES\nBUS ART\nAR\nT\nAUG\nEDU\nENG\nEN\nG\nFOMD\nFOMD\nFO\nM\nD\nRM\nSC ND\nND\nND\nPredominantly\tResearch\nEqually\tWeighted\nSpecific\tTime\tAllocation\nPredominantly\tTeaching\nFigure\t15.\tDistribution\tof\tPerceived\tFEC\tWeighting\n60.5% \n14.0% \n14.0% \n11.6% \n\t 14\t\n4.4. Need\tfor\tAdditional\tSupports\tto\tBetter\tEvaluate\tTeaching\t\nMost\tparticipants\talso\tvoiced\ttheir\turgent\tneed\tfor\tadditional\tsupports\tto\tbetter\tevaluate\tteaching.\tOne\tparticipant,\tfor\t\nexample,\tremarked\tthat\t“I\twas\tlooking\tto\tyou\tto\tfind\tthis\tout,\tto\tfind\tout\tif\tthe\tresult\tof\tthis\tsurvey\twould\tgive\tme\tsome\t\nideas\tof\twhat\tthis\tis”;\tand\tanother\tcommented\tthat\tin\ttheir\tdepartment\t“We’re\thoping\tthe\tuniversity\twill\tsolve\tthis\tissue.”\t\nIndeed,\t 83.7%\t of\t participants\t mentioned\t needing\t some\t support,\t whereas\t 9.3%\t indicated\t not\t needing\t additional\t\nresources\t(see\tFigure\t16).\t\nSome\tparticipants\texplicitly\trecognized\ttheir\tconcerns\tabout\tdepending\texclusively\ton\tUSRI,\tand\tthe\tinability\tof\tUSRIs\tto\t\neffectively\tevaluate\tdiverse\tapproaches\tto\tteaching\t(46.5%),\tother\tmentioned\tnot\thaving\tenough\ttime\tand\tresources\tto\t\nadopt\tsupplementary\ttools\tin\tthe\tteaching\tevaluation\tprocess\t(27.9%).\tParticipants\talso\texpressed\tconcerns\tabout\tlower\t\nUSRI\tscores\tfor\twomen\tand\tvisible\tminorities\t(11.6%),\tas\twell\tas\tthe\tdifficulties\tof\tcompelling\tsenior\tfaculty\t(usually\twith\t\nfull\tprofessor\trank)\tto\timprove\ttheir\tteaching\tpractices\t(9.3%)\t(see\tFigure\t17):\t\nThat\tquestion\tset\tdoesn’t\tserve\tthe\tdiversity\tand\tthe\tkind\tof\tpedagogy\twe\thave\tnow,\tand\treally\tneeds\tfixing.\tI\tthink\t\nthere\tneeds\tto\tbe\ta\tconversation\tabout\twhat\tthis\t is\tgoing\tto\t look\t like\tover\ttime.\t I\talso\t think\tthe\tUniversity\thas\tto\t\ntake\tvery\tseriously\tthe\tconcerns\tthat\tequity\tseeking\tgroups\thave\tabout\twhat\thappens\tin\tteaching\tevaluations.\tWhat\t\nhappens\tto\twomen?\tWhat\thappens\tto\tvisible\tminority?\tWhat\thappens\tto\tpeople\tthat\tare\tperceived\tto\thave\tstrong\t\naccents?\tAnd\tI\tthink\tthere’s\ta\thuge\tresponsibility\ton\tchairs\tand\tpeople\ton\tFEC\tto\treally\tbe\teducated\tin\thow\tmuch\tyou\t\ncan\textrapolate\tfrom\tUSRI.\t\nTSQS\t conducted\t descriptive\t analyses\t that\t generated\t gender-specific\t USRI\t scores\t using\t data\t from\t the\t academic\t years\t\n2011/2012\t to\t 2015/2016.\t Results\t show\t there\t is\t no\t overt\t difference\t between\t scores\t for\t males\t(N\t=\t 18576,\tMdn\t=\t\n4.53)\tand\tfemales\t(N\t=\t13679,\tMdn\t=\t4.57)\tfor\tstatement\t211.\tAdditionally,\tTSQS\tmeasures\tthe\treliability\tof\tthe\tUSRI\tby\t\ncomparing\tmedians\tto\tthe\tprevious\tacademic\tyears.\t\tOur\tresearch\tteam\twas\tnot\table\tto\tfind\tinformation\ton\tthe\tvalidity\tof\t\nthe\tUSRI.\t\n83.7% 9.3% 7.0% \nFigure\t16.\tPerceived\tNeed\tfor\tAdditional\tSupports\tto\tBetter\tEvaluate\tTeaching\nYes No Unclear\n46.5% \n27.9% \n11.6% \n9.3% \nUSRI\tDeficiency\tfor\tDifferent\tClass\tMethods\nNot\tEnough\tTime\t&\tResources\tfor\tAdditional\tTools\nUSRI\tIssues\twith\tGender\t&\tMinorities\nIssues\twith\tSenior\tFaculty\nFigure\t17.\tIssues\tEncountered\twhen\tEvaluating\tTeaching\n\t 15\t\nAmong\tthe\tmost\tcommonly\tlisted\ttypes\tof\tsupports\tto\tbetter\tevaluate\tteaching,\tparticipants\tmentioned\tthat\tideally,\tthey\t\nwould\t implement\t peer\t in-class\t observations\t not\t only\t for\t promotion\t purposes,\t but\t across\t their\t department\t (41.9%),\t\nobtain\tuniversity\tguidelines\tto\tunderstand\thow\tto\taccurately\tand\teffectively\tevaluate\tteaching\t(27.9%)\t(see\tFigure\t18):\t\nMy\tlearning\tcurve\tcoming\tin\tto\tthe\tchair\trole\thas\tbeen\thuge.\tWe\tused\tto\thave\ta\tchair’s\tschool\tkind\tof\tthing.\tNow\t\nthere’s\tthe\tgold\tand\tgreen\tleadership\tcollege\tor\twhatever\tit’s\tcalled,\tand\tit’s\ta\tvery\tdifferent\tthing.\tSo,\tyou\ttransition\t\ninto\tchair\tnow\tand\tyou’re\ton\tyour\town.\tYou’ve\tgot\tto\tgo\tfigure\tit\tout,\task\tpeople\tfor\tcoffee,\tand\tlearn\tup,\tbut\tthere’s\t\nno\torientation\tto\tbeing\ta\tchair.\t\nSome\t also\t indicated\t that\t it\t would\t be\t useful\t to\t gain\t access\t to\t teaching\t training\t and\t workshops\t that\t they\t could\t refer\t\nstruggling\tprofessors\tto\t(when\tnot\tavailable\tin\ttheir\tdepartments)\t(20.9%),\thave\tdiscipline\tspecific\tconcept\tinventories\tto\t\nbetter\t determine\t the\t knowledge\t increase\t in\t students\t (11.6%),\t implement\t peer\t support\t initiatives\t to\t improve\t teaching\t\npractices\t (11.6%),\t video\t record\t lectures\t for\t later\t analysis\t of\t the\t quality\t of\t teaching\t (7%),\t request\t pedagogical\t self-\nreflections\t in\twhich\tprofessors\t give\t a\t thoughtful\t summary\tof\t their\t teaching\t (7%),\t and\t review\tclass\tmaterials\t to\thave\ta\t\nbetter\tpanorama\tof\tthe\tinstructor\t(4.7%)\t(see\tFigure\t18).\tHaving\tmore\tresources\tto\tbetter\tevaluate\tteaching\tis\timportant,\t\nas\tone\tof\tthem\tmentioned:\t\nI\tthink\twe\tneed\tsupport\tto\tdevelop\tour\town\tteaching\tskills\tmore\tcomfortably\tso\twe\tcan\tbe\texcellent\tteachers,\tbut\t\nalso\tit\twould\tbe\timportant\tto\tmake\tsure\tour\tinstruments\tare\tvalid\tand\tthat\twe\tcan\tactually\tuse\tthem\ton\ta\tjourney\tof\t\nself-improvement,\tand\tdepartmental\tculture\tand\timprovement.\tAnd\tto\tdo\tthat\thaving\tsome\tfacilitation\tfrom\tpeople\t\nwho\tknow\tthe\tart\tand\twho\tcan\twork\twith\tus\twould\tbe\tbetter\tthan\tjust\thaving\ta\tlist\tof\tstuff\ton\ta\twebsite\twhere\tyou\t\ndo\tclick,\tclick,\tand\taccess\twhat\tyou\twant.\tThat’s\tnot\tenough.\t\n41.9% \n27.9% \n20.9% \n11.6% \n11.6% \n7.0% \n7.0% \n4.7% \nImplement\tPeer\tObservations\nObtain\tGuidelines\tto\tEvaluate\tTeaching\nAccess\tTraining\t&\tWorkshops\tfor\tStruggling\tProfessors\nDiscipline\tSpecific\tConcept\tInventories\nGenerate\tPeer\tSupport\tInitiatives\nVideo\tRecord\tLectures\nRequest\tPedagogical\tSelf-Reflections\nReview\tClass\tMaterials\nFigure\t18.\tMost\tCommon\tIdeal\tTypes\tof\tSupports\tto\tBetter\tEvaluate\tTeaching\n\t 16\t\n4.5. Difference\tBetween\tTeaching\tEvaluation\tfor\tAnnual\tReview\t&\tPromotion\t\nEven\tthough\tevaluation\tof\tteaching\tfor\tannual\treview\tand\tfor\tpromotion\twas\ta\tdifferent\tprocess\tfor\t68.3%,\tand\tthe\tsame\t\nprocess\tfor\t26.8%\tof\tparticipants\t(see\tFigure\t19),\tboth\tends\tof\tthe\tspectrum\tseem\tto\tagree\tthat\tmore\tcomponents\twere\t\ntaking\tinto\tconsideration\twhen\tthey\twere\tdealing\twith\tpromotion:\t\nThe\tannual\treview\tlooks\tonly\tat\tthat\tyear,\tand\tif\tthere’s\treal\tconcerns\tthen\tyou’ll\t look\tfor\ttrends,\twhereas\twhen\tit\t\ncomes\tto\tpromotion,\t it\t looks\tto\ta\tcareer,\twhat\thas\tthis\t individual\tbeen\tdoing\twith\tteaching,\tand\tnot\tjust\tthis\tyear\t\nbut\t intentionally\t over\t the\t entire\t career.\tWhen\t it\t comes\t to\t application\t promotion,\t there\t is\t a\t larger\t view\t taken\t of\t\nteaching.\t\n4.6. Characteristics\tof\tEffective\t&\tExcellent\tTeachers\t\nEven\tthough\tmost\tparticipants\tstruggled\twith\tthe\tbreadth\tof\tthis\tquestion,\tfor\tthem\tan\teffective\tand/or\texcellent\tteacher\t\nappropriately\tconveys\tthe\tknowledge\tand\tthe\tskills\t that\tstudents\tneed\tto\tobtain\t(58.1%),\tengages\tstudents\tdespite\tthe\t\ndifficulty\tof\tthe\tcourse\tmaterial\t(46.5%),\tgets\thigh\tUSRI\tscores\tand\tteaching\tawards\t(30.2%),\t innovates\tin\ttheir\tteaching\t\npractices\t(23.3%),\tknows\thow\tto\tchallenge\tstudents\twithout\tburning\tthem\tout\t(18.6%),\tregularly\tupdates\tthe\tinformation\t\nand\t the\tmaterial\t of\t the\t course\t (18.6%),\t and\tengages\t in\t scholarship\tof\t teaching\t and\t learning\t related\t activities\t (18.6%).\t\nOther\t participants\t indicated\t that\t being\t supportive\t of\t students\t was\t also\t important\t (14%),\t seeking\t professional\t\ndevelopment\topportunities\tto\timprove\ttheir\tpedagogical\tpractices\t(7%),\tand\tlearning\tfrom\tstudents\tas\tmuch\tas\tstudents\t\nlearn\tfrom\tthem\t(4.7%)\t(see\tFigure\t21):\t\nI\ttry\tto\tavoid\tdefinitions\tif\tthat\tinvolves\tany\tkind\tof\texplicit\tcriteria.\tWhat\tI\tlook\tfor,\twhat\tI\tthink\tis\tmost\timportant\tin\t\nteaching\tis\tthat\tall\tgood\tteaching\tis\ttransformative.\tAnd\tit’s\tmostly\ttransformative\tfor\tthe\tstudent,\talthough\ttruth\tbe\t\nknown\tgood\tteaching\tis\ttransformative\tfor\tboth\tstudent\tand\tteacher.\t\nALES BUS ART\nART\nART\nAU\nG\nAU\nG\nEDU EN\nG\nENG\nFOMD\nFOMD\nRM\nRM\nSCI\nSCI\nND\nND\nA\tDifferent\tProcess\nThe\tSame\tProcess\nUnclear\nFigure\t19.\tPerceived\tDifferences\tbetween\tEvaluation\tof\tTeaching\tfor\tAnnual\tReview\t&\tPromotion\n58.1% \n46.5% \n30.2% \n23.3% \n18.6% \n18.6% \n18.6% \n14.0% \n7.0% \n4.7% \nConvey\tKnowledge\t&\tSkills\tto\tStudents\nEngage\tStudents\nGet\tHigh\tUSRI\tScores\t&\tAwards\nInnovate\nChallenge\tStudents\nUpdate\tInformation\t&\tMaterial\nEngage\tin\tthe\tSoTL\nSupportive\tof\tStudents\nSeek\tProfessional\tDevelopment\nLearn\tfrom\tStudents\nFigure\t20.\tCharacteristics\tof\tEffective\t&\tExcellent\tTeachers\n68.3% \n26.8% \n4.9% \n\t 17\t\n4.7. Experiences\tTransitioning\tto\te-USRI\tCompared\tto\tPaper-Based\tUSRI\t\nFROM\tTHIS\tPOINT\tON\tINFORMATION\tONLY\tCONSIDERS\tPARTICIPANTS\tWHO\tREPORTED\tUSING\tUSRI\t\nMost\tparticipants\tbelieved\tthat\tresponse\trates\thave\tdecreased\tsince\tthe\timplementation\tof\tthe\te-USRI:\t48.6%\thad\tsome\t\ndata\t to\t back\t up\t this\t claim,\t such\t as\t their\t personal\t USRI\t response\t rates,\t or\t the\t actual\t number\t of\t students\t that\t now\t\ncomplete\tthe\tevaluations\tcompared\tto\tprevious\tyears;\tand\t18.9%\tbelieved\tthat\tthe\tresponse\trates\thad\tdeclined,\tbut\thad\t\nno\tdata\t to\tsupport\t this\tclaim.\tAlternatively,\t21.6%\tof\tparticipants\tbelieved\t there\twas\ta\tsimilar\t response\t rate\twith\tboth\t\nmethods\tof\tdelivery,\t8.1%\tthought\tthat\t it\t increased\twith\tthe\tswitch\tto\telectronic,\tbut\tdid\tnot\toffer\tdata\tto\tsupport\tthis\t\nclaim\t (see\tFigure\t21).\tMoreover,\t some\tparticipants\t (8.1%)\tbelieved\t that\ta\tmajor\t issue\twith\tUSRI\t response\t rates\t is\t that\t\nstudents\tare\tasked\tto\tcomplete\ta\tlarge\tamount\tof\tassessments:\t\nI\t think\t they\t get\t completely\t annoyed\t because\t they’re\t being\t bombarded\twith\t e-mails\t in\t their\t last\tweek\t of\t classes\t\nreminding\tthem\tto\tdo\tUSRIs,\tand\tprofessors\treminding\tthem\tto\tdo\tUSRIs\tto\tthe\tpoint\twhere\tI\tthink\tthey\tjust\tgo:\tI’m\t\nreally\tannoyed.\tI’m\tnot\tgoing\tto\tdo\tthem\tat\tall.\tI\tdon’t\tknow\twhat\tkind\tof\ta\tsystem\tthey\tuse\tto\tsend\tthem\tout,\tbut\t\nit’s\talmost\tlike\tthey\tsend\tout\tone\tfor\tevery\tclass,\tfor\tevery\tstudent,\tso\tthey’re\tjust\tharassing\tthem\tto\tdeath\tand\tthey\t\nget\tmad\tabout\tit.\t\n18.9% 48.6% 21.6% 8.1% \n2.\n7%\nFigure\t21.\tReported\tResponse\tRate\tExperiences\twith\te-USRI\tcompared\tto\tPaper-Based\tUSRI\nDecline\t(no\tdata) Decline\t(some\tdata) Same Increase Unclear\n\t 18\t\n\t 19\t\n5. Conclusions\t\nHow\tare\tthe\tUSRIs\tand\tother\ttools\tused\tin\tthe\tevaluation\tof\tteaching\tevaluation\tat\tthe\tUniversity\tof\tAlberta?\t\n• Participants\t from\t all\t faculties\t other\t than\t FOMD\t use\tUSRI\t scores\t and\t comments\t (and\t only\t a\t portion\t of\t\nparticipants\tfrom\tFOMD)\tto\tevaluate\tteaching.\t\n• Statement\t221\t(overall\tthe\tinstructor\twas\texcellent),\tand\tstatement\t25\t(overall\tthe\tquality\tof\tthe\tcourse\t\ncontent\twas\texcellent)\tare\tthe\tmost\tcommonly\tused\tUSRI\titems\tto\tevaluate\tteaching.\t\n• Most\tparticipants\ttry\tto\tcontextualize\ttheir\tinterpretation\tof\tUSRI\tresults.\t\nWhat\tare\tsome\tapproaches\tfor\tmulti-faceted\tevaluation\tof\tteaching?\t\n• In-class\tpeer\tteaching\tobservations\twere\tthe\tmost\tcommonly\tused\tadditional\tsource\tof\tinformation,\tfollowed\t\nby\tannual\tinstructor\tpedagogical\tself-reflections.\t\n• Most\tparticipants\tobtain\tthese\tresources\ton\ta\tvoluntary\tbasis,\tonly\twhen\tprofessors\tagree\tto\tgive\tthem\tthese\t\nsupplementary\tresources.\t\n• Some\t participants\t have\t implemented\t yearly\t faculty\t audits,\t in\t which\t a\t manageable\t portion\t of\t their\t\nprofessorate’s\tteaching\tis\tevaluated\tusing\tadditional\tinformation.\t\n• Even\twhen\tparticipants\tobtain\tthese\tresources,\tnot\tall\treported\tto\tbring\tthem\tto\tFEC.\tWhen\tthis\tinformation\t\nmakes\tit\tto\tFEC,\tit\tis\tused\tto\tinform\ttheir\tnarrative,\tand\tis\tonly\texplicitly\tbrought\tup\twhen\tthere\tis\ta\tchallenge.\t\n• Participants\trecognized\tthat\tthere\tis\tstill\ta\tstrong\tbias\ttowards\tresearch\tat\ttheir\trespective\tFEC.\t\n• Most\tparticipants\tvoiced\ttheir\tneed\tfor\tadditional\tsupports\tto\tbetter\tevaluate\tteaching.\t\n• They\t have\t identified\t some\t issues\t when\t evaluating\t teaching\t exclusively\t with\t USRI,\t and\t possible\t\nalternatives\tto\tsupplement\tthese\tscores,\tbut\tstill\tthey\thope\tthe\tinstitution\tprovides\ta\tsolution\tfor\ttheir\t\nconcerns.\t\n\t 20\t\n\t 21\t\n6. Appendix\t1:\tSemi-Structured\tInterview\tQuestions\t\nStudy\tTitle:\tEvaluation\tof\tTeaching\tat\tthe\tUniversity\tof\tAlberta\t\n1. Demographics\t\t\na. Identify\tdepartment/faculty\t\t\nb. Number\tof\tfaculty/\tFSOs\twho\tteach\t\t\nc. Number\tof\tsessionals\twho\tteach\t\nd. Number\tof\tgraduate\tstudents\twho\tteach\t\n2. How\tdo\tyou\tevaluate\tteaching?\t\t\t\na. Do\tyou\t(or\tyour\tFEC)\tuse\tUSRIs\tto\tevaluate\tthe\tteaching\tof\tyour\tfaculty\tmembers?\t\t\nb. If\tyes,\twhich\tof\tthe\tfollowing\tstandard\tUSRI\tstatements\tare\tconsidered\tin\tyour\tfaculty’s\tteaching\tevaluation\t\nprocess?\t\ni. the\tgoals\tand\tobjectives\tof\tthe\tcourse\twere\tclear\t\t\nii. in-class\ttime\twas\tused\teffectively\t\t\niii. I\tam\tmotivated\tto\tlearn\tmore\tabout\tthese\tsubject\tareas\t\t\niv. I\tincreased\tmy\tknowledge\tof\tthe\tsubject\tareas\tin\tthis\tcourse\t\t\nv. Overall\tthe\tquality\tof\tthe\tcourse\tcontent\twas\texcellent\t\t\nvi. the\tinstructor\tspoke\tclearly\t\t\nvii. the\tinstructor\twas\twell\tprepared\t\t\nviii. the\tinstructor\ttreated\tstudents\twith\trespect\t\t\nix. the\tinstructor\tprovided\tconstructive\tfeedback\tthroughout\tthis\tcourse\t\t\nx. overall\tthis\tinstructor\twas\texcellent\t\t\n3. How\tdo\tyou\tcompare\tyour\texperience\twith\te-USRIs\tand\tin-class\tpaper-based\tUSRIs?\t\n4. What,\tif\tany,\tadditional\ttools\tdo\tyou\tregularly\tuse,\tother\tthan\tUSRI\tto\tevaluate\tteaching?\tIf\tyou\tdon’t,\twhy\tnot?\t\t\n5. Do\tyou\tuse\tadditional\tsources\tof\tinformation\tto\tevaluate\tteaching?\tIf\tso,\twhat\tinformation\tdo\tyou\tuse\tand\thow\tare\t\nthese\tsources\tof\tinformation\tweighted\tin\tteaching\tevaluations?\tWhy?\t\n6. Do\tyou\tbelieve\tmost\tof\tthe\tFEC\tmembers\tweight\tteaching,\tresearch\tand\tservice\tequally?\tIf\tnot,\tdescribe\tthe\taverage\t\nweighting,\tin\tyour\topinion.\t\t\n7. How\tis\tevaluation\tof\tteaching\tdifferent\t(or\tnot)\tfor\tannual\treview,\tor\tfor\tpromotion?\t\n8. How\tdo\tyou\tdefine\teffective\tand/or\texcellent\tteaching?\tDo\tyou\thave\tset\tstandards,\tor\tdo\tyou\tmake\ta\trelative\t\ncomparison?\t\t\n9. What\tadditional\tsupports\twould\tbe\tuseful\tto\tyou\tto\tbetter\tevaluate\tteaching?\t\n\t 22\t\n\t 23\t\n7. Appendix\t2:\tSample\tUSRI\tResults\tfor\tDepartment\tChairs\t\nStudy\tTitle:\tEvaluation\tof\tTeaching\tat\tthe\tUniversity\tof\tAlberta\t\nPlease\t look\t at\t the\t USRI\t information\t provided\t for\t two\t different\t instructors\t teaching\t the\t same\t course.\t How\twould\t you\t\ndescribe\tthe\tinstructors’\tteaching\tto\tFEC?\t\t\tOR\t\t\tIn\tterms\tof\tevaluating\tteaching,\twhat\tis\tyour\tinterpretation\tof\tthis\tdata\tfor\t\neach\tinstructor?\t\nInstructor\tA\t\n\t \t \t \t \t \t \t \t \t Reference\tData\t\nQuestion\t\nMedian\t Tukey\t\t\nFence\t 25%\t 50%\t 75%\t\nThe\tgoals\tand\tobjectives\tof\tthe\tcourse\twere\tclear\t 3.4\t 2.7\t 3.9\t 4.3\t 4.7\t\nIn-class\ttime\twas\tused\teffectively.\t 3.6\t 2.5\t 3.8\t 4.3\t 4.7\t\nI\tam\tmotivated\tto\tlearn\tmore\tabout\tthese\tsubject\tareas.\t 3.5\t 2.9\t 4.1\t 4.5\t 4.8\t\nI\tincreased\tmy\tknowledge\tof\tthe\tsubject\tareas\tin\tthis\tcourse.\t 4.4\t 3.0\t 4.1\t 4.6\t 4.8\t\nOverall,\tthe\tquality\tof\tthe\tcourse\tcontent\twas\texcellent.\t 3.8\t 2.4\t 3.8\t 4.3\t 4.8\t\nThe\tinstructor\tspoke\tclearly.\t 4.5\t 3.8\t 4.5\t 4.8\t 4.9\t\nThe\tinstructor\twas\twell\tprepared.\t 4.6\t 3.4\t 4.3\t 4.8\t 4.9\t\nThe\tinstructor\ttreated\tthe\tstudents\twith\trespect.\t 4.0\t 4.2\t 4.7\t 4.9\t 5.0\t\nThe\tinstructor\tprovided\tconstructive\tfeedback\tthroughout\tthis\tcourse.\t 4.5\t 2.8\t 4.0\t 4.5\t 4.8\t\nOverall,\tthis\tinstructor\twas\texcellent.\t 4.0\t 3.2\t 4.2\t 4.7\t 4.9\t\nInstructor\tB\t\n\t \t \t \t \t \t \t \t \t \t \t \t Reference\tData\t\nQuestion\t\nMedian\t Tukey\t\t\nFence\t 25%\t 50%\t 75%\t\nThe\tgoals\tand\tobjectives\tof\tthe\tcourse\twere\tclear\t 4.0\t 2.7\t 3.9\t 4.3\t 4.7\t\nIn-class\ttime\twas\tused\teffectively.\t 4.2\t 2.5\t 3.8\t 4.3\t 4.7\t\nI\tam\tmotivated\tto\tlearn\tmore\tabout\tthese\tsubject\tareas.\t 3.7\t 2.9\t 4.1\t 4.5\t 4.8\t\nI\tincreased\tmy\tknowledge\tof\tthe\tsubject\tareas\tin\tthis\tcourse.\t 4.1\t 3.0\t 4.1\t 4.6\t 4.8\t\nOverall,\tthe\tquality\tof\tthe\tcourse\tcontent\twas\texcellent.\t 4.2\t 2.4\t 3.8\t 4.3\t 4.8\t\nThe\tinstructor\tspoke\tclearly.\t 4.7\t 3.8\t 4.5\t 4.8\t 4.9\t\nThe\tinstructor\twas\twell\tprepared.\t 4.4\t 3.4\t 4.3\t 4.8\t 4.9\t\nThe\tinstructor\ttreated\tthe\tstudents\twith\trespect.\t 4.8\t 4.2\t 4.7\t 4.9\t 5.0\t\nThe\tinstructor\tprovided\tconstructive\tfeedback\tthroughout\tthis\tcourse.\t 4.0\t 2.8\t 4.0\t 4.5\t 4.8\t\nOverall,\tthis\tinstructor\twas\texcellent.\t 4.5\t 3.2\t 4.2\t 4.7\t 4.9\t\nAppendix C: Interview Questions \nStudy Title: ​Evaluation of Teaching at the University of Alberta \n1. Demographics \na.​   ​Identify department/faculty \nb.​  ​Number of faculty/ FSOs who teach \nc.​   ​Number of sessionals who teach \nd.​  ​Number of graduate students who teach \n2. How do you evaluate teaching?  \na.​   ​Do you (or your FEC) use USRIs to evaluate the teaching of your faculty members? \nb.​  ​If yes, which of the following standard USRI statements are considered in your \nfaculty’s teaching evaluation process? \n                                        ​i.​              ​the goals and objectives of the course were clear \nii.​           ​in-class time was used effectively \niii.​          ​I am motivated to learn more about these subject areas \niv.​         ​I increased my knowledge of the subject areas in this course \nv.​          ​Overall the quality of the course content was excellent \nvi.​         ​the instructor spoke clearly \nvii.​        ​the instructor was well prepared \nviii.​       ​the instructor treated students with respect \nix.​         ​the instructor provided constructive feedback throughout this course \nx.​          ​overall this instructor was excellent \n3. How do you compare your experience with e-USRIs and in-class paper-based USRIs? \n4. What, if any, additional tools do you regularly use, other than USRI to evaluate teaching? If \nyou don’t, why not? \n5. Do you use additional sources of information to evaluate teaching? If so, what information \ndo you use and how are these sources of information weighted in teaching evaluations? \nWhy? \n6. Do you believe most of the FEC members weight teaching, research and service equally? If \nnot, describe the average weighting, in your opinion. \n7. How is evaluation of teaching different (or not) for annual review, or for promotion? \n8. How do you define effective and/or excellent teaching? Do you have set standards, or do \nyou make a relative comparison? \n9.    What additional supports would be useful to you to better evaluate teaching? \nAppendix D: Sample USRI Case Studies \nStudy Title: ​Evaluation of Teaching at the University of Alberta \nPlease look at the USRI information provided for two different instructors teaching the same \ncourse. How would you describe the instructors’ teaching to FEC?   OR   In terms of evaluating \nteaching, what is your interpretation of this data for each instructor? \nInstructor A \nReference Data \nQuestion Median Tukey \nFence \n25% 50% 75% \nThe goals and objectives of the course were clear 3.4 2.7 3.9 4.3 4.7 \nIn-class time was used effectively. 3.6 2.5 3.8 4.3 4.7 \nI am motivated to learn more about these subject areas. 3.5 2.9 4.1 4.5 4.8 \nI increased my knowledge of the subject areas in this course. 4.4 3.0 4.1 4.6 4.8 \nOverall, the quality of the course content was excellent. 3.8 2.4 3.8 4.3 4.8 \nThe instructor spoke clearly. 4.5 3.8 4.5 4.8 4.9 \nThe instructor was well prepared. 4.6 3.4 4.3 4.8 4.9 \nThe instructor treated the students with respect. 4.0 4.2 4.7 4.9 5.0 \nThe instructor provided constructive feedback throughout this \ncourse. \n4.5 2.8 4.0 4.5 4.8 \nOverall, this instructor was excellent. 4.0 3.2 4.2 4.7 4.9 \nInstructor B \nReference Data \nQuestion Median Tukey \nFence \n25% 50% 75% \nThe goals and objectives of the course were clear 4.0 2.7 3.9 4.3 4.7 \nIn-class time was used effectively. 4.2 2.5 3.8 4.3 4.7 \nI am motivated to learn more about these subject areas. 3.7 2.9 4.1 4.5 4.8 \nI increased my knowledge of the subject areas in this course. 4.1 3.0 4.1 4.6 4.8 \nOverall, the quality of the course content was excellent. 4.2 2.4 3.8 4.3 4.8 \nThe instructor spoke clearly. 4.7 3.8 4.5 4.8 4.9 \nThe instructor was well prepared. 4.4 3.4 4.3 4.8 4.9 \nThe instructor treated the students with respect. 4.8 4.2 4.7 4.9 5.0 \nThe instructor provided constructive feedback throughout this \ncourse. \n4.0 2.8 4.0 4.5 4.8 \nOverall, this instructor was excellent. 4.5 3.2 4.2 4.7 4.9 \nAppendix E: Summary of Positions and Recommendations Related to USRIs in University \nof Alberta Policy, Documents, and Reports \nStudent input should be \nsought in teaching \nevaluation using USRIs or \nsimilar instruments \nX  X    \nPurpose of USRI must be \nclarified X X     \nOpen-ended comments \nshould be included  X     \nOpen-ended comments \nshould not be included   X    \nOpen-ended comments: \nstudent identities should not \nbe included in reports to \ninstructors but kept on \nrecord (for the protection of \ninstructors and students) \n  X X   \nUse and administration of \nUSRI must be considered in \nbroader context (not just \nfocused on teaching) \nX X     \nUSRI is outdated, lacks \nvalidation, and needs \nredevelopment \nX X X    \n(Table continued on next page) \n1 \n(Table, continued) \nRequired​ USRI items need \nto be modified to apply to \nmultiple teaching contexts; \nadditional (optional) question \nvariants should be \ndeveloped that apply to \ndiverse teaching contexts \n(e.g. labs, clinical, blended) \n    X  \nA professionally developed \ninstrument should be \ncreated to ensure validity \nand reliability \nX X X    \nA moratorium on USRI use \nshould be implemented until \nredevelopment occurs; \ndeadline end of 2015 Fall \nterm \n  X    \nUSRIs should be used as \npart of a broader teaching \nevaluation, not the sole \nmeasure of teaching \nperformance \nX  X X  X \nConcern that “the instructor \nwas excellent” is the only \nUSRI item used in FEC \nassessments \n X X    \n(Table continued on next page) \n2 \n(Table, continued) \nThere are aspects of \nteaching that students \ncannot evaluate \nX   X   \n(End of table) \n3 \nAppendix F: ​Summary of Positions and Recommendations Related to Multifaceted \nEvaluation in University of Alberta Policy, Documents, and Reports \nTeaching evaluation should \nbe multifaceted X X X X  X \nChairs, Deans, Supervisors \nand Faculty may struggle \nwith implementing \nmultifaceted evaluation and \nrequire support \nX X     \nA multifaceted teaching \nevaluation guide should be \ndeveloped, including \ndefinitions, strategies, and \nexamples \nX X X    \nFEC decisions regarding \npromotion and tenure must \nbe based on multiple \nindicators of teaching; this \nmay not have been \nconsistently applied in the \npast \nX  X X  X \nPeer review should be a part \nof evaluation for tenure and \npromotion \n  X    \n(Table continued on next page) \n1 \n(Table, continued) \nEvaluation of teaching \nshould include broader \nteaching duties, such as \ngraduate student supervision \nand mentoring, course \ndesign, curriculum \ndevelopment, etc. \n  X    \nOpportunities for teacher \ntraining and support are \nneeded \n  X X   \n(End of table) \n2 \nAppendix G: References for Reviewed Literature \nThese are the references used to review the literature only. Other references consulted for \npreparation of the report (such as University of Alberta reports and documents) are included at \nthe end of the report. \nAl-Eidan, F., Baig, L. A., Magzoub, M., & Omair, A. (2016). Reliability and validity of the faculty \nevaluation instrument used at King Saud bin Abdulaziz University for Health Sciences: \nResults from the haematology course. ​The Journal of the Pakistan Medical Association, \n66​(4), 453-457. ​http://www.jpma.org.pk/full_article_text.php?article_id=7711 \nBacker, E. (2012). Burnt at the student evaluation stake – the penalty for failing students. \nE-Journal of Business Education & Scholarship of Teaching, 6​(1), 1-13. Retrieved from \nhttp://www.ejbest.org/upload/eJBEST_Backer_2012_1.pdf \nBedggood, R. E., & Donovan, J. D. (2012). University performance evaluations: What are we \nreally measuring? ​Studies in Higher Education, 37​(7), 825-842. \nhttp://dx.doi.org/10.1080/03075079.2010.549221 \nBerk, R. A. (2013). Top five flashpoints in the assessment of teaching effectiveness. ​Medical \nTeacher, 35​(1), 15-26.​ ​http://dx.doi.org/10.3109/0142159X.2012.732247 \nBlackhart, G. C., Peruche, B. M., DeWall, C. N., & Joiner, T. E., Jr. (2006). Faculty forum: \nFactors influencing teaching evaluations in higher education. ​Teaching of Psychology, \n33​(1), 37-39. ​http://dx.doi.org/10.1207/s15328023top3301_9 \nBlair, E., & Valdez Noel, K. (2014). Improving higher education practice through student \nevaluation systems: is the student voice being heard? ​Assessment & Evaluation in \nHigher Education, 39​(7), 879-894.​ ​http://dx.doi.org/10.1080/02602938.2013.875984 \nBoring, A., Ottoboni, K., & Stark, P. B. (2016). Student evaluations of teaching (mostly) do not \nmeasure teaching effectiveness. ​ScienceOpen Research, 2016​(1). \nhttp://dx.doi.org/10.14293/S2199-1006.1.SOR-EDU.AETBZC.v1  \nBoysen, G.A. (2015). Uses and misuses of student evaluations of teaching: The interpretation of \ndifferences in teaching evaluation means irrespective of statistical information. ​Teaching \nof Psychology, 42​(2), 109-118.​ ​http://dx.doi.org/10.1177/0098628315569922 \nBoysen, G. A., Kelly, T. J., Raesly, H. N., & Casner, R. W. (2014). The (mis)interpretation of \nteaching evaluations by college faculty and administrators. ​Assessment & Evaluation in \nHigher Education, 39​(6), 641-656.​ ​http://dx.doi.org/10.1080.02602938.2013.860950 \nBrown, G. D. A., Wood, A. M., Ogden, R. S., & Maltby, J. (2014). Do student evaluations of \nuniversity reflect inaccurate beliefs or actual experience? A relative rank model.​ Journal \nof Behavioral Decision Making, 28​, 14-26. ​http://dx.doi.org/10.1002/bdm.1827 \nCampbell, J. P., & Bozeman, W. C. (2008). The value of student ratings: Perceptions of \nstudents, teachers, and administrators. ​Community College Journal of Research and \nPractice, 32​, 13-24.​ ​http://dx.doi.org/10.1080/10668920600864137 \nCentra, J.A. (2003). Will teachers receive higher student evaluations by giving higher grades \nand less course work? ​Research in Higher Education, 44​(5), 495-518. \nhttp://www.jstor.org.login.ezproxy.library.ualberta.ca/stable/40197319 \nCentra, J. A., & Gaubatz, N. B. (2000). Is there gender bias in student evaluations of teaching? \nhttp://dx.doi.org/10.1080.02602938.2013.860950\nhttp://dx.doi.org/10.1080/10668920600864137\nhttp://dx.doi.org/10.1080/03075079.2010.549221\nhttp://dx.doi.org/10.1002/bdm.1827\nhttp://www.ejbest.org/upload/eJBEST_Backer_2012_1.pdf\nhttp://www.jstor.org.login.ezproxy.library.ualberta.ca/stable/40197319\nhttp://dx.doi.org/10.1080/02602938.2013.875984\nhttp://dx.doi.org/10.1080/02602938.2013.875984\nhttp://dx.doi.org/10.1080/10668920600864137\nhttp://dx.doi.org/10.3109/0142159X.2012.732247\nhttp://dx.doi.org/10.1207/s15328023top3301_9\nhttp://dx.doi.org/10.3109/0142159X.2012.732247\nhttp://dx.doi.org/10.1177/0098628315569922\nhttp://dx.doi.org/10.1177/0098628315569922\nhttp://dx.doi.org/10.14293/S2199-1006.1.SOR-EDU.AETBZC.v1\nhttp://dx.doi.org/10.1080.02602938.2013.860950\nhttp://www.jpma.org.pk/full_article_text.php?article_id=7711\nThe Journal of Higher Education, 71​(1), 17-44. \nhttp://login.ezproxy.library.ualberta.ca/login?url=http://search.ebscohost.com/login.aspx?\ndirect=true&db=edsjsr&AN=edsjsr.10.2307.2649280&site=eds-live&scope=site \nChen, Y., & Hoshower, L. B. (2003). Student evaluation of teaching effectiveness: an \nassessment of student perception and motivation. ​Assessment & Evaluation in Higher \nEducation, 28​(1), 71-88.​ ​http://dx.doi.org/10.1080/0260293032000033071 \nCheng, D. A. (2015). Effects of professorial tenure on undergraduate ratings of teaching \nperformance. ​Education Economics, 23​(3), 338-357. \nhttp://dx.doi.org/10.1080/09645292.2013.826632 \nCho, D., Baek, W., & Cho, J. (2015). Why do good performing students highly rate their \ninstructors? Evidence from a natural experiment. ​Economics of Education Review, 49​, \n172-179. ​http://dx.doi.org/10.1016/j.econedurev.2015.10.001 \nCho, J., & Otani, K. (2014). Differences in student evaluations of limited-term lecturers and \nfull-time faculty. ​Journal on Excellence in College Teaching, 25​(2), 5-24. \nhttp://opus.ipfw.edu/profstudies_facpubs/64 \nChonko, L. B., Tanner, J. F., & Davis, R. (2002). What are they thinking? Students’ expectations \nand self-assessments. ​Journal of Education for Business, 77​(5), 271-281. Retrieved \nfrom \nhttp://login.ezproxy.library.ualberta.ca/login?url=http://search.ebscohost.com/login.aspx?\ndirect=true&db=bth&AN=7214031&site=eds-live&scope=site \nClayson, D. E. (2013). Initial impressions and the student evaluation of teaching. ​Journal of \nEducation for Business, 88​(1), 26-53. ​http://dx.doi.org/10.1080/08832323.2011.633580 \nCohen, E. H. (2005). Student evaluations of course and teacher: factor analysis and SSA \napproaches. ​Assessment & Evaluation in Higher Education, 30​(2), 123-136. \nhttp://dx.doi.org/10.1080/0260293042000264235 \nCohen, P. A. (1981). Student ratings of instruction and student achievement: A meta-analysis of \nmultisection validity studies. ​Review of Educational Research, 51​(3), 281-309. \nCox, C.D., Peeters, M. J., Stanford, B. L., & Seifert, C. F. (2013). Pilot of peer assessment \nwithin experiential teaching and learning. ​Currents in Pharmacy Teaching and Learning, \n5​(4), 311-320.​ ​http://dx.doi.org/10.1016/j.cptl.2013.02.003 \nCurwood, J.S., Tomitsch, M., Thomson, K., & Hendry. G.D. (2015). Professional learning in \nhigher education: Understanding how academics interpret student feedback and access \nresources to improve their teaching. ​Australasian Journal of Educational Technology, \n31​(5).​ ​http://dx.doi.org/10.14742/ajet.2516 \nd’Apollonia, S., & Abrami, P. C. (1997). Navigating student ratings of instruction. ​American \nPsychologist, 52​(11), 1198-1208. ​http://dx.doi.org/10.1037/0003-066X.52.11.1198 \nDolmans, D. M., Janssen-Noordman, A., & Wolfhagen, H. P. (2006). Can students differentiate \nbetween PBL tutors with different tutoring deficiencies? Medical Teacher, 28(6), \n156-161. doi: 10.1080/01421590600776545 \nDodeen, H. (2013). Validity, reliability, and potential bias of short forms of students’ evaluation \nof teaching: The case of UAE University. ​Educational Assessment, 18​(4), 235-250. \nhttp://dx.doi.org/10.1080/10627197.2013.846670 \nFelton, J., Mitchell, J., & Stinson, M. (2004). Web-based student evaluations of professors: the \nhttp://dx.doi.org/10.14742/ajet.2516\nhttp://dx.doi.org/10.1080/0260293032000033071\nhttp://login.ezproxy.library.ualberta.ca/login?url=http://search.ebscohost.com/login.aspx?direct=true&db=edsjsr&AN=edsjsr.10.2307.2649280&site=eds-live&scope=site\nhttp://login.ezproxy.library.ualberta.ca/login?url=http://search.ebscohost.com/login.aspx?direct=true&db=bth&AN=7214031&site=eds-live&scope=site\nhttp://dx.doi.org/10.1016/j.cptl.2013.02.003\nhttp://dx.doi.org/10.1080/0260293042000264235\nhttp://dx.doi.org/10.14742/ajet.2516\nhttp://opus.ipfw.edu/profstudies_facpubs/64\nhttp://dx.doi.org/10.1080/08832323.2011.633580\nhttp://login.ezproxy.library.ualberta.ca/login?url=http://search.ebscohost.com/login.aspx?direct=true&db=edsjsr&AN=edsjsr.10.2307.2649280&site=eds-live&scope=site\nhttp://dx.doi.org/10.1016/j.econedurev.2015.10.001\nhttp://dx.doi.org/10.1080/0260293042000264235\nhttp://dx.doi.org/10.1037/0003-066X.52.11.1198\nhttp://login.ezproxy.library.ualberta.ca/login?url=http://search.ebscohost.com/login.aspx?direct=true&db=edsjsr&AN=edsjsr.10.2307.2649280&site=eds-live&scope=site\nhttp://login.ezproxy.library.ualberta.ca/login?url=http://search.ebscohost.com/login.aspx?direct=true&db=bth&AN=7214031&site=eds-live&scope=site\nhttp://dx.doi.org/10.1080/0260293032000033071\nhttp://dx.doi.org/10.1016/j.cptl.2013.02.003\nhttp://dx.doi.org/10.1080/10627197.2013.846670\nhttp://dx.doi.org/10.1080/10627197.2013.846670\nhttp://dx.doi.org/10.1080/09645292.2013.826632\nrelations between perceived quality, easiness and sexiness. ​Assessment & Evaluation in \nHigher Education, 29​(1), 91-108.​ ​http://dx.doi.org/10.1080/0260293032000158180 \nFraile, R., & Bosch-Morell, F. (2015). Considering teaching history and calculating confidence \nintervals in student evaluations of teaching quality: An approach based on Bayesian \ninference. ​Higher Education, 70​(1), 55-72.​ ​http://dx.doi.org/10.1007/s10734-014-9823-0 \nGehrt, K., Louie, T. A., & Osland, A. (2015). Student and professor similarity: Exploring the \neffects of gender and relative age. ​Journal of Education for Business, 90​, 1-9. \nhttp://dx.doi.org/10.1080/08832323.2014.968514  \nGinns, P., Prosser, M., & Barrie, S. (2007). Students’ perceptions of teaching quality in higher \neducation: the perspective of currently enrolled students. ​Studies in Higher Education, \n32​(5), 603-615. ​http://dx.doi.org/10.1080/03075070701573773 \nGrammatikopoulos, V., Linardakis, M., Gregoriadis, A., & Oikonomidis, V. (2015). Assessing the \nstudents’ evaluations of educational quality (SEEQ) questionnaire in Greek higher \neducation. ​Higher Education, 70​(3), 395-408. \nhttp://dx.doi.org/10.1007/s10734-014-9837-7 \nGrayson, J. P. (2015). Repeated low teaching evaluations: A form of habitual behavior? \nCanadian Journal of Higher Education, 45​(4), 298-321. \nhttp://journals.sfu.ca/cjhe/index.php/cjhe/article/view/184404 \nGreenwald, A. G. (1997). Validity concerns and usefulness of student ratings of instruction. \nAmerican Psychologist, 52​(11), 1182-1186. \nhttp://dx.doi.org/10.1037/0003-066X.52.11.1182 \nGreenwald, A. G., Gillmore, G. M. (1997). Grade leniency is a removable contaminant of student \nratings. ​American Psychologist, 52​(11), 1209-1217. \nhttp://dx.doi.org/10.1037/0003-066X.52.11.1209 \nGreimel-Fuhrmann, B. (2014). Student’s perception of teaching behaviour and its effect on \nevaluation. ​International Journal for Cross-Disciplinary Subjects in Education, 5​(1), \n1557-1563.​ ​http://dx.doi.org/10.20533/ijcdse.2042.6364.2014.0218 \nGump, S.E. (2007). Student evaluations of teaching effectiveness and the leniency hypothesis: \nA literature review. ​Education Research Quarterly, 30​(3), 55-68. Retrieved from \nhttp://eric.ed.gov.login.ezproxy.library.ualberta.ca/?id=EJ787711 \nHuebner, L., & Magel, R. C. (2015). A gendered study of student ratings of instruction. ​Open \nJournal of Statistics, 5,​ 552-567. ​http://dx.doi.org/10.4236/ojs.2015.56058  \nHughes II, K. E., & Pate, G. R. (2013). Moving beyond student ratings: A balanced scorecard \napproach for evaluating teaching performance. Issues in ​Accounting Education, 28​(1), \n49-75.​ ​http://dx.doi.org/10.2308/iace-50302 \nIqbal, I. (2013). Academics’ resistance to summative peer review of teaching: questionable \nrewards and the importance of student evaluations. ​Teaching in Higher Education, 18​(5), \n557-569.​ ​http://dx.doi.org/10.1080/13562517.2013.764863 \nJackson, M. J., & Jackson, W. T. (2015). The misuse of student evaluations of teaching: \nImplications, suggestions and alternatives. ​Academy of Educational Leadership Journal, \n19​(3), 165-173. \nhttp://www.alliedacademies.org/academy-of-educational-leadership-journal/ \nJones, J., Gaffney-Rhys, R., & Jones, E. (2014). Handle with care! An exploration of the \nhttp://dx.doi.org/10.1037/0003-066X.52.11.1209\nhttp://dx.doi.org/10.1080/08832323.2014.968514\nhttp://dx.doi.org/10.2308/iace-50302\nhttp://dx.doi.org/10.1080/13562517.2013.764863\nhttp://dx.doi.org/10.1080/03075070701573773\nhttp://dx.doi.org/10.1007/s10734-014-9837-7\nhttp://www.alliedacademies.org/academy-of-educational-leadership-journal/\nhttp://dx.doi.org/10.1007/s10734-014-9823-0\nhttp://dx.doi.org/10.1080/0260293032000158180\nhttp://psycnet.apa.org/doi/10.1037/0003-066X.52.11.1182\nhttp://dx.doi.org/10.20533/ijcdse.2042.6364.2014.0218\nhttp://www.alliedacademies.org/academy-of-educational-leadership-journal/\nhttp://dx.doi.org/10.2308/iace-50302\nhttp://dx.doi.org/10.1080/13562517.2013.764863\nhttp://eric.ed.gov.login.ezproxy.library.ualberta.ca/?id=EJ787711\nhttp://journals.sfu.ca/cjhe/index.php/cjhe/article/view/184404\nhttp://psycnet.apa.org/doi/10.1037/0003-066X.52.11.1182\nhttp://journals.sfu.ca/cjhe/index.php/cjhe/article/view/184404\nhttp://dx.doi.org/10.1080/0260293032000158180\nhttp://dx.doi.org/10.1007/s10734-014-9823-0\nhttp://dx.doi.org/10.20533/ijcdse.2042.6364.2014.0218\nhttp://dx.doi.org/10.4236/ojs.2015.56058\nhttp://eric.ed.gov.login.ezproxy.library.ualberta.ca/?id=EJ787711\npotential risks associated with the publication and summative usage of student \nevaluation of teaching (SET) results. ​Journal of Further and Higher Education, 38​(1), \n37-56.​ ​http://dx.doi.org/10.1080/0309877X.2012.699514 \nKeeley, J. W., English, T., Irons, J., & Henslee, A. M. (2013). Investigating halo and ceiling \neffects in student evaluations of instruction. ​Educational and Psychological \nMeasurement, 73​(3), 440-457.​ ​http://dx.doi.org/10.1177/0013164412475300 \nKhong, T. L. (2014). The validity and reliability of the student evaluation of teaching: A case in a \nprivate higher educational institution in Malaysia. ​International Journal for Innovation \nEducation and Research, 2​(9), 57-63.​ ​http://www.ijier.net/index.php/ijier/article/view/317 \nKim, L. E., MacCann, C. (2016). What is students’ ideal university instructor personality? An \ninvestigation of absolute and relative personality preferences. ​Personality and Individual \nDifferences, 102​, 190-203. ​http://dx.doi.org/10.1016/j.paid.2016.06.068 \nKuwaiti, A. A., AlQuraan, M., & Subbarayalu, A. V. (2016). Understanding the effect of response \nrate and class size interaction on students evaluation of teaching in a higher education. \nEducational Assessment & Evaluation, 3​, \nhttps://doi.org/10.1080/2331186X.2016.1204082 \nLama, T., Arias, P., Mendoza, K. & Manahan, J. (2015). Student evaluation of teaching surveys: \ndo students provide accurate and reliable information? ​e-Journal of Social & Behavioural \nResearch in Business, 6​(1), 30-39.​ ​http://www.ejsbrb.org/a.php?/content/issue/10 \nLaube, H., Massoni, K., Sprague, J., & Ferber, A. L. (2007). The impact of gender on the \nevaluation of teaching: What we know and what we can do. ​NWSA Journal,​ ​19​(3), \n87-104. Retrieved from ​http://www.jstor.org/stable/40071230  \nLyde, A.R., Grieshaber, D.C., Byrns, G. (2016). Faculty teaching performance: Perceptions of a \nmulti-source method for evaluation (MME). ​Journal of the Scholarship of Teaching and \nLearning, 16​(3), 82-94.​ ​http://dx.doi.org/10.14434/josotl.v16i3.18145 \nMacfadyen, L. P., Dawson, S., Prest, S., & Gasevic, D. (2016). Whose feedback? A multilevel \nanalysis of student completion of end-of-term teaching evaluations. ​Assessment & \nEvaluation in Higher Education, 41​(6), 821-839. \nhttp://dx.doi.org/10.1080/02602938.2015.1044421 \nMacNell, L., Driscoll, A., & Hunt, A. N. (2015). What’s in a name: Exposing gender bias in \nstudent ratings of teaching. ​Innovative Higher Education, 40​, 291-303. \nhttp://dx.doi.org/10.1007/s10755-014-9313-4  \nMakondo, L., & Ndebele, C. (2014). University lecturers’ views on student-lecturer evaluations. \nAnthropologist, 17​(2), 377-386. \nhttp://www.krepublishers.com/02-Journals/T-Anth/Anth-17-0-000-14-Web/Anth-17-0-000\n-14-Contents/Anth-17-0-000-14-Contents.htm \nMarsh, H. W., & Roche, L. A. (1997). Making students’ evaluations of teaching effectiveness \neffective: The critical issues of validity, bias, and utility. ​American Psychologist, 52​(11), \n1187-1197. ​http://dx.doi.org/10.1037/0003-066X.52.11.1187 \nMartin, L. R., Dennehy, R., & Morgan, S. (2013). Unreliability in student evaluation of teaching \nquestionnaires: Focus groups as an alternative approach. ​Organization Management \nJournal, 10​(1), 66-74.​ ​http://dx.doi.org/10.1080/15416518.2013.781401 \nhttp://www.ijier.net/index.php/ijier/article/view/317\nhttp://www.jstor.org/stable/40071230\nhttp://dx.doi.org/10.1016/j.paid.2016.06.068\nhttps://doi.org/10.1080/2331186X.2016.1204082\nhttp://dx.doi.org/10.14434/josotl.v16i3.18145\nhttp://www.ejsbrb.org/a.php?/content/issue/10\nhttp://dx.doi.org/10.1177/0013164412475300\nhttp://dx.doi.org/10.1007/s10755-014-9313-4\nhttp://www.krepublishers.com/02-Journals/T-Anth/Anth-17-0-000-14-Web/Anth-17-0-000-14-Contents/Anth-17-0-000-14-Contents.htm\nhttp://dx.doi.org/10.1037/0003-066X.52.11.1187\nhttp://dx.doi.org/10.1080/0309877X.2012.699514\nhttp://dx.doi.org/10.1177/0013164412475300\nhttp://dx.doi.org/10.14434/josotl.v16i3.18145\nhttp://dx.doi.org/10.1080/15416518.2013.781401\nhttp://www.krepublishers.com/02-Journals/T-Anth/Anth-17-0-000-14-Web/Anth-17-0-000-14-Contents/Anth-17-0-000-14-Contents.htm\nhttp://www.krepublishers.com/02-Journals/T-Anth/Anth-17-0-000-14-Web/Anth-17-0-000-14-Contents/Anth-17-0-000-14-Contents.htm\nhttp://www.ijier.net/index.php/ijier/article/view/317\nhttp://dx.doi.org/10.1080/15416518.2013.781401\nhttp://www.ejsbrb.org/a.php?/content/issue/10\nhttp://dx.doi.org/10.1080/02602938.2015.1044421\nhttp://dx.doi.org/10.1080/0309877X.2012.699514\nhttp://dx.doi.org/10.1080/02602938.2015.1044421\nMaurer, T. W. (2006). Cognitive dissonance or revenge? Student grades and course \nevaluations. ​Teaching of Psychology, 33​(3), 176-179. \nhttp://dx.doi.org/10.1207/s15328023top3303_4 \nMcKeachie, W. J. (1997). Student ratings: The validity of use. ​American Psychologist, 52​(11), \n1218-1225. ​http://dx.doi.org/10.1037/0003-066X.52.11.1218 \nMerritt, D. J. (2012). Bias, the brain, and student evaluations of teaching. ​St. John’s Law \nReview, 82​(1), Article 6, 235-288. \nhttp://scholarship.law.stjohns.edu/lawreview/vol82/iss1/6 \nMiles, P., & House, D. (2015). The tail wagging the dog: An overdue examination of student \nteaching evaluations. ​International Journal of Higher Education, 4​(2). \nhttp://dx.doi.org/10.5430/ijhe.v4n2p116  \nMitry, D. J., & Smith, D. E. (2014). Student evaluations of faculty members: A call for analytical \nprudence. ​Journal on Excellence in College Teaching, 25​(2), 56-67. \nhttp://celt.miamioh.edu/ject/issue.php?v=25&n=2 \nMorley, D. D. (2012). Claims about the reliability of student evaluations of instruction: The \necological fallacy rides again. ​Studies in Educational Evaluation, 38​(1), 15-20. \nhttp://dx.doi.org/10.1016/j.stueduc.2012.01.001 \nNargundkar, S., & Shrikhande, M. (2012). An empirical investigation of student evaluations of \ninstruction: The relative importance of factors. ​Decision Sciences Journal of Innovative \nEducation, 10​(1), 117-135.​ ​http://dx.doi.org/10.1111/j.1540-4609.2011.00328.x \nNargundkar, S., & Shrikhande, M. (2014). Norming of student evaluations of instruction: Impact \nof noninstructional factors. ​Decision Sciences Journal of Innovative Education, 12​(1), \n55-72. ​http://dx.doi.org/10.1111/dsji.12023 \nO​tani, K., Kim, J., & Cho, J. (2012). Student evaluation of teaching (SET) in higher education: \nHow to use SET more effectively and efficiently in public affairs education. ​Journal of \nPublic Affairs Education, 18​(3), 531-544. \nhttp://www.naspaa.org/JPAEMessenger/index_2012summer.asp \nPalmer, S. (2012). Student evaluation of teaching: keeping in touch with reality. ​Quality in \nHigher Education, 18​(3), 297-311.​ ​http://dx.doi.org/10.1080/13538322.2012.730336 \nPepe, J.W., & Wang, M.C. (2012). What instructor qualities do students reward? ​College \nStudent Journal, 46​(3), 603-614. ​http://www.projectinnovation.biz/csj_2006.html \nPounder, J. S. (2007). Is student evaluation of teaching worthwhile? An analytical framework for \nanswering the question. ​Quality Assurance in Education, 15​(2), 178-191. \nhttp://dx.doi.org/10.1108/09684880710748938 \nRantanen, P. (2013). The number of feedbacks needed for reliable evaluation. A multilevel \nanalysis of the reliability, stability and generalizability of students’ evaluation of teaching. \nAssessment & Evaluation in Higher Education, 38​(2), 224-239. \nhttp://dx.doi.org/10.1080/02602938.2011.625471 \nReardon, R. C., Leierer, S. J., & Lee, D. (2014). Class meeting schedules in relation to students’ \ngrades and evaluations of teaching. ​The Professional Counselor, 2​(1), 81-89. \nhttp://dx.doi.org/10.15241/rcr.2.1.81 \nReisenwitz, T.H. (2015). Student evaluation of teaching: An investigation of nonresponse bias in \nan online context. ​Journal of Marketing Education, 38​(1), 7-17. \nhttp://celt.miamioh.edu/ject/issue.php?v=25&n=2\nhttp://dx.doi.org/10.1108/09684880710748938\nhttp://dx.doi.org/10.1080/13538322.2012.730336\nhttp://dx.doi.org/10.1111/j.1540-4609.2011.00328.x\nhttp://www.projectinnovation.biz/csj_2006.html\nhttp://www.naspaa.org/JPAEMessenger/index_2012summer.asp\nhttp://scholarship.law.stjohns.edu/lawreview/vol82/iss1/6\nhttp://celt.miamioh.edu/ject/issue.php?v=25&n=2\nhttp://dx.doi.org/10.1111/j.1540-4609.2011.00328.x\nhttp://dx.doi.org/10.5430/ijhe.v4n2p116\nhttp://dx.doi.org/10.1080/02602938.2011.625471\nhttps://doi.org/10.1177/0273475315596778\nhttp://dx.doi.org/10.1016/j.stueduc.2012.01.001\nhttp://dx.doi.org/10.1207/s15328023top3303_4\nhttp://dx.doi.org/10.1108/09684880710748938\nhttp://dx.doi.org/10.1080/13538322.2012.730336\nhttp://dx.doi.org/10.1037/0003-066X.52.11.1218\nhttp://dx.doi.org/10.15241/rcr.2.1.81\nhttp://dx.doi.org/10.1080/02602938.2011.625471\nhttp://dx.doi.org/10.1111/dsji.12023\nhttp://dx.doi.org/10.1016/j.stueduc.2012.01.001\nhttp://scholarship.law.stjohns.edu/lawreview/vol82/iss1/6\nhttp://www.naspaa.org/JPAEMessenger/index_2012summer.asp\nhttps://doi.org/10.1177/0273475315596778 \nRidley, D., & Collins, J. (2015). A suggested evaluation metric instrument for faculty members at \ncolleges and universities. ​International Journal of Education Research, 10​(1), 97-114. \nRetrieved from \nhttp://eds.a.ebscohost.com.login.ezproxy.library.ualberta.ca/eds/pdfviewer/pdfviewer?sid\n=9ff24389-d34d-43d1-83fc-6ef82bd1ad47%40sessionmgr4009&vid=2&hid=4102 \nRoyal, K. D., & Stockdale, M. R. (2015). Are teacher course evaluations biased against faculty \nthat teach quantitative methods courses? ​International Journal of Higher Education, 4​(1), \n217-224. ​http://dx.doi.org/10.5430/ijhe.v4n1p217 \nSmith, S. W., Yoo, J. H., Farr, A. C., Salmon, C. T., & Miller, V. D. (2007). The influence of \nstudent sex and instructor sex on student ratings of instructors: Results from a college of \ncommunication. ​Women's Studies in Communication, 30​(1), 64-77. \nhttp://dx.doi.org/10.1080/07491409.2007.10162505  \nSocha, A. (2013). A hierarchical approach to students’ assessment of instruction. ​Assessment & \nEvaluation in Higher Education, 38​(1), 94-113. \nhttp://dx.doi.org/10.1080/02602938.2011.604713 \nSpooren, P., Brockx, B., & Mortelmans, D. (2013). On the validity of student evaluation of \nteaching: The state of the art. ​Review of Educational Research, 83​(4), 598-642. \nhttp://dx.doi.org/10.3102/0034654313496870 \nStein, S. J., Spiller, D., Terry, S., Harris, T., Deaker, L., & Kennedy, J. (2013). Tertiary teachers \nand student evaluations: never the twain shall meet? ​Assessment & Evaluation in Higher \nEducation, 38​(7), 892-904.​ ​http://dx.doi.org/10.1080/02602938.2013.767876 \nStonebraker, R. J., & Stone, G. S. (2015). Too old to teach? The effect of age on college and \nuniversity professors. ​Research in Higher Education, 56​(8), 793-812. \nhttp://dx.doi.org/​10.1007/s11162-015-9374-y \nStupans, I., McGuren, T., & Babey, A. M. (2016). Student evaluation of teaching: A study \nexploring student rating instrument free-form text comments. ​Innovative Higher \nEducation, 41​(1), 33-52. ​http://10.1007/s10755-015-9328-5 \nUijtdehaage, S., & O’Neal, C. (2015). A curious case of the phantom professor: mindless \nteaching evaluations by medical students. ​Medical Education, 49​(9), 928-932. \nhttp://dx.doi.org/10.1111/medu.12805 \nUttl, B., White, C. A., Gonzalez, D. W. (2016). Meta-analysis of faculty’s teaching effectiveness: \nStudent evaluation of teaching ratings and student learning are not related. ​Studies in \nEducational Evaluation,​ (in press, available online September 19, 2106). \nhttp://dx.doi.org/10.1016/j.stueduc.2016.08.007 \nWilson, J. H., Beyer, D., & Monteiro, H. (2014). Professor age affects student ratings: Halo \neffect for younger teachers. ​College Teaching, 62​, 20-24. \nhttp://dx.doi.org/10.1080/87567555.2013.825574  \nWright, S. L., & Jenkins-Guarieri, M. A. (2012). Student evaluations of teaching: combining the \nmeta-analyses and demonstrating further evidence for effective use. ​Assessment & \nEvaluation in Higher Education, 37​(6), 683-699. \nhttp://dx.doi.org/10.1080/02602938.2011.563279 \nZimmerman, B. (2008). Course evaluations - students’ revenge? ​University Affairs.​ Retrieved \nhttp://dx.doi.org/10.5430/ijhe.v4n1p217\nhttp://dx.doi.org/10.1080/02602938.2013.767876\nhttp://dx.doi.org/10.1111/medu.12805\nhttp://dx.doi.org/10.1080/02602938.2011.604713\nhttp://eds.a.ebscohost.com.login.ezproxy.library.ualberta.ca/eds/pdfviewer/pdfviewer?sid=9ff24389-d34d-43d1-83fc-6ef82bd1ad47%40sessionmgr4009&vid=2&hid=4102\nhttp://dx.doi.org/10.1016/j.stueduc.2016.08.007\nhttp://dx.doi.org/10.1007/s11162-015-9374-y\nhttp://dx.doi.org/10.1080/02602938.2011.563279\nhttp://dx.doi.org/10.3102/0034654313496870\nhttp://dx.doi.org/10.3102/0034654313496870\nhttp://dx.doi.org/10.1080/02602938.2011.604713\nhttp://dx.doi.org/10.1080/02602938.2011.563279\nhttp://dx.doi.org/10.1080/87567555.2013.825574\nhttps://doi.org/10.1177/0273475315596778\nhttp://eds.a.ebscohost.com.login.ezproxy.library.ualberta.ca/eds/pdfviewer/pdfviewer?sid=9ff24389-d34d-43d1-83fc-6ef82bd1ad47%40sessionmgr4009&vid=2&hid=4102\nhttp://dx.doi.org/10.1080/07491409.2007.10162505\nhttp://dx.doi.org/10.1080/02602938.2013.767876\nhttp://dx.doi.org/10.1007/s11162-015-9374-y\nhttp://dx.doi.org/10.1111/medu.12805\nfrom \nhttp://www.universityaffairs.ca/opinion/in-my-opinion/course-evaluations-students-reveng\ne/ \nZumbach, J., & Funke, J. (2014). Influences of mood on academic course evaluations. ​Practical \nAssessment, Research & Evaluation, 19​(4). \nhttp://pareonline.net/genpare.asp?wh=0&abt=19 \nhttp://www.universityaffairs.ca/opinion/in-my-opinion/course-evaluations-students-revenge/\nhttp://pareonline.net/genpare.asp?wh=0&abt=19\nhttp://dx.doi.org/10.1080/02602938.2011.563279\nhttp://pareonline.net/genpare.asp?wh=0&abt=19\nhttp://www.universityaffairs.ca/opinion/in-my-opinion/course-evaluations-students-revenge/\nAppendix H: Abstracts for Reviewed Literature \nClick on the links to move directly to each bookmarked section. For brief summarizing points of \neach article, see Appendix A \nBiases \n● Gender \n● Instructor characteristics \n● Correlation between grades and ratings \n● Nonresponse \n● Non-instructional \n● Other \nValidity \nImpact on Teaching Quality \nEvaluating Faculty for Tenure and Promotion \nMultifaceted Evaluation \n Biases, Gender \nBoring, Ottoboni, & Stark​ (2016): ratings are biased against female instructors by an \namount that is large and statistically significant \nBoring, A., Ottoboni, K., & Stark, P. B. (2016). Student evaluations of teaching (mostly) do not \nmeasure teaching effectiveness. ​ScienceOpen Research, 2016​(1). \nhttp://dx.doi.org/10.14293/S2199-1006.1.SOR-EDU.AETBZC.v1  \n[Abstract, abridged] We show: SET are biased against female instructors by an amount that is \nlarge and statistically significant; The bias affects how students rate even putatively objective \naspects of teaching, such as how promptly assignments are graded; The bias varies by \ndiscipline and by student gender, among other things; It is not possible to adjust for the bias, \nbecause it depends on so many factors; SET are more sensitive to students’ gender bias and \ngrade expectations than they are to teaching effectiveness; Gender biases can be large \nenough to cause more effective instructors to get lower SET than less effective instructors. \nCentra & Gaubatz​ (2000): only small same-gender preferences found, particularly with \nfemales \nCentra, J. A., Gaubatz, N. B. (2000). Is there gender bias in student evaluations of teaching? \nThe Journal of Higher Education, 71​(1), 17-44. \nhttp://login.ezproxy.library.ualberta.ca/login?url=http://search.ebscohost.com/login.aspx?direct\n=true&db=edsjsr&AN=edsjsr.10.2307.2649280&site=eds-live&scope=site \n[Abstract] In an attempt to determine whether male and female students rate teachers \nhttp://login.ezproxy.library.ualberta.ca/login?url=http://search.ebscohost.com/login.aspx?direct=true&db=edsjsr&AN=edsjsr.10.2307.2649280&site=eds-live&scope=site\nhttp://login.ezproxy.library.ualberta.ca/login?url=http://search.ebscohost.com/login.aspx?direct=true&db=edsjsr&AN=edsjsr.10.2307.2649280&site=eds-live&scope=site\nhttp://login.ezproxy.library.ualberta.ca/login?url=http://search.ebscohost.com/login.aspx?direct=true&db=edsjsr&AN=edsjsr.10.2307.2649280&site=eds-live&scope=site\nhttp://dx.doi.org/10.14293/S2199-1006.1.SOR-EDU.AETBZC.v1\ndifferently depending on the gender of the teacher, we analyzed data from 741 classes in \nwhich there were at least 10 male and 10 female students. The results revealed small same \ngender preferences, particularly in female students rating female teachers. Teaching style \nrather than gender may well explain these preferences. \nGehrt, Louie, & Osland​ (2015): female students evaluated female lower-ranked faculty most \nfavorably; male students evaluations were more favorable for lower ranked male faculty, but \nthey did not degrade higher ranked female faculty \nGehrt, K., Louie, T. A., & Osland, A. (2015). Student and professor similarity: Exploring the \neffects of gender and relative age. ​Journal of Education for Business, 90​, 1-9. \nhttp://dx.doi.org/10.1080/08832323.2014.968514  \n[Abstract, abridged] It was hypothesized that students would more favorably evaluate faculty \nwho were similar in gender and in relative age (as reflected in faculty rank). As anticipated, \nfemale students evaluated female lower ranked faculty most favorably, and male higher \nranked faculty least favorably. However, male students showed mixed effects. Although their \nevaluations were more favorable for lower ranked male faculty, they unexpectedly did not \ndegrade higher ranked female faculty. \nHuebner & Magel​ (2015): variances of the class average responses between male and \nfemale faculty were higher for male faculty \nHuebner, L., & Magel, R. C. (2015). A gendered study of student ratings of instruction. ​Open \nJournal of Statistics, 5,​ 552-567. ​http://dx.doi.org/10.4236/ojs.2015.56058  \n[Abstract, abridged] This research tests for differences in mean class averages between male \nand female faculty for questions on a student rating of instruction form at one university in the \nMidwest. Differences in variances of class averages are also examined for male and female \nfaculty. Tests are conducted by first considering all classes across the entire university and \nthen classes just within the College of Science and Mathematics. The proportion of classes \ntaught by female instructors in which the average male student rating was higher than the \naverage female student rating was compared to the proportion of classes taught by male \ninstructors in which the average male student rating was higher than the average female \nstudent rating. \nLaube, Massoni, Sprague, & Ferber​ (2007): the inconsistency on the question of whether \nstudent evaluations are gendered is itself an artifact of the way that quantitative measures can \nmask underlying gender bias \nLaube, H., Massoni, K., Sprague, J., & Ferber, A. L. (2007). The impact of gender on the \nevaluation of teaching: What we know and what we can do. ​NWSA Journal,​ ​19​(3), 87-104. \nRetrieved from ​http://www.jstor.org/stable/40071230  \nhttp://www.jstor.org/stable/40071230\nhttp://dx.doi.org/10.1080/08832323.2014.968514\nhttp://dx.doi.org/10.4236/ojs.2015.56058\n[Abstract, abridged] Scholars who have attempted to determine whether/how gender enters \ninto students' evaluations of their teachers generally fall into two camps: those who find \ngender to have no (or very little) influence on evaluations, and those who find gender to affect \nevaluations significantly. Drawing on insights developed from sociological scholarship on \ngender and evaluation, we argue that the apparent inconsistency on the question of whether \nstudent evaluations are gendered is itself an artifact of the way that quantitative measures can \nmask underlying gender bias. \nMacNell, Driscoll, & Hunt​ (2015): students rate males significantly higher than females \nMacNell, L., Driscoll, A., & Hunt, A. N. (2015). What’s in a name: Exposing gender bias in \nstudent ratings of teaching. ​Innovative Higher Education, 40​, 291-303. \nhttp://dx.doi.org/10.1007/s10755-014-9313-4  \n[Abstract, abridged] Although instructor gender has been shown to play an important role in \ninfluencing student ratings, the extent and nature of that role remains contested. While difficult \nto separate gender from teaching practices in person, it is possible to disguise an instructor’s \ngender identity online. In our experiment, assistant instructors in an online class each \noperated under two different gender identities. Students rated the male identity significantly \nhigher than the female identity, regardless of the instructor’s actual gender, demonstrating \ngender bias. \nMiles & House​ (2015): lower ratings for female instructors teaching larger required classes \nMiles, P., & House, D. (2015). The tail wagging the dog: An overdue examination of student \nteaching evaluations. ​International Journal of Higher Education, 4​(2). \nhttp://dx.doi.org/10.5430/ijhe.v4n2p116  \n[Abstract, abridged] Purpose: The purpose of this research is to examine the impact of \nseveral factors beyond the professor's control and their unique impact on Student Teaching \nEvaluations (STEs). The present research pulls together a substantial amount of data to \nstatistically analyze several academic historical legends about just how vulnerable STEs are \nto the effects of: class size, course type, professor gender, and course grades. \nDesign/methodology/approach: This research is utilizes over 30,000 individual student \nevaluations of 255 professors, spanning six semesters, during a three year time period to test \nsix hypotheses. The final sample represents 1057 classes ranging in size between 10 and \n190 students. Each hypothesis is statistically analyzed, with either analysis of variance or a \nRegression model. Findings: This study finds support for 5 out of 6 hypotheses. Specifically, \nthese data suggest STEs are likely to be closest to \"5\" (using a 1-5 scale with 5 being highest) \nin small elective classes, and lowest in large required classes taught by females. As well we \nfind support for the notion that higher expected course grades may lead to higher STEs.  \nhttp://dx.doi.org/10.5430/ijhe.v4n2p116\nhttp://dx.doi.org/10.1007/s10755-014-9313-4\nSmith, Yoo, Farr, Salmon, & Miller​ ​(2007): male and female students rated female \ninstructors more highly; effect was small but significant due to sample size \nSmith, S. W., Yoo, J. H., Farr, A. C., Salmon, C. T., & Miller, V. D. (2007). The influence of \nstudent sex and instructor sex on student ratings of instructors: Results from a college of \ncommunication. ​Women's Studies in Communication, 30​(1), 64-77. \nhttp://dx.doi.org/10.1080/07491409.2007.10162505  \n[Abstract, abridged] ​We posed research questions as to whether male and female students \nwould rate male or female instructors more highly on five dimensions of student rating forms, \none of which was instructor interaction. Results indicated that male and female students rated \nfemale instructors more highly on all five dimensions. The effect sizes of these results were \nextremely small, but significant due to the large sample size (almost 12,000). These findings \nsuggest that administrators should not assume one sex to provide better or poorer instruction, \nand they should reward instructors on the basis of individual course performance rather than \naccording to instructor sex. \nWilson, Beyer, & Monteiro​ (2014): lower ratings for older instructors, but more so for \nfemales than males \nWilson, J. H., Beyer, D., & Monteiro, H. (2014). Professor age affects student ratings: Halo \neffect for younger teachers. ​College Teaching, 62​, 20-24. \nhttp://dx.doi.org/10.1080/87567555.2013.825574  \n[Abstract, abridged] In the present study, we examined the potential effects of professor age \nand gender on student perceptions of the teacher as well as their anticipated rapport in the \nclassroom. We also asked students to rate each instructor’s attractiveness based on societal \nbeliefs about age and beauty. We expected students to rate a picture of a middle-aged female \nprofessor more negatively (and less attractive) than the younger version of the same woman. \nFor the young versus old man offered in a photograph, we expected no age effects. Although \nage served as a detriment for both genders, evaluations suffered more based on aging for \nfemale than male professors. \nWright & Jenkins-Guarieri​ (2012): SETs appear to be valid and free from gender bias \nWright, S. L., & Jenkins-Guarieri, M. A. (2012). Student evaluations of teaching: combining \nthe meta-analyses and demonstrating further evidence for effective use. ​Assessment & \nEvaluation in Higher Education, 37​(6), 683-699. \nhttp://dx.doi.org/10.1080/02602938.2011.563279 \n[Abstract, abridged] Given that there is not one study summarising all these domains of \nresearch, a comprehensive overview of SETs was conducted by combining all prior \nmeta-analyses related to SETs. Eleven meta-analyses were identified, and nine \nmeta-analyses covering 193 studies were included in the analysis, which yielded a \nhttp://dx.doi.org/10.1080/02602938.2011.563279\nhttp://dx.doi.org/10.1080/87567555.2013.825574\nhttp://dx.doi.org/10.1080/02602938.2011.563279\nhttp://dx.doi.org/10.1080/07491409.2007.10162505\nsmall-to-medium overall weighted mean effect size (r = .26) between SETs and the variables \nstudied. Findings suggest that SETs appear to be valid, have practical use that is largely free \nfrom gender bias and are most effective when implemented with consultation strategies. \n Biases, Instructor Characteristics \nCheng​ (2015): ​tenure does not have a significant impact on student ratings of teaching \nperformance \nCheng, D. A. (2015). Effects of professorial tenure on undergraduate ratings of teaching \nperformance. ​Education Economics, 23​(3), 338-357. \nhttp://dx.doi.org/10.1080/09645292.2013.826632 \n[Abstract, abridged] This study estimates the effect of professorial tenure on undergraduate \nratings of learning, instructor quality, and course quality at the University of California, San \nDiego from Summer 2004 to Spring 2012. During this eight-year period, 120 assistant \nprofessors received tenure and 83 associate professors attained full rank. A \ndifferences-in-differences model controlling for teaching experience, study hours, response \nrate, and unobserved heterogeneity among terms, courses, and professors suggests that for \na given professor, tenure does not have a significant impact on student ratings of teaching \nperformance, at least in the immediate years after advancement. The results are similar for \nthe promotion from associate to full professor. \nCho & Otani​ (2014): students give higher ratings for limited-term lecturers versus full-time \nfaculty \nCho, J., & Otani, K. (2014). Differences in student evaluations of limited-term lecturers and \nfull-time faculty. ​Journal on Excellence in College Teaching, 25​(2), 5-24. \nhttp://opus.ipfw.edu/profstudies_facpubs/64 \n[Abstract, abridged] This study compared student evaluations of teaching (SET) for \nlimited-term lecturers (LTLs) and full-time faculty (FTF) using a Likert-scaled survey \nadministered to students (N = 1,410) at the end of university courses. Data were analyzed \nusing a general linear regression model to investigate the influence of multi-dimensional \nevaluation items on the overall rating item (Overall, I would rate the instructor of this course as \noutstanding) on the SET. Results showed that students provided higher ratings for LTLs than \nFTF, but they value different items when rating the overall evaluation of LTLs and FTF. Some \nsurvey items (for instance, those about instructor planning and enthusiasm) influence more on \nthe rating of the overall item for LTLs than for FTF, whereas other, multi-dimensional items \n(for instance, those about assessment strategies and instructor's availability) influence more \non the overall rating for FTF than for LTLs. \nClayson​ (2013): students’ first perceptions of an instructor’s personality are significantly \nrelated to ratings at the end of the semester \nhttp://opus.ipfw.edu/profstudies_facpubs/64\nhttp://dx.doi.org/10.1080/09645292.2013.826632\nClayson, D. E. (2013). Initial impressions and the student evaluation of teaching. ​Journal of \nEducation for Business, 88​(1), 26-53. ​http://dx.doi.org/10.1080/08832323.2011.633580 \n[Abstract, abridged] The author looked at the initial student perceptions and conditions of a \nclass and compared these with conditions and evaluations 16 weeks later at the end of the \nterm. It was found that the first perceptions of the instructor and the instructor’s personality \nwere significantly related to the evaluations made at the end of the semester. \nFelton, Mitchell, & Stinson​ (2004): students give attractively-rated professors higher quality \nand easiness scores \nFelton, J., Mitchell, J., & Stinson, M. (2004). Web-based student evaluations of professors: \nthe relations between perceived quality, easiness and sexiness. ​Assessment & Evaluation in \nHigher Education, 29​(1), 91-108.​ ​http://dx.doi.org/10.1080/0260293032000158180 \n[Abstract, abridged] College students critique their professors’ teaching at \nRateMyProfessors.com, a web page where students anonymously rate their professors on \nQuality, Easiness, and Sexiness. Using the self-selected data from this public forum, we \nexamine the relations between quality, easiness, and sexiness for 3190 professors at 25 \nuniversities. For faculty with at least ten student posts, the correlation between quality and \neasiness is 0.61, and the correlation between quality and sexiness is 0.30. Using simple linear \nregression, we find that about half of the variation in quality is a function of easiness and \nsexiness. When grouped into sexy and non-sexy professors, the data reveal that students \ngive sexy-rated professors higher quality and easiness scores.  \nKim & MacCann​ (2016): students’ expressed educational satisfaction was related to \nperceptions of instructor personality \nKim, L. E., MacCann, C. (2016). What is students’ ideal university instructor personality? An \ninvestigation of absolute and relative personality preferences. ​Personality and Individual \nDifferences, 102​, 190-203. ​http://dx.doi.org/10.1016/j.paid.2016.06.068 \n[Abstract, abridged] The current two studies investigate students' descriptions of “ideal” \ninstructor personality using the Five-Factor Model of personality. Both absolute personality \npreferences (certain traits are universally desired) and relative personality preferences \n(certain traits are desired relative to students' own level of the trait) are examined among 137 \nfirst year mathematics students (Study 1) and 378 first year psychology students (Study 2). \nStudents provided Big Five personality ratings for themselves, their actual instructor, and their \nideal instructor. Supporting the absolute preference hypothesis, students rated their ideal \ninstructor as having significantly higher levels than both themselves and the general \npopulation on all five personality domains (except for openness in Study 1), with particularly \nlarge effect sizes for emotional stability and conscientiousness. Supporting the relative \npreference hypothesis, students also rated their ideal instructor as having a similar Big Five \nprofile to themselves. Moreover, if their actual instructor's personality was similar to their ideal \ninstructor's personality, students showed greater educational satisfaction (but not higher \nperformance self-efficacy nor academic achievement). \nhttp://dx.doi.org/10.1080/0260293032000158180\nhttp://dx.doi.org/10.1080/08832323.2011.633580\nhttp://dx.doi.org/10.1080/0260293032000158180\nhttp://dx.doi.org/10.1016/j.paid.2016.06.068\nStonebraker & Stone​ (2015): age has a negative impact on student ratings of faculty \nmembers; begins around mid-forties; offset by attractiveness \nStonebraker, R. J., & Stone, G. S. (2015). Too old to teach? The effect of age on college and \nuniversity professors. ​Research in Higher Education, 56​(8), 793-812. \nhttp://dx.doi.org/​10.1007/s11162-015-9374-y \n[Abstract, abridged] Using data from the RateMyProfessors.com website for a large sample of \ninstructors in a broad cross-section of colleges and universities, we find that age does affect \nteaching effectiveness, at least as perceived by students. Age has a negative impact on \nstudent ratings of faculty members that is robust across genders, groups of academic \ndisciplines and types of institutions. However, the effect does not begin until faculty members \nreach their mid-forties and does not seem to increase even when they reach the former \nretirement ages of 65 or 70. Moreover, the quantitative impact of age on student ratings is \nsmall and can be offset by other factors, especially the physical appearance of professors and \nhow easy students consider them to be. When we restrict our sample to those professors \ndeemed hot by student raters, the effect of age disappears completely. \nWilson, Beyer, & Monteiro​ (2014): lower ratings for older instructors, but more so for \nfemales than males \nWilson, J. H., Beyer, D., & Monteiro, H. (2014). Professor age affects student ratings: Halo \neffect for younger teachers. ​College Teaching, 62​, 20-24. \nhttp://dx.doi.org/10.1080/87567555.2013.825574  \n[Abstract, abridged] In the present study, we examined the potential effects of professor age \nand gender on student perceptions of the teacher as well as their anticipated rapport in the \nclassroom. We also asked students to rate each instructor’s attractiveness based on societal \nbeliefs about age and beauty. We expected students to rate a picture of a middle-aged female \nprofessor more negatively (and less attractive) than the younger version of the same woman. \nFor the young versus old man offered in a photograph, we expected no age effects. Although \nage served as a detriment for both genders, evaluations suffered more based on aging for \nfemale than male professors. \n Biases, Correlation Between Grades and Ratings \nBacker​ (2012): some students punish academics for failing grades with low ratings \nBacker, E. (2012). Burnt at the student evaluation stake – the penalty for failing students. \nE-Journal of Business Education & Scholarship of Teaching, 6​(1), 1-13. Retrieved from \nhttp://www.ejbest.org/upload/eJBEST_Backer_2012_1.pdf \n[Abstract, abridged] Despite the wealth of research in the area of SETs, little has been done \nhttp://www.ejbest.org/upload/eJBEST_Backer_2012_1.pdf\nhttp://dx.doi.org/10.1080/87567555.2013.825574\nhttp://dx.doi.org/10.1007/s11162-015-9374-y\nhttp://dx.doi.org/10.1007/s11162-015-9374-y\nto examine student and academic perceptions of SETs. This research examined student \n(n=235) and academic (n=49) perceptions concerning SETs at one Australian regional \nuniversity. Almost one-third of respondents felt that some students punish academics for \nfailing their work by giving the lecturer low scores on the SET form. Thus, academics can \nessentially be burnt at the student evaluation stake as punishment for failing students. \nBlackhart, Peruche, DeWall, & Joiner​ (2006): higher ratings given to instructors who give \nhigher grades, and also to graduate teaching assistant rank \nBlackhart, G. C., Peruche, B .M., DeWall, C. N., & Joiner, T. E., Jr. (2006). Faculty forum: \nFactors influencing teaching evaluations in higher education. ​Teaching of Psychology, 33​(1), \n37-39. ​http://dx.doi.org/10.1207/s15328023top3301_9 \n[Abstract, abridged] Past research indicates several factors influencing teaching evaluation \nratings instructors receive. We analyzed teaching evaluations from psychology courses during \nfall and spring semesters of 2003– 2004 to determine if class size, class level, instructor \ngender, number of publications (faculty instructors), average grade given by the instructor, \nand instructor rank predicted teaching evaluation ratings. Entering predictor variables into a \nmultiple regression analysis concurrently, results indicated that only average grade given and \ninstructor rank significantly predicted instructor ratings. Specifically, higher average grades \ngiven by the instructor predicted higher ratings, and graduate teaching assistants received \nhigher overall ratings than faculty instructors. \nBoring, Ottoboni, & Stark​ (2016): ratings​ are more sensitive to students’ grade expectations \nthan they are to teaching effectiveness \nBoring, A., Ottoboni, K., & Stark, P. B. (2016). Student evaluations of teaching (mostly) do not \nmeasure teaching effectiveness. ​ScienceOpen Research, 2016​(1). \nhttp://dx.doi.org/10.14293/S2199-1006.1.SOR-EDU.AETBZC.v1 \n[Abstract, abridged] ​We show: SET are biased against female instructors by an amount that is \nlarge and statistically significant; The bias affects how students rate even putatively objective \naspects of teaching, such as how promptly assignments are graded; The bias varies by \ndiscipline and by student gender, among other things; It is not possible to adjust for the bias, \nbecause it depends on so many factors; SET are more sensitive to students’ gender bias and \ngrade expectations than they are to teaching effectiveness; Gender biases can be large \nenough to cause more effective instructors to get lower SET than less effective instructors. \nCentra​ (2003): expected grades generally do not affect student evaluations \nCentra, J.A. (2003). Will teachers receive higher student evaluations by giving higher grades \nand less course work? ​Research in Higher Education, 44​(5), 495-518. \nhttp://www.jstor.org.login.ezproxy.library.ualberta.ca/stable/40197319 \n[Abstract, abridged] This study investigated whether mean expected grades and the level of \ndifficult/workload in courses, as reported by students, unduly influence student ratings \nhttp://www.jstor.org.login.ezproxy.library.ualberta.ca/stable/40197319\nhttp://dx.doi.org/10.14293/S2199-1006.1.SOR-EDU.AETBZC.v1\nhttp://dx.doi.org/10.1207/s15328023top3301_9\ninstruction. Over 50,000 college courses were analyzed. After controlling for learning \noutcomes, expected grades generally did not affect student evaluations. In fact, contrary to \nwhat some faculty think, courses in natural sciences with expected grades of A were rated \nlower, not higher. Courses were rated lower when they were rated as either difficult or too \nelementary. Courses rated at the “just right” level received the highest evaluations. \nCho, Baek, & Cho​ (2015): students with better grades than their expected grades provide a \npsychological “gift” to their teachers by giving higher ratings \nCho, D., Baek, W., & Cho, J. (2015). Why do good performing students highly rate their \ninstructors? Evidence from a natural experiment. ​Economics of Education Review, 49​, \n172-179. ​http://dx.doi.org/10.1016/j.econedurev.2015.10.001 \n[Abstract, abridged] This article analyzes the behavior of students in a college classroom with \nregard to their evaluation of teacher performance. As some students are randomly able to see \ntheir grades prior to the evaluation, the “natural” experiment provides a unique opportunity for \ntesting the hypothesis as to whether there exists a possibility of a hedonic (implicit) exchange \nbetween the students’ grades and teaching evaluations. Students with good grades tend to \nhighly rate the teaching quality of their instructors, in comparison with those who receive \nrelatively poor grades. This study finds that students with better grades than their expected \ngrades provide a psychological “gift” to their teachers by giving a higher teacher evaluation, \nwhereas it is the opposite with those students receiving lower grades than their expectation. \nGreenwald & Gillmore​ (1997): the grades-ratings correlation is due to an unwanted influence \nof instructors' grading leniency; there are 5 theories of the grades-ratings correlation \nGreenwald, A. G., Gillmore, G. M. (1997). Grade leniency is a removable contaminant of \nstudent ratings. ​American Psychologist, 52​(11), 1209-1217. \nhttp://dx.doi.org/10.1037/0003-066X.52.11.1209 \n[Abstract] It is well established that students' evaluative ratings of instruction correlate \npositively with expected course grades. The authors identify 4 additional data patterns that, \ncollectively, discriminate among 5 theories of the grades-ratings correlation. The presence of \nall 4 of these markers in student ratings data (obtained at University of Washington) was most \nconsistent with the theory that the grades-ratings correlation is due to an unwanted influence \nof instructors' grading leniency on ratings. This conclusion justifies use of a statistical \ncorrection – illustrated here with actual ratings data – to remove the unwanted inflation of \nratings produced by lenient grading. Additional research can profitably seek other \ninappropriate influences on ratings to identify more opportunities for validity-enhancing \nadjustments. \nGump​ (2007): questions the validity of research done on the leniency hypothesis \nhttp://dx.doi.org/10.1016/j.econedurev.2015.10.001\nhttp://dx.doi.org/10.1037/0003-066X.52.11.1209\nGump, S.E. (2007). Student evaluations of teaching effectiveness and the leniency \nhypothesis: A literature review. ​Education Research Quarterly, 30​(3), 55-68. Retrieved from \nhttp://eric.ed.gov.login.ezproxy.library.ualberta.ca/?id=EJ787711 \n[Abstract, abridged] ​This review presents an overview of selected articles on the leniency \nhypothesis: the idea that students give higher evaluations to instructors who grade more \nleniently. In this diverse literature, research methods and aims have frequently affected the \noutcomes and conclusions, since SETs are typically context-specific instruments whose \nresults, in isolated instances, do not generalize well. Thus this review questions the very \ngeneralizability of the massive and often contradictory SET-related literature on the leniency \nhypothesis and argues that future research must be designed and carried out in light of the \nimplicit problems existing in the majority of earlier studies. \nMaurer​ (2006): cognitive dissonance may be a theory to explain the grades-ratings \ncorrelation \nMaurer, T. W. (2006). Cognitive dissonance or revenge? Student grades and course \nevaluations. ​Teaching of Psychology, 33​(3), 176-179. \nhttp://dx.doi.org/10.1207/s15328023top3303_4 \n[Abstract] I tested 2 competing theories to explain the connection between students’ expected \ngrades and ratings of instructors: cognitive dissonance and revenge. Cognitive dissonance \ntheory holds that students who expect poor grades rate instructors poorly to minimize ego \nthreat whereas the revenge theory holds that students rate instructors poorly in an attempt to \npunish them. I tested both theories via an experimental manipulation of the perceived ability to \npunish instructors through course evaluations. Results indicated that student ratings appear \nunrelated to the ability to punish instructors, thus supporting cognitive dissonance theory. \nAlternative interpretations of the data suggest further research is warranted. \nMiles & House​ (2015): higher expected grades may lead to higher ratings \nMiles, P., & House, D. (2015). The tail wagging the dog: An overdue examination of student \nteaching evaluations. ​International Journal of Higher Education, 4​(2). \nhttp://dx.doi.org/10.5430/ijhe.v4n2p116  \n[Abstract, abridged] Purpose: The purpose of this research is to examine the impact of \nseveral factors beyond the professor's control and their unique impact on Student Teaching \nEvaluations (STEs). The present research pulls together a substantial amount of data to \nstatistically analyze several academic historical legends about just how vulnerable STEs are \nto the effects of: class size, course type, professor gender, and course grades. \nDesign/methodology/approach: This research is utilizes over 30,000 individual student \nevaluations of 255 professors, spanning six semesters, during a three year time period to test \nsix hypotheses. The final sample represents 1057 classes ranging in size between 10 and \n190 students. Each hypothesis is statistically analyzed, with either analysis of variance or a \nRegression model. Findings: This study finds support for 5 out of 6 hypotheses. Specifically, \nhttp://eric.ed.gov.login.ezproxy.library.ualberta.ca/?id=EJ787711\nhttp://dx.doi.org/10.1207/s15328023top3303_4\nhttp://dx.doi.org/10.5430/ijhe.v4n2p116\nhttp://eric.ed.gov.login.ezproxy.library.ualberta.ca/?id=EJ787711\nthese data suggest STEs are likely to be closest to \"5\" (using a 1-5 scale with 5 being highest) \nin small elective classes, and lowest in large required classes taught by females. As well we \nfind support for the notion that higher expected course grades may lead to higher STEs. \n Biases, Nonresponse \nKuwaiti, AlQuraan, & Subbarayalu​ (2016): ratings are affected by class size and response \nrate \nKuwaiti, A. A., AlQuraan, M., & Subbarayalu, A. V. (2016). Understanding the effect of \nresponse rate and class size interaction on students evaluation of teaching in a higher \neducation. ​Educational Assessment & Evaluation, 3​, \nhttps://doi.org/10.1080/2331186X.2016.1204082 \n[Abstract, abridged] This study aims to investigate the interaction between response rate and \nclass size and its effects on students’ evaluation of instructors and the courses offered at a \nhigher education Institution in Saudi Arabia. It is observed that when the class size is at the \nmedium level, the ratings of instructors and courses increase as the response rate increases. \nOn the contrary; when the class size is small, a high response rate is required for the \nevaluation of instructors and at least medium response rate is required for evaluation of \ncourses. The study suggests that the interaction between response rate and class size is an \nimportant factor that needs to be taken into account while interpreting the students’ evaluation \nof instructors and courses. \nMacfadyen, Dawson, Prest, & Gasevic​ (2016): much bias based on who is completing the \nsurveys \nMacfadyen, L. P., Dawson, S., Prest, S., & Gasevic, D. (2016). Whose feedback? A multilevel \nanalysis of student completion of end-of-term teaching evaluations. ​Assessment & Evaluation \nin Higher Education, 41​(6), 821-839.​ ​http://dx.doi.org/10.1080/02602938.2015.1044421 \n[Abstract, abridged] While much research has examined the validity of SETs for measuring \nteaching quality, few studies have investigated the factors that influence student participation \nin the SET process. This study aimed to address this deficit through the analysis of an SET \nrespondent pool at a large Canadian research-intensive university. The findings were largely \nconsistent with available research (showing influence of student gender, age, specialisation \narea and final grade on SET completion). However, the study also identified additional \ninfluential course-specific factors such as term of study, course year level and course type as \nstatistically significant. Collectively, such findings point to substantively significant patterns of \nbias in the characteristics of the respondent pool. \nReisenwitz​ (2015): ​there are significant differences between those who complete online \nstudent evaluations and those who do not \nReisenwitz, T.H. (2015). Student evaluation of teaching: An investigation of nonresponse bias \nhttp://dx.doi.org/10.1080/02602938.2015.1044421\nhttp://dx.doi.org/10.1080/02602938.2015.1044421\nhttps://doi.org/10.1080/2331186X.2016.1204082\nin an online context. ​Journal of Marketing Education, 38​(1), 7-17. \nhttps://doi.org/10.1177/0273475315596778 \n[Abstract, abridged] This study examines nonresponse bias in online student evaluations of \ninstruction, that is, the differences between those students who complete online evaluations \nand those who decide not to complete them. It builds on the work of Estelami that revealed a \nresponse bias based on the timing in which the evaluations were completed, that is, \ndifferences in early evaluations versus later evaluations. In contrast, this study examines the \ndemographic variables that have contributed to nonresponse bias in online student \nevaluations, namely gender, grade point average, and ethnicity. It also examines multiple \npsychographic variables that may contribute to nonresponse bias: time poverty, complaining \nbehavior, and technology savviness. This study found that there are significant differences \nbetween those who complete online student evaluations and those who do not. \n Biases, Non-instructional \nKuwaiti, AlQuraan, & Subbarayalu​ (2016): ratings are affected by class size and response \nrate \nKuwaiti, A. A., AlQuraan, M., & Subbarayalu, A. V. (2016). Understanding the effect of \nresponse rate and class size interaction on students evaluation of teaching in a higher \neducation. ​Educational Assessment & Evaluation, 3​, \nhttps://doi.org/10.1080/2331186X.2016.1204082 \n[Abstract, abridged] This study aims to investigate the interaction between response rate and \nclass size and its effects on students’ evaluation of instructors and the courses offered at a \nhigher education Institution in Saudi Arabia. It is observed that when the class size is at the \nmedium level, the ratings of instructors and courses increase as the response rate increases. \nOn the contrary; when the class size is small, a high response rate is required for the \nevaluation of instructors and at least medium response rate is required for evaluation of \ncourses. The study suggests that the interaction between response rate and class size is an \nimportant factor that needs to be taken into account while interpreting the students’ evaluation \nof instructors and courses. \nNargundkar & Shrikhande​ (2014): combined impact of all the noninstructional factors \nstudied is statistically significant \nNargundkar, S., & Shrikhande, M. (2014). Norming of student evaluations of instruction: \nImpact of noninstructional factors. ​Decision Sciences Journal of Innovative Education, 12​(1), \n55-72. ​http://dx.doi.org/10.1111/dsji.12023 \n[Abstract, abridged] Student Evaluations of Instruction (SEIs) from about 6,000 sections over \n4 years representing over 100,000 students at the college of business at a large public \nuniversity are analyzed, to study the impact of noninstructional factors on student ratings. \nAdministrative factors like semester, time of day, location, and instructor attributes like gender \nhttps://doi.org/10.1080/2331186X.2016.1204082\nhttps://doi.org/10.1177/0273475315596778\nhttp://dx.doi.org/10.1111/dsji.12023\nhttps://doi.org/10.1177/0273475315596778\nand rank are studied. The combined impact of all the noninstructional factors studied is \nstatistically significant. Our study has practical implications for administrators who use SEIs to \nevaluate faculty performance. SEI scores reflect some inherent biases due to noninstructional \nfactors. Appropriate norming procedures can compensate for such biases, ensuring fair \nevaluations. \nReardon, Leierer, & Lee​ (2014): class schedule does not affect ratings \nReardon, R. C., Leierer, S. J., & Lee, D. (2014). Class meeting schedules in relation to \nstudents’ grades and evaluations of teaching. ​The Professional Counselor, 2​(1), 81-89. \nhttp://dx.doi.org/10.15241/rcr.2.1.81 \n[Abstract, abridged] A six-year retrospective study of a university career course evaluated the \neffect of four different class schedule formats on students' earned grades, expected grades \nand evaluations of teaching. Some formats exhibited significant differences in earned and \nexpected grades, but significant differences were not observed in student evaluations of \ninstruction.  \nRoyal & Stockdale​ (2015): students give lower ratings to instructors of quantitative methods \nsubjects \nRoyal, K. D., & Stockdale, M. R. (2015). Are teacher course evaluations biased against faculty \nthat teach quantitative methods courses? ​International Journal of Higher Education, 4​(1), \n217-224. ​http://dx.doi.org/10.5430/ijhe.v4n1p217 \n[Abstract, abridged] The present study investigated graduate students’ responses to \nteacher/course evaluations (TCE) to determine if students’ responses were inherently biased \nagainst faculty who teach quantitative methods courses. Item response theory (IRT) and \nDifferential Item Functioning (DIF) techniques were utilized for data analysis. Results indicate \nstudents in non-methods courses preferred the structure of quantitative courses, but tend to \nbe more critical of quantitative instructors. \n Biases, Other \nBlackhart, Peruche, DeWall, & Joiner​ (2006): varying results for investigation if class size, \nclass level, instructor gender, number of publications (faculty instructors), average grade \ngiven by the instructor, and instructor rank predicted teaching evaluation ratings \nBlackhart, G. C., Peruche, B. M., DeWall, C. N., & Joiner, T. E., Jr. (2006). Faculty forum: \nFactors influencing teaching evaluations in higher education. ​Teaching of Psychology, 33​(1), \n37-39. ​http://dx.doi.org/10.1207/s15328023top3301_9 \n[Abstract, abridged] Past research indicates several factors influencing teaching evaluation \nratings instructors receive. We analyzed teaching evaluations from psychology courses during \nhttp://dx.doi.org/10.5430/ijhe.v4n1p217\nhttp://dx.doi.org/10.1207/s15328023top3301_9\nhttp://dx.doi.org/10.15241/rcr.2.1.81\nfall and spring semesters of 2003-2004 to determine if class size, class level, instructor \ngender, number of publications (faculty instructors), average grade given by the instructor, \nand instructor rank predicted teaching evaluation ratings. Entering predictor variables into a \nmultiple regression analysis concurrently, results indicated that only average grade given and \ninstructor rank significantly predicted instructor ratings. Specifically, higher average grades \ngiven by the instructor predicted higher ratings, and graduate teaching assistants received \nhigher overall ratings than faculty instructors. \nKeeley, English, Irons, & Henslee​ (2013): found halo and ceiling/floor effects to be present \nand persistent \nKeeley, J. W., English, T., Irons, J., & Henslee, A. M. (2013). Investigating halo and ceiling \neffects in student evaluations of instruction. ​Educational and Psychological Measurement, \n73​(3), 440-457.​ ​http://dx.doi.org/10.1177/0013164412475300 \n[Abstract, abbreviated, and other article text] ​Many measurement biases affect student \nevaluations of instruction (SEIs). However, two have been relatively understudied: halo effects \nand ceiling/floor effects. This study examined these effects in two ways. Both biases were \nrobust and remained despite characteristics of the measure designed to combat them. \n“halo effects occur when a rater’s opinion about one aspect of the teacher influences the \nremainder of that person’s ratings” \n“Ceiling and floor effects (also referred to as maximizing and minimizing effects) occur when a \nscale does not have a sufficient range to produce meaningful variability at the upper or lower \nends of possible scores.” \nMarsh & Roche​ (1997): evaluations are valid and unaffected by hypothesized biases \nMarsh, H. W., & Roche, L. A. (1997). Making students’ evaluations of teaching effectiveness \neffective: The critical issues of validity, bias, and utility. ​American Psychologist, 52​(11), \n1187-1197. ​http://dx.doi.org/10.1037/0003-066X.52.11.1187 \n[Abstract, abridged] This article reviews research indicating that, under appropriate conditions, \nstudents' evaluations of teaching (SETs) are (a) multidimensional; (b) reliable and stable; (c) \nprimarily a function of the instructor who teaches a course rather than the course that is \ntaught; (d) relatively valid against a variety of indicators of effective teaching; (e) relatively \nunaffected by a variety of variables hypothesized as potential biases (e.g., grading leniency, \nclass size, workload, prior subject interest); and (f) useful in improving teaching effectiveness \nwhen SETS are coupled with appropriate consultation. The authors recommend rejecting a \nnarrow criterion-related approach to validity and adopting a broad construct-validation \napproach, recognizing that effective teaching and SETs that reflect teaching effectiveness are \nmultidimensional; no single criterion of effective teaching is sufficient; and tentative \ninterpretations of relations with validity criteria and potential biases should be evaluated \ncritically in different contexts, in relation to multiple criteria of effective teaching, theory, and \nexisting knowledge. \nhttp://dx.doi.org/10.1177/0013164412475300\nhttp://dx.doi.org/10.1037/0003-066X.52.11.1187\nhttp://dx.doi.org/10.1177/0013164412475300\nMerritt​ (2012): covers biases in general, including race minority \nMerritt, D. J. (2012). Bias, the brain, and student evaluations of teaching. ​St. John’s Law \nReview, 82​(1), Article 6, 235-288.​ ​http://scholarship.law.stjohns.edu/lawreview/vol82/iss1/6 \n[It seems that a 2008 version of this article was used in the UA report, but the version now \nonline is 2012. No abstract.] \nPounder​ (2007): identifies and organizes factors influencing SET scores; literature review \nPounder, J. S. (2007). Is student evaluation of teaching worthwhile? An analytical framework \nfor answering the question. ​Quality Assurance in Education, 15​(2), 178-191. \nhttp://dx.doi.org/10.1108/09684880710748938 \n[Abstract, abridged] Identifies student related, course related and teacher related aspects of \nresearch on teaching evaluations. Factors commonly addressed within these aspects are also \nidentified. On the basis of a comprehensive survey of the literature, this paper identifies and \ndiscusses the central factors influencing SET scores. These factors are then presented in a \ncomprehensible table that can be used as a reference point for researchers and practitioners \nwishing to examine the effectiveness of the SET system. \nZumback & Funke​ (2014): students’ mood affects ratings \nZumbach, J., & Funke, J. (2014). Influences of mood on academic course evaluations. \nPractical Assessment, Research & Evaluation, 19​(4). \nhttp://pareonline.net/genpare.asp?wh=0&abt=19 \n[Abstract, abridged] In two subsequent experiments, the influence of mood on academic \ncourse evaluation is examined. By means of facial feedback, either a positive or a negative \nmood was induced while students were completing a course evaluation questionnaire during \nlectures. Results from both studies reveal that a positive mood leads to better ratings of \ndifferent dimensions of lecture quality. While in Study 1 (N=109) mood was not directly \ncontrolled, Study 2 (N=64) replicates the findings of the prior study and reveals direct \ninfluences of positive and negative mood on academic course evaluation. \n Validity \nAl-Eidan, Baig, Magzoub, & Omair​ (2016): the faculty evaluation tool was found to be \nreliable, but validity has to be interpreted with caution because of low response \nAl-Eidan, F., Baig, L. A., Magzoub, M., & Omair, A. (2016). Reliability and validity of the \nfaculty evaluation instrument used at King Saud bin Abdulaziz University for Health Sciences: \nResults from the haematology course. ​The Journal of the Pakistan Medical Association, 66​(4), \n453-457. ​http://www.jpma.org.pk/full_article_text.php?article_id=7711 \nhttp://scholarship.law.stjohns.edu/lawreview/vol82/iss1/6\nhttp://dx.doi.org/10.1108/09684880710748938\nhttp://scholarship.law.stjohns.edu/lawreview/vol82/iss1/6\nhttp://pareonline.net/genpare.asp?wh=0&abt=19\nhttp://www.jpma.org.pk/full_article_text.php?article_id=7711\nhttp://dx.doi.org/10.1108/09684880710748938\nhttp://pareonline.net/genpare.asp?wh=0&abt=19\n[Abstract, abridged] Objectives: To assess reliability and validity of evaluation tool using \nHaematology course as an example. Results: Of the 116 subjects in the study, 80(69%) were \nmales and 36(31%) were females. Reliability of the questionnaire was Cronbach's alpha 0.91. \nFactor analysis yielded a logically coherent 7 factor solution that explained 75% of the \nvariation in the data. The factors were group dynamics in problem-based learning (alpha0.92), \nblock administration (alpha 0.89), quality of objective structured clinical examination (alpha \n0.86), block coordination (alpha 0.81), structure of problem-based learning (alpha 0.84), \nquality of written exam (alpha 0.91), and difficulty of exams (alpha0.41). Female students' \nopinion on depth of analysis and critical thinking was significantly higher than that of the \nmales (p=0.03). Conclusion: The faculty evaluation tool used was found to be reliable, but its \nvalidity, as assessed through factor analysis, has to be interpreted with caution as the \nresponders were less than the minimum required for factor analysis. \nBedggood & Donovan​ (2012): student satisfaction does not equal teaching quality; both \nstudent satisfaction and student learning are relevant measures \nBedggood, R. E., & Donovan, J. D. (2012). University performance evaluations: What are we \nreally measuring? ​Studies in Higher Education, 37​(7), 825-842. \nhttp://dx.doi.org/10.1080/03075079.2010.549221 \n[Abstract, abridged] Despite the criticisms surrounding whether measures associated with \nthese surveys are indeed valid, university managers continue to utilise them in key decision \nmaking. However, some argue that universities are misdirected in measuring satisfaction as a \nproxy for teaching quality, possibly subverting the potentially conflicting objective of student \nlearning. Even so, both student satisfaction and student learning can be relevant performance \nmeasures. Accordingly, we have developed two robust measures of these constructs. We \nargue that student learning can be measured and used to provide formative feedback for \nimproving teaching effectiveness. Alternatively, student satisfaction can be appropriate for \ndetermining whether students are ‘enjoying’ their studies, and likewise offers distinct benefits \nto university managers measuring performance outcomes. \nBrown, Wood, Ogden, & Maltby​ (2014): students’ satisfaction rating is context dependent; \nobjective quality and subjective satisfaction are different things and should be assessed \naccordingly \nBrown, G. D. A., Wood, A. M., Ogden, R. S., & Maltby, J. (2014). Do student evaluations of \nuniversity reflect inaccurate beliefs or actual experience? A relative rank model.​ Journal of \nBehavioral Decision Making, 28​, 14-26. ​http://dx.doi.org/10.1002/bdm.1827 \n[Abstract] It was shown that student satisfaction ratings are influenced by context in ways that \nhave important theoretical and practical implications. Using questions from the UK’s National \nStudent Survey, the study examined whether and how students’ expressed satisfaction with \nissues such as feedback promptness and instructor enthusiasm depends on the context of \ncomparison (such as possibly inaccurate beliefs about the feedback promptness or \nenthusiasm experienced at other universities) that is evoked. Experiment 1 found strong \neffects of experimentally provided comparison context—for example, satisfaction with a given \nfeedback time depended on the time’s relative position within a context. Experiment 2 used a \nhttp://dx.doi.org/10.1080/03075079.2010.549221\nhttp://dx.doi.org/10.1002/bdm.1827\nnovel distribution-elicitation methodology to determine the prior beliefs of individual students \nabout what happens in universities other than their own. It found that these beliefs vary widely \nand that students’ satisfaction was predicted by how they believed their experience ranked \nwithin the distribution of others’ experiences. A third study found that relative judgment \nprinciples also predicted students’ intention to complain. An extended model was developed \nto show that purely rank-based principles of judgment can account for findings previously \nattributed to range effects. It was concluded that satisfaction ratings and quality of provision \nare different quantities, particularly when the implicit context of comparison includes beliefs \nabout provision at other universities. Quality and satisfaction should be assessed separately, \nwith objective measures (such as actual times to feedback), rather than subjective ratings \n(such as satisfaction with feedback promptness), being used to measure quality wherever \npracticable.  \nChen & Hoshower​ (2003): student motivation to participate in SET affects ratings \nChen, Y., & Hoshower, L. B. (2003). Student evaluation of teaching effectiveness: an \nassessment of student perception and motivation. ​Assessment & Evaluation in Higher \nEducation, 28​(1), 71-88.​ ​http://dx.doi.org/10.1080/0260293032000033071 \n[Abstract, abridged] Very few studies have looked into students’ perception of the teaching \nevaluation system and their motivation to participate. This study employs expectancy theory \nto evaluate some key factors that motivate students to participate in the teaching evaluation \nprocess. The results show that students generally consider an improvement in teaching to be \nthe most attractive outcome of a teaching evaluation system. The second most attractive \noutcome was using teaching evaluations to improve course content and format. Using \nteaching evaluations for a professor’s tenure, promotion and salary rise decisions and making \nthe results of evaluations available for students’ decisions on course and instructor selection \nwere less important from the students’ standpoint. Students’ motivation to participate in \nteaching evaluations is also impacted significantly by their expectation that they will be able to \nprovide meaningful feedback. \nChonko, Tanner, & Davis​ (2002): students focus more on qualities that make a course \nappealing, not learning \nChonko, L. B., Tanner, J. F., & Davis, R. (2002). What are they thinking? Students’ \nexpectations and self-assessments. ​Journal of Education for Business, 77​(5), 271-281. \nRetrieved from \nhttp://login.ezproxy.library.ualberta.ca/login?url=http://search.ebscohost.com/login.aspx?direct\n=true&db=bth&AN=7214031&site=eds-live&scope=site \n[Abstract] Student teacher evaluations have been the subject of a great deal of research. In \nthis study, the authors surveyed 750 freshmen in an Introduction to Business class. The \nauthors found that students' actual perceptions often diverged from what they were assessing \non teaching evaluations and that their expectations of the teacher and the class, as well as \ntheir self-assessments, were very related to how students rate classes and teachers. The \nauthors suggest that caution should be exercised in the use of student evaluations. \nhttp://dx.doi.org/10.1080/0260293032000033071\nhttp://dx.doi.org/10.1080/0260293032000033071\nhttp://login.ezproxy.library.ualberta.ca/login?url=http://search.ebscohost.com/login.aspx?direct=true&db=bth&AN=7214031&site=eds-live&scope=site\nhttp://login.ezproxy.library.ualberta.ca/login?url=http://search.ebscohost.com/login.aspx?direct=true&db=bth&AN=7214031&site=eds-live&scope=site\nCohen​ (1981): student ratings are a valid measure of teaching effectiveness; this is the \nmeta-analysis targeted by Uttl et al., 2016 \nCohen, P. A. (1981). Student ratings of instruction and student achievement: A meta-analysis \nof multisection validity studies. ​Review of Educational Research, 51​(3), 281-309. \n[Abstract, abridged] The data for the meta-analysis came from 41 independent validity studies \nreporting on 68 separate multisection courses relating student ratings to student achievement. \nA hierarchical multiple regression analysis showed that rating/achievement correlations were \nlarger for full-time faculty when students knew their final grades before rating instructors and \nwhen an external evaluator graded students' achievement tests. The results of the \nmeta-analysis provide strong support for the validity of student ratings as measures of \nteaching effectiveness. \nd'Apollonia & Abrami​ (1997): student ratings are moderately valid; however, they are \naffected by administrative, instructor, and course characteristics \n d’Apollonia, S., & Abrami, P. C. (1997). Navigating student ratings of instruction. ​American \nPsychologist, 52​(11), 1198-1208. ​http://dx.doi.org/10.1037/0003-066X.52.11.1198 \n[Abstract, abridged] Many colleges and universities have adopted the use of student ratings of \ninstruction as one (often the most influential) measure of instructional effectiveness. In this \narticle, the authors present evidence that although effective instruction may be \nmultidimensional, student ratings of instruction measure general instructional skill, which is a \ncomposite of three subskills: delivering instruction, facilitating interactions, and evaluating \nstudent learning.The authors subsequently report the results of a meta-analysis of the \nmultisection validity studies that indicate that student ratings are moderately valid; however, \nadministrative, instructor, and course characteristics influence student ratings of instruction. \nDodeen​ (2013): validity of SET is questionable \nDodeen, H. (2013). Validity, reliability, and potential bias of short forms of students’ evaluation \nof teaching: The case of UAE University. ​Educational Assessment, 18​(4), 235-250. \nhttp://dx.doi.org/10.1080/10627197.2013.846670 \n[Abstract, abridged] Students' opinions continue to be a significant factor in the evaluation of \nteaching in higher education institutions. The purpose of this study was to psychometrically \nassess short students evaluation of teaching (SET) forms using the UAE University form as a \nmodel. The study evaluated the form validity, reliability, the overall question, and potential \nbias with respect to gender, college, grade point average, expected grade, and class size. A \ntotal of 3,661 students participated in this study in different random samples. Results \nindicated that the short SET form lacked content validity and could not identify key dimensions \nof evaluating teaching effectiveness. The form showed stability over time and acceptable \ninternal reliability. Results indicated also that there was a potential bias due to college, \nexpected grade, and class size, but there was no relationship between grade point average \nand students' ratings. It was concluded that short SET forms do not cover all domain content \nhttp://dx.doi.org/10.1080/10627197.2013.846670\nhttp://dx.doi.org/10.1080/10627197.2013.846670\nhttp://dx.doi.org/10.1037/0003-066X.52.11.1198\nand unable to provide teachers with enough information for the improvement of teaching. \nDolmans, Janssen-Noordman, & Wolfhagen​ (2006): students can distinguish excellent and \npoor teaching quality \nDolmans, D. M., Janssen-Noordman, A., & Wolfhagen, H. P. (2006). Can students \ndifferentiate between PBL tutors with different tutoring deficiencies? Medical Teacher, 28(6), \n156-161. doi: 10.1080/01421590600776545 \n[Abstract, abridged] Although everyone will agree that students are able to distinguish \nbetween poor and excellent tutors, one can question whether students are also able to \ndifferentiate between tutors with different tutoring deficiencies—tutors who perform badly on a \nspecific key aspect of their performance. The aim of this study was to investigate to what \ndegree students are able to differentiate between tutors with different tutoring deficiencies, \nhow effective tutors are with different deficiencies and what kind of tips students give for \nimprovement of a tutor's behaviour. The results of this study demonstrate that students are \nnot only able to distinguish between poor and excellent tutors, but are also able to diagnose \ntutors with different tutoring deficiencies and are able to provide tutors with specific feedback \nto improve their performance. \nGinns, Prosser, & Barrie​ (2007): the SET tool studied supports quality assurance and \nimprovement processes at the university \nGinns, P., Prosser, M., & Barrie, S. (2007). Students’ perceptions of teaching quality in higher \neducation: the perspective of currently enrolled students. ​Studies in Higher Education, 32​(5), \n603-615. ​http://dx.doi.org/10.1080/03075070701573773 \n[Abstract, abridged] The psychometric properties of a version of the Course Experience \nQuestionnaire revised for students currently enrolled at the University of Sydney, the Student \nCourse Experience Questionnaire (SCEQ), were assessed, gathering students’ perceptions \non a number of scales, including Good Teaching, Clear Goals and Standards, Appropriate \nAssessment, Appropriate Workload, and an outcome scale measuring Generic Skills \ndevelopment. Confirmatory factor analyses supported the hypothesised factor structure, and \nestimates of inter-rater agreement on SCEQ scales indicated student ratings of degrees can \nbe meaningfully aggregated up to the faculty level. Derived from a substantial research base, \nlinking the student experience to approaches to study and learning outcomes, its goal is to \nsupport both quality assurance and improvement processes within the university, at both the \ndegree level and faculty level. The analyses described above indicate that the SCEQ is \nappropriate for these purposes. \nGrammatikopoulos, Linardakis, Gregoriadis, & Oikonomidis​ (2015): provides evidence of \na valid SET instrument; evaluating test validity is a continuous process, not a one-time event \nGrammatikopoulos, V., Linardakis, M., Gregoriadis, A., & Oikonomidis, V. (2015). Assessing \nthe students’ evaluations of educational quality (SEEQ) questionnaire in Greek higher \neducation. ​Higher Education, 70​(3), 395-408. ​http://dx.doi.org/10.1007/s10734-014-9837-7 \nhttp://dx.doi.org/10.1080/03075070701573773\nhttp://dx.doi.org/10.1007/s10734-014-9837-7\n[Abstract, abridged] The aim of the current study was to provide a valid and reliable \ninstrument for the evaluation of the teaching effectiveness in the Greek higher education \nsystem. Other objectives of the study were (a) the examination of the dimensionality and the \nhigher-order structure of the Greek version of Students’ Evaluation of Educational Quality \n(SEEQ) questionnaire, and (b) the investigation of the effects of several background variables \non students’ evaluations of teaching (SET) scores provided by the Greek version of SEEQ. A \ntotal of 1,264 students participated by filling in the questionnaires administered to them. The \nresults showed solid evidence of the applicability of the Greek version of SEEQ, by confirming \nthe factor structure of the instrument and reassuring the multidimensionality of the teaching \neffectiveness construct. Additionally, the effects of several background variables on teaching \neffectiveness further supported the validity of SET scores. \nGrayson​ (2015): questions student’s ability to give accurate ratings \nGrayson, J. P. (2015). Repeated low teaching evaluations: A form of habitual behavior? \nCanadian Journal of Higher Education, 45​(4), 298-321. \nhttp://journals.sfu.ca/cjhe/index.php/cjhe/article/view/184404 \n[Abstract, abridged] In this article, comparisons were made between first- and third-year \ncollective evaluations of professors’ performance at the University of British Columbia, York \nUniversity, and McGill University. Overall, it was found that students who provided low \nevaluations in their first year were also likely to do so in their third year. Given that over the \ncourse of their studies, students likely would have been exposed to a range of different \nbehaviours on the part of their professors, it is argued that the propensity of a large number of \nstudents to give consistently low evaluations was a form of “habitual behaviour. \nGreenwald​ (1997): student rating measures have validity concerns \nGreenwald, A. G. (1997). Validity concerns and usefulness of student ratings of instruction. \nAmerican Psychologist, 52​(11), 1182-1186.​ ​http://dx.doi.org/10.1037/0003-066X.52.11.1182 \n[Abstract] The validity of student rating measures of instructional quality was severely \nquestioned in the 1970s. By the early 1980s, however, most expert opinion viewed student \nrating measures as valid and as worthy of widespread use. In retrospect, older \ndiscriminant-validity concerns were not so much resolved as they were displaced from \nresearch attention by accumulating evidence for convergent validity. This article introduces a \nCurrent Issues section that gives new attention to validity concerns associated with student \nratings. The section's 4 articles deal, respectively, with (a) conceptual structure (are student \nratings unidimensional or multidimensional?), (b) convergent validity (how well do ratings \ncorrelate with other indicators of effective teaching?), (c) discriminant validity (are ratings \ninfluenced by factors other than teaching effectiveness?), and (d) consequential validity (are \nratings used effectively in personnel development and evaluation?). Although all 4 articles \nfavor the use of ratings, they disagree on controversial points associated with interpretation \nand use of ratings data. \nKhong​ (2014): SET is a valid instrument in evaluating teaching effectiveness \nhttp://psycnet.apa.org/doi/10.1037/0003-066X.52.11.1182\nhttp://journals.sfu.ca/cjhe/index.php/cjhe/article/view/184404\nhttp://psycnet.apa.org/doi/10.1037/0003-066X.52.11.1182\nhttp://journals.sfu.ca/cjhe/index.php/cjhe/article/view/184404\nKhong, T. L. (2014). The validity and reliability of the student evaluation of teaching: A case in \na private higher educational institution in Malaysia. ​International Journal for Innovation \nEducation and Research, 2​(9), 57-63.​ ​http://www.ijier.net/index.php/ijier/article/view/317 \n[Abstract, abridged] Most universities are using the Student Evaluation of Teaching (SET) as \nan instrument for students to assess a lecturer’s teaching performance. It is an essential \ninstrument to reflect the feedback in enhancing the quality of teaching and learning. The \npurpose of this paper is to examine the validity and reliability of the SET as a valid instrument \nin evaluating teaching effectiveness in a private higher education institution in Malaysia. \nExploratory Factor Analysis and Confirmatory Factor Analysis have validated all 10 items of \nSET whereby all items indicated high reliability and internal consistency. \nThe conclusion of this study showed that the SET is a valid instrument in evaluating teaching \neffectiveness. \nLama, Arias, Mendoza, & Manahan​ (2015): lack of student diligence when rating instructors \nraises validity concerns \nLama, T., Arias, P., Mendoza, K. & Manahan, J. (2015). Student evaluation of teaching \nsurveys: do students provide accurate and reliable information? ​e-Journal of Social & \nBehavioural Research in Business, 6​(1), 30-39.​ ​http://www.ejsbrb.org/a.php?/content/issue/10 \n[Abstract, abridged] This paper explores patterns of students' response behaviour of \ninternational students studying in an Australian university when filling out student surveys \nevaluating lecturers and courses. The study focuses on whether information obtained through \nthe survey process can be relied upon to make management decisions. The results of the \nstudy seem to suggest a reasonable level of diligence is lacking on the students' part in \nanswering the surveys, raising a concern about the reliability of information. This tendency \nseems to be prevalent among all students irrespective of their gender and nationality. \nMarsh & Roche​ (1997): evaluations are relatively valid and unaffected by hypothesized \nbiases \nMarsh, H. W., & Roche, L. A. (1997). Making students’ evaluations of teaching effectiveness \neffective: The critical issues of validity, bias, and utility. ​American Psychologist, 52​(11), \n1187-1197. ​http://dx.doi.org/10.1037/0003-066X.52.11.1187 \n[Abstract, abridged] This article reviews research indicating that, under appropriate conditions, \nstudents' evaluations of teaching (SETs) are (a) multidimensional; (b) reliable and stable; (c) \nprimarily a function of the instructor who teaches a course rather than the course that is \ntaught; (d) relatively valid against a variety of indicators of effective teaching; (e) relatively \nunaffected by a variety of variables hypothesized as potential biases (e.g., grading leniency, \nclass size, workload, prior subject interest); and (f) useful in improving teaching effectiveness \nwhen SETS are coupled with appropriate consultation. The authors recommend rejecting a \nnarrow criterion-related approach to validity and adopting a broad construct-validation \napproach, recognizing that effective teaching and SETs that reflect teaching effectiveness are \nmultidimensional; no single criterion of effective teaching is sufficient; and tentative \nhttp://dx.doi.org/10.1037/0003-066X.52.11.1187\nhttp://www.ijier.net/index.php/ijier/article/view/317\nhttp://www.ijier.net/index.php/ijier/article/view/317\nhttp://www.ejsbrb.org/a.php?/content/issue/10\nhttp://www.ejsbrb.org/a.php?/content/issue/10\ninterpretations of relations with validity criteria and potential biases should be evaluated \ncritically in different contexts, in relation to multiple criteria of effective teaching, theory, and \nexisting knowledge.  \nMartin, Dennehy, & Morgan​ (2013): validity of SET is questioned; student focus groups \nsuggested as an alternative \nMartin, L. R., Dennehy, R., & Morgan, S. (2013). Unreliability in student evaluation of teaching \nquestionnaires: Focus groups as an alternative approach. ​Organization Management Journal, \n10​(1), 66-74.​ ​http://dx.doi.org/10.1080/15416518.2013.781401 \n[Abstract, abridged] Research on the validity and reliability of SETs is vast, though riddled \nwith inconsistencies. The many “myths” of SETs are investigated and the incongruities are \ndemonstrated. We hypothesize that the discrepancies in empirical studies come from \nmisunderstanding and inappropriate actions by students. To address the complexity inherent \nin these problems, we suggest the use of focus groups as an alternative approach or \ncomplement to the standard SETs. A recommended format and guidelines for running \nclassroom focus groups are provided. Institutional constraints and implementation concerns \nare addressed as well. This article lays the foundation for implementing a change in student \nassessment of teaching by proposing a method to compensate for bias in SETs, using focus \ngroups as an evaluation tool, either as a stand-alone process or as a supplement to current \nmethods. \nMcKeachie​ (1997): student ratings are valid but affected by contextual variables such as \ngrading leniency \nMcKeachie, W. J. (1997). Student ratings: The validity of use. ​American Psychologist, 52​(11), \n1218-1225. ​http://dx.doi.org/10.1037/0003-066X.52.11.1218 \n[Abstract, abridged] In this article, the author discusses the other articles in this Current \nIssues section and concludes that all of the authors agree that student ratings are valid but \nthat contextual variables such as grading leniency can affect the level of ratings. The authors \ndisagree about the wisdom of applying statistical corrections for such contextual influences. \nThis article argues that the problem lies neither in the ratings nor in the correction but rather in \nthe lack of sophistication of personnel committees who use the ratings. Thus, more attention \nshould be directed toward methods of ensuring more valid use.  \nMorley​ (2012): ​student evaluations in this study were generally unreliable \nMorley, D. D. (2012). Claims about the reliability of student evaluations of instruction: The \necological fallacy rides again. ​Studies in Educational Evaluation, 38​(1), 15-20. \nhttp://dx.doi.org/10.1016/j.stueduc.2012.01.001 \n[Abstract, abridged] The vast majority of the research on student evaluation of instruction has \nassessed the reliability of groups of courses and yielded either a single reliability coefficient \nfor the entire group, or grouped reliability coefficients for each student evaluation of teaching \n(SET) item. This manuscript argues that these practices constitute a form of ecological \nhttp://dx.doi.org/10.1080/15416518.2013.781401\nhttp://dx.doi.org/10.1037/0003-066X.52.11.1218\nhttp://dx.doi.org/10.1016/j.stueduc.2012.01.001\nhttp://dx.doi.org/10.1016/j.stueduc.2012.01.001\nhttp://dx.doi.org/10.1080/15416518.2013.781401\ncorrelation and therefore yield incorrect estimates of reliability. Intraclass reliability and \nagreement coefficients were proposed as appropriate for making statements about the \nreliability of SETs in specific classes. An analysis of 1073 course sections using inter-rater \ncoefficients found that students using this particular instrument were generally unable to \nreliably evaluate faculty. In contrast, the traditional ecologically flawed multi-class “group” \nreliability coefficients had generally acceptable reliability. \nNargundkar & Shrikhande​ (2012): an instrument that was validated 20 years ago is still valid \nNargundkar, S., & Shrikhande, M. (2012). An empirical investigation of student evaluations of \ninstruction: The relative importance of factors. ​Decision Sciences Journal of Innovative \nEducation, 10​(1), 117-135.​ ​http://dx.doi.org/10.1111/j.1540-4609.2011.00328.x \n[Abstract, abridged] We analyzed over 100,000 student evaluations of instruction over 4 years \nin the college of business at a major public university. We found that the original instrument \nthat was validated about 20 years ago is still valid, with factor analysis showing that the six \nunderlying dimensions used in the instrument remained relatively intact. Also, we found that \nthe relative importance of those six factors in the overall assessment of instruction changed \nover the past two decades, reflecting changes in the expectations of the current millennial \ngeneration of students. The results were consistent across four subgroups \nstudied—Undergraduate Core, Undergraduate Noncore, Graduate Core, and Graduate \nNoncore classes, with minor differences. \nRantanen​ (2013): reliability of SET is questionable; multiple feedbacks required \nRantanen, P. (2013). The number of feedbacks needed for reliable evaluation. A multilevel \nanalysis of the reliability, stability and generalizability of students’ evaluation of teaching. \nAssessment & Evaluation in Higher Education, 38​(2), 224-239. \nhttp://dx.doi.org/10.1080/02602938.2011.625471 \n[Abstract, abridged] A multilevel analysis approach was used to analyse students’ evaluation \nof teaching (SET). The low value of inter-rater reliability stresses that any solid conclusions on \nteaching cannot be made on the basis of single feedbacks. To assess a teacher’s general \nteaching effectiveness, one needs to evaluate four randomly chosen course implementations. \nTwo implementations are needed when one course is evaluated, and if one implementation is \nevaluated, up to 15 feedbacks are needed. The stability of students’ ratings is very high, \nwhich reflects students’ stable rating criteria. There is an obvious rating paradox: from the \nstudent’s point of view, each rating is very precise, stable and justifiable, but from the \nteacher’s point of view a single feedback reflects the quality of teaching to just a moderate \nextent. Cross-hierarchical analysis reveals that there are large discrepancies between the \nuses of rating scales; some students are systematically more lenient in their rating whereas \nothers are systematically more severe. The study also reveals that some courses are \ngenerally rated more favourably and that some courses are more suitable for certain teachers. \nSocha​ (2013): a SET instrument was found to have overall good reliability and validity with \nrelatively few biases \nhttp://dx.doi.org/10.1111/j.1540-4609.2011.00328.x\nhttp://dx.doi.org/10.1111/j.1540-4609.2011.00328.x\nhttp://dx.doi.org/10.1080/02602938.2011.625471\nhttp://dx.doi.org/10.1080/02602938.2011.625471\nSocha, A. (2013). A hierarchical approach to students’ assessment of instruction. ​Assessment \n& Evaluation in Higher Education, 38​(1), 94-113. \nhttp://dx.doi.org/10.1080/02602938.2011.604713 \n[Abstract, abridged] Since students are extensively exposed to course elements, students’ \nevaluation of instruction should be one of several components in the teacher evaluation \nsystem. Since traditional methods, such as Cronbach’s alpha and ordinary least squares \nregression, do not address the hierarchical data of the classroom, the current study used the \nstatistical techniques of confirmatory factor analysis and hierarchical linear modelling in order \nto properly investigate the reliability and validity of the Students’ Assessment of Instruction \n(SAI) instrument. Overall, the SAI was found to have good reliability and validity with relatively \nfew biases and could be used to extract five distinguishable traits of instructional \neffectiveness. \nSpooren, Brockx, & Mortelmans​ (2013): the utility and validity of SET is questionable \nSpooren, P., Brockx, B., & Mortelmans, D. (2013). On the validity of student evaluation of \nteaching: The state of the art. ​Review of Educational Research, 83​(4), 598-642. \nhttp://dx.doi.org/10.3102/0034654313496870 \n[Abstract] This article provides an extensive overview of the recent literature on student \nevaluation of teaching (SET) in higher education. The review is based on the SET \nmeta-validation model, drawing upon research reports published in peer-reviewed journals \nsince 2000. Through the lens of validity, we consider both the more traditional research \nthemes in the field of SET (i.e., the dimensionality debate, the ‘bias’ question, and \nquestionnaire design) and some recent trends in SET research, such as online SET and bias \ninvestigations into additional teacher personal characteristics. The review provides a clear \nidea of the state of the art with regard to research on SET, thus allowing researchers to \nformulate suggestions for future research. It is argued that SET remains a current yet delicate \ntopic in higher education, as well as in education research. Many stakeholders are not \nconvinced of the usefulness and validity of SET for both formative and summative purposes. \nResearch on SET has thus far failed to provide clear answers to several critical questions \nconcerning the validity of SET. \nUttl, White, & Gonzalez​ (2016): SETs do not indicate teaching quality, meta-analysis \nUttl, B., White, C. A., Gonzalez, D. W. (2016). Meta-analysis of faculty’s teaching \neffectiveness: Student evaluation of teaching ratings and student learning are not related. \nStudies in Educational Evaluation,​ (in press, available online September 19, 2106). \nhttp://dx.doi.org/10.1016/j.stueduc.2016.08.007 \n[Abstract, abridged] We re-analyzed previously published meta-analyses of the multisection \nstudies and found that their findings were an artifact of small sample sized studies and \npublication bias. Whereas the small sample sized studies showed large and moderate \ncorrelation, the large sample sized studies showed no or only minimal correlation between \nSET ratings and learning. Our up-to-date meta-analysis of all multisection studies revealed no \nsignificant correlations between the SET ratings and learning. These findings suggest that \nhttp://dx.doi.org/10.1080/02602938.2011.604713\nhttp://dx.doi.org/10.3102/0034654313496870\nhttp://dx.doi.org/10.3102/0034654313496870\nhttp://dx.doi.org/10.1080/02602938.2011.604713\nhttp://dx.doi.org/10.1016/j.stueduc.2016.08.007\ninstitutions focused on student learning and career success may want to abandon SET ratings \nas a measure of faculty's teaching effectiveness.  \nWright & Jenkins-Guarieri​ (2012): SETs appear to be valid and free from gender bias \nWright, S. L., & Jenkins-Guarieri, M. A. (2012). Student evaluations of teaching: combining \nthe meta-analyses and demonstrating further evidence for effective use. ​Assessment & \nEvaluation in Higher Education, 37​(6), 683-699. \nhttp://dx.doi.org/10.1080/02602938.2011.563279 \n[Abstract, abridged] Given that there is not one study summarising all these domains of \nresearch, a comprehensive overview of SETs was conducted by combining all prior \nmeta-analyses related to SETs. Eleven meta-analyses were identified, and nine \nmeta-analyses covering 193 studies were included in the analysis, which yielded a \nsmall-to-medium overall weighted mean effect size (r = .26) between SETs and the variables \nstudied. Findings suggest that SETs appear to be valid, have practical use that is largely free \nfrom gender bias and are most effective when implemented with consultation strategies. \n Impact on Teaching Quality \nBlair & Valdez Noel​ (2014): little evidence that student feedback is leading to improved \nteaching \nBlair, E., & Valdez Noel, K. (2014). Improving higher education practice through student \nevaluation systems: is the student voice being heard? ​Assessment & Evaluation in Higher \nEducation, 39​(7), 879-894.​ ​http://dx.doi.org/10.1080/02602938.2013.875984 \n[Abstract, abridged] This paper examines the student evaluations at a university in Trinidad \nand Tobago in an effort to determine whether the student voice is being heard. The research \nfocused on students’ responses to the question, ‘How do you think this course could be \nimproved?’ Student evaluations were gathered from five purposefully selected courses taught \nat the university during 2011–2012 and then again one year later, in 2012–2013. This allowed \nfor an analysis of the selected courses. Whilst the literature suggested that student evaluation \nsystems are a valuable aid to lecturer improvement, this research found little evidence that \nthese evaluations actually led to any real significant changes in lecturers’ practice. \nCampbell & Bozeman​ (2008): questions the effect student evaluations have on teaching \nquality \nCampbell, J. P., & Bozeman, W. C. (2008). The value of student ratings: Perceptions of \nstudents, teachers, and administrators. ​Community College Journal of Research and Practice, \n32​, 13-24.​ ​http://dx.doi.org/10.1080/10668920600864137 \n[Abstract, abridged] This research responded to the lack of emphasis on more effective use of \nthe data for the purpose of improving teaching effectiveness by questioning the opinions and \nhttp://dx.doi.org/10.1080/10668920600864137\nhttp://dx.doi.org/10.1080/10668920600864137\nhttp://dx.doi.org/10.1080/02602938.2011.563279\nhttp://dx.doi.org/10.1080/02602938.2013.875984\nhttp://dx.doi.org/10.1080/02602938.2011.563279\nhttp://dx.doi.org/10.1080/02602938.2013.875984\npractices of students, faculty, and administrators. More importantly, this research questioned \nthe value of student ratings of teaching: Is the effort of doing student evaluations worth the \ninstitutional investment or is it simply a routine process which has little or no effect on \nimproving teaching? \nCurwood, Tomitsch, Thomson, & Hendry​ (2015): provide an example of support for \nacademics’ learning from SETs \nCurwood, J.S., Tomitsch, M., Thomson, K., & Hendry. G.D. (2015). Professional learning in \nhigher education: Understanding how academics interpret student feedback and access \nresources to improve their teaching. ​Australasian Journal of Educational Technology, 31​(5). \nhttp://dx.doi.org/10.14742/ajet.2516 \n[Abstract, abridged] Previous research on professional learning has identified that face-to-face \nconsultation is an effective approach to support academics’ learning from student feedback. \nHowever, this approach is labour and time intensive, and does not necessarily provide all \nacademics with just-in-time support. In this article, we describe an alternative approach, which \ninvolves the creation of ​Ask Charlie​, a mobile website that visually represents results from \nstudent evaluation of teaching (SET), and provides academics with personalised \nrecommendations for teaching resources. ​Ask Charlie​ was developed and evaluated by \ndrawing on design-based research methods with the aim to support professional learning \nwithin higher education. \nMakondo & Ndebele​ (2014): SETs are beneficial for improving teaching quality \nMakondo, L., & Ndebele, C. (2014). University lecturers’ views on student-lecturer \nevaluations. ​Anthropologist, 17​(2), 377-386. \nhttp://www.krepublishers.com/02-Journals/T-Anth/Anth-17-0-000-14-Web/Anth-17-0-000-14-C\nontents/Anth-17-0-000-14-Contents.htm \n[Abstract, abridged] This paper discusses university lecturers’ views on student-lecturer \nevaluation of teaching and learning process. Specific reference is given to the university \nlecturers’ views on the usefulness of the evaluation exercise, the evaluation process, items in \nthe evaluation questionnaires and evaluation feedback reports at a formerly disadvantaged \nSouth African University. A total of 118 (53.8%) lecturers out of a staff establishment of 219 \nteaching staff volunteered their participation in this study. The findings of the study show that \ninsights from student-lecturer evaluations are an important source of information for university \nteaching staff and administration to consider in their quest to improve on the quality of \nuniversity teaching and learning moves that can help improve on throughput rates.  \nStein, Spiller, Harris, Deaker, & Kennedy​ (2013): there are gaps in the way academics \nengage with student evaluation \nStein, S. J., Spiller, D., Terry, S., Harris, T., Deaker, L., & Kennedy, J. (2013). Tertiary \nteachers and student evaluations: never the twain shall meet? ​Assessment & Evaluation in \nHigher Education, 38​(7), 892-904.​ ​http://dx.doi.org/10.1080/02602938.2013.767876 \nhttp://www.krepublishers.com/02-Journals/T-Anth/Anth-17-0-000-14-Web/Anth-17-0-000-14-Contents/Anth-17-0-000-14-Contents.htm\nhttp://www.krepublishers.com/02-Journals/T-Anth/Anth-17-0-000-14-Web/Anth-17-0-000-14-Contents/Anth-17-0-000-14-Contents.htm\nhttp://www.krepublishers.com/02-Journals/T-Anth/Anth-17-0-000-14-Web/Anth-17-0-000-14-Contents/Anth-17-0-000-14-Contents.htm\nhttp://dx.doi.org/10.1080/02602938.2013.767876\nhttp://dx.doi.org/10.14742/ajet.2516\nhttp://dx.doi.org/10.1080/02602938.2013.767876\nhttp://dx.doi.org/10.14742/ajet.2516\n[Abstract, abridged] While extensive research has been done on student evaluations, there is \nless research-based evidence about teachers’ perceptions of and engagement with student \nevaluations, the focus of the research reported in this paper. Results highlighted the general \nacceptance of the notion of student evaluations, recurring ideas about the limitations of \nevaluations and significant gaps in the way academics engage with student evaluation \nfeedback. \n Evaluating Faculty for Tenure and Promotion \nBoysen​ (2015): faculty and administrators can over-interpret small variations \nBoysen, G. A. (2015). Uses and misuses of student evaluations of teaching: The \ninterpretation of differences in teaching evaluation means irrespective of statistical \ninformation. ​Teaching of Psychology, 42​(2), 109-118. \nhttp://dx.doi.org/10.1177/0098628315569922 \n[Abstract] Student evaluations of teaching are among the most accepted and important            \nindicators of college teachers’ performance. However, faculty and administrators can          \noverinterpret small variations in mean teaching evaluations. The current research examined           \nthe effect of including statistical information on the interpretation of teaching evaluations.            \nStudy 1 (​N = 121) showed that faculty members interpreted small differences between mean              \ncourse evaluations even when confidence intervals and statistical tests indicated the absence            \nof meaningful differences. Study 2 (​N = 183) showed that differences labeled as             \nnonsignificant still influenced perceptions of teaching qualifications and teaching ability. The           \nresults suggest the need for increased emphasis on the use of statistics when presenting and               \ninterpreting teaching evaluation data. \nBoysen, Raesly, & Casner​ (2014): ratings are misinterpreted by faculty and administrators \nBoysen, G. A., Kelly, T. J., Raesly, H. N., & Casner, R. W. (2014). The (mis)interpretation of \nteaching evaluations by college faculty and administrators. ​Assessment & Evaluation in \nHigher Education, 39​(6), 641-656.​ ​http://dx.doi.org/10.1080.02602938.2013.860950 \n[Abstract, abridged] The current research consisted of three studies documenting the effect of \nsmall mean differences in teaching evaluations on judgements about teachers. Differences in \nmeans small enough to be within the margin of error significantly impacted faculty members’ \nassignment of merit-based rewards (Study 1), department heads’ evaluation of teaching \ntechniques (Study 2) and faculty members’ evaluation of specific teaching skills (Study 3). \nThe results suggest that faculty and administrators do not apply appropriate statistical \nprinciples when evaluating teaching evaluations and instead use a general heuristic that \nhigher evaluations are better. \nFraile & Bosch-Morell​ (2015): present a reliable approach to SET interpretation \nFraile, R., & Bosch-Morell, F. (2015). Considering teaching history and calculating confidence \nhttp://dx.doi.org/10.1177/0098628315569922\nhttp://dx.doi.org/10.1080.02602938.2013.860950\nhttp://dx.doi.org/10.1080.02602938.2013.860950\nhttp://dx.doi.org/10.1177/0098628315569922\nintervals in student evaluations of teaching quality: An approach based on Bayesian \ninference. ​Higher Education, 70​(1), 55-72.​ ​http://dx.doi.org/10.1007/s10734-014-9823-0 \n[Abstract, abbreviated, edited] Student evaluations of teaching quality are among the most \nused and analysed sources of such information [for lecturer promotion and tenure decisions]. \nHowever, to date little attention has been paid in how to process them in order to be able to \nestimate their reliability. Within this paper we present an approach that provides estimates of \nsuch reliability in terms of confidence intervals. This approach, based on Bayesian inference, \nalso provides a means for improving reliability even for lecturers having a low number of \nstudent evaluations. Such improvement is achieved by using past information in every year’s \nevaluations.  \nJackson & Jackson​ (2015): concerns with use of SETs for summative purposes \nJackson, M. J., & Jackson, W. T. (2015). The misuse of student evaluations of teaching: \nImplications, suggestions and alternatives. ​Academy of Educational Leadership Journal, \n19​(3), 165-173.​ ​http://www.alliedacademies.org/academy-of-educational-leadership-journal/ \n[Abstract, abridged] A five year longitudinal study of the results from Student Evaluations of \nTeaching (SETs) was accomplished within the business school of a small southwestern state \nuniversity. Based upon the findings of the study, the authors argue that prior practices in \napplying the results of SETs for summative purposes have not been based upon a sound \nstatistical foundation. Results from both instructor samples and populations are compared and \nindicate that the use of means to measure and compare instructor effectiveness requires \nassumptions of normality which the data does not meet. \nJones, Gaffney-Rhys, & Jones​ (2015): presents issues if decision-makers use SET results \nsummatively \nJones, J., Gaffney-Rhys, R., & Jones, E. (2014). Handle with care! An exploration of the \npotential risks associated with the publication and summative usage of student evaluation of \nteaching (SET) results. ​Journal of Further and Higher Education, 38​(1), 37-56. \nhttp://dx.doi.org/10.1080/0309877X.2012.699514 \n[Abstract, abridged] This article presents a synthesis of previous ideas relating to student \nevaluation of teaching (SET) results in higher education institutions (HEIs), with particular \nfocus upon possible validity issues and matters that HEI decision-makers should consider \nprior to interpreting survey results and using them summatively. Furthermore, the research \nexplores relevant legal issues (namely, defamation, breach of the duty to take reasonable \ncare for an employee’s welfare, breach of the duty of trust and confidence, breach of the right \nto privacy and, if the lecturer is forced to resign as a consequence of such infringements, \nconstructive dismissal) that decision-makers, in UK HEIs, should appreciate if survey results \nare widely published or used to inform employment decisions. \nMitry & Smith​ (2014): conclusions drawn from evaluations may be invalid and harmful \nMitry, D. J., & Smith, D. E. (2014). Student evaluations of faculty members: A call for \nhttp://dx.doi.org/10.1080/0309877X.2012.699514\nhttp://dx.doi.org/10.1007/s10734-014-9823-0\nhttp://www.alliedacademies.org/academy-of-educational-leadership-journal/\nhttp://www.alliedacademies.org/academy-of-educational-leadership-journal/\nhttp://dx.doi.org/10.1007/s10734-014-9823-0\nhttp://dx.doi.org/10.1080/0309877X.2012.699514\nanalytical prudence. ​Journal on Excellence in College Teaching, 25​(2), 56-67. \nhttp://celt.miamioh.edu/ject/issue.php?v=25&n=2 \n[Abstract, abridged] The authors of this article express concern about the use of parametric \ntechniques to report faculty performance based on categorical Likert survey data gleaned \nfrom student responses to teaching evaluations. They argue that these surveys often violate \nprimary statistical requirements for evaluative application. Therefore, the conclusions drawn \nfrom such evaluations may be invalid and even harmful to faculty members over time. The \nauthors conclude that it is imprudent for university administrators to support questionable \nanalysis methods simply because they have, on the surface, the appearance of rigor, or \nbecause the practice has become commonplace. \nPalmer​ (2012): presents examples of ineffective responses to evaluation results \nPalmer, S. (2012). Student evaluation of teaching: keeping in touch with reality. ​Quality in \nHigher Education, 18​(3), 297-311.​ ​http://dx.doi.org/10.1080/13538322.2012.730336 \n[Abstract, abridged] This article used publicly available student evaluation of teaching data to \npresent examples of where institutional responses to evaluation processes appeared to be \neducationally ineffective and where the pursuit of the ‘right’ student evaluation results appears \nto have been mistakenly equated with the aim of improved teaching and learning. If the vast \nresources devoted to student evaluation of teaching are to be effective, then the data \nproduced by student evaluation systems must lead to real and sustainable improvements in \nteaching quality and student learning, rather than becoming an end in itself. \n Multifaceted Evaluation \nBerk​ (2013): covers several issues, including multifactorial evaluations \nBerk, R. A. (2013). Top five flashpoints in the assessment of teaching effectiveness. ​Medical \nTeacher, 35​(1), 15-26.​ ​http://dx.doi.org/10.3109/0142159X.2012.732247 \n[Berk is also the author of the 2013 book “Top 10 Flashpoints in Student Ratings and the \nEvaluation of Teaching”] \n[Abstract, abridged] Five flashpoints are defined, the salient issues and research described, \nand, finally, specific, concrete recommendations for moving forward are proffered. Those \nflashpoints are: (1) student ratings vs. multiple sources of evidence; (2) sources of evidence \nvs. decisions: which come first?’ (3) quality of ‘‘home-grown’’ rating scales vs. \ncommercially-developed scales; (4) paper-and-pencil vs. online scale administration; and (5) \nstandardized vs. unstandardized online scale administrations. Conclusions: Multiple sources \nof evidence collected through online administration, when possible, can furnish a solid \nfoundation from which to infer teaching effectiveness and contribute to fair and equitable \ndecisions about faculty contract renewal, merit pay, and promotion and tenure. \nhttp://celt.miamioh.edu/ject/issue.php?v=25&n=2\nhttp://dx.doi.org/10.3109/0142159X.2012.732247\nhttp://dx.doi.org/10.1080/13538322.2012.730336\nhttp://dx.doi.org/10.1080/13538322.2012.730336\nhttp://celt.miamioh.edu/ject/issue.php?v=25&n=2\nhttp://dx.doi.org/10.3109/0142159X.2012.732247\nCox, Peeters, Stanford, & Seifert​ (2013): a peer assessment instrument was piloted; \nformative peer assessment seems important \nCox, C.D., Peeters, M. J., Stanford, B. L., & Seifert, C. F. (2013). Pilot of peer assessment \nwithin experiential teaching and learning. ​Currents in Pharmacy Teaching and Learning, 5​(4), \n311-320.​ ​http://dx.doi.org/10.1016/j.cptl.2013.02.003 \n[Abstract, abridged] Objectives of this study were as follows: (1) to pilot test an instrument for \npeer assessment of experiential teaching, (2) to compare peer evaluations from faculty with \nstudent evaluations of their preceptor (faculty), and (3) to determine the impact of qualitative, \nformative peer assessment on faculty’s experiential teaching. Faculty at Texas Tech \nUniversity Health Sciences Center School of Pharmacy implemented a new peer assessment \ninstrument focused on assessing experiential teaching. Eight faculty members participated in \nthis pilot. Conclusion: A peer assessment of experiential teaching was developed and \nimplemented. Aside from evaluation, formative peer assessment seemed important in \nfostering feedback for faculty in their development. \nHughes II & Pate​ (2013): present a multisource evaluation method \nHughes II, K. E., & Pate, G. R. (2013). Moving beyond student ratings: A balanced scorecard \napproach for evaluating teaching performance. Issues in ​Accounting Education, 28​(1), 49-75. \nhttp://dx.doi.org/10.2308/iace-50302 \n[Abstract, abridged] This position paper proposes a viable alternative to higher education’s \ncurrent focus on student ratings as the primary metric for summative teaching evaluations \n(i.e., for personnel decisions). In contrast to the divergent opinions among educational \nresearchers about the validity of student ratings, a strong consensus exists that summative \nmeasures derived from the student ratings process represent a necessary rather than a \nsufficient source for evaluating teaching performance (Cashin 1990; Berk 2005). Accordingly, \nto more completely describe annual teaching performance, we propose a multisource, \nmultiple-perspective Teaching Balanced Scorecard (TBSC), fashioned from the ‘‘classic’’ \nBalanced Scorecard developed by Kaplan and Norton (1992a). The TBSC can guide \nacademic administrators to expand their conceptual view of teaching performance beyond the \nboundaries of the classroom, while coherently communicating the department’s teaching \nexpectations to the faculty; consistent with this proposition, we provide supporting evidence \nfrom a successful TBSC implementation in an academic department. \nIqbal​ (2013): faculty express concerns with peer reviews \nIqbal, I. (2013). Academics’ resistance to summative peer review of teaching: questionable \nrewards and the importance of student evaluations. ​Teaching in Higher Education, 18​(5), \n557-569.​ ​http://dx.doi.org/10.1080/13562517.2013.764863 \n[Abstract, abridged] This study draws from 30 semi-structured interviews with tenure-track \nfaculty members in a research-intensive university to examine their lack of engagement in the \nsummative peer review of teaching. Findings indicate that most academics in the study do not \nthink peer review outcomes contribute meaningfully to decisions about career advancement \nhttp://dx.doi.org/10.1016/j.cptl.2013.02.003\nhttp://dx.doi.org/10.1080/13562517.2013.764863\nhttp://dx.doi.org/10.1080/13562517.2013.764863\nhttp://dx.doi.org/10.2308/iace-50302\nhttp://dx.doi.org/10.1016/j.cptl.2013.02.003\nhttp://dx.doi.org/10.2308/iace-50302\nand believe that, in comparison, student evaluation of teaching scores matter more. The \nfindings suggest that faculty member resistance to summative peer reviews will persist unless \nacademics are confident that the results will be seriously considered in decisions about tenure \nand promotion. \nLyde, Grieshaber, & Byrns​ (2016): a multisource method of evaluating is a useful tool \nLyde, A.R., Grieshaber, D.C., Byrns, G. (2016). Faculty teaching performance: Perceptions of \na multi-source method for evaluation (MME). ​Journal of the Scholarship of Teaching and \nLearning, 16​(3), 82-94.​ ​http://dx.doi.org/10.14434/josotl.v16i3.18145 \n[Abstract, abridged] A holistic system of evaluating university teaching is necessary for \nreasons including the limitations of student evaluations and the complexity of assessing \nteaching performance. University faculty members were interviewed to determine their \nperceptions of the multisource method of evaluating (MME) teaching performance after a \nrevision of policies and procedures was approved. The MME is comprised of three primary \ndata sources: student evaluations, instructor reflections describing attributes of their own \nteaching such as the teaching philosophy, and a formative external review. While the faculty \nperceived the MME as a useful tool, they still believe it operates more to produce a \nsummative product than work as a formative process. According to the results, a more \nformative process would be supported by addressing several factors, including timing of \nreflections, accountability from year to year, and mentoring. Improving these constraints may \nmake the proposed MME a more appropriate tool for formative review of teaching.  \nMarsh & Roche​ (1997): multidimensional aspects of teaching should be evaluated; suggest \nnine factors \nMarsh, H. W., & Roche, L. A. (1997). Making students’ evaluations of teaching effectiveness \neffective: The critical issues of validity, bias, and utility. ​American Psychologist, 52​(11), \n1187-1197. ​http://dx.doi.org/10.1037/0003-066X.52.11.1187 \nThis article has been included in previous themes. For this theme, Marsh & Roche (1997) \nbelieve that effective evaluation tools should consider nine factors: “Learning/Value, Instructor \nEnthusiasm, Organization/Clarity, Group Interaction, Individual Rapport, Breadth of Coverage, \nExaminations/Grading, Assignments/Readings, and Workload/Difficulty” (p.1187). The \nauthors also comment on the nature of “homemade” evaluation instruments being of \nquestionable quality (p. 1188).  \nMartin, Dennehy, & Morgan​ (2013): validity of SET is questioned; student focus groups \nsuggested as an alternative \nMartin, L. R., Dennehy, R., & Morgan, S. (2013). Unreliability in student evaluation of teaching \nquestionnaires: Focus groups as an alternative approach. ​Organization Management Journal, \n10​(1), 66-74.​ ​http://dx.doi.org/10.1080/15416518.2013.781401 \n[Abstract, abridged] Research on the validity and reliability of SETs is vast, though riddled \nhttp://dx.doi.org/10.14434/josotl.v16i3.18145\nhttp://dx.doi.org/10.14434/josotl.v16i3.18145\nhttp://dx.doi.org/10.1080/15416518.2013.781401\nhttp://dx.doi.org/10.1037/0003-066X.52.11.1187\nhttp://dx.doi.org/10.1080/15416518.2013.781401\nwith inconsistencies. The many “myths” of SETs are investigated and the incongruities are \ndemonstrated. We hypothesize that the discrepancies in empirical studies come from \nmisunderstanding and inappropriate actions by students. To address the complexity inherent \nin these problems, we suggest the use of focus groups as an alternative approach or \ncomplement to the standard SETs. A recommended format and guidelines for running \nclassroom focus groups are provided. Institutional constraints and implementation concerns \nare addressed as well. This article lays the foundation for implementing a change in student \nassessment of teaching by proposing a method to compensate for bias in SETs, using focus \ngroups as an evaluation tool, either as a stand-alone process or as a supplement to current \nmethods. \nRidley & Collins​ (2015): suggests a comprehensive performance evaluation instrument \nRidley, D., & Collins, J. (2015). A suggested evaluation metric instrument for faculty members \nat colleges and universities. ​International Journal of Education Research, 10​(1), 97-114. \nRetrieved from \nhttp://eds.a.ebscohost.com.login.ezproxy.library.ualberta.ca/eds/pdfviewer/pdfviewer?sid=9ff2\n4389-d34d-43d1-83fc-6ef82bd1ad47%40sessionmgr4009&vid=2&hid=4102 \n[Abstract, abridged] This study puts forth a comprehensive performance evaluation method \nfor university faculty members. The instrument is comprised of a teaching evaluation metric, a \nresearch evaluation metric, and a service evaluation metric. This study provides a unique \nmethod for measuring the performance of university faculty members by regressing \ncumulative student grade point average on the fraction of the total number of credit hours that \nstudents are taught by each faculty member. The study postulates that the resulting \nregression coefficients measure the average rate at which each faculty member contributes to \nstudent learning as measured by cumulative grade points earned per contact hour of \ninstruction. Since this model of teaching effectiveness is based on grades, freely assigned by \nindividual faculty members, it is a no contact, non-intrusive, non-confrontational, \nnon-threatening, non-coercive evaluation of teaching. \nStupans, McGuren, & Babey​ (2016): present a tool for analyzing free-form comments on \nratings forms \nStupans, I., McGuren, T., & Babey, A. M. (2016). Student evaluation of teaching: A study \nexploring student rating instrument free-form text comments. ​Innovative Higher Education, \n41​(1), 33-52. ​http://10.1007/s10755-015-9328-5 \n[Abstract] Student rating instruments are recognised to be valid indicators of effective \ninstruction, providing a valuable tool to improve teaching. However, free-form text comments \nobtained from the open-ended question component of such surveys are only infrequently \nanalysed comprehensively. We employed an innovative, systematic approach to the analysis \nof text-based feedback relating to student perceptions of and experiences with a recently \ndeveloped university program. The automated nature of the semantic analysis tool \n\"Leximancer\" enabled a critical interrogation across units of study, mining the cumulative text \nfor common themes and recurring core concepts. The results of this analysis facilitated the \nidentification of issues that were not apparent from the purely quantitative data, thus providing \nhttp://eds.a.ebscohost.com.login.ezproxy.library.ualberta.ca/eds/pdfviewer/pdfviewer?sid=9ff24389-d34d-43d1-83fc-6ef82bd1ad47%40sessionmgr4009&vid=2&hid=4102\nhttp://eds.a.ebscohost.com.login.ezproxy.library.ualberta.ca/eds/pdfviewer/pdfviewer?sid=9ff24389-d34d-43d1-83fc-6ef82bd1ad47%40sessionmgr4009&vid=2&hid=4102\na deeper understanding of the curriculum and teaching effectiveness that was constructive \nand detailed. \n[Link from ​Zimmerman​ (2008): some tools may encourage students to focus on negative \naspects of teaching; anonymous feedback means that students are not held accountable for \ntheir comments \nZimmerman, B. (2008). Course evaluations - students’ revenge? ​University Affairs.​ Retrieved \nfrom \nhttp://www.universityaffairs.ca/opinion/in-my-opinion/course-evaluations-students-revenge/ \nThis is an online opinion article.  \n“Even choosing the right questions is difficult. Instead of ‘What did you like least about the \nlectures?’ shouldn’t we be asking, ‘Is there something you liked least about the lectures?’ \nWhen we manipulate students into providing negative responses, we encourage them to cast \nabout for some negative remark, ​any​ negative remark, when they might otherwise have been \ndeclined” (paragraph 7). \n“Many students don’t need any encouragement to bash their teachers. The exercise is meant \nin part to ensure that instructors are held accountable, yet students engage in libel with \nimpunity. The student who referred to a colleague as a “cow” was not held accountable” \n(paragraph 8). \nhttp://www.universityaffairs.ca/opinion/in-my-opinion/course-evaluations-students-revenge/\nAppendix I: Recommendations Related to Evaluation of Teaching from the 2013 \nRenaissance Committee Report \nThese recommendations are taken from pages 11 and 12 of the report. \nSource: ​Cheeseman, C., MacLaren, I., Carey, J., Glanfield, F., Liu, L., McFarlane, L., Cahill, J. \nC., Garneau, T., Supernant, K., & Szeman, I. (2013, December 9). ​Report of the Renaissance \nCommittee.​ Retrieved from ​http://www.renaissance.ualberta.ca/ \n3-2 That all scholars be evaluated using the same evaluation structure, with \nconstituency-specific evaluation committees.  Non-scholarly activities should be evaluated \nseparately. \n3-3 That the number of committees evaluating the excellence of scholarly activities performed \nby a single constituency be substantially reduced from 3 to 6. Such committees will be formed \naround scholarly discipline, not faculty boundaries. Cultural practices within the unit should not \nbe allowed to influence the salary trajectories nor the process by which scholars are evaluated. \n3-4 That there be greater consistency in the size of comparator groups used for evaluation, at \nboth the small and large unit levels. \n3-8 That all scholars, which include tenure-track faculty, librarians, and specialized scholars, be \nevaluated in accordance with the broad definition of Scholarship provided in Section 2 of this \nreport. These constituencies should be evaluated equitably based on the Scholarship \nperformance measures and the extent to which Scholarship comprises a part of their duties. \n3-9 That all scholarly activities be evaluated using more than simple metrics (e.g. Impact \nFactors, USRI); that multifaceted evaluations be applied to all scholarly activities to allow for \nidentification of scholarly excellence.  \n3-11 Establishment of a Teaching Strategy for the University of Alberta that reviews and \nupdates the teaching and learning policies currently in place in the GFC Policy Manual, and \ndetermined implementation of those policies. \n3-12 Creation of specific, transparent policies for teaching evaluation to guide annual reviews, \ncontract renewal decisions, and decisions on tenure and promotion.  (As, for example, \ndelineated in the CAUT model policy on the evaluation of teaching performance, create policies \nand procedures that allow recognition of all aspects of teaching duties performed by academic \nstaff.) \n3-13 Establish a committee to redesign the USRI questions, ensuring a reliable and valid tool \nthat meets international standards for summative evaluation, provides a degree of formative \nfeedback, minimizes the potential for derogatory feedback, ensures value to the students who \nhttp://www.renaissance.ualberta.ca/\nparticipate in the process, and is in alignment with the University’s Teaching Strategy. To \nensure movement on this recommendation, establish a two-year limit on implementation. \n3-14 If changes to the USRI are not accomplished within two years (end of Fall term, 2015), \n(AASUA and Administration) declare a moratorium on their use. \n3-15 Provide leadership, support, and resources further to encourage teaching development \nand teaching Scholarship at the University of Alberta. \n3-16 Standardize reporting periods for all evaluation committees. \n3-22 require all scholarly evaluation committees to use external standards for the assessment of \nScholarship, reaching decisions by reference to agreed-upon external standards rather than to \ncolleagues’ performance.  \nFINAL Item No. 9 \nGFC EXECUTIVE COMMITTEE \nFor the Meeting of September 11, 2017 \nOUTLINE OF ISSUE \nAction Item \nAgenda Title: Faculty of Graduate Studies and Research: Proposed revisions to existing Supervision \nand Examinations policy. \nMotion:  THAT the GFC Executive Committee recommend that General Faculties Council approve the \nproposed revisions to existing Supervision and Examinations policy, as recommended by the GFC Academic \nStandards Committee, as submitted by the Faculty of Graduate Studies and Research and as set forth in \nAttachment 1, to take effect July 1, 2018. \nItem   \nAction Requested Approval Recommendation   \nProposed by Heather Zwicker, Dean, Faculty of Graduate Studies and Research  \nPresenter Deborah Burshtyn, Vice-Dean, Faculty of Graduate Studies and \nResearch \nDetails \nResponsibility Provost and Vice-President (Academic) \nThe Purpose of the Proposal is \n(please be specific) \nThe revisions are intended to clarify the policies, elaborate on \nprocedures, and improve policies.  The impact will be to have greater \nclarity for students, faculty and staff in the administration and conduct \nand outcomes of examinations in thesis-based programs. \nThe Impact of the Proposal is The conduct of graduate examinations holds extremely high stakes for \nindividual students and presents significant reputational risk for the \nfaculty, program and institution. A major revision the Supervision and \nStructure of Examining Committees in the Graduate Program Manual \nwas approved by FGSR Council in May 2012. Subsequently in May 2013 \nthe authority for approval of supervisors, supervisory committees, \nexternal examiners and examining committees was delegated to the \ndisciplinary department/Faculty of the program and the change to the \nCalendar governing examinations was approved by FGSR Council \nOctober 2013 appearing in the 2014-2015 Calendar.  A number of areas \nhave come to light that have caused problems due to apparent \ncontradictions, gaps and/or confusing language.  The FSGR Policy \nReview Committee undertook a comprehensive review of the \nSupervision and Examination regulations.  The resulting proposal \naddresses the organization and clarity of the policy as well as changes to \npolicy as follow: \n• The chair of doctoral examinations cannot be an examiner to \nremove issues of bias that have arisen \n• One supervisor of a supervisory team must meet the employment \ncriteria of a UofA examiner \n• Size limits for examination committees are set to prevent \nextraordinarily long examinations in light of current flexibility in \nsupervisory committee composition and the need to fulfill \nexaminer composition balance. \n• A revamped section on “Conduct of Thesis and Candidacy \nExams” was added back to provide consistency across the \nacademy. \n• Guidance added for outcome of “Conditional Pass” for doctoral \ncandidacy exam to lessen the rates of students not meeting the \nconditions. \nFINAL Item No. 9 \nGFC EXECUTIVE COMMITTEE \nFor the Meeting of September 11, 2017 \nReplaces/Revises (eg, policies, \nresolutions) \nRevises Supervision and Examinations policy as found in the FGSR \nsection of the Calendar. \nTimeline/Implementation Date Effective July 1, 2018. The changes will be published in the 2018-2019 \nCalendar. \nEstimated Cost and funding \nsource \nn/a \nNext Steps (ie.: \nCommunications Plan, \nImplementation plans) \nUpon final approval, an email will be sent to all members of FGSR \nCouncil that includes all Associate Deans Graduate and Graduate \nCoordinators of graduate programs, as well as the Graduate Program \nadministrators. There will be internal communication to front end FGSR \nstaff. \nSupplementary Notes and \ncontext \nn/a \nEngagement and Routing (Include meeting dates) \nParticipation: \n(parties who have seen the \nproposal and in what capacity) \n<For further information see \nthe link posted on \nthe Governance Toolkit section \nStudent Participation Protocol> \nThose who have been informed: \n•  \nThose who have been consulted: \n• Dean and Associate Deans, FGSR \n• FGSR Program Services staff \n• Graduate Program Administrators Council (GPAC) \n• Faculty Graduate Councils (or equivalents) \n• FGSR Council \n• Graduate Students Association (GSA)—represented on the PRC \n(below), also conducted wider consultation with graduate \nstudents \nThose who are actively participating: \n• FGSR Policy Review Committee (PRC) \n• Brent Epperson, Graduate Ombudsperson (as a member of PRC) \n• Graduate Students Association (GSA)—(represented on PRC \nand FGSR Council) \n• Vice Dean, FGSR \nApproval Route (Governance) \n(including meeting dates) \nFGSR Council, May 17, 2017, approved \nASC-Subcommittee on Standards - June 1, 2017 (for discussion) \nGFC Academic Standards Committee - June 15, 2017 \nGFC Executive Committee - September 11, 2017 \nGeneral Faculties Council - September 25, 2017 \nFinal Approver General Faculties Council \nAlignment/Compliance \nAlignment with Guiding \nDocuments \nFor the Public Good \nSustain:  \nGOAL: Sustain our people, our work, and the environment by attracting \nand stewarding the resources we need to deliver excellence to the \nbenefit of all. \n21. OBJECTIVE \nEncourage continuous improvement in administrative, governance, \nplanning, and stewardship systems, procedures, and policies that enable \nstudents, faculty, staff, and the institution as a whole to achieve shared \nhttp://www.governance.ualberta.ca/GovernanceToolkit/Toolkit.aspx\nhttp://www.governance.ualberta.ca/GovernanceToolkit/Toolkit.aspx\nFINAL Item No. 9 \nGFC EXECUTIVE COMMITTEE \nFor the Meeting of September 11, 2017 \nstrategic goals. \ni. Strategy: Encourage transparency and improve communication across \nthe university through clear consultation and decision-making processes, \nsubstantive and timely communication of information, and access to \nshared, reliable institutional data. \nii. Strategy: Ensure that individual and institutional annual review \nprocesses align with and support key institutional strategic goals. \niii. Strategy: Consolidate unit review and strategic planning processes, \nand where possible, align with accreditation processes, to ensure \nefficient assessment practices. \niv. Strategy: Facilitate easy access to and use of university services and \nsystems, reduce duplication and complexity, and encourage cross-\ninstitutional administrative and operational collaboration. \nCompliance with Legislation, \nPolicy and/or Procedure \nRelevant to the Proposal \n(please quote legislation and \ninclude identifying section \nnumbers) \n1. Post-Secondary Learning Act (PSLA):  \n“26(1) Subject to the authority of the board of Governors, a general \nfaculties council is responsible for the academic affairs of the university \n[…] \n(3) A general faculties council may delegate any of its powers, duties \nand functions under this Act” \n2. GFC Academic Standard Committee – terms of reference \n“B. Admission and Transfer, Academic Standing, Marking and Grading, \nTerm Work, Examinations, International Baccalaureate (IB), Advanced \nPlacement (AP)   \ni. All proposals from the Faculties or the Administration related to \nadmission and transfer, to the academic standing of students, to \ninstitutional marking and grading policies and/or procedures and to term \nwork policies and procedures are submitted to the Provost and Vice-\nPresident (Academic) (or delegate) who chairs the GFC Academic \nStandards Committee. ASC will consult as necessary with the Faculties \nand with other individuals and offices in its consideration of these \nproposals. “ \n3. UAPPOL Academic Standing Policy: “All current academic \nstanding regulations, including academic standing categories, \nUniversity graduating standards and requirements for all individual \nprograms will be those prescribed by Faculty Councils and GFC as set \nforth in the University Calendar.” \n4. UAPPOL Academic Standing Regulations Procedures: “All \nproposed new academic standing regulations and changes to existing \nacademic standing regulations will be submitted by the Faculties or the \nAdministration to the Provost and Vice-President (Academic). Faculties \nwill also submit to the Provost and Vice President (Academic) any \nproposed changes to the use and/or computation of averages relating to \nacademic standing, including promotion and graduation. If the Provost \nand Vice-President (Academic) determines the proposal to be in good \norder, the proposal will be introduced to the appropriate University \ngovernance process(es). In considering these proposals, governance \nbodies will consult as necessary with the Faculties and with other \nindividuals and offices. Normally, changes become effective once they \nare approved by GFC or its delegate and are published in the University \nCalendar.” \nFINAL Item No. 9 \nGFC EXECUTIVE COMMITTEE \nFor the Meeting of September 11, 2017 \n5. GFC Executive Committee – terms of reference \n“7. Examinations \n“consider and make decisions on the reports of faculty councils as to the \nappointment of examiners and the conduct and results of examinations \nin the faculties” \n“8. Agendas of General Faculties Council \nGFC has delegated to the Executive Committee the authority to decide \nwhich items are placed on a GFC agenda, and the order in which those \nagenda items appear on each GFC agenda. \n[…] \nThe role of the Executive Committee shall be to examine and debate the \nsubstance of reports or recommendations and to decide if an item is \nready to be forwarded to the full governing body” \nAttachments (each to be numbered 1 - <>) \n1. Proposal for revision to existing Supervision and Examinations policy; changes to be reflected in the 2018-\n2019 Calendar (pages 1-25) \nPrepared by: Janice Hurlburt, Graduate Governance and Policy Coordinator \nPage 1 of 25 \nJune 8, 2017 \n2018-2019 University of Alberta Proposed Calendar Graduate Program Changes: Proposal from the \nFaculty of Graduate Studies and Research regarding policy and process for Supervision and \nExaminations. \nCurrent Proposed  \nFaculty of Graduate Studies and \nResearch \n[…] \nSupervision and Examinations  \nThe minimum requirements for all graduate programs are \nset by the Council of the Faculty of Graduate Studies and \nResearch of the University of Alberta. In this Calendar the \nminimum requirements acceptable are outlined under the \nrespective headings. Students should note that the \nindividual graduate program may impose additional \nrequirements. \nSupervision and Supervisory \nCommittees \nDepartmental Regulations \nDepartments are responsible for preparing a set of \nregulations and guidelines for supervisors and students. \nGuidelines should deal with the selection and functioning \nof supervisors and should outline the joint \nresponsibilities of faculty members and graduate \nstudents. Avenues of appeal open to students who feel \nthey are receiving unsatisfactory supervision should also \nbe specified. \nAppointment of the Supervisor(s) \nEvery student in a thesis-based program is required to \nhave a supervisor. The department that admits a student \nto a thesis-based graduate program is responsible for \nproviding supervision within a subject area in which it \nhas competent supervisors, and in which the student has \nexpressed an interest. \nNormally there is only one supervisor. Departments may \nconsider the appointment of more than one supervisor for \na student. \nImplicit in the admission process is the following: on the \napplicant's part, that there has been an indication of at \nFaculty of Graduate Studies and \nResearch \n[…] \nSupervision and Examinations  \nThe minimum requirements for all graduate programs are \nset by the Council of the Faculty of Graduate Studies and \nResearch of the University of Alberta. In this Calendar the \nminimum requirements acceptable are outlined under the \nrespective headings. Students should note that the \nindividual graduate program may impose additional \nrequirements. \nSupervision and Supervisory \nCommittees \nDepartmental Regulations and Responsibilities \nDepartments are responsible for preparing a set of \nregulations and guidelines for supervisors and students. \nGuidelines should deal with the selection and functioning \nof supervisors and should outline the joint \nresponsibilities of faculty members and graduate \nstudents. Options for students to pursue who believe they \nare receiving unsatisfactory supervision should also be \nspecified. \nAppointment of the Supervisor(s) \nEvery student in a thesis-based program is required to \nhave a supervisor. The department that admits a student \nto a thesis-based graduate program is responsible for \nproviding supervision within a subject area in which it \nhas competent supervisors, and in which the student has \nexpressed an interest. \nNormally there is only one supervisor. Departments may \nconsider the appointment of more than one supervisor for \na student. \nImplicit in the admission process is the following: on the \napplicant's part, that there has been an indication of at \nPage 2 of 25 \nleast a general area of interest and, preferably, provision \nof some form of proposal, particularly if the program is at \nthe doctoral level; on the department's part, that the \napplication has been reviewed, the area of interest \nexamined, academic expectations and potential \nperformance considered, and that the department accepts \nits obligation to provide appropriate supervision for the \napplicant in the specified subject area. \nIt is expected that every effort will be made to arrive at a \nmutually agreeable arrangement for supervision between \nthe student and the department. Students are normally \ninvolved in the process for selecting their supervisor(s) \nalthough this process varies from program to program. \nWhen the department is making arrangements for the \nappointment of supervisors, supervisory committees, and \nexamining committees, or for the scheduling of meetings \nand examinations, the student shall be consulted and kept \ninformed, but the student shall not be asked to conduct \nsuch organizational activities. \nThe authority for the appointment of supervisors, and \nfinal examining committees rests with the Dean of the \ndepartment's Faculty, while the authority for the \nappointment of supervisory committees and doctoral \ncandidacy examining committees rests with the \ndepartment. Such appointment decisions are final and \nnonappealable. \nArticle 7.02.1 of the Faculty Agreement lists the \n\"supervision of graduate students\" as a form of \n\"participation in teaching programs\". It is expected that a \ndepartment will monitor and review the performance of \nsupervisors. \nSupervisors on Leave \nIt is the responsibility of supervisors to make adequate \nprovision for supervision of their graduate students \nduring their leave. Therefore, if a supervisor is to be \nabsent from the University for a period exceeding two \nmonths, it is the supervisor's responsibility to nominate \nan adequate interim substitute and to inform the student \nand the department. \nSupervisors planning to take a sabbatical should follow \nthe requirements found in Appendix E of the Faculty \nAgreement with respect to adequate advance \narrangements for graduate students while a supervisor is \non sabbatical. \nEligibility for Appointment as Supervisor \nleast a general area of interest and, preferably, provision \nof some form of proposal, particularly if the program is at \nthe doctoral level; on the department's part, that the \napplication has been reviewed, the area of interest \nexamined, academic expectations and potential \nperformance considered, and that the department accepts \nits obligation to provide appropriate supervision for the \napplicant in the specified subject area. \nIt is expected that every effort will be made to arrive at a \nmutually agreeable arrangement for supervision between \nthe student and the department. Students are normally \ninvolved in the process for selecting their supervisor(s) \nalthough this process varies from program to program. \n[moved to Committee and Exam Sections] \nThe authority for the appointment of supervisors rests \nwith the Dean of the department's Faculty. Such \nappointment decisions are final and non-appealable. \n[the other statements have been moved to appropriate \nsections under Size and Composition of Examining \nCommittees] \nArticle 7.02.1 of the Faculty Agreement lists the \n\"supervision of graduate students\" as a form of \n\"participation in teaching programs\". It is expected that a \ndepartment will monitor and review the performance of \nsupervisors. \nSupervisors on Leave \nIt is the responsibility of supervisors to make adequate \nprovision for supervision of their graduate students \nduring their leave. Therefore, if a supervisor is to be \nabsent from the University for a period exceeding two \nmonths, it is the supervisor's responsibility to nominate \nan adequate interim substitute or indicate the means by \nwhich supervision will be maintained. It is the \nsupervisor’s responsibility to inform the student and the \ndepartment in writing at the time the leave is approved. \nSupervisors planning to take a sabbatical should follow \nthe requirements found in Appendix E of the Faculty \nAgreement with respect to adequate advance \narrangements for graduate students while a supervisor is \non sabbatical. \nEligibility for Appointment as Supervisor \nPage 3 of 25 \nEach of the following criteria must be met by at least one \nof the supervisor(s): \n1. be a tenured, tenure-track, or retired faculty \nmember, or a Faculty Service Officer, of the \nUniversity of Alberta (current or retired \ncategories A1.1, A1.3, or current category C1.1, as \ndefined in the University's Recruitment Policy \n(Appendix A) Definition and Categories of \nAcademic Staff and Colleagues); \n2. be active in the general subject area of the \nstudent's research;. \n3. demonstrate continuing scholarly or creative \nactivity of an original nature; \nand \n4. either hold a degree equivalent to or higher than \nthat for which the student is a candidate, or have \na demonstrated record of successfully \nsupervising students for the degree. \nIf one of conditions (1)-(4) is not satisfied by any of the \nproposed supervisors, then a departmental justification \n(with the proposed supervisors' CV) is put forward to the \nDean of the department's Faculty for approval. \nFor supervisors from outside the University of Alberta, \nworking with a supervisor at the University of \nAlberta, there should be an indication of the means by \nwhich meaningful interaction can be maintained. \nTime Line for the Appointment of \nSupervisors and Introductory Meetings \nIdeally, the supervisor for a thesis-based student, both \nmaster's and doctoral, should be appointed as soon as the \nstudent arrives to begin their program of studies. If this is \nnot possible, an interim academic advisor may be \nappointed by the department. Supervisor(s) must be \nappointed within the first 12 months of the student's \nprogram following the procedures approved by the Dean \nof the department's Faculty.  \nEvery department must develop a list of topics that will \nbe covered during the introductory meetings between a \nsupervisor and a graduate student. These meetings \nshould be held during the term in which a supervisor is \nfirst appointed. Topics likely to be listed include program \nrequirements, academic integrity requirements, the role \nof the supervisor, the preferred means of communication, \nthe availability or non-availability of funding, and \nscholarly practices and outputs.  \nEach of the following criteria must be met by at least one \nof the supervisor(s): \n1. be a tenured, tenure-track, or retired faculty \nmember, or a Faculty Service Officer, of the \nUniversity of Alberta (current or retired \ncategories A1.1, A1.3, or current category C1.1, as \ndefined in the University's Recruitment Policy \n(Appendix A) Definition and Categories of \nAcademic Staff and Colleagues); \n2. be active in the general subject area of the \nstudent's research; \n3. demonstrate continuing scholarly or creative \nactivity of an original nature; \nand \n4. either hold a degree equivalent to or higher than \nthat for which the student is a candidate, or have \na demonstrated record of successfully \nsupervising students for the degree. \nIf one of conditions (2)-(4) is not satisfied by any of the \nproposed supervisors, then a departmental justification \n(with the proposed supervisors' CV) is put forward to the \nDean of the department's Faculty for approval. \nFor supervisors from outside the University of Alberta, \nworking with a supervisor at the University of Alberta, the \nmeans by which meaningful interaction can be \nmaintained should be specified in writing to the student \nand the department. \nTime Line for the Appointment of Supervisors  \nIdeally, the supervisor for a thesis-based student, both \nmaster's and doctoral, should be appointed as soon as the \nstudent arrives to begin their program of studies. If this is \nnot possible, an interim academic advisor should be \nappointed by the department. Supervisor(s) must be \nappointed within the first 12 months of the student's \nprogram following the procedures approved by the Dean \nof the department's Faculty and submitted to FGSR.  \nIntroductory Meetings  \nEvery department must develop a list of topics that will \nbe covered during the introductory meetings between a \nsupervisor and a graduate student. These meetings \nshould be held during the term in which a supervisor is \nfirst appointed. Topics likely to be listed include program \nrequirements, academic integrity requirements, the role \nof the supervisor, the composition of the supervisory \ncommittee, the preferred means of communication, the \navailability of funding, and scholarly practices and \noutputs.  \nPage 4 of 25 \n[Moved from just before The Roles and Structure of \nExamining Committees ] \nResolving Conflicts in Supervisor-Student \nRelationships   \nThe relationship between students and supervisors is \nnormally close and long-lasting. At times, conflicts may \narise between a student and the supervisor. In such cases, \nthe first step must be to try to resolve the \nmisunderstanding or conflict informally. This is more \nlikely to be successful if attended to as early as possible. \nThe supervisor and student should discuss the problem \ntogether. The supervisor should document the \ndiscussions and keep a record of any agreements made. \nThis document should be shared with the student. In the \nevent of a conflict that cannot be resolved, the graduate \ncoordinator should be consulted as early as possible by \nthe parties involved. \nIt is the responsibility of the graduate coordinator to \narrange for consultation and mediation. The graduate \ncoordinator or the parties involved may request advice \nand/or mediation assistance from their Faculty, the FGSR, \nand/or other appropriate services, such as the Student \nOmbudservice. The student and supervisors shall not be \nrequired to participate in informal resolution. \nIf informal resolution is unsuccessful or inappropriate, \nand the graduate coordinator determines that the \nsupervisor-student relationship is beyond repair, the \ndepartment will attempt in good faith to work with the \nstudent to find alternative supervision within the \ndepartment, and inform the FGSR of these efforts in \nwriting. \nWhere the supervisor has been providing funding to the \nstudent, the funding should continue for a period of at \nleast 30 days from the date on which the graduate \ncoordinator determines that the supervisor-student \nrelationship is beyond repair. \nIf the best arrangements of the department and the FGSR \nfail to meet the expectations of the student, the student \nmay choose to withdraw without prejudice. If the student \nrefuses to accept the supervision provided, or if no \nsupervision can be secured, then the student is not \nfulfilling the academic requirement of having a supervisor \nand may, on academic grounds, be required to withdraw. \nResolving Conflicts in Supervisor-Student \nRelationships   \nThe relationship between students and supervisors is \nnormally close and long-lasting. At times, conflicts may \narise between a student and the supervisor. In such cases, \nthe first step should be to try to resolve the \nmisunderstanding or conflict informally. This is more \nlikely to be successful if attended to as early as possible. \nThe supervisor and student should discuss the problem \ntogether. The supervisor should document the \ndiscussions and keep a record of any agreements made. \nThis document should be shared with the student. In the \nevent of a conflict that cannot be resolved, the graduate \ncoordinator should be consulted as early as possible by \nthe parties involved. \nIt is the responsibility of the graduate coordinator to \narrange for consultation and mediation. The graduate \ncoordinator or the parties involved may request advice \nand/or mediation assistance from their Faculty, the FGSR, \nand/or other appropriate services, such as the Student \nOmbudservice. The student and supervisors shall not be \nrequired to participate in informal resolution. \nIf informal resolution is unsuccessful or inappropriate, \nand the graduate coordinator determines that the \nsupervisor-student relationship is beyond repair, the \ndepartment will attempt in good faith to work with the \nstudent to find alternative supervision within the \ndepartment, and inform the FGSR of these efforts in \nwriting. \nWhere the supervisor has been providing funding to the \nstudent, the funding should continue for a period of at \nleast 30 days from the date on which the graduate \ncoordinator determines that the supervisor-student \nrelationship is beyond repair. \nIf the best arrangements of the department and the FGSR \nfail to meet the expectations of the student, the student \nmay choose to withdraw without prejudice. If the student \nrefuses to accept the supervision provided, or if no \nsupervision can be secured, then the student is not \nfulfilling the academic requirement of having a supervisor \nand may, on academic grounds, be required to withdraw. \nPage 5 of 25 \nSupervisory Committees \nThesis-based master's students \nEvery thesis-based master's student must have a \nsupervisor. It is not a University requirement for master's \nstudents to have a supervisory committee; however, some \ngraduate programs may require them. As ex-officio \nmembers of the master's final examining \ncommittee, departments should ensure that the members \nof the supervisory committee meet the eligibility criteria \nas examiners. \nDoctoral students \nEvery doctoral student's program shall be under the \ndirection of a supervisory committee approved by the \ndepartment. A doctoral supervisory committee must have \nat least three members, and must include all the \nsupervisors. As ex-officio members of the candidacy and \nthe doctoral final examining committees, all members of \nthe supervisory committee must meet the eligibility \ncriteria for examiners. \n[moved from below] \n The supervisory committee is chaired by one of the \nsupervisors. \nCompliance with the University of Alberta's Conflict \nPolicy - Conflict of Interest and Commitment, and \nInstitutional Conflict - is mandatory. \nThe committee will arrange for the necessary \nexaminations and for adjudication of the thesis. The \ncommittee shall have a formal regular meeting with the \nstudent at least once a year. \nThe department should ensure that the members of a \nsupervisory committee are sufficiently competent and \nexperienced to serve at the required level. In forming a \nSupervisory Committees \nThesis-based master's students \nIt is not a University requirement for master's students to \nhave a supervisory committee; however, some graduate \nprograms require them. If required by the program, the \nsupervisory committee members are ex-officio members \nof the master's final examining committee. Attention \nshould be paid to the qualifications of the committee \nmembers as examiners to ensure the composition and \nsize of the examination committee will be appropriate.   \nDoctoral students \nEvery doctoral student's program shall be under the \ndirection of a supervisory committee approved by the \ndepartment.  \nA doctoral supervisory committee must have at least \nthree members, and must include all the supervisors.   \nThe department should ensure that the members of a \nsupervisory committee are sufficiently competent and \nexperienced to serve at the required level. In forming a \nsupervisory committee, the department should consider \nthe rank and experience of the prospective members, \ntheir publications and other demonstrations of \ncompetence in the subject area or field of specialization, \nand the prospective members' experience in graduate \nsupervision.  \nAttention should be paid to the qualifications of the \ncommittee members as examiners to ensure the \ncomposition of the examination committee will be \nappropriate as they are ex-officio members of doctoral \nexamining committees.   \nThe supervisory committee is chaired by one of the \nsupervisors. \nCompliance with the University of Alberta's Conflict \nPolicy - Conflict of Interest and Commitment, and \nInstitutional Conflict - is mandatory. \nThe supervisor is responsible for ensuring committee \nmeetings are held and making arrangements. The \ncommittee shall have a formal regular meeting with the \nstudent at least once a year.  The department should \nmaintain a record of meetings that have occurred and \nwhen students who are not on an approved leave fail to \nrespond to requests to schedule a committee meeting. \n[Moved above] \nhttps://policiesonline.ualberta.ca/PoliciesProcedures/Policies/Conflict-Policy--Conflict-of-Interest-and-Commitment-and-Institutional-Conflict.pdf\nhttps://policiesonline.ualberta.ca/PoliciesProcedures/Policies/Conflict-Policy--Conflict-of-Interest-and-Commitment-and-Institutional-Conflict.pdf\nhttps://policiesonline.ualberta.ca/PoliciesProcedures/Policies/Conflict-Policy--Conflict-of-Interest-and-Commitment-and-Institutional-Conflict.pdf\nhttps://policiesonline.ualberta.ca/PoliciesProcedures/Policies/Conflict-Policy--Conflict-of-Interest-and-Commitment-and-Institutional-Conflict.pdf\nPage 6 of 25 \nsupervisory committee, the department should consider \nthe rank and experience of the prospective members, \ntheir publications and other demonstrations of \ncompetence in the subject area or field of specialization, \nand the prospective members' experience in graduate \nsupervision. \nFor doctoral students, the department shall appoint the \nsupervisory committee well in advance of the candidacy \nexamination. \nResolving Conflicts in Supervisor-Student \nRelationships  \nThe relationship between students and supervisors is \nnormally close and long-lasting. At times, conflicts may \narise between a student and the supervisor. In such cases, \nthe first step must be to try to resolve the conflict or \nmisunderstanding informally. This is more likely to be \nsuccessful if attended to as early as possible. The \nsupervisor and student should discuss the problem \ntogether. The supervisor should document the \ndiscussions and keep a record of any agreements made. In \nthe event of a conflict the graduate coordinator should be \nnotified as early as possible. \nIt is the responsibility of the graduate coordinator to \narrange for consultation and mediation. The graduate \ncoordinator or the parties involved may request advice \nand/or mediation assistance from their Faculty, the FGSR, \nand/or other appropriate services, such as the Student \nOmbudservice. The student and supervisors shall not be \nrequired to participate in informal resolution against \ntheir wishes if either party's behaviour towards the other \nwarrants a complaint under the Code of Student \nBehaviour, the Discrimination and Harassment Policy, or \nother University policy. \nIf informal resolution is unsuccessful or inappropriate, \nand the graduate coordinator determines that the \nsupervisor-student relationship is beyond repair, the \ndepartment will attempt in good faith to work with the \nstudent to find alternative supervision within the \ndepartment, and will keep the FGSR apprised of these \nefforts. \nWhere the supervisor has been providing funding to the \nstudent, the funding should continue for a period of at \nleast 30 days from the date on which the graduate \ncoordinator determines that the supervisor-student \nrelationship is beyond repair. \nIf the best arrangements of the department and the FGSR \nfail to meet the expectations of the student, the student \nmay choose to withdraw without prejudice. If the student \nrefuses to accept the supervision provided, or if no \nFor doctoral students, the department shall appoint the \nsupervisory committee well in advance of the candidacy \nexamination. \n[Moved above to just before Supervisory \nCommittees] \nPage 7 of 25 \nsupervision can be secured, then the student is not \nfulfilling the academic requirement of having a supervisor \nand may, on academic grounds, be required to withdraw. \nThe Structure of Examining Committees  \nFormal examining committees are required for thesis-\nbased master’s final examination, doctoral candidacy \nexaminations, and doctoral final examinations. Members \nof these examining committees perform two functions: 1) \nthey bring disciplinary knowledge and expertise to the \nassessment of the thesis, and 2) they ensure that the \nUniversity’s expectations are met regarding the conduct \nof the examination, adherence to all relevant policies, and \nthe suitability of the thesis for the degree.  \nThe Chair  \nEvery examining committee must have a chair who is not \na supervisor but is a member of the student’s home \ndepartment. The chair should have sufficient experience \nof graduate examinations to be able to allow the \nexamination to be conducted in a fair manner, and is \nresponsible for moderating the discussion and directing \nquestions. It is the chair’s responsibility to ensure that \ndepartmental and FGSR regulations relating to the final \nexamination are followed. If the chair is not an examiner, \nthen the chair does not vote.  \nThe FGSR encourages, and for doctoral examinations \nstrongly recommends, that committee chairs not be \nexaminers.  \nExaminers  \nExaminers are full voting members of the examining \ncommittee. With the exception of the Dean, FGSR, the \nDean of the department’s Faculty, or a Pro Dean (Dean’s \nrepresentative), who may participate fully in the \nexamination, persons other than the examiners may \nattend only with the prior approval of the Dean, FGSR, the \nDean of the department’s Faculty, or the chair of the \nexamining committee. With the possible exception of the \nPro Deans, all examiners must be either active in the \ngeneral subject area of the student’s research, or bring \nrelevant expertise to the assessment of the thesis.  \nThe Role and Structure of Examining \nCommittees  \nFormal examining committees are required for thesis-\nbased master’s final examination, doctoral candidacy \nexaminations, and doctoral final examinations. Members \nof these examining committees perform two functions: 1) \nthey bring knowledge and expertise to the assessment of \nthe thesis, and 2) they ensure that the University’s \nexpectations are met regarding the conduct of the \nexamination, adherence to all relevant policies, and the \nsuitability of the thesis for the degree.  \nThe Chair  \nEvery examining committee must have a chair who is not \nthe supervisor and is a faculty member with experience \nsupervising graduate students. The chair should have \nsufficient experience of graduate examinations to be able \nto allow the examination to be conducted in a fair \nmanner. The chair is responsible for moderating the \ndiscussion and directing questions. It is the chair’s \nresponsibility to ensure that departmental and FGSR \nregulations relating to the final examination are followed. \nIf the chair is not an examiner, then the chair does not \nvote.  \nThe committee chair is not an examiner for doctoral \nexaminations.  See Size and Composition of Examining \nCommittees for the requirements for each examination.  \nThe chair should not have real or apparent conflict of \ninterest with the student or any of the examiners.  \nExaminers  \nExaminers are full voting members of the examining \ncommittee. All examiners must be either active in the \ngeneral subject area of the student’s research or bring \nrelevant expertise to the assessment of the thesis.  \n[Deleted sentences already found under Attendance at \nExaminations, below] \nCategories of Examiners and Eligibility \nThere are four types of examiners: ex-officio examiner, \narm’s length examiner, University of Alberta examiner \nand External examiner. \nEx-officio Examiners \nPage 8 of 25 \nArm’s Length Examiners  \nAn arm’s length examiner must not be (or have been) a \nmember of the supervisory committee, or have been \nconnected with the thesis research in a significant way.  \nThe examiner should not have been associated with the \nstudent, outside of usual contact in courses or other non-\nthesis activities within the University, nor be related to \nthe student or supervisor(s).  \nExcept in special circumstances (fully justified in writing \nto the Dean of the department’s Faculty), an arm’s length \nexaminer should not be a close collaborator of the \nsupervisor(s) within the last six years.  \nArm’s length examiners who have served on a student’s \ncandidacy examination committee do not lose their arm’s \nlength status as a result, and are eligible to serve as arm’s \nlength examiners on the student’s doctoral final \nexamination if the other conditions of being arm’s length \nremain unchanged.  \nIn the case of a doctoral final examination, the required \nExternal (i.e., the arm’s length examiner from outside the \nUniversity of Alberta) is, by definition, an arm’s length \nexaminer. \nEvery examining committee requires a minimum number \nof arm’s length examiners: At least one for a master’s final \nexamination, at least two for a candidacy examination, \nand at least two for a doctoral final examination. \nCompliance with the University of Alberta’s Conflict Policy \n- Conflict of Interest and Commitment, and Institutional \nConflict is mandatory.  \nEx-Officio Examiners  \nThe supervisor(s), and, for doctoral students, the other \nmembers of the student’s supervisory committee, are ex-\nofficio members of the examining committee.  \n[Moved from below] \nThe supervisor(s) and, for doctoral students, the other \nmembers of the student’s supervisory committee are ex-\nofficio members of the examining committee. \nBy definition, no individual can be both an ex-officio and \nan arm’s length examiner on the same examining \ncommittee. \nArm’s Length Examiners  \nAn arm’s length examiner is knowledgeable in the field \nand comes fresh to the examination. They must not be (or \nhave been) a member of the supervisory committee, or \nhave been connected with the thesis research in a \nsignificant way. The examiner should not have been \nassociated with the student, outside of usual contact in \ncourses or other non-thesis activities within the \nUniversity, nor be related to the student or supervisor(s).  \nThe arm’s length examiners should not be a former \nsupervisor or student of the supervisor(s). \nExcept in special circumstances (fully justified in writing \nto the Dean of the department’s Faculty), an arm’s length \nexaminer should not be an active collaborator of the \nsupervisor(s) (see Conflict of Interest Guidelines, below ) \nArm’s length examiners who have served on a student’s \ncandidacy examination committee do not lose their arm’s \nlength status as a result, and are eligible to serve as arm’s \nlength examiners on the student’s doctoral final \nexamination if the other conditions of being arm’s length \nremain unchanged.  \nExternal Examiner \nAn external examiner from outside the University of \nAlberta is required for doctoral thesis examinations. In \naddition to being an arm’s length examiner this examiner \nmust fulfill additional criteria as described under “Final \nDoctoral Examination … Inviting the External Examiner or \nReader” in the Calendar. \n[Moved above] \nUniversity of Alberta Examiners \nPage 9 of 25 \n[Restored from earlier Calendar wording and revised] \nMinimum Membership Requirements for \nExamining Committees  \nAt least half of the examiners on every examining \ncommittee must have a degree which is equivalent to, or \nhigher than, the degree being examined.  \nAt least half of the examiners on every examining \ncommittee must be tenured, tenure-track, or retired \nUniversity of Alberta faculty members, or Faculty Service \nOfficers, (current or retired categories A1.1, A1.3, or \ncurrent category C1.1, as defined in the University of \nAlberta’s Recruitment Policy (Appendix A) Definition and \nCategories of Academic Staff and Colleagues).  \nMinimum Size of an Examining Committee  \nBy definition, no individual can be both an arm’s length \nexaminer and an ex-officio examiner on the same \nexamining committee.  \nThe minimum size of a master’s final examining \ncommittee is three. This minimum size condition is \nautomatically met except when the student has one \nsupervisor, no supervisory committee, and there is only \none arm’s length examiner on the examining committee. \nIn this case, the examining committee requires at least \none more examiner.  \nThe University of Alberta examiner is a tenured, tenure-\ntrack, or retired University of Alberta faculty member, or \nFaculty Service Officer, (current or retired categories \nA1.1, A1.3, or current category C1.1, as defined in the \nUniversity of Alberta’s Recruitment Policy (Appendix A) \nDefinition and Categories of Academic Staff and \nColleagues). \nConflict of Interest Guidelines  for \nSupervisory and Examination Committees \nThe key relationships are: the supervisor to the student; \nthe supervisor to the other committee members; and the \nstudent to the committee members. There must be no \nconflict of interest in these relationships, as defined by \nthe University of Alberta policy.  Any personal or \nprofessional relationships that alter or affect this \nacademic relationship may constitute a conflict-of-\ninterest.  \nIt is a best practice to request examiners and the chair \ndeclare any potential conflicts of interest prior to \napproval of the examination committee. Where potential \nconflicts-of-interest emerge, the matter may be referred \nto an Associate Dean at FGSR for advice on how to best \nmanage unavoidable conflicts of interest. \nSize and Composition of Examining Committees \nFor all examination committees, Aat least half of the \nexaminers must have a degree equivalent to or higher \nthan the degree being examined.  \nFor all examination committees, at least half of the \nexaminers must fulfill the criteria as a University of \nAlberta examiner as tenured, tenure-track, or retired \nUniversity of Alberta faculty members, or Faculty Service \nOfficers (see above under Categories of Examiners and \nEligibility).  \n[Moved above under Categories of Examiners and \nEligibility] \nMaster’s Thesis Examination Committee \n• The minimum size of a master’s final examining \ncommittee is three. The maximum size is five. \n• The ex officio members of the committee are the \nsupervisor(s) and the supervisory committee \nmembers if there is a committee. \n• There must be one arm’s length examiner. \n• At least half of the examiners must hold a \nhttps://policiesonline.ualberta.ca/PoliciesProcedures/Policies/Conflict-Policy--Conflict-of-Interest-and-Commitment-and-Institutional-Conflict.pdf\nPage 10 of 25 \n[Moved here from The Appointment of the Supervisor(s)] \nFor doctoral candidacy and doctoral final \nexaminations, the minimum size of the \nexamining committee is five.  \n[Moved here from The Appointment of the Supervisor(s)] \nmaster’s degree or higher (see above). \n• At least half of the examiners must fulfill the \ncriteria of University of Alberta examiner (see \nabove) \n• The chair is not the supervisor. The chair is a \nfaculty member in the student’s home \ndepartment or with experience chairing master’s \nexaminations. The FGSR recommends that \ncommittee chairs not be examiners except in \nextenuating circumstances where any conflict of \ninterest in this role be managed transparently for \nthe student. \nThe authority for the appointment of final examining \ncommittees rests with the Dean of the department’s \nFaculty [unless delegated to the department]. \nDoctoral Candidacy Examination Committee \n• The minimum size of a doctoral candidacy \ncommittee is five. The maximum size is seven. \n• The ex officio members of the committee are the \nsupervisor(s) and the supervisory committee \nmembers. \n• There must be two arm’s length examiners. \n• At least half or more of the examiners must hold a \ndoctoral degree or higher (see above). \n• At least half of the examiners must fulfill the \ncriteria of University of Alberta examiner (see \nabove) \n• The chair is not an examiner. The chair is a \nfaculty member in the student’s home \ndepartment or with experience chairing doctoral \nexaminations  \nThe authority for the appointment of doctoral candidacy \nexamining committees rests with the department.  \nDoctoral Thesis Examination Committee \n• The minimum size of a doctoral final examining \ncommittee is five. The maximum size is seven. \n• The ex officio members of the committee are the \nsupervisor(s) and the supervisory committee \nmembers. \n• There must be two arm’s length examiners, one \nof whom must be a reader or examiner external \nto the University  \n• At least half of the examiners must hold a \ndoctoral degree or higher (see above). \n• At least half of the examiners must fulfill the \ncriteria of University of Alberta examiner (see \nabove) \n• The chair is not an examiner. The chair is a \nfaculty member in the student’s home \ndepartment or with experience chairing doctoral \nexaminations.  \nPage 11 of 25 \n[Moved here from The Appointment of the Supervisor(s)] \nConduct of Examinations  \nCommon Examination Protocols  \nAttendance at Examinations: In the absence of \nunforeseen circumstances, it is essential that all \nexaminers attend the entire examination. Attendance \nmeans participation in the examination either in person \nor via Teleconferencing (see below). The only exception \nallowed is the External Reader for a doctoral final \nexamination, who participates by providing a detailed \nreport and a list of questions.  \nIf the department has warning that any member of the \nexamining committee cannot attend the examination, the \ndepartment should contact the Dean of the FGSR for \nadvice. The situation will be dealt with on a case-by-case \nbasis, but it may be necessary that the examination be \npostponed and rescheduled, or the examiner be replaced.  \nExcept for the Dean, FGSR, the Dean of the department’s \nFaculty, or a Pro Dean (the representative of the Dean, \nFGSR), who may participate fully in the examination, \npersons other than the examiners may attend only with \nthe approval of the Dean, FGSR, the Dean of the \ndepartment’s Faculty, or the chair of the committee.  \nAttendance and Responsibilities of a Pro Dean at \nExaminations: A Pro Dean is a full voting member when \nattending an examination. The Pro Dean’s presence is in \naddition to the regular membership. Attendance of the \nPro Dean may be at the request of a committee member, \nstudent, chair, graduate coordinator, the Dean of the \ndepartment’s Faculty, or the Dean, FGSR.  \nThe Pro Dean’s role is to ensure the proper conduct of the \nexamination and will intercede actively to correct \nprocedural problems. The Pro Dean has the power to \nadjourn an examination. If problems are encountered, the \nPro Dean is asked to submit a brief report to the Dean, \nFGSR.  \nTeleconferencing Guidelines for Examinations: The \nterm ‘teleconferencing’ is used here generically to include \nall forms of distance conference facilitation including \ntelephone, video and electronic communication. \nDepartments may wish to use teleconferencing for one or \nmore of the examiners (including the External). It is \nrecommended that no more than two participants use \nteleconferencing. Teleconferencing may be used for \nmaster’s or doctoral examinations. Examiners \nparticipating in examinations by this means are \nconsidered to be in attendance.  \nThe authority for the appointment of final examining \ncommittees rests with the Dean of the department’s \nFaculty [unless delegated to the department]. \nConduct of Examinations  \nCommon Examination Protocols  \nAttendance at Examinations: In the absence of \nunforeseen circumstances, it is essential that all \nexaminers attend the entire examination. Attendance \nmeans participation in the examination either in person \nor via Teleconferencing (see below). The only exception \nallowed is the External Reader for a doctoral final \nexamination, who participates by providing a detailed \nreport and a list of questions.  \nIf the department has warning that any member of the \nexamining committee cannot attend the examination, the \ndepartment should contact the Dean of the FGSR for \nadvice. The situation will be dealt with on a case-by-case \nbasis, but it may be necessary that the examination be \npostponed, or the examiner replaced.  \nThe Dean, FGSR, the Dean of the department’s Faculty, or \na Pro Dean (the representative of the Dean, FGSR) may \nparticipate fully in the examination. Persons other than \nthe examiners may attend only with the approval of the \nDean, FGSR, the Dean of the department’s Faculty, or the \nchair of the committee.  \nResponsibilities of a Pro Dean at Examinations: A Pro \nDean is a full voting member when attending an \nexamination. The Pro Dean’s presence is in addition to the \nregular membership. Attendance of the Pro Dean may be \nat the request of a committee member, student, chair, \ngraduate coordinator, the Dean of the department’s \nFaculty, or the Dean, FGSR.  \nThe Pro Dean’s role is to ensure the proper conduct of the \nexamination and will intercede actively to correct \nprocedural problems. The Pro Dean has the power to \nadjourn an examination. If problems are encountered, the \nPro Dean is asked to submit a brief report to the Dean, \nFGSR.  \nTeleconferencing Guidelines for Examinations: The \nterm ‘teleconferencing’ is used here generically to include \nall forms of distance conference facilitation including \ntelephone, video and synchronous electronic \ncommunication. Departments may wish to use \nteleconferencing for one or more of the examiners \n(including the External). No more than two \nparticipants may attend by teleconference. \nTeleconferencing may be used for master’s or doctoral \nexaminations. Examiners participating in examinations by \nPage 12 of 25 \nStudents must attend their candidacy examinations in \nperson. In exceptional circumstances, for the final \nexaminations, students may participate by \nteleconferencing. It is recommended that if the student is \nthe remote participant, no remote committee members be \nused.  \nUse of teleconferencing must be submitted for approval to \nthe Dean of the department’s Faculty at the time the \nexamination committee is approved, following the \nFaculty’s established procedures.  \nTimelines and Approval of the Examining Committee: \nIt is the responsibility of the department to nominate the \nmembers of the examining committee following the \nprocedures established by the Dean of the department’s \nFaculty using the Forms available on the FGSR website \nThe notice of final approval must be received by the FGSR \nat least two weeks in advance of the examination to be \ncoded into the system.  \nScheduling of Examinations: It is the responsibility of \nthe supervisor(s) to ensure that:  \n1. proper arrangements are made for the student’s \nexamination,  \n2. the exam is scheduled and held in accordance \nwith FGSR and departmental regulations,  \n3. committee members are informed of meetings \nand details of examinations  \n4. the student does not make these arrangements,  \n5. the student provides copies of the thesis \n(master’s and doctoral final examination) to \nthe examiners at least three weeks before the \nexamination. Note that the External for a doctoral \nfinal examination must receive a copy of the \nthesis at least four weeks before the examination.  \nIn the absence of the supervisor, the department’s \ngraduate coordinator or designate shall be responsible for \nthese arrangements.  \nChanging an Examining Committee Member: Changes \nto the membership of the Examining Committee \nmust occur following the procedures established by the \nDean of the department’s Faculty.  \nLanguage of Examinations: The language used to \nconduct examinations shall be English, except where \nalready approved by the FGSR Council. However, the \nexamining committee may petition the Dean of the FGSR, \nand on receiving written approval, may conduct the \nthis means are considered to be in attendance.  \n Students must attend their candidacy examinations in \nperson. In exceptional circumstances, for the final \nexaminations, students may participate by \nteleconferencing. It is recommended that if the student is \nthe remote participant, no remote committee members be \nused.  \nUse of teleconferencing must be submitted for approval to \nthe Dean of the department’s Faculty at the time the \nexamination committee is approved, following the \nFaculty’s established procedures.  \nTimelines and Approval of the Examining Committee: \nIt is the responsibility of the department to nominate the \nmembers of the examining committee following the \nprocedures established by the Dean of the department’s \nFaculty using the Forms available on the FGSR website \nThe notice of final approval must be received by the FGSR \nat least two weeks in advance of the examination to be \ncoded into the system.  \nScheduling of Examinations: It is the responsibility of \nthe supervisor(s) to ensure that:  \n1. proper arrangements are made for the student’s \nexamination,  \n2. the exam is scheduled and held in accordance \nwith FGSR and departmental regulations,  \n3. committee members are informed of meetings \nand details of examinations  \n4. the student does not make these arrangements,  \n5. the student provides a copy of the thesis \n(master’s and doctoral final examination) to \nthe individual delegated by the program to \ndistribute the thesis to the examiners (ex. chair of \nthe examination, program administrator, \nsupervisor). The supervisor is responsible for \nensuring that all examiners receive the thesis in a \ntimely way. All examiners for a doctoral final \nexamination must receive a copy of the thesis at \nleast four weeks before the examination.  \nIn the absence of the supervisor, the department’s \ngraduate coordinator or designate shall be responsible for \nthese arrangements.  \nChanging an Examining Committee Member: Changes \nto the membership of the Examining Committee must \nfollow the procedures established by the Dean of the \ndepartment’s Faculty.  \nLanguage of Examinations: The language used to \nconduct examinations shall be English, except where \nalready approved by the FGSR Council. However, the \nexamining committee may petition the Dean of the FGSR, \nPage 13 of 25 \nexamination in a language other than English.  \nTime Limit for Submission of Theses to FGSR: \nFollowing completion of the final examination at which \nthe thesis is passed or passed subject to revisions, the \nstudent shall make the appropriate revisions where \nnecessary and submit the approved thesis to the FGSR \nwithin six months of the date of the final examination. \nDepartments may impose earlier deadlines for submitting \nrevisions.  \nIf the thesis is not submitted to the FGSR within the six-\nmonth time limit, the student will be considered to have \nwithdrawn from the program. After this time, the student \nmust apply and be readmitted to the FGSR and register \nagain before the thesis can be accepted. If the final \nexamination is adjourned, the six-month time limit will \ntake effect from the date of completion of the examination \nwhere the thesis was passed with or without revisions.  \nIn order to convocate, all thesis-based students must \nsubmit their thesis to the FGSR and have it approved \nbefore they can be cleared for convocation. The thesis \ncannot be approved without a valid student registration \nat the time of approval.  \nand on receiving written approval, may conduct the \nexamination in a language other than English.  \nTime Limit for Submission of Theses to FGSR: \nFollowing completion of the final examination at which \nthe thesis is passed or passed subject to revisions, the \nstudent shall make any necessary revisions and submit \nthe approved thesis to the FGSR within six months of the \ndate of the final examination. Departments may impose \nearlier deadlines for submitting revisions.  \nIf the thesis is not submitted to the FGSR within the six-\nmonth time limit, the student will be considered to have \nwithdrawn from the program. After this time, the student \nmust apply and be readmitted to the FGSR and register \nagain before the thesis can be accepted. If the final \nexamination is adjourned, the six-month time limit will \ntake effect from the date of completion of the examination \nwhere the thesis was passed with or without revisions.  \nIn order to convocate, all thesis-based students must \nsubmit their thesis to the FGSR and have it approved \nbefore they can be cleared for convocation. The thesis \ncannot be approved without a valid student registration \nat the time of approval.  \nConduct of Thesis and Candidacy Examinations \nThe following apply to all examinations.  Matters specific \nto each type of examination are detailed in the sections \nthat follow.  Programs may have additional regulations in \ntheir program guidelines. \n• The student may be required to give a presentation \nprior to the examination.  The presentation may be \npublic or only for the examining committee (and \nothers approved to attend the examination—see \nAttendance at Doctoral Examinations, above). \n• If a public seminar is held before the examination, \ntypically the examiners do not ask questions until the \nexamination itself begins. \n• At the start of the examination the chair should \nreview the procedures as detailed by the program’s \nguidelines for the examination including the order of \nexaminers, number of rounds of questions,the length \nof time allotted to each examiner and whether \ninterjections by other examiners are \npermitted.  Departmental examination procedures \nshould have flexibility to adjust accordingly when \nthere are large supervisory committees so as not to \nextend the questioning portion of the examination \nbeyond a reasonable duration (2 hours for master’s \nand 3 hours for doctoral examinations).  \n• The student may be asked to leave the room while the \norder of examiners is determined, and the student’s \nacademic record is reviewed by the supervisor for the \ncommittee.  Typically the order of examiners is the \nExternal if applicable, the arm’s length examiners, the \nPage 14 of 25 \nThesis Based Master’s Program Examination  \nDecision of the Master’s Final Examining Committee: \nThe decision of the examining committee will be based \nboth on the content of the thesis and on the student’s \nability to defend it. The final examination may result in \none of the following outcomes:  \n• Adjourned  \n• Pass  \n• Pass subject to revisions  \n• Fail  \nThere is no provision for a final examination to be “passed \nsupervisory committee members and then the \nsupervisor.  The Examiners may seek clarification at \nthis time regarding exam procedures. \n• If academic misconduct is suspected, an Associate \nDean, FGSR should be consulted prior to the exam. \n• For thesis examinations the questioning should focus \non establishing the quality of the thesis [or thesis \nsubstitute] and the student’s breadth and depth of \nunderstanding at a level appropriate to the degree \nqualification.  Expectations for a Candidacy \nexamination are detailed in the program’s guidelines. \n• When the questions have concluded, the chair should \nask the student if they have any final comments they \nwould like to add. \nDeliberation: \n• The student is required to leave the room and will be \nasked to take their personal belongings including \nelectronic devices with them. \n• The deliberations are confidential proceedings. The \ncommittee will agree on the report to be provided to \nthe student with the outcome of the examination. \n• The examiners are asked to give their opinions on the \nquality of the thesis and the defense, or performance \nin the candidacy examination, in the same order as \nquestioning occurred. All examiners must provide \ntheir opinion before a final decision is made. \n• The options of the outcomes from the vote are \ndetailed for each type of examination. \n• If the outcome of the first vote does not result in a \ndecision (eg. two of five examiners vote to fail), the \nchair will allow for further discussion and attempt to \nreach a decision.  Only in cases where a decision \ncannot be reached in a reasonable time will the \nstudent be informed and matter referred to the Dean \nFGSR, who will determine the appropriate course of \naction. \n• The chair of the Examination Committee may sign the \nthesis examination form on behalf of an examiner \nwho is participating from a remote location.  \nThesis Based Master’s Program Examination  \nEach department offering a thesis-based Master’s degree \nis required to establish detailed examination procedures \nfor final examinations. These procedures must be made \navailable publicly.  \nDecision of the Master’s Final Examining Committee: \nThe decision of the examining committee will be based \nboth on the content of the thesis and on the student’s \nability to defend it. The final examination may result in \none of the following outcomes:  \n• Adjourned  \n• Pass  \n• Pass subject to revisions  \n• Fail  \nPage 15 of 25 \nsubject to major revisions”.  \nIf the Examining Committee fails to reach a decision, the \ndepartment will refer the matter to the Dean, FGSR, who \nwill determine an appropriate course of action. \nAdjourned: An adjourned examination is one that has \nbeen abandoned officially. A majority of examiners must \nagree to an outcome of Adjourned. The final examination \nshould be adjourned in the following situations:  \n• The revisions to the thesis are sufficiently substantial \nthat it will require further research or experimentation or \nmajor reworking of sections, or if the committee is so \ndissatisfied with the general presentation of the thesis \nthat it will require a reconvening of the examining \ncommittee. In such circumstances the committee cannot \npass the student, and must adjourn the examination.  \n• The committee is dissatisfied with the student’s oral \npresentation and defence of the thesis, even if the thesis \nitself is acceptable with or without minor revisions.  \n• Compelling, extraordinary circumstances such as a \nsudden medical emergency taking place during the \nexamination.  \n• Discovery of possible offences under the Code of Student \nBehaviour after the examination has started.  \nIf the examination is adjourned, the committee should:  \n• Specify in writing to the student, with as much precision \nas possible, the nature of the deficiencies and, in the case \nof revisions to the thesis, the extent of the revisions \nrequired. Where the oral defence is unsatisfactory, it may \nbe necessary to arrange some discussion periods with the \nstudent prior to reconvening the examination.  \n• Decide upon a date to reconvene. If the date of the \nreconvened examination depends upon the completion of \na research task or a series of discussions, it should be \nmade clear which committee members will decide on the \nappropriate date to reconvene. This new examination \nmust be held within six months of the initial examination. \n• Make it clear to the student what will be required by \nway of approval before the examination is reconvened \n(e.g., approval of the committee chair or supervisor, \napproval of the entire committee, or of select members of \nthe committee).  \n• Specify the supervision and assistance the student may \nexpect from the committee members in meeting the \nnecessary revisions.  \n• Advise the Dean, FGSR, in writing of the adjournment \nand the conditions.  \n• When the date is set for the adjourned final examination, \nthe department will notify the FGSR. Normally a Pro Dean \nattends the examination.  \nPass: All or all but one of the examiners must agree to an \nThere is no provision for a final examination to be “passed \nsubject to major revisions”.  \nIf the Examining Committee fails to reach a decision, the \ndepartment will refer the matter to the Dean, FGSR, who \nwill determine an appropriate course of action. \nAdjourned: An adjourned examination is one that has \nbeen abandoned officially. A majority of examiners must \nagree to an outcome of Adjourned. The final examination \nshould be adjourned in the following situations:  \n• The revisions to the thesis are sufficiently substantial \nthat it will require further research or experimentation or \nmajor reworking of sections, or if the committee is so \ndissatisfied with the general presentation of the thesis \nthat it will require a reconvening of the examining \ncommittee. In such circumstances the committee cannot \npass the student, and must adjourn the examination.  \n• The committee is dissatisfied with the student’s oral \npresentation and defence of the thesis, even if the thesis \nitself is acceptable with or without minor revisions.  \n• Compelling, extraordinary circumstances such as a \nsudden medical emergency taking place during the \nexamination.  \n• Discovery of possible offences under the Code of Student \nBehaviour after the examination has started.  \nIf the examination is adjourned, the committee should:  \n• Specify in writing to the student, with as much precision \nas possible, the nature of the deficiencies and, in the case \nof revisions to the thesis, the extent of the revisions \nrequired. Where the oral defence is unsatisfactory, it may \nbe necessary to arrange some discussion periods with the \nstudent prior to reconvening the examination.  \n• Decide upon a date to reconvene. If the date of the \nreconvened examination depends upon the completion of \na research task or a series of discussions, it should be \nmade clear which committee members will decide on the \nappropriate date to reconvene. This new examination \nmust be held within six months of the initial examination. \n• Make it clear to the student what will be required by \nway of approval before the examination is reconvened \n(e.g., approval of the committee chair or supervisor, \napproval of the entire committee, or of select members of \nthe committee).  \n• Specify the supervision and assistance the student may \nexpect from the committee members in meeting the \nnecessary revisions.  \n• Advise the Dean, FGSR, in writing of the adjournment \nand the conditions.  \n• When the date is set for the adjourned final examination, \nthe department will notify the FGSR. Normally a Pro Dean \nattends the examination. The Pro Dean should be included \non all correspondence for the rescheduling of the \nexamination. \nPage 16 of 25 \noutcome of Pass. If the student passes the examination, \nthe department should submit a completed Thesis \nApproval/Program Completion form to the FGSR. If one of \nthe examiners fails the student, that examiner does not \nhave to sign this form.  \nPass subject to revisions: All or all but one of the \nexaminers must agree to an outcome of Pass subject to \nrevisions. The student has satisfactorily defended the \nthesis but the revisions to the thesis are sufficiently minor \nthat it will not require a reconvening of the examining \ncommittee.  \nIf the examining committee agrees to a “Pass subject to \nrevisions” for the student, the chair of the examining \ncommittee must provide in writing, within five working \ndays of the examination, to the Dean, FGSR, the graduate \ncoordinator and the student:  \n• the reasons for this outcome,  \n• the details of the required revisions,  \n• the approval mechanism for meeting the requirement \nfor revisions (e.g., approval of the examining committee \nchair or supervisor, or approval of the entire examining \ncommittee, or select members of the committee), and  \n• the supervision and assistance the student can expect to \nreceive from committee members.  \nThe student must make the revisions within six months of \nthe date of the final examination. Once the required \nrevisions have been made and approved, the department \nshall submit a completed Thesis Approval/Program \nCompletion form to the FGSR indicating “pass subject to \nrevisions”. If one of the examiners fails the student that \nexaminer does not have to sign the form. If the required \nrevisions have not been made and approved by the end of \nthe six months deadline, the outcome of the examination \nis a Fail.  \nFail: All or all but one of the examiners must agree to an \noutcome of Fail. If the examination result is a Fail, no \nmember of the examining committee signs the Thesis \nApproval/Completion form.  \nWhen the outcome is a Fail, the committee chair will \nprovide the reasons for this decision to the department. \nThe department will then provide this report, together \nwith its recommendation for the student’s program, to the \nDean, FGSR, and to the student. \nAn Associate Dean, FGSR will normally arrange to meet \nwith the student, the graduate coordinator, and others if \nneeded, before acting upon any departmental \nrecommendation that affects the student’s academic \nstanding.  \nDoctoral Candidacy Examination  \nPass: Pass is the decision given when the only revisions \nrequired are typographical or minor editorial changes. All \nor all but one of the examiners must agree to an outcome \nof Pass. If the student passes the examination, the \ndepartment should submit a completed Thesis \nApproval/Program Completion form to the FGSR. If one of \nthe examiners fails the student, that examiner does not \nhave to sign this form.  \nPass subject to revisions: All or all but one of the \nexaminers must agree to an outcome of Pass subject to \nrevisions. The student has satisfactorily defended the \nthesis but the revisions to the thesis it will not require a \nreconvening of the examining committee.  \nIf the examining committee agrees to a “Pass subject to \nrevisions” for the student, the chair of the examining \ncommittee must provide in writing, within five working \ndays of the examination, to the student, the graduate \ncoordinator, and FGSR:  \n• the reasons for this outcome,  \n• the details of the required revisions,  \n• the approval mechanism for meeting the requirement \nfor revisions (e.g., approval of the examining committee \nchair or supervisor, or approval of the entire examining \ncommittee, or select members of the committee), and  \n• the supervision and assistance the student can expect to \nreceive from committee members.  \nThe student must make the revisions within six months of \nthe date of the final examination. Once the required \nrevisions have been made and approved, the department \nshall submit a completed Thesis Approval/Program \nCompletion form to the FGSR indicating the committee \ndecision was “pass subject to revisions”. If one of the \nexaminers fails the student that examiner does not have \nto sign the form. If the required revisions have not been \nmade and approved by the end of the six months deadline, \nthe student will be required to withdraw.  \nFail: All or all but one of the examiners must agree to an \noutcome of Fail. If the examination result is a Fail, no \nmember of the examining committee signs the Thesis \nApproval/Completion form.  \nWhen the outcome is a Fail, the committee chair will \nprovide the reasons for this decision to the department. \nThe department will then provide this report, together \nwith its recommendation for the student’s program, to the \nDean, FGSR, and to the student. \nAn Associate Dean, FGSR will normally arrange to meet \nwith the student, the graduate coordinator, and others if \nneeded, before acting upon any departmental \nrecommendation that affects the student’s academic \nstanding.  \nPage 17 of 25 \nEstablishing Candidacy Examination Procedures: Each \ndepartment offering a doctoral degree is responsible for \nestablishing detailed examination policies and procedures \nfor the candidacy examination. These documents should \nbe publicly available.  \nThe candidacy examination is an oral examination; some \ndepartments may also require that students take \ncomprehensive written examinations prior to the \ncandidacy examination, but such examinations do not \nform part of the candidacy examination itself.  \nFor candidacy examinations, students must demonstrate \nto the satisfaction of the examining committee that they \npossess:  \n1. an adequate knowledge of the discipline and of the \nsubject matter relevant to the thesis;  \n2. the ability to pursue and complete original research at \nan advanced level; and  \n3. the ability to meet any other requirements found in the \ndepartment’s published policy on candidacy \nexaminations.  \nThe candidacy examination must be held within three \nyears of the commencement of the program in accordance \nwith The Degree of PhD of the University Calendar. The \ncandidacy examination must be passed no less than six \nmonths prior to taking the final examination.  \nDecision of the Candidacy Committee: The candidacy \nexamination may result in one of the following outcomes: \n• Adjourned  \n• Pass  \n• Conditional pass  \n• Fail and repeat the candidacy  \n• Fail with a recommendation to terminate the doctoral \nprogram or for a change of category to a master’s \nprogram. If the Examining Committee fails to reach a \ndecision, the department will refer the matter to the Dean, \nFGSR, who will determine an appropriate course of action. \nAdjourned: A majority of examiners must agree to an \noutcome of Adjourned. The candidacy examination should \nbe adjourned in the event of compelling, extraordinary \ncircumstances such as a sudden medical emergency \ntaking place during the examination or possible offences \nunder the Code of Student Behaviour after the \nexamination has started.  \nPass: All or all but one of the examiners must agree to an \noutcome of Pass. If the student passes the candidacy \nexamination, the department should complete the Report \nDoctoral Candidacy Examination  \nEstablishing Candidacy Examination Procedures: Each \ndepartment offering a doctoral degree is responsible for \nestablishing detailed examination policies and procedures \nfor the candidacy examination. These documents should \nbe publicly available.  \nThe candidacy examination is an oral examination; some \ndepartments may also require that students take \ncomprehensive written examinations prior to the \ncandidacy examination, but such examinations do not \nform part of the candidacy examination itself.  \nFor candidacy examinations, students must demonstrate \nto the satisfaction of the examining committee that they \npossess:  \n1. an adequate knowledge of the discipline and of the \nsubject matter relevant to the thesis;  \n2. the ability to pursue and complete original research at \nan advanced level; and  \n3. the ability to meet any other requirements found in the \ndepartment’s published policy on candidacy \nexaminations.  \nThe candidacy examination must be held within three \nyears of the commencement of the program in accordance \nwith The Degree of PhD of the University Calendar. The \ncandidacy examination must be passed no less than six \nmonths prior to taking the final examination.  \nDecision of the Candidacy Committee: The candidacy \nexamination may result in one of the following outcomes: \n• Adjourned  \n• Pass  \n• Conditional pass  \n• Fail and repeat the candidacy  \n• Fail with a recommendation to terminate the doctoral \nprogram or for a change of category to a master’s \nprogram. If the Examining Committee fails to reach a \ndecision, the department will refer the matter to the Dean, \nFGSR, who will determine an appropriate course of action. \nWhen the decision is Conditional Pass or Fail, chairs may \nrefer to the decision process flowchart found on the FGSR \nwebsite. \nAdjourned: A majority of examiners must agree to an \noutcome of Adjourned. The candidacy examination should \nbe adjourned in the event of compelling, extraordinary \ncircumstances such as a sudden medical emergency \ntaking place during the examination or possible offences \nunder the Code of Student Behaviour after the \nexamination has started.  \nPass: All or all but one of the examiners must agree to an \noutcome of Pass. If the student passes the candidacy \nPage 18 of 25 \nof Completion of Candidacy Examination form and submit \nit to the FGSR.  \nConditional Pass:  \nA majority of examiners must agree to an outcome of \nConditional Pass. If the candidacy examining committee \nagrees to a conditional pass for the student, the chair of \nthe examining committee will provide in writing within \nfive working days to the Dean, FGSR, the graduate \ncoordinator and the student:  \n• the reasons for this recommendation,  \n• the details of the conditions,  \n• the timeframe for the student to meet the conditions,  \n• the approval mechanism for meeting the conditions \n(e.g., approval of the committee chair or supervisor, or \napproval of the entire committee, or select members of \nthe committee), and  \n• the supervision and assistance the student can be \nexpected to receive from committee members  \nConditions are subject to final approval by the Dean, \nFGSR. At the deadline specified for meeting the \nconditions, two outcomes are possible:  \n• All the conditions have been met. In this case, the \ndepartment will complete the Report of Completion of \nCandidacy Examination form and submit it to the FGSR; or \n• Some of the conditions have not been met. In this case, \nthe outcome of the candidacy examination is a Fail, and \nthe options below are available to the examining \ncommittee. Note that the options are different after a \nfailed second candidacy examination.  \nFail: If the candidacy examining committee agrees that \nthe student has failed, the committee chair will provide \nthe reasons for this recommendation to the department. \nThe graduate coordinator will then provide this report, \ntogether with the department’s recommendation for the \nstudent’s program, to the Dean, FGSR, and to the student.  \nFor failed candidacy examinations, an Associate Dean, \nFGSR, normally arranges to meet with the student and \nothers as required before acting upon any department \nrecommendation.  \nThe options available to the examining committee when \nthe outcome of a student’s candidacy exam is “Fail” are  \nexamination, the department should complete the Report \nof Completion of Candidacy Examination form and submit \nit to the FGSR.  \nConditional Pass:  \nA Conditional Pass is appropriate when the student has \nsatisfied the committee in all but a very discrete area of \ndeficiency that can addressed through a reasonable \nrequirements (e.g., coursework, literature review, \nupgrading of writing skills).  Reworking of the entire \ncandidacy proposal is not an acceptable condition and the \nexaminers should consider the options available for a \nstudent that has failed the examination. \nA majority of examiners must agree to an outcome of \nConditional Pass. If the candidacy examining committee \nagrees to a conditional pass for the student, the chair of \nthe examining committee will provide in writing within \nfive working days to the Dean, FGSR, the graduate \ncoordinator and the student:  \n• the reasons for this recommendation,  \n• the details of the conditions,  \n• the timeframe for the student to meet the \nconditions, but which should be no less than six weeks \nand no more than six months. \n• the approval mechanism for meeting the conditions \n(e.g., approval of the committee chair or supervisor, or \napproval of the entire committee, or select members of \nthe committee), \n• the supervision and assistance the student can expect \nto receive from committee members \nConditions are subject to final approval by the Dean, \nFGSR. At the deadline specified for meeting the \nconditions, two outcomes are possible:  \n• All the conditions have been met. In this case, the \ndepartment will complete the Report of Completion of \nCandidacy Examination form and submit it to the FGSR; or \n• If the conditions are not met by the deadline, the \noutcome of the examination is a fail and the committee \nmust be reconvened to make the recommendation as \ndescribed in the following section.   \nFail: All or all but one of the examiners must agree to an \noutcome of Fail. \nThe options available to the examining committee when \nPage 19 of 25 \n• Repeat the Candidacy:  \nA majority of examiners must agree to an outcome of Fail \nand Repeat the Candidacy. If the student’s first candidacy \nexam performance was inadequate but the student’s \nperformance and work completed to date indicate that \nthe student has the potential to perform at the doctoral \nlevel, the examining committee should consider the \npossibility of recommending that the student be given an \nopportunity to repeat the candidacy exam. Normally, the \ncomposition of the examining committee does not change \nfor the repeat candidacy exam.  \nIf the recommendation of a repeat candidacy is \nformulated by the examining committee and approved by \nthe FGSR, the student and graduate coordinator are to be \nnotified in writing of the student’s exam deficiencies by \nthe chair of the examining committee. The second \ncandidacy exam is to be scheduled no later than six \nmonths from the date of the first candidacy. In the event \nthat the student fails the second candidacy, the examining \ncommittee shall recommend one of the following two \noptions to the department:  \n• Change of Category to a Master’s Program: All or all but \none of the examiners must agree to an outcome of Fail and \nChange of Category to a Master’s Program. This outcome \nshould be considered if the student’s candidacy \nexamination performance was inadequate and the \nstudent’s performance and work completed to date \nindicates that the student has the potential to complete a \nmaster’s, but not a doctoral, program; or  \n• Termination of the Doctoral Program: All or all but one \nof the examiners must agree to an outcome of Fail and \nTerminate the Doctoral Program. If the student’s \nperformance was inadequate, and the work completed \nduring the program is considered inadequate, then the \nexamining committee should recommend termination of \nthe student’s program.  \n[moved from above] \nFinal Doctoral Examination  \nEach department offering a doctoral degree is required to \nestablish detailed examination procedures for final \nexaminations. These procedures must be made available \npublicly.  \nthe outcome of a student’s candidacy exam is “Fail” are  \n• Repeat the Candidacy:  Repeating the Candidacy is not \nan option after a second failed examination. A majority of \nexaminers must agree to an outcome of Fail and Repeat \nthe Candidacy. If the student’s first candidacy exam \nperformance was inadequate but the student’s \nperformance and work completed to date indicate that \nthe student has the potential to perform at the doctoral \nlevel, the examining committee should consider the \npossibility of recommending that the student be given an \nopportunity to repeat the candidacy exam. Normally, the \ncomposition of the examining committee does not change \nfor the repeat candidacy exam.  \nIf the recommendation of a repeat candidacy is \nformulated by the examining committee and approved by \nthe FGSR, the student and graduate coordinator are to be \nnotified in writing of the student’s exam deficiencies by \nthe chair of the examining committee. The second \ncandidacy exam is to be scheduled no later than six \nmonths from the date of the first candidacy. In the event \nthat the student fails the second candidacy, the examining \ncommittee shall recommend one of the following two \noptions to the department:  \n• Change of Category to a Master’s Program: All or all but \none of the examiners must agree to an outcome of Fail and \nChange of Category to a Master’s Program. This outcome \nshould be considered if the student’s candidacy \nexamination performance was inadequate and the \nstudent’s performance and work completed to date \nindicate that the student has the potential to complete a \nmaster’s, but not a doctoral, program; or  \n• Termination of the Doctoral Program: All or all but one \nof the examiners must agree to an outcome of Fail and \nTerminate the Doctoral Program. If the student’s \nperformance was inadequate, and the work completed \nduring the program is considered inadequate, then the \nexamining committee should recommend termination of \nthe student’s program.  \nIf the candidacy examining committee agrees that the \nstudent has failed, the committee chair will provide the \nreasons and the recommendation for the student’s \nprogram to the department. The graduate coordinator \nwill then provide this report, together with the \ndepartment’s recommendation for the student’s program, \nto the Dean, FGSR, and to the student.  \nFor failed candidacy examinations, an Associate Dean, \nFGSR, normally arranges to meet with the student (and \nothers as, required) before acting upon any department \nrecommendation.  \nFinal Doctoral Examination  \nEach department offering a doctoral degree is required to \nestablish detailed examination procedures for final \nexaminations. These procedures must be made available \nPage 20 of 25 \nPreliminary Acceptance of the Thesis: Before the thesis \nis forwarded to the External, the supervisory committee \nmembers must declare in writing to the supervisor(s) \neither that the thesis is of adequate substance and quality \nto warrant that the student proceed to the final \nexamination or that the thesis is unsatisfactory and the \nstudent should not be allowed to proceed to the final \nexamination.  \nThe purpose of this process is to ensure the thesis is \nvetted by the supervisor(s) and all supervisory committee \nmembers and to verify that it is of sufficient substance \nand quality to proceed to the final examination.  \nThis process is critical to protect and uphold the \nreputation of the department and the University of \nAlberta for excellence in graduate programs. It is also \ncritical to ensure that Externals and other additional \nmembers of the examining committee are not asked to \ninvest time reading a thesis that is substandard. \nDepartments may choose to prepare a “Preliminary \nAcceptance of Thesis” signature sheet for their own \nrecords.  \nAttendance at Doctoral Examinations: Faculty \nmembers of the student’s home department as well as \nmembers of FGSR Council (or their alternates) have the \nright to attend doctoral examinations but should notify \nthe chair of the examining committee. Other persons may \nattend the examination only with special permission of \nthe Dean of the department’s Faculty, the Dean, FGSR, or \nthe chair of the examining committee.  \nExcept for a Dean or a Pro Dean who may participate fully \nin the examination, persons who are not members of the \nexamining committee:  \n• may participate in the questioning only by permission of \nthe chair of the committee, but  \n• are not permitted to participate in the discussion of the \nstudent’s performance and must withdraw before such \ndiscussion commences  \nInviting the External Examiner or Reader: Every Final \nDoctoral Examining Committee must have an External i.e., \nan arm’s length examiner from outside the University of \nAlberta. The term External Examiner refers to an \nExternal that attends the examination; whereas the term \nExternal Reader refers to an External who provides a \nwritten evaluation of the thesis and questions to be asked \nduring the examination. External Readers are deemed to \nbe in attendance at the examination.  \nIt is the responsibility of the department to recommend \nan External Examiner or Reader and to submit the name \nto the Dean of the department’s Faculty for approval. \nNormally, this should be done at least two months in \nadvance of the examination date. The submission must \nfollow the procedures established by the Dean of the \npublicly.  \nPreliminary Acceptance of the Thesis: Before the thesis \nis forwarded to the External, the supervisory committee \nmembers must declare in writing to the supervisor(s) \neither that the thesis is of adequate substance and quality \nto warrant that the student proceed to the final \nexamination or that the thesis is unsatisfactory and the \nstudent should not be allowed to proceed to the final \nexamination.  \nThe purpose of this process is to ensure the thesis is \nvetted by the supervisor(s) and all supervisory committee \nmembers and to verify that it is of sufficient substance \nand quality to proceed to the final examination.  \nThis process is critical to protect and uphold the \nreputation of the department and the University of \nAlberta for excellence in graduate programs. It is also \ncritical to ensure that Externals and other additional \nmembers of the examining committee are not asked to \ninvest time reading a thesis that is substandard. \nDepartments may choose to prepare a “Preliminary \nAcceptance of Thesis” signature sheet for their own \nrecords.  \nAttendance at Doctoral Examinations: Faculty \nmembers of the student’s home department as well as \nmembers of FGSR Council (or their alternates) have the \nright to attend doctoral examinations but should notify \nthe chair of the examining committee. Other persons may \nattend the examination only with special permission of \nthe Dean of the department’s Faculty, the Dean, FGSR, or \nthe chair of the examining committee.  \nExcept for a Dean or a Pro Dean who may participate fully \nin the examination, persons who are not members of the \nexamining committee:  \n• may participate in the questioning only by permission of \nthe chair of the committee, but  \n• are not permitted to participate in the discussion of the \nstudent’s performance and must withdraw before such \ndiscussion commences  \nInviting the External Examiner or Reader: Every Final \nDoctoral Examining Committee must have an External i.e., \nan arm’s length examiner from outside the University of \nAlberta. The term External Examiner refers to an \nExternal who attends the examination, whereas the term \nExternal Reader refers to an External who provides a \nwritten evaluation of the thesis and questions to be asked \nduring the examination. External Readers are deemed to \nbe in attendance at the examination.  \nIt is the responsibility of the department to recommend \nan External Examiner or Reader and to submit the name \nto the Dean of the department’s Faculty for approval. \nNormally, this should be done at least two months in \nadvance of the examination date. The submission must \nPage 21 of 25 \ndepartment’s Faculty.  \nThe External:  \n• Must be a recognized authority in the specific field of \nresearch of the student’s thesis.  \n• Will be experienced in evaluating doctoral area work; \nand  \n• Must be in a position to review the thesis objectively and \nto provide a critical analysis of the work and the \npresentation.  \nIt is essential that the External not have an association \nwith the student, the supervisor, or the \ndepartment, within the last six years as this could hinder \nobjective analysis. For example, a proposed External who \nhas within the last six years been associated with the \nstudent as a research collaborator or coauthor would not \nbe eligible. Also, a proposed External must not have had \nan association within the last six years with the doctoral \nstudent’s supervisor (as a former student, supervisor, or \nclose collaborator, for instance).  \nUnder normal circumstances the same person will not be \nused as an External at the University of Alberta if that \nExternal has served in the same capacity in the same \ndepartment at this University within the preceding two \nyears; this does not preclude an External serving in \nanother department.  \nOnce the External has been approved an official letter of \ninvitation is issued to the External by the department.  \nApproval of the Doctoral Final Examining Committee: \nThe department will recommend the names of all \nmembers of the final examining committee and forward \nthem to the Dean of the department’s Faculty, if decanal \napproval is required, following the procedures \nestablished by their Faculty.  \nExternal Readers: Do not attend the examination. \nInstead, the External Reader is asked in the letter of \ninvitation to prepare a written report consisting of:  \n• an evaluation of the scope, structure, methodology, and \nfindings of the thesis,  \n• a list of minor errors (if any), and  \n• either a list of clear, direct, contextualized questions to \nbe posed to the candidate during the examination, or a \nbrief written commentary of the thesis which can be read \nto the candidate for response during the examination.  \nThe External Reader must include a statement that the \nthesis falls into one of the following two categories:  \n• Acceptable with minor or no revisions: In this case, \nthe External Reader submits the report to the Graduate \nCoordinator at least one week before the examination. If \nthe External Reader considers the thesis to be of a calibre \nworthy of consideration for an award, the External \nReader comments on this in the written evaluation; or  \n• Unacceptable without major revisions: In this case, \nfollow the procedures established by the Dean of the \ndepartment’s Faculty.  \nThe External:  \n• Will be a recognized authority in the specific field of \nresearch of the student’s thesis; \n• Will be experienced in evaluating doctoral area work; \nand  \n• Must be in a position to review the thesis objectively and \nto provide a critical analysis of the work and the \npresentation.  \nIt is essential that the External not have an association \nwith the student, the supervisor, or the department \nwithin the last six years as this could hinder objective \nanalysis. For example, a proposed External who has \nwithin the last six years been associated with the student \nas a research collaborator or coauthor would not be \neligible. Also, a proposed External must not have had an \nassociation within the last six years with the doctoral \nstudent’s supervisor (as a former student, supervisor, or \nclose collaborator, for instance).  \nUnder normal circumstances the same person will not be \nused as an External at the University of Alberta if that \nExternal has served in the same capacity in the same \ndepartment at this University within the preceding two \nyears; this does not preclude an External serving in \nanother department.  \nOnce the External has been approved an official letter of \ninvitation is issued to the External by the department.  \nApproval of the Doctoral Final Examining Committee: \nThe department will recommend the names of all \nmembers of the final examining committee and forward \nthem to the Dean of the department’s Faculty, if decanal \napproval is required, following the procedures \nestablished by their Faculty.  \nExternal Readers: Do not attend the examination. \nInstead, the External Reader is asked in the letter of \ninvitation to prepare a written report consisting of:  \n• an evaluation of the scope, structure, methodology, and \nfindings of the thesis,  \n• a list of minor errors (if any), and  \n• either a list of clear, direct, contextualized questions to \nbe posed to the candidate during the examination, or a \nbrief written commentary of the thesis which can be read \nto the candidate for response during the examination.  \nThe External Reader must include a statement that the \nthesis falls into one of the following two categories:  \n• Acceptable with minor or no revisions: In this case, \nthe External Reader submits the report to the Graduate \nCoordinator at least one week before the examination. If \nthe External Reader considers the thesis to be of a calibre \nworthy of consideration for an award, the External \nReader comments on this in the written evaluation; or  \nPage 22 of 25 \nthe External Reader contacts the Dean of the FGSR \nimmediately by email as the examination may need to be \npostponed.  \nThe questions or commentary will be made available to \nthe student for the first time during the examination and \nthe committee will evaluate the student’s answers as part \nof the examination.  \nExternal Examiners: Attend the examination in person. \nIn the letter of invitation, the External Examiner is \nrequested to prepare and send to the Graduate \nCoordinator, at least one week in advance of the \nexamination, an evaluation of the thesis placing it \ntemporarily in one of the following categories:  \n• the thesis is acceptable with minor or no revisions,  \n• the External Examiner wishes to reserve judgment until \nafter the examination, or  \n• the thesis is unacceptable without major revisions.  \nIn the first two cases, the External Examiner is asked to \nprovide a brief written commentary (approximately two \nto three pages) on the structure, methodology, quality, \nsignificance and findings of the thesis for the reference of \nboth the student and supervisor. The commentary should \nnot be given to the student prior to the examination. \nIf the thesis is judged by the External Examiner to fall into \nthe “Unacceptable” category, then the External Examiner \nis asked to contact the Dean of the FGSR immediately, \nsince the final examination may have to be postponed.  \nThe Examination: The examining committee should \nconduct a final examination, based largely on the thesis. \nThe graduate coordinator should ensure that the chair of \nthe examining committee, the student, and all examiners \nhave a final copy of the thesis at the examination.  \nThe student should make a brief presentation about the \nthesis.  \nThe most time should be allotted to the arm’s length \nexaminers, including the External Examiner, while the \nleast time is allocated to the supervisor(s).  \nNo final decision should be made without each examiner \nhaving given an opinion.  \nDecision of the Doctoral Final Examining Committee: The \ndecision of the examining committee will be based both \non the content of the thesis and on the student’s ability to \ndefend it. The final examination may result in one of the \nfollowing outcomes:  \n• Adjourned  \n• Pass  \n• Pass subject to revisions  \n• Fail  \nThere is no provision for a final examination to be “passed \nsubject to major revisions”.  \nIf the Examining Committee fails to reach a decision, the \ndepartment will refer the matter to the Dean, FGSR, who \n• Unacceptable without major revisions: In this case, \nthe External Reader contacts the Dean of the FGSR \nimmediately by email as the examination may need to be \npostponed.  \nThe questions or commentary will be made available to \nthe student for the first time during the examination and \nthe committee will evaluate the student’s answers as part \nof the examination.  \nExternal Examiners: Attend the examination in person. \nIn the letter of invitation, the External Examiner is \nrequested to prepare and send to the Graduate \nCoordinator, at least one week in advance of the \nexamination, an evaluation of the thesis placing it \ntemporarily in one of the following categories:  \n• the thesis is acceptable with minor or no revisions,  \n• the External Examiner wishes to reserve judgment until \nafter the examination, or  \n• the thesis is unacceptable without major revisions.  \nIn the first two cases, the External Examiner is asked to \nprovide a brief written commentary (approximately two \nto three pages) on the structure, methodology, quality, \nsignificance and findings of the thesis for the reference of \nboth the student and supervisor. The commentary should \nnot be given to the student prior to the examination. \nIf the thesis is judged by the External Examiner to fall into \nthe “Unacceptable” category, then the External Examiner \nis asked to contact the Dean of the FGSR immediately, \nsince the final examination may need to be postponed.  \nThe Examination: The examining committee should \nconduct a final examination, based largely on the thesis. \nThe graduate coordinator should ensure that the chair of \nthe examining committee, the student, and all examiners \nhave a final copy of the thesis at the examination.  \nThe student should make a brief presentation about the \nthesis.  \nThe most time should be allotted to the arm’s length \nexaminers, including the External Examiner, while the \nleast time is allocated to the supervisor(s).  \nNo final decision should be made without each examiner \nhaving given an opinion.  \nDecision of the Doctoral Final Examining Committee: The \ndecision of the examining committee will be based both \non the content of the thesis and on the student’s ability to \ndefend it. The final examination may result in one of the \nfollowing outcomes:  \n• Adjourned  \n• Pass  \n• Pass subject to revisions  \n• Fail  \nThere is no provision for a final examination to be “passed \nsubject to major revisions”.  \nIf the Examining Committee fails to reach a decision, the \nPage 23 of 25 \nwill determine an appropriate course of action.  \nAdjourned: An adjourned examination is one that has \nbeen abandoned officially. A majority of examiners must \nagree to an outcome of Adjourned. The final examination \nshould be adjourned in the following situations:  \n• The revisions to the thesis are sufficiently substantial \nthat it will require further research or experimentation or \nmajor reworking of sections, or if the committee is so \ndissatisfied with the general presentation of the thesis \nthat it will require a reconvening of the examining \ncommittee. In such circumstances the committee cannot \npass the student, and must adjourn the examination.  \n• The committee is dissatisfied with the student’s oral \npresentation and defence of the thesis, even if the thesis \nitself is acceptable with or without minor revisions.  \n• Compelling, extraordinary circumstances such as a \nsudden medical emergency taking place during the \nexamination.  \n• Discovery of possible offences under the Code of Student \nBehaviour after the examination has started.  \nIf the examination is adjourned, the committee should:  \n• Specify in writing to the student, with as much precision \nas possible, the nature of the deficiencies and, in the case \nof revisions to the thesis, the extent of the revisions \nrequired. Where the oral defence is unsatisfactory, it may \nbe necessary to arrange some discussion periods with the \nstudent prior to reconvening the examination.  \n• Decide upon a date to reconvene. If the date of the \nreconvened examination depends upon the completion of \na research task or a series of discussions, it should be \nmade clear which committee members will decide on the \nappropriate date to reconvene. The final date set for \nreconvening shall be no later than six months from the \ndate of the examination. This new examination must be \nheld within six months of the initial examination.  \n• Make it clear to the student what will be required by \nway of approval before the examination is reconvened \n(e.g., approval of the committee chair or supervisor, \napproval of the entire committee, or of select members of \nthe committee).  \n• Specify the supervision and assistance the student may \nexpect from the committee members in meeting the \nnecessary revisions.  \n• Advise the Dean of the department’s Faculty following \nthe procedures established for this purpose.  \n• Advise the FGSR in writing of the adjournment and the \nconditions.  \n• When the date is set for the adjourned final examination, \nthe department will notify the Dean of the department’s \nFaculty and the FGSR. Normally a Pro Dean attends the \nexamination.  \nPass:  \ndepartment will refer the matter to the Dean, FGSR, who \nwill determine an appropriate course of action.  \nAdjourned: An adjourned examination is one that has \nbeen abandoned officially. A majority of examiners must \nagree to an outcome of Adjourned. The final examination \nshould be adjourned in the following situations:  \n• The revisions to the thesis are sufficiently substantial \nthat it will require further research or experimentation or \nmajor reworking of sections, or if the committee is so \ndissatisfied with the general presentation of the thesis \nthat it will require a reconvening of the examining \ncommittee. In such circumstances the committee cannot \npass the student, and must adjourn the examination.  \n• The committee is dissatisfied with the student’s oral \npresentation and defence of the thesis, even if the thesis \nitself is acceptable with or without minor revisions.  \n• Compelling, extraordinary circumstances such as a \nsudden medical emergency taking place during the \nexamination.  \n• Discovery of possible offences under the Code of Student \nBehaviour after the examination has started.  \nIf the examination is adjourned, the committee should:  \n• Specify in writing to the student, with as much precision \nas possible, the nature of the deficiencies and, in the case \nof revisions to the thesis, the extent of the revisions \nrequired. Where the oral defence is unsatisfactory, it may \nbe necessary to arrange some discussion periods with the \nstudent prior to reconvening the examination.  \n• Decide upon a date to reconvene. If the date of the \nreconvened examination depends upon the completion of \na research task or a series of discussions, it should be \nmade clear which committee members will decide on the \nappropriate date to reconvene. The final date set for \nreconvening shall be no later than six months from the \ndate of the examination. This new examination must be \nheld within six months of the initial examination.  \n• Make it clear to the student what will be required by \nway of approval before the examination is reconvened \n(e.g., approval of the committee chair or supervisor, \napproval of the entire committee, or of select members of \nthe committee).  \n• Specify the supervision and assistance the student may \nexpect from the committee members in meeting the \nnecessary revisions.  \n• Advise the Dean of the department’s Faculty following \nthe procedures established for this purpose.  \n• Advise the FGSR in writing of the adjournment and the \nconditions.  \n• When the date is set for the adjourned final examination, \nthe department will notify the Dean of the department’s \nFaculty and the FGSR. Normally a Pro Dean attends the \nexamination.  \nPage 24 of 25 \nAll or all but one of the examiners must agree to an \noutcome of Pass. If the student passes the examination, \nthe department should submit a completed Thesis \nApproval/Program Completion form to the FGSR. If one of \nthe examiners fails the student, that examiner does not \nhave to sign this form.  \nPass Subject to Revisions: All or all but one of the \nexaminers must agree to an outcome of Pass Subject to \nRevisions. The student has satisfactorily defended the \nthesis but the revisions to the thesis are sufficiently minor \nthat it will not require a reconvening of the examining \ncommittee. If the examining committee agrees to a “Pass \nsubject to revisions” for the student, the chair of the \nexamining committee must provide in writing, within five \nworking days of the examination, to the Dean, FGSR, the \ngraduate coordinator and the student. \n• the reasons for this outcome,  \n• the details of the required revisions,  \n• the approval mechanism for meeting the requirement \nfor revisions (e.g., approval of the examining committee \nchair or supervisor, or approval of the entire examining \ncommittee, or select members of the committee), and  \n• the supervision and assistance the student can expect to \nreceive from committee members.  \nThe student must make the revisions within six months of \nthe date of the final examination. Once the required \nrevisions have been made and approved, the department \nshall submit a completed Thesis Approval/Program \nCompletion form to the FGSR indicating “pass subject to \nrevisions”. If one of the examiners fails the student that \nexaminer does not have to sign the form. If the required \nrevisions have not been made and approved by the end of \nthe six months deadline, the outcome of the examination \nis a Fail.  \nFail: All or all but one of the examiners must agree to an \noutcome of Fail. If the examination result is a Fail, no \nmember of the examining committee signs the Thesis \nApproval/Completion form.  \nWhen the outcome is a Fail, the committee chair will \nprovide the reasons for this decision to the graduate \ncoordinator. The department will then provide this \nreport, together with its recommendation for the \nstudent’s program, to the Dean of the department’s \nFaculty, the FGSR, and to the student.  \nAn Associate Dean, FGSR will normally arrange to meet \nwith the student and with the graduate coordinator \nbefore acting upon any department recommendation that \naffects the student’s academic standing. \nPass: Pass is the decision given when the only revisions \nrequired are typographical or minor editorial changes. All \nor all but one of the examiners must agree to an outcome \nof Pass. If the student passes the examination, the \ndepartment should submit a completed Thesis \nApproval/Program Completion form to the FGSR. If one of \nthe examiners fails the student, that examiner does not \nhave to sign this form.  \nPass Subject to Revisions: All or all but one of the \nexaminers must agree to an outcome of Pass Subject to \nRevisions. The student has satisfactorily defended the \nthesis but the revisions to the thesis it will not require a \nreconvening of the examining committee. If the examining \ncommittee agrees to a “Pass subject to revisions” for the \nstudent, the chair of the examining committee must \nprovide in writing, within five working days of the \nexamination, to the student, the graduate coordinator, \nand FGSR:  \n• the reasons for this outcome,  \n• the details of the required revisions,  \n• the approval mechanism for meeting the requirement \nfor revisions (e.g., approval of the examining committee \nchair or supervisor, or approval of the entire examining \ncommittee, or select members of the committee), and  \n• the supervision and assistance the student can expect to \nreceive from committee members.  \n• A date for the revisions to be resubmitted, as \nnegotiated with the student, but which should be no \nless than six weeks and no more than six months. \nThe student must make the revisions within six months of \nthe date of the final examination. Once the required \nrevisions have been made and approved, the department \nshall submit a completed Thesis Approval/Program \nCompletion form to the FGSR indicating the committee \ndecision was “pass subject to revisions”. If one of the \nexaminers fails the student that examiner does not have \nto sign the form. If the required revisions have not been \nmade and approved by the end of the six months deadline, \nthe student will be required to withdraw.  \nFail: All or all but one of the examiners must agree to an \noutcome of Fail. If the examination result is a Fail, no \nmember of the examining committee signs the Thesis \nApproval/Completion form.  \nWhen the outcome is a Fail, the committee chair will \nprovide the reasons for this decision to the graduate \ncoordinator. The department will then provide this \nreport, together with its recommendation for the \nstudent’s program, to the Dean of the department’s \nFaculty, the FGSR, and to the student.  \nAn Associate Dean, FGSR will normally arrange to meet \nwith the student and with the graduate coordinator \nbefore acting upon any department recommendation that \nPage 25 of 25 \n affects the student’s academic standing.  \nJustification:  \nThe conduct of graduate examinations holds extremely high stakes for individual students and presents \nsignificant reputational risk for the faculty, program and institution. A major revision the Supervision and \nStructure of Examining Committees in the Graduate Program Manual was approved by FGSR Council in May \n2012. Subsequently in May 2013 the authority for approval of supervisors, supervisory committees, \nexternal examiners and examining committees was delegated to the disciplinary department/Faculty of the \nprogram and the change to the Calendar governing examinations was approved by FGSR Council October \n2013 appearing in the 2014-2015 Calendar.  A number of areas have come to light that have caused \nproblems due to apparent contradictions, gaps and/or confusing language.  The revisions are not intended \nto significantly alter the policies governing examinations but to clarify the policies, elaborate on procedures, \nand update graduate level examination procedures given changes to practices and technologies. \nApproved: FGSR Council, May 17, 2017 \nItem No. 10 \nGFC EXECUTIVE COMMITTEE \nFor the Meeting of September 11, 2017 \nOUTLINE OF ISSUE \nAction Item \nAgenda Title: Proposed Faculty Name Change: Faculty of Kinesiology, Sport, and Recreation (from \nFaculty of Physical Education and Recreation (FPER)) \nMotion:  THAT General Faculties Council approve the proposed name change for the Faculty of Physical \nEducation and Recreation to the ‘Faculty of Kinesiology, Sport, and Recreation’, as submitted by the \nDean of the Faculty, to take effect upon final approval. \nItem   \nAction Requested Approval Recommendation   \nProposed by Kerry Mummery, Dean, Faculty of Physical Education & Recreation \nPresenter Kerry Mummery, Dean, Faculty of Physical Education & Recreation \nDetails \nResponsibility Provost and Vice-President (Academic) \nThe Purpose of the Proposal is \n(please be specific) \nTo change the name of the Faculty of FPER to a name that more \naccurately depicts its academic mission and offerings, in support of \nattracting the best and brightest students and faculty, and being \nrecognized as a leader among its peers. Over the past academic year \nFPER Faculty members, staff, students, alumni and stakeholders were \ngiven the opportunity to provide input on a new Faculty name. After a \nformal process Faculty Council endorsed the name Faculty of \nKinesiology, Sport, and Recreation. \nThe Impact of the Proposal is The new Faculty name better defines and describes the teaching, \nresearch and service activities of the Faculty. The new name will both \ndefine and differentiate the Faculty at the national and international level, \nthus helping to attract top quality students, faculty and staff. \nReplaces/Revises (eg, policies, \nresolutions) \nCurrent name:  Faculty of Physical Education and Recreation. \nTimeline/Implementation Date Effective upon approval. \nEstimated Cost and funding \nsource \nThe estimated cost of name change is approximately $250,000, which \nincludes costs related to signage inside and outside of all Faculty \nbuildings on North and South Campus, the update of all Faculty-named \nmedia, marketing and promotional material, and well as a dedicated \nmarketing and communication plan to promote the new name locally, \nprovincially, nationally, and internationally. Funds to support the costs of \nthe name change will come from the Faculty, the Office of the Provost \nand Vice-President (Academic), and the Office of the Vice President \nUniversity Relations. \nNext Steps (ie.: \nCommunications Plan, \nImplementation plans) \nOn final approval by GFC, the Marketing and Communication office in \nthe Faculty will complete both a ‘soft’ and ‘hard’ launch of the new \nFaculty name. The soft launch will immediately begin using the new \nFaculty name on any item that allows for immediate alteration (i.e. email \nsignatures, newly created Faculty documents, etc.). The soft launch will \noccur immediately following approval by GFC. The hard launch of the \nnew Faculty name will take place when all of the marketing, media, \npromotional material and way-finding signage are prepared. Upon hard \nlaunch all references to the former Faculty name will be removed, and \nthe former Faculty name will only be used in the historical context. \nSupplementary Notes and \ncontext \nItem No. 10 \nGFC EXECUTIVE COMMITTEE \nFor the Meeting of September 11, 2017 \nEngagement and Routing (Include meeting dates) \nParticipation: \n(parties who have seen the \nproposal and in what capacity) \n<For further information see \nthe link posted on \nthe Governance Toolkit section \nStudent Participation Protocol> \nThose who have been informed: \n• Canadian Council of University Physical Education and \nKinesiology Administrators (CCUPEKA) \n• Presidential Visiting Committee (PVC) \n• International Partner Universities  \nThose who have been consulted: \n• Faculty staff, students, and alumni \n• Physical Education and Recreation Council of Students (PERCS) \n• Physical Education and Recreation and Recreation Graduate \nStudents Society (PERGGS) \n• Physical Education and Recreation Alumni Associate (PERRA) \n• Community stakeholders \nThose who are actively participating: \n• Faculty of Physical Education and Recreation Academic Planning \nCommittee \n• Faculty of Physical Education and Recreation Faculty \nManagement Group (APC) \n• Faculty of Physical Education and Recreation Faculty Council \nExecutive Committee (FEXC) \n• Faculty of Physical Education and Recreation Faculty Council \nApproval Route (Governance) \n(including meeting dates) \nFaculty of Physical Education and Recreation Council  \nGFC Academic Planning Committee – September 13, 2017 \nGFC Executive Committee (for information) – September 11, 2017 \nGeneral Faculties Council – September 25, 2017 \nFinal Approver General Faculties Council \nAlignment/Compliance \nAlignment with Guiding \nDocuments \nThe name Faculty of Kinesiology, Sport, and Recreation will position \nthe Faculty to ‘build a diverse, inclusive community of exceptional \nundergraduate and graduate students from Edmonton, Alberta, Canada \nand the world’ (Institutional Strategic Plan 2016 – 2021, Objective 1) by \nbetter describing the areas of research, teaching and service. The \nunique-in-Canada inclusion of the term ‘sport’ in the faculty name will \noffer a point of differentiation on the international scene, whereas the \nreplacement of the name Physical Education with Kinesiology aligns the \nofferings of the Faculty with our domestic competitors. The renaming of \nthe Faculty will address Objective 6 of the Institution Plan, by developing \na ‘brand platform’ that will enhance our reputation, image and identity. \nThe renaming of the Faculty aligns the name/brand of the Faculty with its \nmission and mandate, which is to ‘create and share (sic) the best \nunderstandings and applications of physical activity, sport and recreation \nfor the public good’ (Faculty Strategic Plan 2016-2021). Consistent and \naligned with the Institutional plan, the renaming of the Faculty positions \nthe Faculty to Recruit and enroll high quality students and increase the \nnumber of out-of-province and international students in the Faculty \n(aligns with Faculty Strategic Plan; Build). Additionally, the proposed \nname of the Faculty aligns with Engage under the Faculty Strategic Plan, \nwhich seeks to ‘increase and depend the understanding’ of the Faculty. \nhttp://www.governance.ualberta.ca/GovernanceToolkit/Toolkit.aspx\nhttp://www.governance.ualberta.ca/GovernanceToolkit/Toolkit.aspx\nItem No. 10 \nGFC EXECUTIVE COMMITTEE \nFor the Meeting of September 11, 2017 \nCompliance with Legislation, \nPolicy and/or Procedure \nRelevant to the Proposal \n(please quote legislation and \ninclude identifying section \nnumbers) \n1. Post-Secondary Learning Act (PSLA): The Post-Secondary \nLearning Act (PSLA) gives GFC responsibility, subject to the \nauthority of the Board of Governors, over academic affairs (Section \n26(1)).  \n2. GFC Academic Planning Committee Terms of Reference \n“APC is responsible for making recommendations to GFC and/or the \nBoard of Governors concerning policy matters and action matters \nwith respect to the following: […] \n9. Name Changes of Faculties, Departments, and Divisions \na. To recommend to GFC on proposals to change the name of \nFaculties.” \n3. GFC Executive Committee Terms of Reference (3. Mandate of \nthe Committee) \n“5. Agendas of General Faculty Council \nGFC has delegated to the Executive Committee the authority to \ndecide which items are placed on a GFC Agenda, and the order in \nwhich those agenda items appear on each GFC agenda.  \nWhen ordering items, the GFC Executive Committee will be mindful \nof any matters that are of particular concern to students during March \nand April so that the student leaders who bring those items forward \nare able to address these items at GFC before their terms end.  \nWhen recommendations are forwarded to General Faculties Council \nfrom APC, the role of the Executive shall be to decide the order in \nwhich items should be considered by GFC. The Executive \nCommittee is responsible for providing general advice to the Chair \nabout proposals being forwarded from APC to GFC.” \nAttachments  \n1. Attachment 1 Faculty of Physical Education and Recreation – Faculty Name Change Process \n(pages 1 - 8) \n2.  Attachment 2 Letters of Support (pages 1 - 58) \nPrepared by:  Dr. Kerry Mummery, Dean,  \nFaculty of Physical Education and Recreation \nkerry.mummery@ualberta.ca \n1\tAttachment\t1\t/\tPage\t#\t\nFaculty\tof\tPhysical\tEducation\tand\tRecreation\t–\tFaculty\tName\tChange\tProcess\t\nExecutive\tSummary\t\nFor\tthe\tfirst\ttime\tin\tover\t40\tyears,\tthe\tFaculty\tof\tPhysical\tEducation\tand\tRecreation\t\nhas,\tfollowing\textensive\tresearch\tand\tconsultation\twith\tinternal\tand\texternal\t\nstakeholders,\tvoted\tat\tFaculty\tCouncil\tto\tsupport\ta\tnew\tfaculty\tname\tto\tgo\tforward\t\nfor\tapproval\tto\tGeneral\tFaculty\tCouncil\t(GFC).\t\t\nThe\timpetus\tfor\tthe\tname\tchange\tcame\tfrom\ta\tneed\tto\tbetter\treflect\tthe\tnature\tand\t\nbreadth\tof\tofferings\twithin\tthe\tFaculty.\tSpecifically,\tthe\tterm\t‘Physical\tEducation’,\t\nwhich\tis\tat\tthe\thistoric\theart\tof\tthe\tFaculty,\twas\tfelt\tto\tno\tlonger\treflect\tthe\tareas\tof\t\nteaching\tor\tresearch\twithin\tthe\tFaculty.\tLargely\tdue\tto\tstudent\tdemand,\tthe\tlong-\nstanding\tBachelor\tof\tPhysical\tEducation\t(BPE)\twas\tchanged\tin\t2015\tto\ta\tBachelor\tof\t\nKinesiology\t(BKin),\tleaving\tthe\tFaculty\twith\tno\tdegree\tor\tofferings\tin\tthe\tarea\tof\t\nphysical\teducation.\t\t\nThe\ttiming\tof\tthe\tname\tchange\twas\tin\tresponse\tto\trecommendations\tmade\tby\tthe\t\n2014-15\tPresidential\tVisiting\tCommittee’s\t(PVC)\tand\tin\tthe\tFaculty\tstrategic\t\nplanning\tprocess\tof\t2016.\tAdditionally,\tthe\tneed\tfor\tthe\tFaculty\tname\tto\treflect\tthe\t\nfields\tof\tresearch\tand\tstudy\tgiven\trecent\tchanges\tto\texisting\tdegree\tprograms\t\nprovides\ttimeliness\tto\tthe\tproposal.\t\nAfter\ta\tnine-month\titerative\tprocess,\ta\tmajority\tof\tFaculty\tCouncil\tvoted\tto\tsupport\t\nthe\tchange\tthe\tname\tof\tthe\tFaculty\tof\tPhysical\tEducation\tand\tRecreation\tto\tthe\t\nFaculty\tof\tKinesiology,\tSport,\tand\tRecreation.\t\t\nOnce\tapproved\tby\tGFC,\tthe\tFaculty\tof\tKinesiology,\tSport,\tand\tRecreation\twill\t\nbecome:\t\n• One\tof\tthe\tlast\tfaculties\tof\tour\ttype\tin\tCanada\tto\tchange\tits\tname\tfrom\t\nPhysical\tEducation\tto\tKinesiology,\t\n• Remain\tthe\toldest\tfaculty\tin\tCanada\tto\thave\tRecreation\tin\tthe\tname,\tand\t\n• Become\tthe\tfirst\tfaculty\tin\tCanada\tto\thave\tSport\tin\tthe\tname.\t\nThe\tFaculty\tof\tPhysical\tEducation\tand\tRecreation\thas\ta\tstrong\thistory\tand\ttradition.\t\nRecently\tranked\tas\tone\tof\tthe\ttop\tten\tin\tthe\tworld\tfor\tsports-related\tsubjects\tby\tthe\t\nprestigious\tQS\tWorld\tUniversity\tRankings,\tthe\trenaming\tof\tthe\tFaculty\tdescribes\tthe\t\ndiversity\tand\tbreadth\tof\tofferings\twithin\tthe\tfaculty\tand\tpositions\tthe\tfaculty\twell\t\nover\tthe\tcoming\tdecades\tto\tmaintain\tand\textend\tits\tstrong\tnational\tand\t\ninternational\treputation.\t\n2\tAttachment\t1\t/\tPage\t#\t\nIntroduction\t\nThe\tFaculty\tof\tPhysical\tEducation\tand\tRecreation\t(FPER)\thas\ta\tlong\tand\tstoried\t\nhistory\tof\tone\tof\tCanada’s\tleading\tfaculties\tin\tthe\tarea\tof\tphysical\tactivity\tand\t\nexercise,\tsport\tand\trecreation.\tRecently\tranked\tin\tthe\ttop\tten\tprograms\t\ninternationally\tin\tsports-related\tsubjects1,\tFPER\tis\tone\tof\tCanada’s\tfew\tintegrated\t\nfaculties.\tFPER\thouses\ta\tmulti-disciplinary\tacademic\tprogram\tthat\tserves\tover\t1,000\t\nundergraduate\tstudents\tand\tmore\tthan\t150\tgraduate\tstudents.\tIn\taddition,\tthe\t\nFaculty\tis\tthe\thome\tfor\tCampus\t&\tCommunity\tRecreation\t(CCR)\tand\tGolden\tBears\t\nand\tPandas\tAthletics\t(GBPA).\tThese\ttwo\tservice\tarms\tof\tthe\tFaculty\ttouch\tmore\t\nthan\t1.5\tmillion\tusers\tannually\tfrom\tthe\tcampus\tand\tbroader\tcommunity.\t\t\t\nEstablished\tmore\tthan\t70\tyears\tago,\tthe\troots\tof\tthe\tFaculty\tlie\tin\tphysical\teducation\t\nand\tthe\tpreparation\tof\tphysical\teducators.\tOver\tthe\tpast\tseven\tdecades,\tthe\t\nacademic\tbreadth\tof\tthe\tFaculty\thas\tbecome\tmuch,\tmuch\tbroader.\t\tCurrently\tthe\t\nFaculty\thas\tseven\tresearch\tclusters\tand,\timportantly\tfor\tthis\tdiscussion,\tno\tlonger\t\ndirectly\tprepares\tstudents\tto\tbecome\tphysical\teducators.\tThe\tareas\tof\tresearch\t\nfocus\tinclude:\t\n• Adapted\tPhysical\tActivity\t\n• Coaching\tStudies\tand\tSport\tPsychology\t\n• Health\tPsychology\tand\tBehavioural\tMedicine\t\n• Neuroscience\tand\tMovement\t\n• Physiology\t\n• Recreation,\tSport,\tand\tTourism\tand\t\n• Sociocultural\tStudies\t\nThe\tfield\tof\tphysical\teducation\thas\tchanged\tand\tevolved\tover\tthe\tpast\t70\tyears\tand\t\nit\tis\tnow\tpast\ttime\tfor\tthe\tFaculty\tto\trespond\tin\tupdating\tits\tname\tand\tbrand\tto\t\nremain\ta\tleader\tnationally\tand\tinternationally.\tFollowing\tare\tsome\tkey\thistorical\t\nevents\tand\tdates\tthat\tlead\tto\tthe\trequest\tfor\ta\tFaculty\tname\tchange.\t\nEvolution\tof\tthe\tFaculty\t–\tKey\tDates\t\n1945\t The\tDepartment\tof\tPhysical\tEducation\tis\testablished\twithin\tthe\tFaculty\tof\t\nEducation.\tProfessor\tMaury\tVan\tVliet\tbegan\tits\toperation\twith\ta\tprimary\t\nfocus\ton\tintercollegiate\tathletics\tand\tcompulsory\tfirst-\tand\tsecond-year\t\nphysical\teducation\tclasses.\t\t\n1950:\t\tThe\tfour-year\tBachelor\tof\tEducation\tin\tPhysical\tEducation\tdegree\tprogram\t\nbegins\toperation.\t\n1954:\t\tThe\tDepartment\tof\tPhysical\tEducation\tbecomes\tthe\tSchool\tof\tPhysical\t\nEducation\twithin\tthe\tFaculty\tof\tEducation\t\n1\t2017\tQS\trankings\tfor\tsports-related\tsubjects\t(including\tkinesiology):\t\nhttps://www.topuniversities.com/university-rankings-articles/university-subject-\nrankings/top-universities-sports-related-subjects-2017\t\n3\tAttachment\t1\t/\tPage\t#\t\n1958:\t The\tSchool\tof\tPhysical\tEducation\tconvocation\tcolors\tof\troyal\tblue\tand\tgold\t\nwas\testablished\t\n1960:\t First\tMaster’s\tdegree\tprogram\tstarted\tin\tthe\tSchool\tof\tPhysical\tEducation.\t\n1962:\t Four-year\tBachelor\tof\tArts\tin\tRecreation\tLeadership\tinstituted\t\n1964:\t School\tof\tPhysical\tEducation\tchanged\tto\tthe\tFaculty\tof\tPhysical\tEducation\t–\t\nthe\tfirst\tof\tits\tkind\tin\tthe\tCommonwealth.\tDr.\tMaury\tVan\tVliet\tappointed\tfirst\t\ndean\t\n1967:\t PhD\tprogram\tin\tPhysical\tEducation\tbegins\t–\tthe\tfirst\tsuch\tdoctoral\tdegree\tin\t\nthe\tCommonwealth\t\n1976:\t Addition\tof\tthe\tterm\t‘recreation’\tto\tthe\tFaculty\tname,\tto\tbecome\tthe\tFaulty\t\nof\tPhysical\tEducation\tand\tRecreation\t\n1990:\t Combined\tBachelor\tof\tPhysical\tEducation/Bachelor\tof\tEducation\tdegree\t\nprogram\testablished\t\n1996:\t\tPhD\tin\tRecreation\tand\tLeisure\tStudies\testablished\t\n1999:\t\tBachelor\tof\tScience\tin\tKinesiology\t(BSc\tKin)\testablished\t\n2003:\t Faculty\tname\treview\t(no\tchange\tmade)\t\n2008:\t 100th\tAnniversary\tof\tAthletics\t\n2013:\t Master\tof\tCoaching\t(MCoach)\tdegree\testablished\t\n2014:\t Presidential\tVisiting\tCommittee\t(PVC)\trecommends\tthe\tFaculty\tchange\tits\t\nname\tto\tbetter\tserve\tand\tattract\tstudents\t\t\n2015:\t Bachelor\tof\tPhysical\tEducation\t(BPE)\tand\tBachelor\tof\tPhysical\t\nEducation/Bachelor\tof\tEducation\t(BPE/BEd)\tchanged\tto\tBachelor\tof\t\nKinesiology\t(BKin)\tand\tBachelor\tof\tKinesiology/Bachelor\tof\tEducation\t\n(BKin/BEd)\t\n2016:\t Faculty\tStrategic\tPlanning\tprocess\tidentifies\tthe\tneed\tand\ttimeliness\tfor\ta\t\nchange\tof\tFaculty\tname\t\n2016:\t Formal\tFaculty\tname\tchange\tprocess\tinitiated\t\n2017:\t Faculty\tCouncil\tapproves\tnew\tname\t“Faculty\tof\tKinesiology,\tSport,\tand\t\nRecreation”.\t\tThis\tname\tis\tbrought\tforward\tto\tAcademic\tPlanning\t\nCommittee\t(APC)\tand\tGeneral\tFaculties\tCouncil\t(GFC)\tfor\tapproval\t\t\nPrograms\tof\tthe\tFaculty\t\nThe\tFaculty\toffers\tundergraduate\tand\tgraduate\tprograms\tin\tthe\tfollowing\tareas.\tIt\tis\t\nimportant\tto\tnote\tthat\tthe\tFaculty\tno\tlonger\toffers\ta\tphysical\teducation\tdegree\t\n(formerly\tthe\tBPE,\tnow\tBKin).\t\tThe\tchange\tfrom\tBPE\tto\tBKin\tresulted\tin\ta\tlarger-\nthan-anticipated\tspike\tin\tapplications\tto\tthe\talready\tover-subscribed\tBKin\tprogram.\t\nThis\tchange\thas\tbeen\tattributed\tsimply\tto\tthe\tchange\tin\tname\tand\tbroader\tappeal\tto\t\nstudents\tentering\tour\tprogram.\t\n• Bachelor\tof\tArts\tin\tRecreation,\tSport\tand\tTourism\t(BARST)\t\n• Bachelor\tof\tKinesiology\t(BKin)\t\n• Bachelor\tof\tKinesiology/\tBachelor\tof\tEducation\t(BKin/BEd)\t\n• Bachelor\tof\tScience\tin\tKinesiology\t(BSc\tKin)\t\n• Master\tof\tArts\t(MA)\t\n• Master\tof\tScience\t(MSc)\t\n4\tAttachment\t1\t/\tPage\t#\t\n• Master\tof\tCoaching\t(MCoach)\t\n• Doctor\tof\tPhilosophy\t(PhD)\t\nResearch\tand\tConsultation\t\nThe\tprocess\tof\tname\tchange\tincluded\tinternal\tand\texternal\tconsultation\tand\twas\t\nformally\tinitiated\tfollowing\tthe\trecommendation\tfrom\tthe\tPresidential\tVisiting\t\nCommittee\tand\tcompletion\tof\tthe\t2016-2021\tFaculty\tStrategic\tPlan.\tKey\tactivities\t\nand\ttimelines\tare\tpresented\tbelow:\t\nOverview\tof\tFaculty\tRenaming\tProcess\t Timeline\t\nThe\tPresidential\tVisiting\tCommittee\t(PVC)\trecommends\tthat\tthe\tFaculty\tchanges\tits\t\nname,\tnoting\tthat\tthe\tterm\t“Physical\tEducation”\tis\tmisleading\tand\tlimiting.\t\nOctober\t2014\t\nGovernment\tof\tAlberta\tapproves\tthe\trenaming\tof\tthe\tBachelor\tof\tPhysical\tEducation\t\n(BPE)\tand\tBachelor\tof\tPhysical\tEducation/Bachelor\tof\tEducation\t(BPE/BEd)\tto\ta\t\nBachelor\tof\tKinesiology\t(BKin)\tand\tBachelor\tof\tKinesiology/Bachelor\tof\tEducation\t\n(BKin/BEd).\t\nJanuary\t2015\t\nThe\tFaculty\tagrees\tto\timplement\ta\tFaculty-wide\tdiscussion\tregarding\ta\tpotential\t\nchange\tof\tFaculty\tname\tin\tits\tresponse\tto\tthe\tPresidential\tVisiting\tCommittee\t(PVC)\t\nreport\t\nFebruary\t2015\t\nFPER\t2016-21\tStrategic\tPlan\tidentifies\tthe\tneed\tto\tchange\tthe\tFaculty\tname\tto\tbetter\t\ndescribe\tthe\tacademic\tmission\tand\tofferings\tof\tthe\tFaculty\t\t\nMay\t2016\t\nDean\tKerry\tMummery\tmeets\twith\tthe\tProvost\tand\tVice\tPresident\tAcademic\tto\t\ndiscuss\tthe\tFaculty\tname\tchange\tprocess\t\nJune\t2016\t\nDean\tKerry\tMummery\tnotifies\tDean’s\tCouncil\tto\tthe\tbeginning\tof\tthe\tFaculty\tname\t\nchange\tprocess\t\t\nJune\t13,\t2016\t\nComparison\tof\tfaculty/school\tnames\tat\t23\tCanadian\tcompetitor\tuniversities\toffering\t\nsimilar\tacademic\tofferings\tto\tthe\tFaculty\tof\tPhysical\tEducation\tand\tRecreation\t\nJanuary\t2017\t\nReview\tof\tFaculty/School\tnames\tat\t13\tinternational\tuniversities\toffering\tsimilar\t\nacademic\tofferings\tto\tthe\tFaculty\tof\tPhysical\tEducation\tand\tRecreation\t\nJanuary\t2017\t\nReview\tof\tpublished\tresearch\tregarding\tthe\tlanguage\tused\tto\tdescribe\tacademic\t\nofferings\tsimilar\tto\tthose\toffered\tby\tPER\tunder\tthe\tterm\t‘physical\teducation’\t\t\nJanuary\t2017\t\nFPER\tExecutive\tCommittee\tinput\ton\tproposed\trenaming\tconsultation\tprocess\t January\t18,\t2017\t\nFaculty\tManagement\tCouncil\tinput\ton\tproposed\trenaming\tconsultation\tprocess\t January\t19,\t2017\t\nFPER\tAcademic\tPlanning\tCouncil\tinput\ton\tproposed\trenaming\tconsultation\tprocess\t February\t6,\t2017\t\nInterviews\tof\tseven\tFPER\tstaff\tto\tseek\trelevant\tperspectives\tand\tbackground\t\ninformation\tpertaining\tto\tstudent\trecruitment;\tstudent\tplacement;\tstudent\tinput\tre\t\nreplacement\tof\tPhysical\tEducation\twith\tKinesiology\tin\tFaculty\tdegree\tnames\tin\t\n2015;\tmarketing\tand\tcommunications,\tetc.\t\t\nFebruary/March\t2017\t\nReview\tof\tlanguage\tused\tby\t12\tkinesiology\torganizations/associations\tand\tcolleges\t\nacross\tCanada\tto\tdescribe\tthe\troles,\tcareers\tand\tscope\tof\tpractice\tfor\tthose\t\ngraduating\twith\t‘kinesiology’\tdegrees\t\nFebruary\t2017\t\nThree\tTown\tHall\tMeetings\t-\tone\teach\twith\tStudents,\tUndergraduate\tStudents,\tand\t\nFaculty\tand\tStaff\t\nFebruary/March\t2017\t\nInterviews\tof\tPERCS,\tPERGSS\tand\tPERAA\tpresidents\t March/April\t2017\t\nSurvey\tof\tUndergraduate\tand\tGraduate\tStudents\tre\tpossible\tnames\t March\t29-April\t2017\t\nSurvey\tof\tFaculty\tAlumni\tre\tpossible\tnames\t March\t29-April\t2017\t\nInterviews\tof\tcommunity\tpartners:\tCEO,\tAlberta\tSport\tConnection;\tDirector,\t\nRecreation\t&\tPhysical\tActivity\tDivision,\tAlberta\tCulture\tand\tTourism;\tand,\tCEO,\t\nAlberta\tRecreation\tand\tParks\tAssociation\t\nApril\t2017\t\nAnalysis\tby\tUniversity\tDigital\tCommunications\tof\thow\tU\tof\tA\tcompares\twith\teight\t April\t2017\t\n5\tAttachment\t1\t/\tPage\t#\t\ncompetitor\tuniversities\twhen\tkey\tterms\trelated\tto\tPER’s\tacademic\tofferings\tare\t\nsearched\t\nReview\tof\tthe\tnames\tof\tresearch\tjournals\tpublishing\tFaculty\twork\t April\t2017\t\nFaculty\tRenaming\tBackgrounder\tsummarizing\tinput\treceived\tdistributed\tto\tFaculty\t\nCouncil\tmembers\tin\tadvance\tof\tFaculty\tCouncil\tvote\t\nMay\t2017\t\nFPER\tAcademic\tPlanning\tCommittee\t(APC)\tdiscussion\tand\tapproval\tto\tproceed\twith\t\ndecision-making\tprocess\tand\tname\toptions\t\nMay\t4,\t2017\t\nFaculty\tCouncil\tExecutive\tCommittee\t(FEXC)\tdiscussion\tand\tapproval\tto\tproceed\t\nwith\tdecision-making\tand\tname\toptions\t\nMay\t17,\t2017\t\nFaculty\tManagement\tGroup\t(FMG)\tdiscussion\tand\tapproval\tto\tproceed\twith\t\ndecision-making\tprocess\tand\tname\toptions\t\nMay\t18,\t2017\t\nDean\temails\tall\tUofA\tDeans\twith\tthe\ttwo\tpotential\tnames\t(Faculty\tof\tKinesiology\tand\t\nRecreation;\tFaculty\tof\tKinesiology,\tSport,\tand\tRecreation)\tto\tconfirm\tno\tconcerns\tor\t\nconflicts\twith\tthe\tproposed\tnames\t\nMay\t18,\t2017\t\nFPER\tFaculty\tCouncil\tMeeting\tto\treview\tcase\tfor\tname\tchange\tand\tname\tchange\t\noptions\tdeveloped\tbased\ton\tinput\treceived\tthroughout\tprocess\t\nMay\t24,\t2017\t\nFaculty\tCouncil\tElectronic\tVoting\tPeriod\t May\t24-31,\t2017\t\nFaculty\tCouncil\tvote\tresults\tshared\twith\tFPER\tFaculty,\tstaff,\tPERCS,\tPERGSS\tand\t\nPERRA\t(85/100\tvoting\tmembers\tvoted,\twith\t62/85\tor\t73%\tchoosing\tthe\tname\t\nKinesiology,\tSport,\tand\tRecreation)\t\t\nMay\t31,\t2017\t\nDean\tKerry\tMummery\tpresents\tthe\tnew\trecommended\tFaculty\tname\tto\tDeans\tand\t\nDirectors\tof\tsimilar\tprograms\tat\tthe\tCanadian\tCouncil\tof\tUniversity\tPhysical\t\nEducation\tand\tKinesiology\tAdministrators\t(CCUPEKA)\tAnnual\tMeeting\tin\tBanff\t\nAlberta\tand\tseeks\tformal\tletters\tof\tsupport\t\nJune\t28,\t2017\t\nDean\tKerry\tMummery\tpresents\tthe\tnew\trecommended\tname\tof\tthe\tFaculty\tto\tthe\t\nUniversity\tof\tAlberta\tFaculty\tDeans\tand\tseeks\tindications\tof\tsupport\tfor\tthe\t\npreferred\tname\t\nJuly\t14,\t2017\t\nDean\tKerry\tMummery\tpresents\tthe\tnew\trecommended\tname\tof\tthe\tFaculty\tto\tDr.\t\nJurgen\tBeckman,\tChair\tof\tthe\tPresidential\tVisiting\tCommittee\t(PVC)\tfor\tendorsement\t\nJuly\t25,\t2017\t\nDean\tKerry\tMummery\tseeks\tletters\tof\tsupport\tfor\tnew\trecommended\tFaculty\tname\t\nfrom\tcommunity\tstakeholders\tand\tinternational\tpartner\tuniversities\t\nJuly\t2017\t\nProposed\tName\t\nAfter\tformal\tinternal\tand\texternal\tconsultation\tand\tresearch,\tthe\tAcademic\tPlanning\t\nCommittee\t(APC),\tFaculty\tManagement\tGroup\t(FMG)\tand\tFaculty\tCouncil\tExecutive\t\nCommittee\t(FEXC)\teach\tagreed\tto\tbring\tforward\ttwo\t(2)\tnames\tto\tFaculty\tCouncil\t\nfor\tconsideration.\tThe\ttwo\tproposed\tnames\twere:\t\n• Faculty\tof\tKinesiology\tand\tRecreation\t\n• Faculty\tof\tKinesiology,\tSport,\tand\tRecreation\t\nThe\tOxford\tComma\t\nIt\tshould\tbe\tnoted\tthat\tthe\tinclusion\tof\tthe\tcomma\tfollowing\tSport\tin\tthe\tFaculty\tof\t\nKinesiology,\tSport,\tand\tRecreation\tdid\tnot\tcome\twithout\tmuch\tthought\tand\tdebate\t\nat\tFaculty\tCouncil.\tUse\tof\tthe\t‘Oxford\tComma’\tdenotes\tthat\tSport\tand\tRecreation\tare\t\nseparate\tacademic\tdisciplines\tand\tshould\tthus\tbe\tdenoted\tas\tsuch\tin\tthe\tname\t\nKinesiology,\tSport,\tand\tRecreation\tas\topposed\tto\tKinesiology,\tSport\tand\tRecreation.\t\n6\tAttachment\t1\t/\tPage\t#\t\nThe\timportance\tof\tthe\tuse\tof\tthe\tOxford\tComma\twas\thighlighted\tin\ta\twidely\t\npublicized\tcourt\tcase\tthat\tcoincided\ttime-wise\twith\tthe\tFaculty\tdebate2.\t\nFaculty\tCouncil\tFaculty\tName\tChange\tMotions\t\nAt\tthe\tFaculty\tof\tPhysical\tEducation\tand\tRecreation\tFaculty\tCouncil\ton\tMay\t24,\t\n2017,\tthe\tfollowing\tmotions\twere\tmade\tand\tcarried\twith\tquorum\tpresent.\t\nMotion\t7.1:\t\t Be\tit\tmoved\tthat\tthe\tvote\ton\tthe\tFaculty\tname\tbe\tconducted\tby\t\nelectronic\tballot\tsent\tto\tall\tvoting\tmembers\tof\tFaculty\tCouncil\t\n(N=100).\tThe\telectronic\tballot\tshall\topen\tat\t12:00\tnoon\ton\t\nWednesday\tMay\t24th,\t2017\tand\tclose\tat\t11:59\tam\ton\tWednesday\tMay\t\n31st,\t2017.\tThe\tpreferred\tname\tfor\tthe\tFaculty\twill\trequire\ta\tmajority\t\nvote\tof\tquorum.\tFor\tthe\telectronic\tvote,\tquorum\twill\trequire\tvoting\t\nresponse\tfrom\ta\tminimum\tof\tforty\tpercent\t(40%)\tof\tvoting\tmembers\t\nof\tFaculty\tCouncil.\tFor\tthis\tpurpose\tan\tabstaining\tvote\twill\tcount\t\ntowards\tquorum,\twhereas\tno\tvoting\tresponse\twill\tnot.\t\t\nResult:\tCarried\t\nMotion\t7.2:\t\t Be\tit\tmoved\tthat\tthe\twording\ton\tthe\telectronic\tballot\tbe\tas\tfollows:\t\n“The\tFaculty\tof\tPhysical\tEducation\tand\tRecreation\thas\tgone\tthrough\tan\t\nextensive\tprocess\tin\tconsideration\tof\ta\tnew\tFaculty\tname.\tFollowing\t\napproval\tfrom\tthe\tAcademic\tPlanning\tCommittee\t(APC),\tFaculty\t\nManagement\tGroup\t(FMG)\tand\tFaculty\tExecutive\tCommittee\t(FEXC)\tthe\t\nfollowing\ttwo\t(2)\tnames\tare\tpresented.\tPlease\tindicate\tyour\tpreferred\t\nname\tfor\tthe\tFaculty\tfrom\tthe\tfollowing\tchoices.\tShould\tyou\tnot\twish\tto\t\nsupport\teither\tof\tthe\tnames\tbelow,\tplease\tindicate\tyour\tabstention.\t\t\na)\tFaculty\tof\tKinesiology\tand\tRecreation\t\t\nb)\tFaculty\tof\tKinesiology,\tSport\tand\tRecreation\t\t\nc)\tAbstain.”\t\t\nResult:\tCarried\t\nElectronic\tVote\t\nAs\tper\tMotion\t7.1\tendorsed\tby\tFaculty\tCouncil\ton\tMay\t24,\t2017\tthe\telectronic\tvote\t\nopened\tat\t12\tnoon\ton\tWednesday\tMay\t24th,\t2017\tand\tclosed\tat\t11:59\tam\ton\t\nWednesday\tMay\t31st,\t2017.\tThere\twere\ta\ttotal\tof\t85\tvoting\tresponses\treceived\t\nfrom\tthe\t100\teligible\tmembers\tof\tfaculty\tCouncil.\tThe\tresults\tof\tthe\tvote\twere\tas\t\nfollows:\t\n• Choice:\tAbstain\t=\t5\t\n• Choice:\tFaculty\tof\tKinesiology,\tSport,\tand\tRecreation\t=\t62\t\n2\thttps://www.nytimes.com/2017/03/16/us/oxford-comma-lawsuit.html\t\n7\tAttachment\t1\t/\tPage\t#\t\n• Choice:\tFaculty\tof\tKinesiology\tand\tRecreation\t=\t18\t\n• No\tvoting\tresponse\t=\t15\t\nHaving\tachieved\tquorum,\tthe\tpreferred\tname\tof\tthe\tFaculty\tas\tsupported\tby\tthe\t\nmajority\tof\tFaculty\tCouncil\twas\tthe\tFaculty\tof\tPhysical\tEducation,\tSport,\tand\t\nRecreation.\t\nKinesiology\tin\tthe\tproposed\tnew\tname\t\n• Kinesiology\tis\tthe\tstudy\tof\thuman\tmovement\tand\tis\tthe\tterm\tthat\thas,\tfor\t\nmore\tthan\ta\tquarter\tof\ta\tcentury,\tbeen\tpromoted\tas\tthe\tlabel\tfor\tthe\tstudy\tof\t\nphysical\tactivity\tin\thigher\teducation3.\t\n• Kinesiology\thas\tgrown\tto\tbe\tthe\taccepted\tdomain\tname\tfor\tthe\tmulti-\ndisciplinary\tstudy\tof\thuman\tmovement\tin\thigher\teducation.\t\n• Kinesiology\thas\treplaced\tthe\tterm\tphysical\teducation\tin\tmany\tdegree\ttitles,\t\nfields\tof\tstudy,\tdepartment\tand\tfaculty\tnames\tover\tthe\tpast\tquarter\tcentury.\t\n• Kinesiology\tis\tviewed\tas\tbetter\tdefining\tthe\tcurrent\tbroad\tmulti-\tand\tinter-\ndisciplinary\tfields\tof\tstudy\tin\tour\tarea,\tthan\tthe\tterm\tphysical\teducation,\t\nwhich\thas\tbeen\tviewed\tas\trestrictive,\tevoking\ta\tvocational,\tteaching-training\t\neducational\tfocus.\t\t\nSport\tin\tthe\tproposed\tnew\tname\t\n• Sport\treflects\tboth\tthe\tacademic\tand\tservice\tofferings\tof\tthe\tFaculty.\t\t\n• Academically,\tthe\tFaculty\toffers\tand\tundergraduate\tdegree\twith\ta\tfocus\ton\t\nsport\t(Bachelor\tof\tArts\tin\tRecreation,\tSport\tand\tTourism,\tBARST).\t\nAdditionally,\tthe\tFaculty\toffers\tan\tundergraduate\tmajor\tis\tSport\tPerformance\t\nand\tSport\tCoaching,\tas\twell\tas\tCanada’s\tfirst\tdedicated\tMaster’s\tdegree\tis\t\nsport\tcoaching\t(Master\tof\tCoaching,\tMCoach).\t\t\n• The\tservice\tarms\tof\tthe\tFaculty\tdeliver\tand\tsupport\toutstanding\tsport\t\nprograms\tand\tservices.\t\t\n• Campus\t&\tCommunity\tRecreation\t(CCR)\tsupports\tmore\tthan\t2000\tstudent\t\nathletes\twho\tparticipate\tin\tone\t(or\tmore)\tof\tthe\t21\tcompetitive\tand\t\nrecreational\tClub\tSport\tprograms\toperated\twithin\tthe\tFaculty.\tCCR\talso\t\noversees\tmore\tthan\t400,000\tsquare\tfeet\tof\tsport\tand\trecreation\tfacilities,\t\nincluding\tthe\tClare\tDrake\tArena,\tThe\tVan\tVliet\tComplex\ton\tthe\tnorth\tcampus\t\nand\tFoote\tField\tand\tthe\tSaville\tCommunity\tSports\tCentre\ton\tour\tSouth\t\nCampus.\t\t\n• Golden\tBears\tand\tPandas\tAthletics\thave\ta\tstrong\thistory\tof\tintercollegiate\t\nsporting\texcellence.\tThe\tteams\tare\tthird\tin\tCanada\tfor\tthe\tmost\tnumber\t\nnational\tchampionships\twith\tmore\tthan\t75\tnational\tchampionship\tteam\t\ntitles,\tand\tleads\tthe\tcountry\twith\tmore\tthan\t2500\tAcademic\tAll-Canadians.\t\n3\tNewell,\tK.M.\t(1990).\tKinesiology:\tThe\tlabel\tfor\tthe\tstudy\tof\tphysical\tactivity\tin\t\nhigher\teducation.\tQuest.\t42,\t269-278.\t\n8\tAttachment\t1\t/\tPage\t#\t\n• Sport\tin\tthe\ttitle\toffers\tthe\tFaculty\ta\tnotable\tpoint\tof\tdifferentiation\t\nnationally.\tCurrently\tthere\tare\tno\tFaculties\twith\tsport\tin\ttheir\tname\tin\t\nCanada,\talthough\tthe\tterm\tsport\tfeatures\tin\tthe\tnames\tof\tmany\tof\t\ninternational\tinstitutions\twith\twhich\twe\twork,\tincluding:\t\n• Norwegian\tSchool\tof\tSports\tScience\t\n• Beijing\tSport\tUniversity\t\n• Shanghai\tSport\tUniversity\t\n• Wuhan\tSports\tUniversity\t\n• German\tSports\tUniversity\t\nRecreation\tin\tthe\tproposed\tnew\tname\t\n• The\tterm\tRecreation\thas\tbeen\tin\tthe\tFaculty\tname\tsince\t1976\t\n• Launched\tin\t1962,\tthe\tBachelor\tof\tArts\tin\tRecreation,\tSport\tand\tTourism,\tand\t\nits\tpredecessors\tis\tthe\tlongest\tcontinuously\trunning\trecreation\tprogram\tin\ta\t\nCanadian\tuniversity.\t\n• The\tFaculty\toffers\tan\tundergraduate\tdegree\tin\tRecreation\t(BARST)\tand\ta\t\nMaster\tof\tArts\tin\tRecreation\tand\tLeisure\tStudies.\t\n• The\tFaculty\tis\ta\tproud\tpartner\tin\tthe\tAlberta\tRecreation\tTripartite,\twith\tthe\t\nAlberta\tRecreation\tand\tParks\tAssociation\t(ARPA)\tand\tthe\tAlberta\tMinistry\tof\t\nCulture\tand\tTourism.\t\n• Campus\t&\tCommunity\tRecreation\toffers\tan\textensive\trange\tof\trecreational\t\nservices\tto\tthe\tuniversity\tand\twider\tcommunity.\t\t\nConclusion\t\nThe\tFaculty\tof\tPhysical\tEducation\tand\tRecreation,\tonly\tfor\tthe\tsecond\ttime\tin\tits\t\nhistory,\tis\tapplying\tto\tformally\tchange\tits\tname.\tAs\tthe\tFaculty\tof\tKinesiology,\t\nSport,\tand\tRecreation\twe\twill\tbe\tbetter\tpositioned\tto\tpromote,\tattract\tand\tservice\t\nour\tfaculty,\tstaff\tand\tstudents\ton\ta\tprovincial,\tnational\tand\tinternational\tscale.\t\nAppendices\t\n• Faculty\tName\tChange\tBackgrounder\t\n• University\tof\tAlberta\tfaculties\tsupport\tletters\t\n• Community\tpartner\tsupport\tletters\t\n• Canadian\tCouncil\tof\tUniversity\tPhysical\tEducation\tand\tKinesiology\tpartner\t\nsupport\tletters\t\n• International\tpartner\tsupport\tletters\t\n• Presidential\tVisiting\tCommittee\tsupport\tletter\t\nLetters/Emails\tof\tSupport\tfor\tFaculty\tName\tChange\nFaculty\tName\tChange\t-\t\tUniversity\tof\tAlberta\tDeans Dean(s)\tInfo Notes\nAgriculture,\tLife\tand\tEnvironmental\tSciences Stan\tBlade Email\tSupport\nAlberta\tSchool\tof\tBusiness Joseph\tDoucet Letter\tSupport\nArts Lesley\tCormack Email\tSupport\nAugustana\tCampus Allan\tBerger Email\tSupport\nCampus\tSaint-Jean Pierre-Yves\tMocquais Letter\tSupport\nEducation Jennifer\tTupper Email\tSupport\nEngineering Fraser\tForbes Email\tSupport\nExtension Katy\tCampbell Letter\tSupport\nGraduate\tStudies\tand\tResearch Heather\tZwicker Email\tSupport\nMedicine\t&\tDentistry Richard\tFedorak Email\tSupport\nNative\tStudies Chris\tAndersen Letter\tSupport\nNursing Greta\tCummings Letter\tSupport\nPharmacy\tand\tPharmaceutical\tSciences Neal\tDavies Letter\tSupport\nRehabilitation\tMedicine Robert\tHaennel Email\tSupport\nSchool\tof\tPublic\tHealth Kue\tYoung Email\tSupport\nScience Jonathan\tSchaeffer Email\tSupport\nFaculty\tName\tChange\t-\tCCUPEKA\tDeans\t\t Dean(s)\tInfo Notes\nBritish\tCoumbia Robert\tBoushel Letter\tSupport\nBrock Brian\tRoy Letter\tSupport\nCalgary Penny\tWerthner Letter\tSupport\nDalhousie Laurene\tRehman Letter\tSupport\nLethbridge Jon\tDoan Letter\tSupport\nManitoba Douglas\tBrown Email\tSupport\nMount\tRoyal Stephen\tPrice Letter\tSupport\nNew\tBrunswick Wayne\tAlbert Letter\tSupport\nOttawa Benoit\tSequin Email\tSupport\nQueens Jean\tCote Email\tSupport\nSaskatchewan Chad\tLondon Letter\tSupport\nRegina Harold\tReimer Letter\tSupport\nToronto Ira\tJacobs Letter\tSupport\nWestern\tOntario Laura\tMisener Letter\tSupport\nYork Angelo\tBelcastro Letter\tSupport\nFaculty\tName\tChange\t-\tCommunity\tStakeholders Contact\tInfo Notes\nAlberta\tRecreation\tand\tParks\tAssociation\t Susan\tLaurin Letter\tSupport\nAlberta\tSport\tConnection Lloyd\tBentz Letter\tSupport\nFaculty\tName\tChange\t-\tInternational\tPartners Contact\tInfo Notes\nNorwegian\tSchool\tof\tSport\tSciences Lars\tTore\tRonglan Letter\tSupport\nOtago Douglas\tBooth Email\tSupport\nFaculty\tName\tChange\t-\tPresidents'\tVisiting\tCommittee\t(PVC) Contact\tInfo Notes\nChair,\tPresidents'\tVisiting\tCommittee Jurgen\tBeckman Letter\tSupport\nAttachment 2 / Page #1\nAttachment 2 / Page #2\nAttachment 2 / Page #3\nAttachment 2 / Page #4\nAttachment 2 / Page #5\nAttachment 2 / Page #6\nAttachment 2 / Page #7\nAttachment 2 / Page #8\nAttachment 2 / Page #9\nAttachment 2 / Page #10\nAttachment 2 / Page #11\nAttachment 2 / Page #12\nAttachment 2 / Page #13\nAttachment 2 / Page #14\nAttachment 2 / Page #15\nAttachment 2 / Page #16\nAttachment 2 / Page #17\nAttachment 2 / Page #18\nAttachment 2 / Page #19\nAttachment 2 / Page #20\nAttachment 2 / Page #21\nAttachment 2 / Page #22\nAttachment 2 / Page #23\nAttachment 2 / Page #24\nAttachment 2 / Page #25\nAttachment 2 / Page #26\nAttachment 2 / Page #27\nAttachment 2 / Page #28\nAttachment 2 / Page #29\nAttachment 2 / Page #30\nAttachment 2 / Page #31\nAttachment 2 / Page #32\nAttachment 2 / Page #33\nAttachment 2 / Page #34\nAttachment 2 / Page #35\nAttachment 2 / Page #36\nAttachment 2 / Page #37\nAttachment 2 / Page #38\nAttachment 2 / Page #39\nAttachment 2 / Page #40\nAttachment 2 / Page #41\nAttachment 2 / Page #42\nAttachment 2 / Page #43\nAttachment 2 / Page #44\nAttachment 2 / Page #45\nAttachment 2 / Page #46\nAttachment 2 / Page #47\nAttachment 2 / Page #48\nAttachment 2 / Page #49\nAttachment 2 / Page #50\nAttachment 2 / Page #51\nAttachment 2 / Page #52\nAttachment 2 / Page #53\n8/29/2017 University of Alberta Mail - RE: RESPONSE REQUESTED for: Faculty Name Change - Response Requested\nhttps://mail.google.com/mail/u/0/?ui=2&ik=6d333bea76&jsver=NQ90xUauj60.en.&view=pt&search=inbox&th=15e2f8fdf9a28b39&siml=15e2f8fdf9a28b39 1/4\nKeri Blue <kblue@ualberta.ca>\nRE: RESPONSE REQUESTED for: Faculty Name Change ­ Response Requested \n1 message\nDoug Booth <doug.booth@otago.ac.nz> Tue, Aug 29, 2017 at 1:55 PM\nTo: Keri Blue <keri.blue@ualberta.ca>\nDear Kerry\nThe School of Physical Education, Sport and Exercise Sciences at the University of\nOtago (New Zealand) is happy to endorse the change of name from the Faculty of\nPhysical Education and Recreation to the Faculty of Kinesiology, Sport, and\nRecreation at the University of Alberta.\nFaculty at Otago acknowledge that the new name has the support of the faculty at\nAlberta and that the name is in keeping with recent trends in the field.\nYours sincerely\nDoug\nProfessor Douglas Booth\nDean, School of Physical Education, Sport and Exercise Sciences\nUniversity of Otago\nPO Box 56\nDunedin, 9016, New Zealand\nSTREET ADDRESS Room 102, 46 Union Street West, Dunedin\nTEL 64 3 479 8995\nFAX 64 3 479 5433\nAttachment 2 / Page #54\n8/29/2017 University of Alberta Mail - RE: RESPONSE REQUESTED for: Faculty Name Change - Response Requested\nhttps://mail.google.com/mail/u/0/?ui=2&ik=6d333bea76&jsver=NQ90xUauj60.en.&view=pt&search=inbox&th=15e2f8fdf9a28b39&siml=15e2f8fdf9a28b39 2/4\nWEB http://www.otago.ac.nz/sopeses/staff/academic/douglas_booth.html\nGOOGLE SCHOLAR https://scholar.google.co.nz/citations?hl=en&user=jo1d_\nksAAAAJ&view_op=list_works\nFrom: Keri Blue [mailto:keri.blue@ualberta.ca]  \nSent: Wednesday, 30 August 2017 2:44 a.m. \nTo: Michelle Alexander <michelle.alexander@otago.ac.nz>; Doug Booth <doug.booth@otago.ac.nz> \nSubject: RESPONSE REQUESTED for: Faculty Name Change ‐ Response Requested\nGood Morning,\nMy name is Keri Blue and I am the assistant to Dean Kerry Mummery here at the University of Alberta in Edmonton.\nWe are hoping you can support us with our request below.\nThanks for your time and attention.\nSincerely, Keri Blue\n­­ \nKeri Blue | Executive Assistant to the Dean | \nFaculty of Physical Education & Recreation | University of Alberta\n3­106 University Hall | Edmonton, Alberta.  T6G 2J9\nPhone:  780.492.3364 | Keri.Blue@ualberta.ca \nFaculty of Physical Education & Recreation |http://www.physedandrec.ualberta.ca/\n­­­­­­­­­­ Forwarded message ­­­­­­­­­­ \nFrom: Kerry Mummery <kerry.mummery@ualberta.ca> \nDate: Fri, Aug 18, 2017 at 9:40 AM \nSubject: Faculty Name Change ­ Response Requested \nTo: doug.booth@otago.ac.nz \nCc: Keri Blue <Keri.Blue@ualberta.ca> \nDear Douglas Booth,\nI am writing to seek your support for the proposed change of name for the Faculty of Physical Education and Recreation.\nAttachment 2 / Page #55\nhttp://www.otago.ac.nz/sopeses/staff/academic/douglas_booth.html\nhttps://scholar.google.co.nz/citations?hl=en&user=jo1d_ksAAAAJ&view_op=list_works\nmailto:keri.blue@ualberta.ca\nmailto:michelle.alexander@otago.ac.nz\nmailto:doug.booth@otago.ac.nz\ntel:(780)%20492-3364\nmailto:Keri.Blue@ualberta.ca\nhttp://www.physedandrec.ualberta.ca/\nmailto:kerry.mummery@ualberta.ca\nmailto:doug.booth@otago.ac.nz\nmailto:Keri.Blue@ualberta.ca\n8/29/2017 University of Alberta Mail - RE: RESPONSE REQUESTED for: Faculty Name Change - Response Requested\nhttps://mail.google.com/mail/u/0/?ui=2&ik=6d333bea76&jsver=NQ90xUauj60.en.&view=pt&search=inbox&th=15e2f8fdf9a28b39&siml=15e2f8fdf9a28b39 3/4\nFor the first time in over 40 years, the Faculty is undertaking a change of name. First established in 1964 as the Faculty of\nPhysical Education, the Faculty is one of the oldest and most prestigious faculties of its type in the country. In 1976 the\nFaculty added Recreation to the name, to reflect our undergraduate degree in recreation, Canada’s longest running\ndegree in this area, which has been offered for more than 50 years. In 2015, the Faculty changed our Bachelor of\nPhysical Education (BPE) degree to a Bachelor of Kinesiology, which precipitated to the process of name change for the\nFaculty.  Currently we offer the following degrees within the Faculty:\n·  Bachelor of Arts in Recreation, Sport and Tourism (BARST)\n·  Bachelor of Kinesiology (BKin)\n·  Bachelor of Science in Kinesiology (BSc Kin)\n·  Master of Arts (MA)\n·  Master of Science (MSc)\n·  Master of Coaching (MCoach)\n·  Doctor of Philosophy (PhD)\nAfter a year­long process of engaging faculty, staff, students, alumni, and stakeholders a vote was held at Faculty Council\nthis May, which supported the name “ Faculty of Kinesiology, Sport, and Recreation.” This name and supporting\ndocumentation – including your letter of support – will go forward for approval by the University’s Governance structure.\nIf successfully supported by University Governance, our Faculty will become one of the last faculties of our type in the\ncountry to transition from Physical Education to Kinesiology; the longest running faculty in the country with Recreation in\nits name; and the first faculty in Canada to include Sport in its name.\nAs part of the name change process we are required to get letters of support from relevant stakeholders. I ask that you\nprovide notice of support, or lack thereof, to me by return email. This note could be as long, or as brief as you wish, but I\nwould be most appreciative that is show a clear indication of support for the name change from you, our valued partner.  If\nyou have any questions or concerns feel free to contact me at your convenience.\nRegards,\nW. Kerry Mummery, PhD, FASMF\nProfessor and Dean\nFaculty of Physical Education and Recreation\nUniversity of Alberta\nEdmonton, Alberta\nCANADA\nT6G 2H9\nTel: +1 780­492­3364\nAttachment 2 / Page #56\ntel:(780)%20492-3364\n8/29/2017 University of Alberta Mail - RE: RESPONSE REQUESTED for: Faculty Name Change - Response Requested\nhttps://mail.google.com/mail/u/0/?ui=2&ik=6d333bea76&jsver=NQ90xUauj60.en.&view=pt&search=inbox&th=15e2f8fdf9a28b39&siml=15e2f8fdf9a28b39 4/4\nLearn more about our Faculty in my Dean's message: \nhttps://www.youtube.com/watch?v=xC8uzDq_DOQ\nAttachment 2 / Page #57\nhttps://www.youtube.com/watch?v=xC8uzDq_DOQ\nTechnical University of \nMünchen \nProf. Dr. Dr. \nJürgen Beckmann \nUptown München \nCampus D \nGeorg-Brauchle-Ring 60-62 \n80992 München  \nGermany \nfon  +49.89.289.24541 \nfax +49.89.289.24555 \njuergen.beckmann@tum.de \nwww.sportpsychologie.sg.tum.de \nDepartment of  \nSport and Health Sciences \nChair of Sport Psychology \nTechnical University of Munich \nFakultät für Sport- und Gesundheitswissenschaft    Georg-Brauchle-Ring 60-62     80992 München    \nName change of the \nFaculty of Faculty of Physical Education and Recreation \nIn its 2014 report the President’s Visiting Committee (PVC) stated that the \nfaculty’s “Physical Education and Recreation” was misleading as the major \ngoal of the Faculty does not lie in the education of PE teachers. Clearly, the \nFaculty’s name is a historic name associated with much success. However, \nthe PVC considered the name as unsuited for increased international \nvisibility and attracting international students. Therefore, the PVC \nrecommended changing the Faculty Name.  \nAs the PVC learned the Faculty entered a process to review and rename the \nFaculty. As a result of this process a change of name to “ Faculty of \nKinesiology, Sport, and Recreation” was suggested by the Faculty Council. \nThe (PVC) is convinced that this name change is in line with the development \nof the Faculty and will contribute to an advancement in recruitment, branding, \nand internationalization. Therefore, the PVC very much supports the \nproposed change of name for the Faculty of Physical Education and \nRecreation at the University of Alberta. \nMunich, August 1, 2017 \nJürgen Beckmann \nChair of the President’s Visiting Committee \nPresident of the University of Alberta \nDr. David H. Turpin \nAttachment 2 / Page #58\n Item No. 11 \nGFC EXECUTIVE COMMITTEE \nFor the Meeting of September 11, 2017 \nOUTLINE OF ISSUE \nAction Item \nAgenda Title: Increase to Required English Language Proficiency (ELP) Scores for Undergraduate \nAdmissions \nMOTION:  THAT General Faculties Council approve: \n- the minimum overall TOEFL score be increased 4 points to 90, with no change to the required score of \n21 on each band.  \n- the minimum band score for the IELTS Academic be increased from 5.0 to 5.5, with no change to the \nrequired minimum overall score of 6.5 \nas recommended by the GFC Academic Planning Committee, as set forth in Attachment 4, to take effect fall \n2018. \nItem   \nAction Requested Approval Recommendation   \nProposed by Lisa Collins, Vice Provost and University Registrar \nPresenter Lisa Collins, Vice Provost and University Registrar \nMelissa Padfield, Deputy Registrar \nDetails \nResponsibility Provost and Vice-President (Academic) \nThe Purpose of the Proposal is \n(please be specific) \nTo make changes to the minimum overall TOEFL score and the \nminimum band score for the IELTS Academic to better support student \nsuccess and increase the likelihood of improved academic outcomes. \nThe proposed changes are supported by research undertaken by the \nOffice of the Registrar. \nThe Impact of the Proposal is It is anticipated that the proposed changes will have a positive impact on \nstudent success within the international student body. Research \nconducted by the Enrolment Management unit in the Office of the \nRegistrar shows the correlation between a higher overall ELP score and \nstudent success in first year courses, as indicated by final GPA and/or \ncourse withdrawals.  \nAs a result of the proposed changes, an increased number of applicants \nmight enter their chosen faculty/program through the Bridging program. \nThe number of International applications may decrease which may lead \nto a reduction in the number of students admitted. There may also be a \npositive reputational impact associated with more rigorous ELP \nrequirements. \nReplaces/Revises (eg, policies, \nresolutions) \nCalendar section “Language Proficiency Requirements” \nTimeline/Implementation Date Fall 2018 \nEstimated Cost and funding \nsource \nNone \nNext Steps (ie.: \nCommunications Plan, \nImplementation plans) \nPublish in 2018/2019 calendar \nPromote to students through recruitment channels  \nBear Track messaging on requirements \nApplications and admissions of International students will be monitored \nover a three year period. \nSupplementary Notes and \ncontext \nOn November 19, 2015, the Chair reported on the establishment of a \ngroup to look at English language proficiency and ASC had a brief \ndiscussion on current band scores and the difference in requirements for \n Item No. 11 \nGFC EXECUTIVE COMMITTEE \nFor the Meeting of September 11, 2017 \ngraduate and undergraduate programs. \nEngagement and Routing (Include meeting dates) \nParticipation: \n(parties who have seen the \nproposal and in what capacity) \n<For further information see \nthe link posted on \nthe Governance Toolkit section \nStudent Participation Protocol> \nThose who have been informed: \n•  \nThose who have been consulted: \n• University of Alberta International (John Soltice, Cen Huang) \n(May-June 2016) \n• Faculty of Extension, English Language School (Donald Mason, \nGreg Sowak, Mimi Hui, Michael Viola, Martin Guardado) Monday, \nJuly 11th, 2016 \n• Academic Standards Committee June 2016 \n• Faculty of Arts Executive Committee \n• Faculty of Arts Chairs’ Council \n• International and undergraduate advisors in the Faculty of Arts \n• Stuart Landon \n• Advisory Committee on Enrolment Management (May, June \n2016) \nThose who are actively participating: \nELP Working Group \nTuesday, December 15th, 2015 \nFriday, May 27th, 2016 \nMembers \nBrenda Leskiw (Science) \nJim Bohun (ALES) \nMelissa Casey (RO) \nNat Kav (Vice Provost’s office) \nElizabeth Taylor (Rehabilitation Medicine) \nSam Stowe (RO) December 2015 meeting only \nRebecca Nagel (Arts) \nYidi Liu (SU) May 2016 meeting only \nMarina Banister (SU) May 2016 meeting only \nFahim Rahman (SU) December 2015 meeting only \nSuzanne French (Provost’s office) \nApproval Route (Governance) \n(including meeting dates) \nASC Subcommittee on Standards  – May 4, 2017 \nGFC Academic Standards Committee – May 18, 2017 \nGFC Academic Planning Committee – September 13, 2017 \nGFC Executive Committee (for information) – September 11, 2017 \nGeneral Faculties Council – September 25, 2017 \nFinal Approver General Faculties Council  \nAlignment/Compliance \nAlignment with Guiding \nDocuments \nAlignment with the Institutional Strategic Plan – For the Public Good \nOBJECTIVE - Build a diverse, inclusive community of exceptional \nundergraduate and graduate students from Edmonton, Alberta, Canada, \nand the world. \nStrategy: Optimize our international recruiting strategies to attract well-\nqualified international students from regions of strategic importance, and \nenhance services and programs to ensure their academic success and \nhttp://www.governance.ualberta.ca/GovernanceToolkit/Toolkit.aspx\nhttp://www.governance.ualberta.ca/GovernanceToolkit/Toolkit.aspx\n Item No. 11 \nGFC EXECUTIVE COMMITTEE \nFor the Meeting of September 11, 2017 \nintegration into the activities of the university. \nCompliance with Legislation, \nPolicy and/or Procedure \nRelevant to the Proposal \n(please quote legislation and \ninclude identifying section \nnumbers) \n1. Post-Secondary Learning Act (PSLA): The PSLA gives GFC \nresponsibility, subject to the authority of the Board of Governors, over \nacademic affairs (Section 26(1)). Further, the PSLA gives the Board of \nGovernors authority over certain admission requirements and rules \nrespecting enrolment (Sections 60(1)(c) and (d)). The Board has \ndelegated its authority over admissions requirements and rules \nrespecting enrolment to GFC. GFC has thus established an Academic \nStandards Committee (GFC ASC).  \n2. GFC Academic Standards Committee (ASC) Terms of Reference: \n“B. Admission and Transfer, Academic Standing, Marking and Grading, \nTerm Work, Examinations, International Baccalaureate (IB), Advanced \nPlacement (AP) \niv. ASC provides advice or recommends to the GFC Academic Planning \nCommittee (APC) on proposals which involve substantial change to \nadmission/transfer regulations or to academic standing regulations. \nv. ASC provides advice or recommends to APC on general University \nadmission or  \n3. UAPPOL Admissions Policy: “Admission to the University of Alberta \nis based on documented academic criteria established by individual \nFaculties and approved by GFC. These criteria may be defined in areas \nsuch as subject requirements, minimum entrance averages, and \nlanguage proficiency requirements. In addition to academic requirements \nfor admission, GFC authorizes each Faculty to establish such other \nreasonable criteria for admission of applicants as the Faculty may \nconsider appropriate to its programs of study, subject to the approval of \nGFC (e.g. interview, audition, portfolio, etc.)  \nThe admission requirements for any Faculty will be those approved by \nGFC as set forth in the current edition of the University Calendar. In \naddition to the admission requirements, selection criteria for quota \nprograms, where they exist, will also be published in the current edition \nof the University Calendar. The responsibility for admission decisions will \nbe vested in the Faculty Admission Committees or in the Deans of the \nrespective Faculties, as the councils of such Faculties will determine.” \n4. UAPPOL Admissions Procedure:  \n“PROCEDURE EFFECTIVE DATE OF CHANGES TO ADMISSION \nREGULATIONS  \nFollowing approval by GFC:  \na. Where changes to admission regulations may disadvantage students \nin the current admission cycle, normally implementation will be effective \nafter the change has been published in the University Calendar for one \nfull year (i.e., effective the second year that the information is published \nin the University Calendar). For example, a change approved in May \n Item No. 11 \nGFC EXECUTIVE COMMITTEE \nFor the Meeting of September 11, 2017 \n2005 would be first published in the 2006-2007 University Calendar in \nMarch 2006. Therefore the statement cannot come into effect until \nSeptember 2007 (affecting applicants who apply for the September 2007 \nterm beginning July 2006).”  \nb. Where changes to admission regulations are deemed by the \napproving body to be ‘advantageous to students’, normally the date of \nimplementation will be effective immediately or at the next available \nintake for the admitting Faculty. \n5. GFC Academic Planning Committee Terms of Reference  \n“7. Admission, Transfer and Academic Standing \na. To consider advice or recommendation from the GFC ASC on \nproposals for the establishment of or change to general University \nadmission or transfer policies affecting students, including policies \naffecting Open Studies students, and to act for GFC in approving \npolicies which in APC’s view are minor or routine; and to \nrecommend to GFC on proposals involving major change \nb. To consider advice or recommendation from GFC ASC on \nproposals which involve substantial change to admission/transfer \nor to academic standing regulations.” \n6. GFC Executive Committee Terms of Reference \n“GFC has delegated to the Executive Committee the authority to decide \nwhich items are placed on a GFC Agenda, and the order in which those \nagenda items appear on each GFC agenda. […]  \nWhen recommendations are forwarded to General Faculties Council \nfrom APC, the role of the Executive shall be to decide the order in which \nitems should be considered by GFC. The Executive Committee is \nresponsible for providing general advice to the Chair about proposals \nbeing forwarded from APC to GFC.” \nAttachments  \n1. Attachment 1: Changes to the Undergraduate English Language Proficiency Requirements \nCase for Action (page(s) 1) \n2. Attachment 2: English Language Proficiency Requirements for U15 (page(s) 2-3)  \n3. Attachment 3: IELTS Band Score Group Analysis (page(s) 3-9) \n4. Attachment 4: Calendar Change Proposal 2018-19 (page(s) 12) \nPrepared by: Melissa Padfield, Deputy Registrar, melissa.padfield@ualberta.ca \nUniversity of Alberta Budget Model \nPrinciples \nThe university’s budget model outlines the mechanisms and processes for allocating/re-\nallocating resources to the Faculties and units in alignment with broad institutional priorities \nand with the university’s strategic plan. The model will help inform decisions enabling the \neffective use of resources and supporting the long-term sustainability of the university’s \nfinancial position. The following principles will guide and inform the development and \napplication of the university’s budget model. \na. Supremacy of academic priorities -- the university’s mission and academic priorities as \nset out in the university’s strategic plan are paramount in all decision making. The \nbudget model will facilitate the alignment of resources in support of the university core \nmandate of teaching and research. \nb. Transparency – the process for making resource allocation decisions is transparent and \nsources of institutional resources and comparative data are clearly identified and made \navailable  \nc. Accountability -- Faculty and unit leadership have the responsibility and authority to \nmake resource allocation decisions and are accountable for achieving performance \ntargets, including financial performance targets. \nd. Simplicity -- rules and processes are understandable and actionable \ne. Consistency -- rules are applied equitably across all Faculties and units. \nf. Predictability – long-term budget planning is facilitated. Changes to the model will \nrequire consultation among the stakeholders. \nAttachment 2: Increase to Required English Language Proficiency (ELP) Scores for Undergraduate Admissions \n3 \nEnglish Language Proficiency Requirements for the U15 \nAccurate as of May 8, 2017 \n(Only U15 institutions offering programs delivered in English as the primary languages of instruction have been included- Universite \nLaval and Universite de Montreal have been excluded) \nInstitution IELTS TOEFL(iBT) Notes \n Total Component Total Component  \nU of A (current) 6.5 5 86 21 Applicants to teaching and health sciences disciplines \nneed a further level of spoken English Proficiency. \nA minimum score of 7.5 on IELTS Speaking or 26 on \nTOEFL speaking. \nUBC 6.5 6 90 Listening: 22 \nSpeaking & \nWriting: 21 \nU of T 6.5 6 100 Writing: 22 Discretionary Range: total score 89~99 & 19~21 on \nWriting \nMcGill 6.5 6 90 21 Education & Management: TOEFL score of 100  \nMusic: TOEFL score of 79~80 \nU of C 6.5 N/A 86 N/A Nursing: IELTS 7.0 with no components below a 7.0; \nTOEFL: 92 with no components below 23 \nEducation: IELTS 8.0 with no components below a 7.0; \nTOEFL 100 with no components below 27 \nMcMaster 6.5 5 86 20  \nWaterloo 6.5 Writing: 6.5 \nSpeaking: 6.5 \n90 Writing: 25 \nSpeaking: 25 \nAttachment 2: Increase to Required English Language Proficiency (ELP) Scores for Undergraduate Admissions \n4 \nReading: 6.0 \nListening: 6.0 \nQueens University 6.5 N/A 88 Writing:24  \nSpeaking: 22 \nReading: 22 \nListening: 20 \nDalhousie \nUniversity \n6.5 6 90 20  \nUniversity of \nManitoba \n6.5 N/A 86 20  \nU of Saskatchewan 6.5 6 86 19  \nWestern 6.5 6 83 20  \nU Ottawa \n(Programs offered \nin English) \n6.5 Writing: 6.5 86 22  \nFIRST YEAR GRADE POINT AVERAGES AND COURSE WITHDRAWALS AMONG REGISTERED HIGH \nSCHOOL AND POST-SECONDARY TRANSFER APPLICANTS WHO MET ELP REQUIREMENT BY IELTS  \n1. DESCRIPTION OF DATA \nOver the academic years from 2010/12 to 2015/16, a total of 5,580 observed1 high school and post-\nsecondary transfer applicants who had submitted IELTS result as part of their application were admitted.  \nOf this, a total of 3,876 eventually registered. Of those who registered, 2,302 were registered in degree \nprograms while 1,574 registered in bridging program.  \nFigure 1: Six-Year Total Registration among observed  High School and Post -Secondary Transfer Applicants who \nsubmitted IELTS Scores for Admission (2010/11 – 2015/16) \nFigure 2 below shows the yearly breakdown of registration in degree and bridging program.  \nFigure 2: Yearly Registration among observed High School and Post –Secondary Transfer Applicants who submitted \nIELTS Scores for Admission  \n1 There are 6,149 applicants (471 registered) whose applicant type (high school, post secondary or internal transfer) could not \nbe observed. As this analysis is specific only to high school and post secondary applicants, applicants for which type could not \nbe observed were removed from consideration.   \n2,302 \n1,574 \n -\n 500\n 1,000\n 1,500\n 2,000\n 2,500\nRegistered in Degree Program Registered in Bridging Program\nP\ner\nso\nn\ns \n0\n200\n400\n600\n800\n1000\n2010/11 2011/12 2012/13 2013/14 2014/15 2015/16\n226 275\n376 436\n530 459121\n228\n302\n309\n315\n299\nRegistered in Bridging Program Registered in Degree Program\nOffice of the Registrar, February 29, 2016 \n2 \nThis report analyzes GPAs as well as course withdrawals within three defined groups drawn from among \nthe 2,302 persons who registerd in degree programs. Each group includes only persons with IELTS \noverall score of 6.5 or greater. In addition to meeting the overall score requirement, the following \nconditions applied to persons in specified group.  \nGroup 1: Band Score = 5.0 or greater in each IELTS band and at least one band score = 5.0 \nGroup 2: Band Score = 5.5 or greater in each IELTS band and at least one band score = 5.5 \nGroup 3: Band Score = 6.0 or greater in each IELTS band and at least one band score = 6.0 \nOf the 2,302 students registered in degreee programs, a total of 1,728 were caught by this grouping \ncriteria as shown in table 1.   \nTable 1: Number of Students  Identified in defined Groups by Academic Year.   \n Academic Year Group 1 Group 2 Group 3 \n2010/11  13 77 53 \n2011/12 26 105 84 \n2012/13 18 158 110 \n2013/14 23 147 145 \n2014/15 18 206 193 \n2015/16 25 180 147 \nTOTAL 123 873 732 \nComparison is made between each group with regards to; \nI. Fall and Winter GPA in the first year of study \nII. Proportion of persons in each group whose first year Fall and Winter GPA fall below 2.0 \nIII. Proportion of persons in each group who withdrew from at least one course during their first \nyear of study and \nIV. Average number of course withdrawals among those withdrawing.  \nOffice of the Registrar, February 29, 2016 \n3 \n2. ANALYSES \n2.1. FALL & WINTER GPAs \nFigure 3 shows yearly  averages of  first-year Fall and Winter GPAs of students in each group. As will be \nseen throughtout this report, 2013/2014 shows a remarkable variation in the yearly trends for students \nin Group 1. Therefore, aggregate statistics is presented in two parts - figure 4 presents the overall  GPAs \nin the 6 year aggregate data in panel  4a whereas the GPAs are reestimated in panel  4b without \n2013/2014 data.    \nFigure 3: Yearly Averages of First-Year Fall and Winter GPA2  \nFigure 4: Averages of First-Year Fall and Winter GPA from 2010/11 to 2015/2016 Data.   \n2 2015/16 GPA is based only on Fall term as Winter term is yet incomplete. GPAs for all other years cover both Fall \nand Winter terms.   \n2.20\n2.27 2.31\n1.89\n2.69 2.68\n2.73\n2.52\n2.53\n1.50\n1.70\n1.90\n2.10\n2.30\n2.50\n2.70\n2.90\n2010/11 2011/12 2012/13 2013/14 2014/15 2015/16\nGroup 1 Group 2 Group 3\n2.34\n2.62 2.61\n2.20\n2.30\n2.40\n2.50\n2.60\n2.70\nGroup 1 Group 2 Group 3\n4a) Including 2013/14\n2.45\n2.63 2.64\n2.30\n2.40\n2.50\n2.60\n2.70\nGroup 1 Group 2 Group 3\n4b) Excluding 2013/14 \nOffice of the Registrar, February 29, 2016 \n4 \n2.2. PROPORTION OF STUDENTS WITH FIRST YEAR FALL/ WINTER GPA OF LESS THAN 2.0 \nFigure 5 shows the proportions of students in each group whose first year Fall and Winter GPAs fell \nbelow 2.0. For instance in 2010/11 academic year, 5 of the 13 students in Group 1 - therefore 38% of \nGroup 1 - had GPAs falling below 2.0.  Also 12 of the 77 students in Group 2, - therefore 16% of Group 2 \nhad GPAs of less than 2.0 in 2010/11. Figures 6a and 6b shows the aggregate proportions with and \nwithout 2013/14 respectively.  \nFigure 5: Proportion of Students with first year GPA less than 2.0  \nFigure 6: Proportion of Students with first year GPA less than 2.0 from 2010/11 to 2015/16 Data \nTable 2: Number of Students with GPA less than 2.0 \nAcademic Year Group 1 Group 2 Group 3 \n2010/11  5 12 13 \n2011/12 9 19 12 \n2012/13 6 31 18 \n2013/14 11 32 36 \n2014/15 3 40 34 \n2015/16 3 38 26 \nTOTAL 37 172 139 \n38%\n35% 33%\n48%\n12%\n16%\n21%25%\n14%\n25%\n0%\n10%\n20%\n30%\n40%\n50%\n60%\n2010/11 2011/12 2012/13 2013/14 2014/15 2015/16\nGroup 1 Group 2 Group 3\n30%\n20% 19%\n0%\n10%\n20%\n30%\nGroup 1 Group 2 Group 3\n6a) Including 2013/14\n26%\n19% 18%\n0%\n10%\n20%\n30%\nGroup 1 Group 2 Group 3\n6b) Excluding 2013/14\nOffice of the Registrar, February 29, 2016 \n5 \nTable 3: GPA Sub-Categories among Students with GPAs less than 2.0 from 2010/11 to 2015/16 Data  \n  Group 1  Group 2 Group 3 Total \nGPA = 1.7 to 1.9 6 67 40 113 \nGPA = 1.1 to 1.6 21 48 43 112 \nGPA below 1.1 10 57 56 123 \nTotal 37 172 139 348 \n2.3 PROPORTION OF STUDENTS WHO WITHDREW FROM AT LEAST ONE COURSE IN FIRST YEAR \nFigure 7 shows the yearly proportion of students in each group who withdrew from at least one course \nduring their first year on the program. Figures 8a and 8b show the estimates from aggregated data.  \nFigure 7: Proportion of Students who Withdrew from at Least One Course During their First Year \nFigure 8: Proportion of Students who Withdrew from at Least One Course in their First Year from 2010/11 \nto 2015/16 Data \n38%\n15%\n33%\n57%\n22%\n4%\n32%\n21%\n32%\n18%\n0%\n10%\n20%\n30%\n40%\n50%\n60%\n2010/11 2011/12 2012/13 2013/14 2014/15 2015/16\nGroup 1 Group 2 Group 3\n27% 25% 26%\n0%\n10%\n20%\n30%\nGroup 1 Group 2 Group 3\n8a) Including 2013/14\n20%\n24% 25%\n0%\n10%\n20%\n30%\nGroup 1 Group 2 Group 3\n8b) Excluding 2013/14\nOffice of the Registrar, February 29, 2016 \n6 \nTable 4: Number of Students who Withdrew from at least One Course \n Group 1 Group 2 Group 3 \n2010/11  5 25 11 \n2011/12 4 25 20 \n2012/13 6 44 36 \n2013/14 13 44 46 \n2014/15 4 52 52 \n2015/16 1 30 27 \nTOTAL 33 220 192 \n2.4 AVERAGE NUMBER OF COURSE WITHDRAWALS AMONG THOSE WITHDRAWING  \nSome of the students withdrew from more than one course during their first year of study. Figure 9 \nshows the average number of courses withdrawn from among persons in each group who withdrew \nfrom at least one course. For instance, the figure shows that a Group 1 student who had at least one \ncourse withdrawal in 2012/13 withdrew from an average of 2 courses, whereas a Group 3 student with \nat least one withdrawal withdrew from an average of 1.42 courses.  Figures 10a and 10b shows the \ncorresponding averages in the aggregated data.   \nFigure 9: Average Number of Courses Withdrawn by those who withdrew from at least One Course in \ntheir First Year \nFigure 10: Average Number of Courses Withdrawn by those who withdrew from at least One Course in \ntheir First Year from 2010/11 to 2015/16 Data \n1.0 1.0\n2.0 2.0\n1.52\n1.18 1.42 1.28 1.33\n1.22\n0.0\n0.5\n1.0\n1.5\n2.0\n2.5\n2010/11 2011/12 2012/13 2013/14 2014/15 2015/16\nGroup 1 Group 2 Group 3\n1.64\n1.43 1.31\n0.00\n0.50\n1.00\n1.50\n2.00\nGroup 1 Group 2 Group 3\n10a) Including 2013/14\n1.40\n1.45\n1.32\n1.20\n1.30\n1.40\n1.50\nGroup 1 Group 2 Group 3\n10b) Excluding 2013/14\nOffice of the Registrar, February 29, 2016 \n7 \nAPPENDIX 1:  STUDENT DISTRIBUTION BY FACULTY  \nMajority of the students who submitted IELTS test scores and registered into degree programs were \nregistered in the faculties of ALES, Arts, Business, Engineering and Science. This following chart shows \nthe distribution of the sub sample of 1,728 students that were caught by the grouping criteria. 95% of \nthose in Group 1 were registered in one of the five faculties listed above. Likewise, 95% of those in \nGroup 2 as well as 93% of those in Group 3 were registered in one of the five faculties.  \nFigure A: Distribution of Students in Specified Groups by Faculty \n11%\n33%\n2%\n24%\n25%\n5%\n9%\n31%\n3%\n29%\n23%\n5%\n7%\n28%\n4%\n32%\n23%\n7%\n0%\n5%\n10%\n15%\n20%\n25%\n30%\n35%\nALES Arts Business Engineering Science Other\nGroup 1 Group 2 Group 3\nAttachment 4. Increase to Required English Language Proficiency (ELP) Scores for \nUndergraduate Admissions \n12 \nLink to Calendar section “Language Proficiency \nRequirements”: http://calendar.ualberta.ca/content.php?catoid=6&navoid=819#language_profici\nency_requirements \nCURRENT PROPOSED \nEnglish Language Proficiency \n... \n5. One of the two TOEFL (Test of English \nas a Foreign Language) test formats \nwith the appropriate score; \na. Internet-based TOEFL (iBT) of \nat least 86, with no less than 21 \non each band (see Note 4). \nb. Paper-based TOEFL of at least \n580 with a TWE of 4.0 or better \n(see Note 4). \n6. A score of at least 85 on the MELAB \n(Michigan English Assessment Battery) \n(see Note 4). \n7. A score of at least 6.5 on the IELTS \nAcademic (International English \nLanguage Testing System) with no band \nless than 5.0 (see Note 4). \n… \nEnglish Language Proficiency \n… \n5. One of the two TOEFL (Test of English \nas a Foreign Language) test formats \nwith the appropriate score; \na. Internet-based TOEFL (iBT) of \nat least 90, with no less than 21 \non each band (see Note 4). \nb. Paper-based TOEFL of at least \n580 with a TWE of 4.0 or better \n(see Note 4). \n6. A score of at least 85 on the MELAB \n(Michigan English Assessment Battery) \n(see Note 4). \n7. A score of at least 6.5 on the IELTS \nAcademic (International English \nLanguage Testing System) with no band \nless than 5.5 (see Note 4). \n… \nhttp://calendar.ualberta.ca/content.php?catoid=6&navoid=819#language_proficiency_requirements\nhttp://calendar.ualberta.ca/content.php?catoid=6&navoid=819#language_proficiency_requirements\nItem No. 12 \nGFC EXECUTIVE COMMITTEE \nFor the Meeting of September 11, 2017 \nOUTLINE OF ISSUE \nAction Item \nAgenda Title: Budget Model Principles \nMotion:  THAT General Faculties Council recommend  that the Board of Governors approve the budget \nmodel principles, as recommended by the GFC Academic Planning Committee, and as set forth in \nAttachment 1, to take effect upon final approval. \nItem   \nAction Requested Approval Recommendation    \nProposed by Provost and Vice-President (Academic), Vice-President (Finance and \nAdministration) \nPresenter Steven Dew, Provost and Vice-President (Academic)  \nDetails \nResponsibility Provost and Vice-President (Academic), Vice-President (Finance and \nAdministration) \nThe Purpose of the Proposal is \n(please be specific) \nTo recommend for approval by GFC the principles that will guide and \ninform the development and application of a new budget model for the \nUniversity of Alberta.  \nThe University’s budget model outlines the mechanisms and processes \nfor allocating/re-allocating resources to the Faculties and units in \nalignment with broad institutional priorities and with the University’s \nstrategic plan. The model will help inform decisions enabling the effective \nuse of resources and supporting the long-term sustainability of the \nUniversity’s financial position. \nThe Impact of the Proposal is The principles will guide the work of the technical working group and \nother stakeholders in the development and application of a new budget \nmodel for the University.  \nReplaces/Revises (eg, policies, \nresolutions) \nN/A \nTimeline/Implementation Date The new budget model is being developed over the 2017/18 fiscal year, \nand is expected to be implemented, at least partially, for the 2018/19 \nfiscal year.  \nEstimated Cost and funding \nsource \nN/A \nNext Steps (ie.: \nCommunications Plan, \nImplementation plans) \nThe technical working group will be primarily responsible for the near-\nterm work on the development of the new model, subject to input and \nfinal approval by senior administration.  The Provost and the Vice-\nPresident (Finance & Administration) are the Executive Sponsors for this \nproject.  \nSupplementary Notes and \ncontext \nEngagement and Routing (Include meeting dates) \nParticipation: \n(parties who have seen the \nThose who have been informed: \n•  \nItem No. 12 \nGFC EXECUTIVE COMMITTEE \nFor the Meeting of September 11, 2017 \nproposal and in what capacity) \n<For further information see \nthe link posted on \nthe Governance Toolkit section \nStudent Participation Protocol> \nThose who have been consulted: \n• Deans \n• Vice-Provosts \n• Associate Vice-Presidents  \nThose who are actively participating: \n• President’s Executive Committee  \n• Budget Model Technical Working Group  \nApproval Route (Governance) \n(including meeting dates) \nGFC Academic Planning Committee – June 14, 2017 \nGFC Executive Committee (for information) – September 11, 2017 \nGeneral Faculties Council – September 25, 2017 \nBoard Finance and Properties Committee – September 26, 2017 \nBoard of Governors – October 20, 2017 \nFinal Approver Board of Governors \nAlignment/Compliance \nAlignment with Guiding \nDocuments \nFor the Public Good: \nObjective 22: Secure and steward financial resources to sustain, \nenhance, promote, and facilitate the university’s core mission and \nstrategic goals.  \nStrategy ii: Ensure a sustainable budget model to preserve and \nenhance our core mission and reputation for excellence in \nteaching, learning, research, and community engagement.  \nCompliance with Legislation, \nPolicy and/or Procedure \nRelevant to the Proposal \n(please quote legislation and \ninclude identifying section \nnumbers) \n1. Post-Secondary Learning Act (PSLA) Section 26(1) states: \n“Subject to the authority of the board, a general faculties council is \nresponsible for the academic affairs of the university and, without \nrestricting the generality of the foregoing has the authority to \n[…] \n(o) make recommendations to the board with respect to affiliation \nwith other institutions, academic planning, campus planning, a \nbuilding program, the budget […] and any other matters considered \nby the general faculties council to be of interest to the university[.] \n[…]” \n2. GFC Academic Planning Committee Terms of Reference (Mandate) \n“The Academic Planning Committee (APC) is GFC's senior committee \ndealing with academic, financial and planning issues. […] \nAPC is responsible for making recommendations to GFC and/or to the \nBoard of Governors concerning policy matters and action matters with \nrespect to the following: […] \n4. Budget Matters \na. To recommend to GFC on budget principles. \n[…]” \n3. GFC Executive Committee Terms of Reference (3. Mandate of the \nCommittee) \n“5. Agendas of General Faculty Council \nGFC has delegated to the Executive Committee the authority to decide \nwhich items are placed on a GFC Agenda, and the order in which those \nagenda items appear on each GFC agenda.  \nhttp://www.governance.ualberta.ca/GovernanceToolkit/Toolkit.aspx\nhttp://www.governance.ualberta.ca/GovernanceToolkit/Toolkit.aspx\nItem No. 12 \nGFC EXECUTIVE COMMITTEE \nFor the Meeting of September 11, 2017 \nWhen ordering items, the GFC Executive Committee will be mindful of \nany matters that are of particular concern to students during March and \nApril so that the student leaders who bring those items forward are able \nto address these items at GFC before their terms end.” \nAttachments (each to be numbered 1 - <>) \n1.  Attachment 1: Budget Model Principles \nPrepared by: Kathleen Brough, Senior Administrative Officer, Office of the Provost and Vice-President \n(Academic) \nUniversity of Alberta Budget Model \nPrinciples \nThe university’s budget model outlines the mechanisms and processes for allocating/re-\nallocating resources to the Faculties and units in alignment with broad institutional priorities \nand with the university’s strategic plan. The model will help inform decisions enabling the \neffective use of resources and supporting the long-term sustainability of the university’s \nfinancial position. The following principles will guide and inform the development and \napplication of the university’s budget model. \na. Supremacy of academic priorities -- the university’s mission and academic priorities as \nset out in the university’s strategic plan are paramount in all decision making. The \nbudget model will facilitate the alignment of resources in support of the university core \nmandate of teaching and research. \nb. Transparency – the process for making resource allocation decisions is transparent and \nsources of institutional resources and comparative data are clearly identified and made \navailable  \nc. Accountability -- Faculty and unit leadership have the responsibility and authority to \nmake resource allocation decisions and are accountable for achieving performance \ntargets, including financial performance targets. \nd. Simplicity -- rules and processes are understandable and actionable \ne. Consistency -- rules are applied equitably across all Faculties and units. \nf. Predictability – long-term budget planning is facilitated. Changes to the model will \nrequire consultation among the stakeholders. \nItem No. 13 \nGFC EXECUTIVE COMMITTEE \nFor the Meeting of September 11, 2017 \nOUTLINE OF ISSUE \nAction Item \nAgenda Title: Draft Agenda for the September 25, 2017 Meeting of General Faculties Council (GFC) \nMotion:  THAT the GFC Executive Committee approve, under delegated authority from General Faculties \nCouncil, the Agenda for the September 25, 2017 meeting of General Faculties Council (GFC), as set forth in \nAttachment 1. \nItem   \nAction Requested Approval Recommendation   \nProposed by David Turpin, President and Chair, GFC Executive Committee \nPresenter David Turpin, President and Chair, GFC Executive Committee \nDetails \nResponsibility GFC Executive Committee \nThe Purpose of the Proposal is \n(please be specific) \nTo approve the Agenda for the GFC meeting to be held on Monday, \nSeptember 25, 2017. \nThe Impact of the Proposal is GFC is the legislative body at the University of Alberta dealing with \nacademic matters and student affairs issues; its composition and powers \nare defined in the Post-Secondary Learning Act (PSLA).  \nReplaces/Revises (eg, policies, \nresolutions) \nN/A \nTimeline/Implementation Date N/A \nEstimated Cost and funding \nsource \nN/A \nNext Steps (ie.: \nCommunications Plan, \nImplementation plans) \nN/A \nSupplementary Notes and \ncontext \nN/A \nEngagement and Routing (Include meeting dates) \nParticipation: \n(parties who have seen the \nproposal and in what capacity) \nDavid Turpin, President and Vice-Chancellor and Chair, GFC Executive \nCommittee; Office of the President; Office of the Provost and Vice-\nPresident (Academic); University Governance; GFC Executive \nCommittee  \nApproval Route (Governance) \n(including meeting dates) \nGFC Executive Committee – September 11, 2017 \nFinal Approver GFC Executive Committee  \nAlignment/Compliance \nAlignment with Guiding \nDocuments \nFor the Public Good,  Comprehensive Institutional Plan, Institutional \nvalues \nCompliance with Legislation, \nPolicy and/or Procedure \nRelevant to the Proposal \n1. Post-Secondary Learning Act (PSLA) \n“Powers of general faculties council \nItem No. 13 \nGFC EXECUTIVE COMMITTEE \nFor the Meeting of September 11, 2017 \n(please quote legislation and \ninclude identifying section \nnumbers) \n26(1) Subject to the authority of the board, a general faculties council is \nresponsible for the academic affairs of the university[…] \n(3) A general faculties council may delegate any of its powers, duties \nand functions under this Act, including the powers referred to in section \n31, as it sees fit and may prescribe conditions governing the exercise or \nperformance of any delegated power, duty or function, including the \npower of subdelegation.” \n2. GFC Executive Committee Terms of Reference \n“5. Agendas of General Faculties Council  \nGFC has delegated to the Executive Committee the authority to decide \nwhich items are placed on a GFC Agenda, and the order in which those \nagenda items appear on each GFC agenda.  \nWhen ordering items, the GFC Executive Committee will be mindful of \nany matters that are of particular concern to students during March and \nApril so that the student leaders who bring those items forward are able \nto address these items at GFC before their terms end. (EXEC 06 NOV \n2006)  \nWhen recommendations are forwarded to General Faculties Council \nfrom APC, the role of the Executive shall be to decide the order in which \nitems should be considered by GFC. The Executive Committee is \nresponsible for providing general advice to the Chair about proposals \nbeing forwarded from APC to GFC.  \nWith respect to recommendations from other bodies and other GFC \ncommittees, however, the role of the Executive Committee shall be to \nexamine and debate the substance of reports or recommendations and \nto decide if an item is ready to be forwarded to the full governing body.  \nThe Executive Committee may decide to refer a proposal back to the \noriginating body, to refer the proposal to another body or individual for \nstudy or review, or to take other action in order to ready a proposal for \nconsideration by General Faculties Council. When the GFC Executive \nCommittee forwards a proposal to GFC, it shall make a recommendation \nthat GFC endorse; endorse with suggested amendments; not endorse; \nor forward the proposal with no comment.” \nAttachments (each to be numbered 1 - <>) \n1. Attachment 1:  Draft Agenda for the General Faculties Council Meeting of September 25, 2017 \nPrepared by:  Meg Brolley, GFC Secretary and Manager of GFC Services, University Governance, meg.brolley@ualberta.ca   \nmailto:meg.brolley@ualberta.ca\nThis agenda and its corresponding attachments are transitory records. University Governance is the official copy holder for files of the Board of \nGovernors, GFC, and their standing committees. Members are instructed to destroy this material following the meeting. \nGENERAL FACULTIES COUNCIL \nOPEN SESSION AGENDA \nGreen. Gold. Governance. \nMonday, September 25, 2017 \nCouncil Chamber, 2-100 University Hall (UNH) \n2:00 PM - 4:00 PM \nOPENING SESSION                               \n1. Approval of the Agenda David Turpin \n2. Approval of the Minutes of June 5, 2017 David Turpin \n3. A. Indigenous Welcome \nB. Report from the President \nTBA \nDavid Turpin \n4. New Members of GFC  \n[Note: A motion to appoint may be proposed only by a statutory member of GFC. A \nmotion to receive may be proposed by any member of GFC.] \nMotion 1: To Appoint New Members \nMotion 2: To Receive New Members \nDavid Turpin \nDISCUSSION ITEMS \n5. A. Goals from the Students Union (SU) 2017-2018  \nB. Graduate Students' Association (GSA) Strategic Work Plan 2017-2018 \nMarina Banister  \nBabak Soltannia \n6. Senate Strategic Plan Douglas Stollery \n7. \nBudget Update \nGitta Kulczycki \nSteven Dew \nACTION ITEMS \n8. Proposed Changes to the University of Alberta Convocation Admission \nMotion: To Approve \nDouglas Stollery \n8. Proposed Increase to Required English Language Proficiency (ELP) Scores for \nUndergraduate Admission \nMotion: To Approve \nLisa Collins \n10\n. \nReport of the GFC Committee on the Learning Environment (CLE) on Teaching and \nLearning and Teaching Evaluation and the Use of Universal Student Ratings of \nInstruction (USRI) as an Evaluation Tool \nMotion: To Approve \nSarah Forgie \nNorma Nocente \n11. Budget Model Principles \nMotion: To Recommend Board of Governors Approval \nKulczycki \nGFC General Faculties Council 09/25/2017 \nPage 2 \n12 Faculty of Graduate Studies and Research: Proposed Revisions to existing \nSupervision and Examinations policy \nMotion: To Approve \nHeather Zwicker \n13 Proposed Faculty name change: Faculty of Kinesiology, Sport, and Recreation (from \nFaculty of Physical Education and Recreation) \nMotion: To Approve \nKerry Mummery \nDISCUSSION ITEMS  \n14 Question Period David Turpin \nINFORMATION REPORTS \n [If a GFC member has a question about a report, or feels that the report should be \ndiscussed by GFC, the GFC member should notify the Secretary to GFC, in writing, \ntwo business days or more before GFC meets so that the Committee Chair (or \nrelevant expert) can be invited to attend.] \n15 Report of the GFC Executive Committee (June 12, September 11, 2017)  \n16 Report of the GFC Academic Planning Committee (June 14, September 13, 2017)  \n17 Report of the GFC Academic Standards Committee (June 15, September 21, 2017)  \n18 Report of the GFC Nominating Committee (August 8, August 16, September 20, \n2016, Dean Selection Committees)  \n(The current list of membership vacancies may be viewed at: \nhttp://www.governance.ualberta.ca/GeneralFacultiesCouncil/NominatingCommittee/\nCommittee-Membership-Replenishment.aspx) \n19 Report of the GFC Replenishment Committee (June 26, 2017)  \n20 Report of the Board of Governors (June 23, 2017)  \n21 Information Forwarded to GFC Members Between Meetings \n22 Information Items (no items to date)  \nCLOSING SESSION  \n23 Adjournment \nMotion: To Adjourn \nMembers are invited to join Senators for a meet and greet reception in 2-210 Van Vliet Centre \nimmediately following the GFC meeting. \nDocumentation was before members unless otherwise noted. \nMeeting REGRETS to:   \nGFC General Faculties Council 09/25/2017 \nPage 3 \nPrepared by: Meg Brolley, GFC Secretary and Manager of GFC Operations, 780-492-4733, \nmeg.brolley@ualberta.ca \nUniversity Governance www.governance.ualberta.ca \nhttp://www.uofaweb.ualberta.ca/governance/\n\tItem-1-Agenda-EXE-SE11\n\tItem-4-Committee-Orientation\n\tItem-4-Committee-Orientation-OI\n\tAtt 1 - Principles for Delegation of Authority\n\tAtt 2 - Principles of Committee Composition\n\tAtt 3 - Roles and Responsibilities of Members\n\tAtt 4 - Meeting Procedural Rules\n\tExecutive-Committee-ToR\n\tItem-5A-SU-Goals-for-17-18\n\tItem-5A-SU-Goals-OI\n\tItem-5A-Att-1-Su exec goals\n\tItem-5B-GSA-Goals-17-18\n\tItem-5B-GSA-Goals-OI\n\tGSA Report - 2017-2018 \n\tItem-7-Convocation-Admission\n\tItem-7-Convocation-Admission-OI\n\t2017 Convocation ADMISSION\n\tItem-8-CLE-Report-on-USRIs-Teaching-Evaluation\n\tItem-8-USRI-Report\n\tRecommendations\n\tSummary Report\n\tAppendix A - Table of Reviewed Literature\n\tAppendix B - Summary of Interviews with Department Chairs\n\tAppendix C - Interview Questions\n\tAppendix D - Sample USRI Case Studies\n\tAppendix E - Summary of  Positions and Recommedations  RE USRIs in UAlberta Policy-Documents-Reports\n\tAppendix F - Summary of Positions and Recommendations RE Multifaceted Evaluation in UAlberta Policy-Documents-Reports\n\tAppendix G - References for Reviewed Literature\n\tAppendix H - Abstracts for Reviewed Literature\n\tAppendix I - Rec Re Evaluation of Teaching from 2013 Renaissance Ctte Report\n\tItem-9-FGSR-Supervision-Examination\n\tItem-9-FGSR-Supervision-Examination\n\tItem-9-ATT1\n\tItem-10-Faculty-name-change-Phys-Ed\n\tFPER proposed name change\n\tFPER Attachments\n\tFaculty Name Change Process\n\tCombined List of Support Letters\n\tLetters of Support_One\n\tLetters of Support_Two\n\tLetters of Support_Three\n\tLetters of Support_Four\n\tNSSS_Letter of support\n\tOtago Email Support\n\tLetter from Chair, PVC Committee\n\tItem-11-ELP-requirements\n\tItem-11-Increased-ELP-Scores-OI\n\tItem-5-Budget-Model-Principles-ATT1-REV\n\tItem-4-Increased-ELP-Scores-ATT2\n\tItem-4-Increased-ELP-Scores-ATT3\n\tItem-4-Increased-ELP-Scores-ATT4\n\tEnglish Language Proficiency\n\tEnglish Language Proficiency\n\tItem-12-Budget-Model-Principles\n\tItem-12-Budget-Model-Principles-OI\n\tUAlberta Budget Model Principles as amended by APC on Jun 14\n\tItem-13-Draft-GFC-Agenda\n\t13-OI-GFC-Agenda\n\tDraft-Agenda-GFC-SE25\n",
    "collection title": "EXEC"
}